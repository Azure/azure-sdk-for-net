// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.

// <auto-generated/>

#nullable disable

using System;
using System.Collections.Generic;
using Azure.Core;

namespace Azure.ResourceManager.DataFactory.Models
{
    /// <summary>
    /// Azure Databricks linked service.
    /// Serialized Name: AzureDatabricksLinkedService
    /// </summary>
    public partial class AzureDatabricksLinkedService : FactoryLinkedServiceDefinition
    {
        /// <summary> Initializes a new instance of AzureDatabricksLinkedService. </summary>
        /// <param name="domain">
        /// &lt;REGION&gt;.azuredatabricks.net, domain name of your Databricks deployment. Type: string (or Expression with resultType string).
        /// Serialized Name: AzureDatabricksLinkedService.typeProperties.domain
        /// </param>
        /// <exception cref="ArgumentNullException"> <paramref name="domain"/> is null. </exception>
        public AzureDatabricksLinkedService(BinaryData domain)
        {
            if (domain == null)
            {
                throw new ArgumentNullException(nameof(domain));
            }

            Domain = domain;
            NewClusterSparkConf = new ChangeTrackingDictionary<string, BinaryData>();
            NewClusterSparkEnvVars = new ChangeTrackingDictionary<string, BinaryData>();
            NewClusterCustomTags = new ChangeTrackingDictionary<string, BinaryData>();
            LinkedServiceType = "AzureDatabricks";
        }

        /// <summary> Initializes a new instance of AzureDatabricksLinkedService. </summary>
        /// <param name="linkedServiceType">
        /// Type of linked service.
        /// Serialized Name: LinkedService.type
        /// </param>
        /// <param name="connectVia">
        /// The integration runtime reference.
        /// Serialized Name: LinkedService.connectVia
        /// </param>
        /// <param name="description">
        /// Linked service description.
        /// Serialized Name: LinkedService.description
        /// </param>
        /// <param name="parameters">
        /// Parameters for linked service.
        /// Serialized Name: LinkedService.parameters
        /// </param>
        /// <param name="annotations">
        /// List of tags that can be used for describing the linked service.
        /// Serialized Name: LinkedService.annotations
        /// </param>
        /// <param name="additionalProperties"> Additional Properties. </param>
        /// <param name="domain">
        /// &lt;REGION&gt;.azuredatabricks.net, domain name of your Databricks deployment. Type: string (or Expression with resultType string).
        /// Serialized Name: AzureDatabricksLinkedService.typeProperties.domain
        /// </param>
        /// <param name="accessToken">
        /// Access token for databricks REST API. Refer to https://docs.azuredatabricks.net/api/latest/authentication.html. Type: string (or Expression with resultType string).
        /// Serialized Name: AzureDatabricksLinkedService.typeProperties.accessToken
        /// Please note <see cref="FactorySecretBaseDefinition"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="FactorySecretString"/> and <see cref="AzureKeyVaultSecretReference"/>.
        /// </param>
        /// <param name="authentication">
        /// Required to specify MSI, if using Workspace resource id for databricks REST API. Type: string (or Expression with resultType string).
        /// Serialized Name: AzureDatabricksLinkedService.typeProperties.authentication
        /// </param>
        /// <param name="workspaceResourceId">
        /// Workspace resource id for databricks REST API. Type: string (or Expression with resultType string).
        /// Serialized Name: AzureDatabricksLinkedService.typeProperties.workspaceResourceId
        /// </param>
        /// <param name="existingClusterId">
        /// The id of an existing interactive cluster that will be used for all runs of this activity. Type: string (or Expression with resultType string).
        /// Serialized Name: AzureDatabricksLinkedService.typeProperties.existingClusterId
        /// </param>
        /// <param name="instancePoolId">
        /// The id of an existing instance pool that will be used for all runs of this activity. Type: string (or Expression with resultType string).
        /// Serialized Name: AzureDatabricksLinkedService.typeProperties.instancePoolId
        /// </param>
        /// <param name="newClusterVersion">
        /// If not using an existing interactive cluster, this specifies the Spark version of a new job cluster or instance pool nodes created for each run of this activity. Required if instancePoolId is specified. Type: string (or Expression with resultType string).
        /// Serialized Name: AzureDatabricksLinkedService.typeProperties.newClusterVersion
        /// </param>
        /// <param name="newClusterNumOfWorker">
        /// If not using an existing interactive cluster, this specifies the number of worker nodes to use for the new job cluster or instance pool. For new job clusters, this a string-formatted Int32, like &apos;1&apos; means numOfWorker is 1 or &apos;1:10&apos; means auto-scale from 1 (min) to 10 (max). For instance pools, this is a string-formatted Int32, and can only specify a fixed number of worker nodes, such as &apos;2&apos;. Required if newClusterVersion is specified. Type: string (or Expression with resultType string).
        /// Serialized Name: AzureDatabricksLinkedService.typeProperties.newClusterNumOfWorker
        /// </param>
        /// <param name="newClusterNodeType">
        /// The node type of the new job cluster. This property is required if newClusterVersion is specified and instancePoolId is not specified. If instancePoolId is specified, this property is ignored. Type: string (or Expression with resultType string).
        /// Serialized Name: AzureDatabricksLinkedService.typeProperties.newClusterNodeType
        /// </param>
        /// <param name="newClusterSparkConf">
        /// A set of optional, user-specified Spark configuration key-value pairs.
        /// Serialized Name: AzureDatabricksLinkedService.typeProperties.newClusterSparkConf
        /// </param>
        /// <param name="newClusterSparkEnvVars">
        /// A set of optional, user-specified Spark environment variables key-value pairs.
        /// Serialized Name: AzureDatabricksLinkedService.typeProperties.newClusterSparkEnvVars
        /// </param>
        /// <param name="newClusterCustomTags">
        /// Additional tags for cluster resources. This property is ignored in instance pool configurations.
        /// Serialized Name: AzureDatabricksLinkedService.typeProperties.newClusterCustomTags
        /// </param>
        /// <param name="newClusterLogDestination">
        /// Specify a location to deliver Spark driver, worker, and event logs. Type: string (or Expression with resultType string).
        /// Serialized Name: AzureDatabricksLinkedService.typeProperties.newClusterLogDestination
        /// </param>
        /// <param name="newClusterDriverNodeType">
        /// The driver node type for the new job cluster. This property is ignored in instance pool configurations. Type: string (or Expression with resultType string).
        /// Serialized Name: AzureDatabricksLinkedService.typeProperties.newClusterDriverNodeType
        /// </param>
        /// <param name="newClusterInitScripts">
        /// User-defined initialization scripts for the new cluster. Type: array of strings (or Expression with resultType array of strings).
        /// Serialized Name: AzureDatabricksLinkedService.typeProperties.newClusterInitScripts
        /// </param>
        /// <param name="newClusterEnableElasticDisk">
        /// Enable the elastic disk on the new cluster. This property is now ignored, and takes the default elastic disk behavior in Databricks (elastic disks are always enabled). Type: boolean (or Expression with resultType boolean).
        /// Serialized Name: AzureDatabricksLinkedService.typeProperties.newClusterEnableElasticDisk
        /// </param>
        /// <param name="encryptedCredential">
        /// The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).
        /// Serialized Name: AzureDatabricksLinkedService.typeProperties.encryptedCredential
        /// </param>
        /// <param name="policyId">
        /// The policy id for limiting the ability to configure clusters based on a user defined set of rules. Type: string (or Expression with resultType string).
        /// Serialized Name: AzureDatabricksLinkedService.typeProperties.policyId
        /// </param>
        /// <param name="credential">
        /// The credential reference containing authentication information.
        /// Serialized Name: AzureDatabricksLinkedService.typeProperties.credential
        /// </param>
        internal AzureDatabricksLinkedService(string linkedServiceType, IntegrationRuntimeReference connectVia, string description, IDictionary<string, EntityParameterSpecification> parameters, IList<BinaryData> annotations, IDictionary<string, BinaryData> additionalProperties, BinaryData domain, FactorySecretBaseDefinition accessToken, BinaryData authentication, BinaryData workspaceResourceId, BinaryData existingClusterId, BinaryData instancePoolId, BinaryData newClusterVersion, BinaryData newClusterNumOfWorker, BinaryData newClusterNodeType, IDictionary<string, BinaryData> newClusterSparkConf, IDictionary<string, BinaryData> newClusterSparkEnvVars, IDictionary<string, BinaryData> newClusterCustomTags, BinaryData newClusterLogDestination, BinaryData newClusterDriverNodeType, BinaryData newClusterInitScripts, BinaryData newClusterEnableElasticDisk, BinaryData encryptedCredential, BinaryData policyId, FactoryCredentialReference credential) : base(linkedServiceType, connectVia, description, parameters, annotations, additionalProperties)
        {
            Domain = domain;
            AccessToken = accessToken;
            Authentication = authentication;
            WorkspaceResourceId = workspaceResourceId;
            ExistingClusterId = existingClusterId;
            InstancePoolId = instancePoolId;
            NewClusterVersion = newClusterVersion;
            NewClusterNumOfWorker = newClusterNumOfWorker;
            NewClusterNodeType = newClusterNodeType;
            NewClusterSparkConf = newClusterSparkConf;
            NewClusterSparkEnvVars = newClusterSparkEnvVars;
            NewClusterCustomTags = newClusterCustomTags;
            NewClusterLogDestination = newClusterLogDestination;
            NewClusterDriverNodeType = newClusterDriverNodeType;
            NewClusterInitScripts = newClusterInitScripts;
            NewClusterEnableElasticDisk = newClusterEnableElasticDisk;
            EncryptedCredential = encryptedCredential;
            PolicyId = policyId;
            Credential = credential;
            LinkedServiceType = linkedServiceType ?? "AzureDatabricks";
        }

        /// <summary>
        /// &lt;REGION&gt;.azuredatabricks.net, domain name of your Databricks deployment. Type: string (or Expression with resultType string).
        /// Serialized Name: AzureDatabricksLinkedService.typeProperties.domain
        /// </summary>
        public BinaryData Domain { get; set; }
        /// <summary>
        /// Access token for databricks REST API. Refer to https://docs.azuredatabricks.net/api/latest/authentication.html. Type: string (or Expression with resultType string).
        /// Serialized Name: AzureDatabricksLinkedService.typeProperties.accessToken
        /// Please note <see cref="FactorySecretBaseDefinition"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="FactorySecretString"/> and <see cref="AzureKeyVaultSecretReference"/>.
        /// </summary>
        public FactorySecretBaseDefinition AccessToken { get; set; }
        /// <summary>
        /// Required to specify MSI, if using Workspace resource id for databricks REST API. Type: string (or Expression with resultType string).
        /// Serialized Name: AzureDatabricksLinkedService.typeProperties.authentication
        /// </summary>
        public BinaryData Authentication { get; set; }
        /// <summary>
        /// Workspace resource id for databricks REST API. Type: string (or Expression with resultType string).
        /// Serialized Name: AzureDatabricksLinkedService.typeProperties.workspaceResourceId
        /// </summary>
        public BinaryData WorkspaceResourceId { get; set; }
        /// <summary>
        /// The id of an existing interactive cluster that will be used for all runs of this activity. Type: string (or Expression with resultType string).
        /// Serialized Name: AzureDatabricksLinkedService.typeProperties.existingClusterId
        /// </summary>
        public BinaryData ExistingClusterId { get; set; }
        /// <summary>
        /// The id of an existing instance pool that will be used for all runs of this activity. Type: string (or Expression with resultType string).
        /// Serialized Name: AzureDatabricksLinkedService.typeProperties.instancePoolId
        /// </summary>
        public BinaryData InstancePoolId { get; set; }
        /// <summary>
        /// If not using an existing interactive cluster, this specifies the Spark version of a new job cluster or instance pool nodes created for each run of this activity. Required if instancePoolId is specified. Type: string (or Expression with resultType string).
        /// Serialized Name: AzureDatabricksLinkedService.typeProperties.newClusterVersion
        /// </summary>
        public BinaryData NewClusterVersion { get; set; }
        /// <summary>
        /// If not using an existing interactive cluster, this specifies the number of worker nodes to use for the new job cluster or instance pool. For new job clusters, this a string-formatted Int32, like &apos;1&apos; means numOfWorker is 1 or &apos;1:10&apos; means auto-scale from 1 (min) to 10 (max). For instance pools, this is a string-formatted Int32, and can only specify a fixed number of worker nodes, such as &apos;2&apos;. Required if newClusterVersion is specified. Type: string (or Expression with resultType string).
        /// Serialized Name: AzureDatabricksLinkedService.typeProperties.newClusterNumOfWorker
        /// </summary>
        public BinaryData NewClusterNumOfWorker { get; set; }
        /// <summary>
        /// The node type of the new job cluster. This property is required if newClusterVersion is specified and instancePoolId is not specified. If instancePoolId is specified, this property is ignored. Type: string (or Expression with resultType string).
        /// Serialized Name: AzureDatabricksLinkedService.typeProperties.newClusterNodeType
        /// </summary>
        public BinaryData NewClusterNodeType { get; set; }
        /// <summary>
        /// A set of optional, user-specified Spark configuration key-value pairs.
        /// Serialized Name: AzureDatabricksLinkedService.typeProperties.newClusterSparkConf
        /// </summary>
        public IDictionary<string, BinaryData> NewClusterSparkConf { get; }
        /// <summary>
        /// A set of optional, user-specified Spark environment variables key-value pairs.
        /// Serialized Name: AzureDatabricksLinkedService.typeProperties.newClusterSparkEnvVars
        /// </summary>
        public IDictionary<string, BinaryData> NewClusterSparkEnvVars { get; }
        /// <summary>
        /// Additional tags for cluster resources. This property is ignored in instance pool configurations.
        /// Serialized Name: AzureDatabricksLinkedService.typeProperties.newClusterCustomTags
        /// </summary>
        public IDictionary<string, BinaryData> NewClusterCustomTags { get; }
        /// <summary>
        /// Specify a location to deliver Spark driver, worker, and event logs. Type: string (or Expression with resultType string).
        /// Serialized Name: AzureDatabricksLinkedService.typeProperties.newClusterLogDestination
        /// </summary>
        public BinaryData NewClusterLogDestination { get; set; }
        /// <summary>
        /// The driver node type for the new job cluster. This property is ignored in instance pool configurations. Type: string (or Expression with resultType string).
        /// Serialized Name: AzureDatabricksLinkedService.typeProperties.newClusterDriverNodeType
        /// </summary>
        public BinaryData NewClusterDriverNodeType { get; set; }
        /// <summary>
        /// User-defined initialization scripts for the new cluster. Type: array of strings (or Expression with resultType array of strings).
        /// Serialized Name: AzureDatabricksLinkedService.typeProperties.newClusterInitScripts
        /// </summary>
        public BinaryData NewClusterInitScripts { get; set; }
        /// <summary>
        /// Enable the elastic disk on the new cluster. This property is now ignored, and takes the default elastic disk behavior in Databricks (elastic disks are always enabled). Type: boolean (or Expression with resultType boolean).
        /// Serialized Name: AzureDatabricksLinkedService.typeProperties.newClusterEnableElasticDisk
        /// </summary>
        public BinaryData NewClusterEnableElasticDisk { get; set; }
        /// <summary>
        /// The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).
        /// Serialized Name: AzureDatabricksLinkedService.typeProperties.encryptedCredential
        /// </summary>
        public BinaryData EncryptedCredential { get; set; }
        /// <summary>
        /// The policy id for limiting the ability to configure clusters based on a user defined set of rules. Type: string (or Expression with resultType string).
        /// Serialized Name: AzureDatabricksLinkedService.typeProperties.policyId
        /// </summary>
        public BinaryData PolicyId { get; set; }
        /// <summary>
        /// The credential reference containing authentication information.
        /// Serialized Name: AzureDatabricksLinkedService.typeProperties.credential
        /// </summary>
        public FactoryCredentialReference Credential { get; set; }
    }
}

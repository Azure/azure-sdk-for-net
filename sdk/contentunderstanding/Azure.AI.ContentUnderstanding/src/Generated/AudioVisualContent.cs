// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.

// <auto-generated/>

#nullable disable

using System;
using System.Collections.Generic;

namespace Azure.AI.ContentUnderstanding
{
    /// <summary> Audio visual content.  Ex. audio/wav, video/mp4. </summary>
    public partial class AudioVisualContent : MediaContent
    {
        /// <summary> Initializes a new instance of <see cref="AudioVisualContent"/>. </summary>
        /// <param name="startTimeMs"> Start time of the content in milliseconds. </param>
        /// <param name="endTimeMs"> End time of the content in milliseconds. </param>
        internal AudioVisualContent(long startTimeMs, long endTimeMs) : base(MediaContentKind.AudioVisual)
        {
            StartTimeMs = startTimeMs;
            EndTimeMs = endTimeMs;
            CameraShotTimesMs = new ChangeTrackingList<long>();
            KeyFrameTimesMs = new ChangeTrackingList<long>();
            TranscriptPhrases = new ChangeTrackingList<TranscriptPhrase>();
            Persons = new ChangeTrackingList<DetectedPerson>();
            Segments = new ChangeTrackingList<AudioVisualSegment>();
        }

        /// <summary> Initializes a new instance of <see cref="AudioVisualContent"/>. </summary>
        /// <param name="kind"> Content kind. </param>
        /// <param name="mimeType"> Detected MIME type of the content.  Ex. application/pdf, image/jpeg, etc. </param>
        /// <param name="category"> Classified content category. </param>
        /// <param name="path"> The path of the content in the input. </param>
        /// <param name="markdown"> Markdown representation of the content. </param>
        /// <param name="fields"> Extracted fields from the content. </param>
        /// <param name="additionalBinaryDataProperties"> Keeps track of any properties unknown to the library. </param>
        /// <param name="startTimeMs"> Start time of the content in milliseconds. </param>
        /// <param name="endTimeMs"> End time of the content in milliseconds. </param>
        /// <param name="width"> Width of each video frame in pixels, if applicable. </param>
        /// <param name="height"> Height of each video frame in pixels, if applicable. </param>
        /// <param name="cameraShotTimesMs"> List of camera shot changes in the video, represented by its timestamp in milliseconds.  Only if returnDetails is true. </param>
        /// <param name="keyFrameTimesMs"> List of key frames in the video, represented by its timestamp in milliseconds.  Only if returnDetails is true. </param>
        /// <param name="transcriptPhrases"> List of transcript phrases.  Only if returnDetails is true. </param>
        /// <param name="persons"> List of detected persons in the video.  Only if enableFace and returnDetails are true. </param>
        /// <param name="segments"> List of audio visual segments.  Only if enableSegmentation and returnDetails are true. </param>
        internal AudioVisualContent(MediaContentKind kind, string mimeType, string category, Uri path, string markdown, IDictionary<string, ContentField> fields, IDictionary<string, BinaryData> additionalBinaryDataProperties, long startTimeMs, long endTimeMs, int? width, int? height, IList<long> cameraShotTimesMs, IList<long> keyFrameTimesMs, IList<TranscriptPhrase> transcriptPhrases, IList<DetectedPerson> persons, IList<AudioVisualSegment> segments) : base(kind, mimeType, category, path, markdown, fields, additionalBinaryDataProperties)
        {
            StartTimeMs = startTimeMs;
            EndTimeMs = endTimeMs;
            Width = width;
            Height = height;
            CameraShotTimesMs = cameraShotTimesMs;
            KeyFrameTimesMs = keyFrameTimesMs;
            TranscriptPhrases = transcriptPhrases;
            Persons = persons;
            Segments = segments;
        }

        /// <summary> Start time of the content in milliseconds. </summary>
        public long StartTimeMs { get; }

        /// <summary> End time of the content in milliseconds. </summary>
        public long EndTimeMs { get; }

        /// <summary> Width of each video frame in pixels, if applicable. </summary>
        public int? Width { get; }

        /// <summary> Height of each video frame in pixels, if applicable. </summary>
        public int? Height { get; }

        /// <summary> List of camera shot changes in the video, represented by its timestamp in milliseconds.  Only if returnDetails is true. </summary>
        public IList<long> CameraShotTimesMs { get; }

        /// <summary> List of key frames in the video, represented by its timestamp in milliseconds.  Only if returnDetails is true. </summary>
        [System.Text.Json.Serialization.JsonPropertyName("KeyFrameTimesMs")]
        public IList<long> KeyFrameTimesMs { get; }

        /// <summary> List of transcript phrases.  Only if returnDetails is true. </summary>
        public IList<TranscriptPhrase> TranscriptPhrases { get; }

        /// <summary> List of detected persons in the video.  Only if enableFace and returnDetails are true. </summary>
        public IList<DetectedPerson> Persons { get; }

        /// <summary> List of audio visual segments.  Only if enableSegmentation and returnDetails are true. </summary>
        public IList<AudioVisualSegment> Segments { get; }
    }
}

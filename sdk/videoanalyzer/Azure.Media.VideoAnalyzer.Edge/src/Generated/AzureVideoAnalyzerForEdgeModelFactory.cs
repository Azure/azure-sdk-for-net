// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.

// <auto-generated/>

#nullable disable

using System;
using System.Collections.Generic;
using System.Linq;

namespace Azure.Media.VideoAnalyzer.Edge.Models
{
    /// <summary> Model factory for generated models. </summary>
    public static partial class AzureVideoAnalyzerForEdgeModelFactory
    {
        /// <summary> Initializes a new instance of LivePipeline. </summary>
        /// <param name="name"> Live pipeline unique identifier. </param>
        /// <param name="systemData"> Read-only system metadata associated with this object. </param>
        /// <param name="properties"> Live pipeline properties. </param>
        /// <returns> A new <see cref="Models.LivePipeline"/> instance for mocking. </returns>
        public static LivePipeline LivePipeline(string name = null, SystemData systemData = null, LivePipelineProperties properties = null)
        {
            return new LivePipeline(name, systemData, properties);
        }

        /// <summary> Initializes a new instance of SystemData. </summary>
        /// <param name="createdAt"> Date and time when this resource was first created. Value is represented in UTC according to the ISO8601 date format. </param>
        /// <param name="lastModifiedAt"> Date and time when this resource was last modified. Value is represented in UTC according to the ISO8601 date format. </param>
        /// <returns> A new <see cref="Models.SystemData"/> instance for mocking. </returns>
        public static SystemData SystemData(DateTimeOffset? createdAt = null, DateTimeOffset? lastModifiedAt = null)
        {
            return new SystemData(createdAt, lastModifiedAt);
        }

        /// <summary> Initializes a new instance of LivePipelineProperties. </summary>
        /// <param name="description"> An optional description of the live pipeline. </param>
        /// <param name="topologyName"> The reference to an existing pipeline topology defined for real-time content processing. When activated, this live pipeline will process content according to the pipeline topology definition. </param>
        /// <param name="parameters"> List of the instance level parameter values for the user-defined topology parameters. A pipeline can only define or override parameters values for parameters which have been declared in the referenced topology. Topology parameters without a default value must be defined. Topology parameters with a default value can be optionally be overridden. </param>
        /// <param name="state"> Current pipeline state (read-only). </param>
        /// <returns> A new <see cref="Models.LivePipelineProperties"/> instance for mocking. </returns>
        public static LivePipelineProperties LivePipelineProperties(string description = null, string topologyName = null, IEnumerable<ParameterDefinition> parameters = null, LivePipelineState? state = null)
        {
            parameters ??= new List<ParameterDefinition>();

            return new LivePipelineProperties(description, topologyName, parameters?.ToList(), state);
        }

        /// <summary> Initializes a new instance of ParameterDefinition. </summary>
        /// <param name="name"> Name of the parameter declared in the pipeline topology. </param>
        /// <param name="value"> Parameter value to be applied on this specific live pipeline. </param>
        /// <returns> A new <see cref="Models.ParameterDefinition"/> instance for mocking. </returns>
        public static ParameterDefinition ParameterDefinition(string name = null, string value = null)
        {
            return new ParameterDefinition(name, value);
        }

        /// <summary> Initializes a new instance of LivePipelineCollection. </summary>
        /// <param name="value"> List of live pipelines. </param>
        /// <param name="continuationToken"> A continuation token to be used in subsequent calls when enumerating through the collection. This is returned when the collection results won&apos;t fit in a single response. </param>
        /// <returns> A new <see cref="Models.LivePipelineCollection"/> instance for mocking. </returns>
        public static LivePipelineCollection LivePipelineCollection(IEnumerable<LivePipeline> value = null, string continuationToken = null)
        {
            value ??= new List<LivePipeline>();

            return new LivePipelineCollection(value?.ToList(), continuationToken);
        }

        /// <summary> Initializes a new instance of PipelineTopologyCollection. </summary>
        /// <param name="value"> List of pipeline topologies. </param>
        /// <param name="continuationToken"> A continuation token to be used in subsequent calls when enumerating through the collection. This is returned when the collection results won&apos;t fit in a single response. </param>
        /// <returns> A new <see cref="Models.PipelineTopologyCollection"/> instance for mocking. </returns>
        public static PipelineTopologyCollection PipelineTopologyCollection(IEnumerable<PipelineTopology> value = null, string continuationToken = null)
        {
            value ??= new List<PipelineTopology>();

            return new PipelineTopologyCollection(value?.ToList(), continuationToken);
        }

        /// <summary> Initializes a new instance of PipelineTopology. </summary>
        /// <param name="name"> Pipeline topology unique identifier. </param>
        /// <param name="systemData"> Read-only system metadata associated with this object. </param>
        /// <param name="properties"> Pipeline topology properties. </param>
        /// <returns> A new <see cref="Models.PipelineTopology"/> instance for mocking. </returns>
        public static PipelineTopology PipelineTopology(string name = null, SystemData systemData = null, PipelineTopologyProperties properties = null)
        {
            return new PipelineTopology(name, systemData, properties);
        }

        /// <summary> Initializes a new instance of PipelineTopologyProperties. </summary>
        /// <param name="description"> An optional description of the pipeline topology. It is recommended that the expected use of the topology to be described here. </param>
        /// <param name="parameters"> List of the topology parameter declarations. Parameters declared here can be referenced throughout the topology nodes through the use of &quot;${PARAMETER_NAME}&quot; string pattern. Parameters can have optional default values and can later be defined in individual instances of the pipeline. </param>
        /// <param name="sources">
        /// List of the topology source nodes. Source nodes enable external data to be ingested by the pipeline.
        /// Please note <see cref="SourceNodeBase"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="IotHubMessageSource"/> and <see cref="RtspSource"/>.
        /// </param>
        /// <param name="processors">
        /// List of the topology processor nodes. Processor nodes enable pipeline data to be analyzed, processed or transformed.
        /// Please note <see cref="ProcessorNodeBase"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="CognitiveServicesVisionProcessor"/>, <see cref="ExtensionProcessorBase"/>, <see cref="GrpcExtension"/>, <see cref="HttpExtension"/>, <see cref="LineCrossingProcessor"/>, <see cref="MotionDetectionProcessor"/>, <see cref="ObjectTrackingProcessor"/> and <see cref="SignalGateProcessor"/>.
        /// </param>
        /// <param name="sinks">
        /// List of the topology sink nodes. Sink nodes allow pipeline data to be stored or exported.
        /// Please note <see cref="SinkNodeBase"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="FileSink"/>, <see cref="IotHubMessageSink"/> and <see cref="VideoSink"/>.
        /// </param>
        /// <returns> A new <see cref="Models.PipelineTopologyProperties"/> instance for mocking. </returns>
        public static PipelineTopologyProperties PipelineTopologyProperties(string description = null, IEnumerable<ParameterDeclaration> parameters = null, IEnumerable<SourceNodeBase> sources = null, IEnumerable<ProcessorNodeBase> processors = null, IEnumerable<SinkNodeBase> sinks = null)
        {
            parameters ??= new List<ParameterDeclaration>();
            sources ??= new List<SourceNodeBase>();
            processors ??= new List<ProcessorNodeBase>();
            sinks ??= new List<SinkNodeBase>();

            return new PipelineTopologyProperties(description, parameters?.ToList(), sources?.ToList(), processors?.ToList(), sinks?.ToList());
        }

        /// <summary> Initializes a new instance of ParameterDeclaration. </summary>
        /// <param name="name"> Name of the parameter. </param>
        /// <param name="type"> Type of the parameter. </param>
        /// <param name="description"> Description of the parameter. </param>
        /// <param name="default"> The default value for the parameter to be used if the live pipeline does not specify a value. </param>
        /// <returns> A new <see cref="Models.ParameterDeclaration"/> instance for mocking. </returns>
        public static ParameterDeclaration ParameterDeclaration(string name = null, ParameterType type = default, string description = null, string @default = null)
        {
            return new ParameterDeclaration(name, type, description, @default);
        }

        /// <summary> Initializes a new instance of SourceNodeBase. </summary>
        /// <param name="type"> Type discriminator for the derived types. </param>
        /// <param name="name"> Node name. Must be unique within the topology. </param>
        /// <returns> A new <see cref="Models.SourceNodeBase"/> instance for mocking. </returns>
        public static SourceNodeBase SourceNodeBase(string type = null, string name = null)
        {
            return new UnknownSourceNodeBase(type, name);
        }

        /// <summary> Initializes a new instance of ProcessorNodeBase. </summary>
        /// <param name="type"> Type discriminator for the derived types. </param>
        /// <param name="name"> Node name. Must be unique within the topology. </param>
        /// <param name="inputs"> An array of upstream node references within the topology to be used as inputs for this node. </param>
        /// <returns> A new <see cref="Models.ProcessorNodeBase"/> instance for mocking. </returns>
        public static ProcessorNodeBase ProcessorNodeBase(string type = null, string name = null, IEnumerable<NodeInput> inputs = null)
        {
            inputs ??= new List<NodeInput>();

            return new UnknownProcessorNodeBase(type, name, inputs?.ToList());
        }

        /// <summary> Initializes a new instance of NodeInput. </summary>
        /// <param name="nodeName"> The name of the upstream node in the pipeline which output is used as input of the current node. </param>
        /// <param name="outputSelectors"> Allows for the selection of specific data streams (eg. video only) from another node. </param>
        /// <returns> A new <see cref="Models.NodeInput"/> instance for mocking. </returns>
        public static NodeInput NodeInput(string nodeName = null, IEnumerable<OutputSelector> outputSelectors = null)
        {
            outputSelectors ??= new List<OutputSelector>();

            return new NodeInput(nodeName, outputSelectors?.ToList());
        }

        /// <summary> Initializes a new instance of OutputSelector. </summary>
        /// <param name="property"> The property of the data stream to be used as the selection criteria. </param>
        /// <param name="operator"> The operator to compare properties by. </param>
        /// <param name="value"> Value to compare against. </param>
        /// <returns> A new <see cref="Models.OutputSelector"/> instance for mocking. </returns>
        public static OutputSelector OutputSelector(OutputSelectorProperty? property = null, OutputSelectorOperator? @operator = null, string value = null)
        {
            return new OutputSelector(property, @operator, value);
        }

        /// <summary> Initializes a new instance of SinkNodeBase. </summary>
        /// <param name="type"> Type discriminator for the derived types. </param>
        /// <param name="name"> Node name. Must be unique within the topology. </param>
        /// <param name="inputs"> An array of upstream node references within the topology to be used as inputs for this node. </param>
        /// <returns> A new <see cref="Models.SinkNodeBase"/> instance for mocking. </returns>
        public static SinkNodeBase SinkNodeBase(string type = null, string name = null, IEnumerable<NodeInput> inputs = null)
        {
            inputs ??= new List<NodeInput>();

            return new UnknownSinkNodeBase(type, name, inputs?.ToList());
        }

        /// <summary> Initializes a new instance of RtspSource. </summary>
        /// <param name="name"> Node name. Must be unique within the topology. </param>
        /// <param name="transport"> Network transport utilized by the RTSP and RTP exchange: TCP or HTTP. When using TCP, the RTP packets are interleaved on the TCP RTSP connection. When using HTTP, the RTSP messages are exchanged through long lived HTTP connections, and the RTP packages are interleaved in the HTTP connections alongside the RTSP messages. </param>
        /// <param name="endpoint">
        /// RTSP endpoint information for Video Analyzer to connect to. This contains the required information for Video Analyzer to connect to RTSP cameras and/or generic RTSP servers.
        /// Please note <see cref="EndpointBase"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="TlsEndpoint"/> and <see cref="UnsecuredEndpoint"/>.
        /// </param>
        /// <returns> A new <see cref="Models.RtspSource"/> instance for mocking. </returns>
        public static RtspSource RtspSource(string name = null, RtspTransport? transport = null, EndpointBase endpoint = null)
        {
            return new RtspSource("#Microsoft.VideoAnalyzer.RtspSource", name, transport, endpoint);
        }

        /// <summary> Initializes a new instance of EndpointBase. </summary>
        /// <param name="type"> Type discriminator for the derived types. </param>
        /// <param name="credentials">
        /// Credentials to be presented to the endpoint.
        /// Please note <see cref="CredentialsBase"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="HttpHeaderCredentials"/>, <see cref="SymmetricKeyCredentials"/> and <see cref="UsernamePasswordCredentials"/>.
        /// </param>
        /// <param name="url"> The endpoint URL for Video Analyzer to connect to. </param>
        /// <returns> A new <see cref="Models.EndpointBase"/> instance for mocking. </returns>
        public static EndpointBase EndpointBase(string type = null, CredentialsBase credentials = null, string url = null)
        {
            return new UnknownEndpointBase(type, credentials, url);
        }

        /// <summary> Initializes a new instance of CredentialsBase. </summary>
        /// <param name="type"> Type discriminator for the derived types. </param>
        /// <returns> A new <see cref="Models.CredentialsBase"/> instance for mocking. </returns>
        public static CredentialsBase CredentialsBase(string type = null)
        {
            return new UnknownCredentialsBase(type);
        }

        /// <summary> Initializes a new instance of IotHubMessageSource. </summary>
        /// <param name="name"> Node name. Must be unique within the topology. </param>
        /// <param name="hubInputName"> Name of the IoT Edge Hub input from which messages will be consumed. </param>
        /// <returns> A new <see cref="Models.IotHubMessageSource"/> instance for mocking. </returns>
        public static IotHubMessageSource IotHubMessageSource(string name = null, string hubInputName = null)
        {
            return new IotHubMessageSource("#Microsoft.VideoAnalyzer.IotHubMessageSource", name, hubInputName);
        }

        /// <summary> Initializes a new instance of IotHubMessageSink. </summary>
        /// <param name="name"> Node name. Must be unique within the topology. </param>
        /// <param name="inputs"> An array of upstream node references within the topology to be used as inputs for this node. </param>
        /// <param name="hubOutputName"> Name of the Iot Edge Hub output to which the messages will be published. </param>
        /// <returns> A new <see cref="Models.IotHubMessageSink"/> instance for mocking. </returns>
        public static IotHubMessageSink IotHubMessageSink(string name = null, IEnumerable<NodeInput> inputs = null, string hubOutputName = null)
        {
            inputs ??= new List<NodeInput>();

            return new IotHubMessageSink("#Microsoft.VideoAnalyzer.IotHubMessageSink", name, inputs?.ToList(), hubOutputName);
        }

        /// <summary> Initializes a new instance of UsernamePasswordCredentials. </summary>
        /// <param name="username"> Username to be presented as part of the credentials. </param>
        /// <param name="password"> Password to be presented as part of the credentials. It is recommended that this value is parameterized as a secret string in order to prevent this value to be returned as part of the resource on API requests. </param>
        /// <returns> A new <see cref="Models.UsernamePasswordCredentials"/> instance for mocking. </returns>
        public static UsernamePasswordCredentials UsernamePasswordCredentials(string username = null, string password = null)
        {
            return new UsernamePasswordCredentials("#Microsoft.VideoAnalyzer.UsernamePasswordCredentials", username, password);
        }

        /// <summary> Initializes a new instance of HttpHeaderCredentials. </summary>
        /// <param name="headerName"> HTTP header name. </param>
        /// <param name="headerValue"> HTTP header value. It is recommended that this value is parameterized as a secret string in order to prevent this value to be returned as part of the resource on API requests. </param>
        /// <returns> A new <see cref="Models.HttpHeaderCredentials"/> instance for mocking. </returns>
        public static HttpHeaderCredentials HttpHeaderCredentials(string headerName = null, string headerValue = null)
        {
            return new HttpHeaderCredentials("#Microsoft.VideoAnalyzer.HttpHeaderCredentials", headerName, headerValue);
        }

        /// <summary> Initializes a new instance of UnsecuredEndpoint. </summary>
        /// <param name="credentials">
        /// Credentials to be presented to the endpoint.
        /// Please note <see cref="CredentialsBase"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="HttpHeaderCredentials"/>, <see cref="SymmetricKeyCredentials"/> and <see cref="UsernamePasswordCredentials"/>.
        /// </param>
        /// <param name="url"> The endpoint URL for Video Analyzer to connect to. </param>
        /// <returns> A new <see cref="Models.UnsecuredEndpoint"/> instance for mocking. </returns>
        public static UnsecuredEndpoint UnsecuredEndpoint(CredentialsBase credentials = null, string url = null)
        {
            return new UnsecuredEndpoint("#Microsoft.VideoAnalyzer.UnsecuredEndpoint", credentials, url);
        }

        /// <summary> Initializes a new instance of TlsEndpoint. </summary>
        /// <param name="credentials">
        /// Credentials to be presented to the endpoint.
        /// Please note <see cref="CredentialsBase"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="HttpHeaderCredentials"/>, <see cref="SymmetricKeyCredentials"/> and <see cref="UsernamePasswordCredentials"/>.
        /// </param>
        /// <param name="url"> The endpoint URL for Video Analyzer to connect to. </param>
        /// <param name="trustedCertificates">
        /// List of trusted certificate authorities when authenticating a TLS connection. A null list designates that Azure Video Analyzer&apos;s list of trusted authorities should be used.
        /// Please note <see cref="CertificateSource"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="PemCertificateList"/>.
        /// </param>
        /// <param name="validationOptions"> Validation options to use when authenticating a TLS connection. By default, strict validation is used. </param>
        /// <returns> A new <see cref="Models.TlsEndpoint"/> instance for mocking. </returns>
        public static TlsEndpoint TlsEndpoint(CredentialsBase credentials = null, string url = null, CertificateSource trustedCertificates = null, TlsValidationOptions validationOptions = null)
        {
            return new TlsEndpoint("#Microsoft.VideoAnalyzer.TlsEndpoint", credentials, url, trustedCertificates, validationOptions);
        }

        /// <summary> Initializes a new instance of CertificateSource. </summary>
        /// <param name="type"> Type discriminator for the derived types. </param>
        /// <returns> A new <see cref="Models.CertificateSource"/> instance for mocking. </returns>
        public static CertificateSource CertificateSource(string type = null)
        {
            return new UnknownCertificateSource(type);
        }

        /// <summary> Initializes a new instance of TlsValidationOptions. </summary>
        /// <param name="ignoreHostname"> When set to &apos;true&apos; causes the certificate subject name validation to be skipped. Default is &apos;false&apos;. </param>
        /// <param name="ignoreSignature"> When set to &apos;true&apos; causes the certificate chain trust validation to be skipped. Default is &apos;false&apos;. </param>
        /// <returns> A new <see cref="Models.TlsValidationOptions"/> instance for mocking. </returns>
        public static TlsValidationOptions TlsValidationOptions(string ignoreHostname = null, string ignoreSignature = null)
        {
            return new TlsValidationOptions(ignoreHostname, ignoreSignature);
        }

        /// <summary> Initializes a new instance of SymmetricKeyCredentials. </summary>
        /// <param name="key"> Symmetric key credential. </param>
        /// <returns> A new <see cref="Models.SymmetricKeyCredentials"/> instance for mocking. </returns>
        public static SymmetricKeyCredentials SymmetricKeyCredentials(string key = null)
        {
            return new SymmetricKeyCredentials("#Microsoft.VideoAnalyzer.SymmetricKeyCredentials", key);
        }

        /// <summary> Initializes a new instance of PemCertificateList. </summary>
        /// <param name="certificates"> PEM formatted public certificates. One certificate per entry. </param>
        /// <returns> A new <see cref="Models.PemCertificateList"/> instance for mocking. </returns>
        public static PemCertificateList PemCertificateList(IEnumerable<string> certificates = null)
        {
            certificates ??= new List<string>();

            return new PemCertificateList("#Microsoft.VideoAnalyzer.PemCertificateList", certificates?.ToList());
        }

        /// <summary> Initializes a new instance of FileSink. </summary>
        /// <param name="name"> Node name. Must be unique within the topology. </param>
        /// <param name="inputs"> An array of upstream node references within the topology to be used as inputs for this node. </param>
        /// <param name="baseDirectoryPath"> Absolute directory path where media files will be stored. </param>
        /// <param name="fileNamePattern"> File name pattern for creating new files when performing event based recording. The pattern must include at least one system variable. </param>
        /// <param name="maximumSizeMiB"> Maximum amount of disk space that can be used for storing files from this sink. Once this limit is reached, the oldest files from this sink will be automatically deleted. </param>
        /// <returns> A new <see cref="Models.FileSink"/> instance for mocking. </returns>
        public static FileSink FileSink(string name = null, IEnumerable<NodeInput> inputs = null, string baseDirectoryPath = null, string fileNamePattern = null, string maximumSizeMiB = null)
        {
            inputs ??= new List<NodeInput>();

            return new FileSink("#Microsoft.VideoAnalyzer.FileSink", name, inputs?.ToList(), baseDirectoryPath, fileNamePattern, maximumSizeMiB);
        }

        /// <summary> Initializes a new instance of VideoPublishingOptions. </summary>
        /// <param name="enableVideoPreviewImage"> When set to &apos;true&apos; the video will publish preview images. Default is &apos;false&apos;. </param>
        /// <returns> A new <see cref="Models.VideoPublishingOptions"/> instance for mocking. </returns>
        public static VideoPublishingOptions VideoPublishingOptions(string enableVideoPreviewImage = null)
        {
            return new VideoPublishingOptions(enableVideoPreviewImage);
        }

        /// <summary> Initializes a new instance of VideoCreationProperties. </summary>
        /// <param name="title"> Optional video title provided by the user. Value can be up to 256 characters long. </param>
        /// <param name="description"> Optional video description provided by the user. Value can be up to 2048 characters long. </param>
        /// <param name="segmentLength"> Video segment length indicates the length of individual video files (segments) which are persisted to storage. Smaller segments provide lower archive playback latency but generate larger volume of storage transactions. Larger segments reduce the amount of storage transactions while increasing the archive playback latency. Value must be specified in ISO8601 duration format (i.e. &quot;PT30S&quot; equals 30 seconds) and can vary between 30 seconds to 5 minutes, in 30 seconds increments. Changing this value after the video is initially created can lead to errors when uploading media to the archive. Default value is 30 seconds. </param>
        /// <param name="retentionPeriod"> Video retention period indicates how long the video is kept in storage, and must be a multiple of 1 day. For example, if this is set to 30 days, then content older than 30 days will be deleted. </param>
        /// <returns> A new <see cref="Models.VideoCreationProperties"/> instance for mocking. </returns>
        public static VideoCreationProperties VideoCreationProperties(string title = null, string description = null, string segmentLength = null, string retentionPeriod = null)
        {
            return new VideoCreationProperties(title, description, segmentLength, retentionPeriod);
        }

        /// <summary> Initializes a new instance of VideoSink. </summary>
        /// <param name="name"> Node name. Must be unique within the topology. </param>
        /// <param name="inputs"> An array of upstream node references within the topology to be used as inputs for this node. </param>
        /// <param name="videoName"> Name of a new or existing Video Analyzer video resource used for the media recording. </param>
        /// <param name="videoCreationProperties"> Optional video properties to be used in case a new video resource needs to be created on the service. </param>
        /// <param name="videoPublishingOptions"> Optional video publishing options to be used for changing publishing behavior of the output video. </param>
        /// <param name="localMediaCachePath"> Path to a local file system directory for caching of temporary media files. This will also be used to store content which cannot be immediately uploaded to Azure due to Internet connectivity issues. </param>
        /// <param name="localMediaCacheMaximumSizeMiB"> Maximum amount of disk space that can be used for caching of temporary media files. Once this limit is reached, the oldest segments of the media archive will be continuously deleted in order to make space for new media, thus leading to gaps in the cloud recorded content. </param>
        /// <returns> A new <see cref="Models.VideoSink"/> instance for mocking. </returns>
        public static VideoSink VideoSink(string name = null, IEnumerable<NodeInput> inputs = null, string videoName = null, VideoCreationProperties videoCreationProperties = null, VideoPublishingOptions videoPublishingOptions = null, string localMediaCachePath = null, string localMediaCacheMaximumSizeMiB = null)
        {
            inputs ??= new List<NodeInput>();

            return new VideoSink("#Microsoft.VideoAnalyzer.VideoSink", name, inputs?.ToList(), videoName, videoCreationProperties, videoPublishingOptions, localMediaCachePath, localMediaCacheMaximumSizeMiB);
        }

        /// <summary> Initializes a new instance of MotionDetectionProcessor. </summary>
        /// <param name="name"> Node name. Must be unique within the topology. </param>
        /// <param name="inputs"> An array of upstream node references within the topology to be used as inputs for this node. </param>
        /// <param name="sensitivity"> Motion detection sensitivity: low, medium, high. </param>
        /// <param name="outputMotionRegion"> Indicates whether the processor should detect and output the regions within the video frame where motion was detected. Default is true. </param>
        /// <param name="eventAggregationWindow"> Time window duration on which events are aggregated before being emitted. Value must be specified in ISO8601 duration format (i.e. &quot;PT2S&quot; equals 2 seconds). Use 0 seconds for no aggregation. Default is 1 second. </param>
        /// <returns> A new <see cref="Models.MotionDetectionProcessor"/> instance for mocking. </returns>
        public static MotionDetectionProcessor MotionDetectionProcessor(string name = null, IEnumerable<NodeInput> inputs = null, MotionDetectionSensitivity? sensitivity = null, bool? outputMotionRegion = null, string eventAggregationWindow = null)
        {
            inputs ??= new List<NodeInput>();

            return new MotionDetectionProcessor("#Microsoft.VideoAnalyzer.MotionDetectionProcessor", name, inputs?.ToList(), sensitivity, outputMotionRegion, eventAggregationWindow);
        }

        /// <summary> Initializes a new instance of ObjectTrackingProcessor. </summary>
        /// <param name="name"> Node name. Must be unique within the topology. </param>
        /// <param name="inputs"> An array of upstream node references within the topology to be used as inputs for this node. </param>
        /// <param name="accuracy"> Object tracker accuracy: low, medium, high. Higher accuracy leads to higher CPU consumption in average. </param>
        /// <returns> A new <see cref="Models.ObjectTrackingProcessor"/> instance for mocking. </returns>
        public static ObjectTrackingProcessor ObjectTrackingProcessor(string name = null, IEnumerable<NodeInput> inputs = null, ObjectTrackingAccuracy? accuracy = null)
        {
            inputs ??= new List<NodeInput>();

            return new ObjectTrackingProcessor("#Microsoft.VideoAnalyzer.ObjectTrackingProcessor", name, inputs?.ToList(), accuracy);
        }

        /// <summary> Initializes a new instance of LineCrossingProcessor. </summary>
        /// <param name="name"> Node name. Must be unique within the topology. </param>
        /// <param name="inputs"> An array of upstream node references within the topology to be used as inputs for this node. </param>
        /// <param name="lines">
        /// An array of lines used to compute line crossing events.
        /// Please note <see cref="NamedLineBase"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="NamedLineString"/>.
        /// </param>
        /// <returns> A new <see cref="Models.LineCrossingProcessor"/> instance for mocking. </returns>
        public static LineCrossingProcessor LineCrossingProcessor(string name = null, IEnumerable<NodeInput> inputs = null, IEnumerable<NamedLineBase> lines = null)
        {
            inputs ??= new List<NodeInput>();
            lines ??= new List<NamedLineBase>();

            return new LineCrossingProcessor("#Microsoft.VideoAnalyzer.LineCrossingProcessor", name, inputs?.ToList(), lines?.ToList());
        }

        /// <summary> Initializes a new instance of NamedLineBase. </summary>
        /// <param name="type"> The Type discriminator for the derived types. </param>
        /// <param name="name"> Line name. Must be unique within the node. </param>
        /// <returns> A new <see cref="Models.NamedLineBase"/> instance for mocking. </returns>
        public static NamedLineBase NamedLineBase(string type = null, string name = null)
        {
            return new UnknownNamedLineBase(type, name);
        }

        /// <summary> Initializes a new instance of ExtensionProcessorBase. </summary>
        /// <param name="name"> Node name. Must be unique within the topology. </param>
        /// <param name="inputs"> An array of upstream node references within the topology to be used as inputs for this node. </param>
        /// <param name="endpoint">
        /// Endpoint details of the pipeline extension plugin.
        /// Please note <see cref="EndpointBase"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="TlsEndpoint"/> and <see cref="UnsecuredEndpoint"/>.
        /// </param>
        /// <param name="image"> Image transformations and formatting options to be applied to the video frame(s) prior submission to the pipeline extension plugin. </param>
        /// <param name="samplingOptions"> Media sampling parameters that define how often media is submitted to the extension plugin. </param>
        /// <returns> A new <see cref="Models.ExtensionProcessorBase"/> instance for mocking. </returns>
        public static ExtensionProcessorBase ExtensionProcessorBase(string name = null, IEnumerable<NodeInput> inputs = null, EndpointBase endpoint = null, ImageProperties image = null, SamplingOptions samplingOptions = null)
        {
            inputs ??= new List<NodeInput>();

            return new ExtensionProcessorBase("#Microsoft.VideoAnalyzer.ExtensionProcessorBase", name, inputs?.ToList(), endpoint, image, samplingOptions);
        }

        /// <summary> Initializes a new instance of ImageProperties. </summary>
        /// <param name="scale"> Image scaling mode. </param>
        /// <param name="format">
        /// Base class for image formatting properties.
        /// Please note <see cref="ImageFormatProperties"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="ImageFormatBmp"/>, <see cref="ImageFormatJpeg"/>, <see cref="ImageFormatPng"/> and <see cref="ImageFormatRaw"/>.
        /// </param>
        /// <returns> A new <see cref="Models.ImageProperties"/> instance for mocking. </returns>
        public static ImageProperties ImageProperties(ImageScale scale = null, ImageFormatProperties format = null)
        {
            return new ImageProperties(scale, format);
        }

        /// <summary> Initializes a new instance of ImageScale. </summary>
        /// <param name="mode"> Describes the image scaling mode to be applied. Default mode is &apos;pad&apos;. </param>
        /// <param name="width"> The desired output image width. </param>
        /// <param name="height"> The desired output image height. </param>
        /// <returns> A new <see cref="Models.ImageScale"/> instance for mocking. </returns>
        public static ImageScale ImageScale(ImageScaleMode? mode = null, string width = null, string height = null)
        {
            return new ImageScale(mode, width, height);
        }

        /// <summary> Initializes a new instance of ImageFormatProperties. </summary>
        /// <param name="type"> Type discriminator for the derived types. </param>
        /// <returns> A new <see cref="Models.ImageFormatProperties"/> instance for mocking. </returns>
        public static ImageFormatProperties ImageFormatProperties(string type = null)
        {
            return new UnknownImageFormatProperties(type);
        }

        /// <summary> Initializes a new instance of SamplingOptions. </summary>
        /// <param name="skipSamplesWithoutAnnotation"> When set to &apos;true&apos;, prevents frames without upstream inference data to be sent to the extension plugin. This is useful to limit the frames sent to the extension to pre-analyzed frames only. For example, when used downstream from a motion detector, this can enable for only frames in which motion has been detected to be further analyzed. </param>
        /// <param name="maximumSamplesPerSecond"> Maximum rate of samples submitted to the extension. This prevents an extension plugin to be overloaded with data. </param>
        /// <returns> A new <see cref="Models.SamplingOptions"/> instance for mocking. </returns>
        public static SamplingOptions SamplingOptions(string skipSamplesWithoutAnnotation = null, string maximumSamplesPerSecond = null)
        {
            return new SamplingOptions(skipSamplesWithoutAnnotation, maximumSamplesPerSecond);
        }

        /// <summary> Initializes a new instance of GrpcExtension. </summary>
        /// <param name="name"> Node name. Must be unique within the topology. </param>
        /// <param name="inputs"> An array of upstream node references within the topology to be used as inputs for this node. </param>
        /// <param name="endpoint">
        /// Endpoint details of the pipeline extension plugin.
        /// Please note <see cref="EndpointBase"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="TlsEndpoint"/> and <see cref="UnsecuredEndpoint"/>.
        /// </param>
        /// <param name="image"> Image transformations and formatting options to be applied to the video frame(s) prior submission to the pipeline extension plugin. </param>
        /// <param name="samplingOptions"> Media sampling parameters that define how often media is submitted to the extension plugin. </param>
        /// <param name="dataTransfer"> Specifies how media is transferred to the extension plugin. </param>
        /// <param name="extensionConfiguration"> An optional configuration string that is sent to the extension plugin. The configuration string is specific to each custom extension and it not understood neither validated by Video Analyzer. Please see https://aka.ms/ava-extension-grpc for details. </param>
        /// <returns> A new <see cref="Models.GrpcExtension"/> instance for mocking. </returns>
        public static GrpcExtension GrpcExtension(string name = null, IEnumerable<NodeInput> inputs = null, EndpointBase endpoint = null, ImageProperties image = null, SamplingOptions samplingOptions = null, GrpcExtensionDataTransfer dataTransfer = null, string extensionConfiguration = null)
        {
            inputs ??= new List<NodeInput>();

            return new GrpcExtension("#Microsoft.VideoAnalyzer.GrpcExtension", name, inputs?.ToList(), endpoint, image, samplingOptions, dataTransfer, extensionConfiguration);
        }

        /// <summary> Initializes a new instance of GrpcExtensionDataTransfer. </summary>
        /// <param name="sharedMemorySizeMiB"> The share memory buffer for sample transfers, in mebibytes. It can only be used with the &apos;SharedMemory&apos; transfer mode. </param>
        /// <param name="mode"> Data transfer mode: embedded or sharedMemory. </param>
        /// <returns> A new <see cref="Models.GrpcExtensionDataTransfer"/> instance for mocking. </returns>
        public static GrpcExtensionDataTransfer GrpcExtensionDataTransfer(string sharedMemorySizeMiB = null, GrpcExtensionDataTransferMode mode = default)
        {
            return new GrpcExtensionDataTransfer(sharedMemorySizeMiB, mode);
        }

        /// <summary> Initializes a new instance of HttpExtension. </summary>
        /// <param name="name"> Node name. Must be unique within the topology. </param>
        /// <param name="inputs"> An array of upstream node references within the topology to be used as inputs for this node. </param>
        /// <param name="endpoint">
        /// Endpoint details of the pipeline extension plugin.
        /// Please note <see cref="EndpointBase"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="TlsEndpoint"/> and <see cref="UnsecuredEndpoint"/>.
        /// </param>
        /// <param name="image"> Image transformations and formatting options to be applied to the video frame(s) prior submission to the pipeline extension plugin. </param>
        /// <param name="samplingOptions"> Media sampling parameters that define how often media is submitted to the extension plugin. </param>
        /// <returns> A new <see cref="Models.HttpExtension"/> instance for mocking. </returns>
        public static HttpExtension HttpExtension(string name = null, IEnumerable<NodeInput> inputs = null, EndpointBase endpoint = null, ImageProperties image = null, SamplingOptions samplingOptions = null)
        {
            inputs ??= new List<NodeInput>();

            return new HttpExtension("#Microsoft.VideoAnalyzer.HttpExtension", name, inputs?.ToList(), endpoint, image, samplingOptions);
        }

        /// <summary> Initializes a new instance of ImageFormatRaw. </summary>
        /// <param name="pixelFormat"> Pixel format to be applied to the raw image. </param>
        /// <returns> A new <see cref="Models.ImageFormatRaw"/> instance for mocking. </returns>
        public static ImageFormatRaw ImageFormatRaw(ImageFormatRawPixelFormat pixelFormat = default)
        {
            return new ImageFormatRaw("#Microsoft.VideoAnalyzer.ImageFormatRaw", pixelFormat);
        }

        /// <summary> Initializes a new instance of ImageFormatJpeg. </summary>
        /// <param name="quality"> Image quality value between 0 to 100 (best quality). </param>
        /// <returns> A new <see cref="Models.ImageFormatJpeg"/> instance for mocking. </returns>
        public static ImageFormatJpeg ImageFormatJpeg(string quality = null)
        {
            return new ImageFormatJpeg("#Microsoft.VideoAnalyzer.ImageFormatJpeg", quality);
        }

        /// <summary> Initializes a new instance of ImageFormatBmp. </summary>
        /// <returns> A new <see cref="Models.ImageFormatBmp"/> instance for mocking. </returns>
        public static ImageFormatBmp ImageFormatBmp()
        {
            return new ImageFormatBmp("#Microsoft.VideoAnalyzer.ImageFormatBmp");
        }

        /// <summary> Initializes a new instance of ImageFormatPng. </summary>
        /// <returns> A new <see cref="Models.ImageFormatPng"/> instance for mocking. </returns>
        public static ImageFormatPng ImageFormatPng()
        {
            return new ImageFormatPng("#Microsoft.VideoAnalyzer.ImageFormatPng");
        }

        /// <summary> Initializes a new instance of NamedLineString. </summary>
        /// <param name="name"> Line name. Must be unique within the node. </param>
        /// <param name="line"> Point coordinates for the line start and end, respectively. Example: &apos;[[0.3, 0.2],[0.9, 0.8]]&apos;. Each point is expressed as [LEFT, TOP] coordinate ratios ranging from 0.0 to 1.0, where [0,0] is the upper-left frame corner and [1, 1] is the bottom-right frame corner. </param>
        /// <returns> A new <see cref="Models.NamedLineString"/> instance for mocking. </returns>
        public static NamedLineString NamedLineString(string name = null, string line = null)
        {
            return new NamedLineString("#Microsoft.VideoAnalyzer.NamedLineString", name, line);
        }

        /// <summary> Initializes a new instance of NamedPolygonBase. </summary>
        /// <param name="type"> The Type discriminator for the derived types. </param>
        /// <param name="name"> Polygon name. Must be unique within the node. </param>
        /// <returns> A new <see cref="Models.NamedPolygonBase"/> instance for mocking. </returns>
        public static NamedPolygonBase NamedPolygonBase(string type = null, string name = null)
        {
            return new UnknownNamedPolygonBase(type, name);
        }

        /// <summary> Initializes a new instance of NamedPolygonString. </summary>
        /// <param name="name"> Polygon name. Must be unique within the node. </param>
        /// <param name="polygon"> Point coordinates for the polygon. Example: &apos;[[0.3, 0.2],[0.9, 0.8],[0.7, 0.6]]&apos;. Each point is expressed as [LEFT, TOP] coordinate ratios ranging from 0.0 to 1.0, where [0,0] is the upper-left frame corner and [1, 1] is the bottom-right frame corner. </param>
        /// <returns> A new <see cref="Models.NamedPolygonString"/> instance for mocking. </returns>
        public static NamedPolygonString NamedPolygonString(string name = null, string polygon = null)
        {
            return new NamedPolygonString("#Microsoft.VideoAnalyzer.NamedPolygonString", name, polygon);
        }

        /// <summary> Initializes a new instance of SignalGateProcessor. </summary>
        /// <param name="name"> Node name. Must be unique within the topology. </param>
        /// <param name="inputs"> An array of upstream node references within the topology to be used as inputs for this node. </param>
        /// <param name="activationEvaluationWindow"> The period of time over which the gate gathers input events before evaluating them. </param>
        /// <param name="activationSignalOffset"> Signal offset once the gate is activated (can be negative). It determines the how much farther behind of after the signal will be let through based on the activation time. A negative offset indicates that data prior the activation time must be included on the signal that is let through, once the gate is activated. When used upstream of a file or video sink, this allows for scenarios such as recording buffered media prior an event, such as: record video 5 seconds prior motions is detected. </param>
        /// <param name="minimumActivationTime"> The minimum period for which the gate remains open in the absence of subsequent triggers (events). When used upstream of a file or video sink, it determines the minimum length of the recorded video clip. </param>
        /// <param name="maximumActivationTime"> The maximum period for which the gate remains open in the presence of subsequent triggers (events). When used upstream of a file or video sink, it determines the maximum length of the recorded video clip. </param>
        /// <returns> A new <see cref="Models.SignalGateProcessor"/> instance for mocking. </returns>
        public static SignalGateProcessor SignalGateProcessor(string name = null, IEnumerable<NodeInput> inputs = null, string activationEvaluationWindow = null, string activationSignalOffset = null, string minimumActivationTime = null, string maximumActivationTime = null)
        {
            inputs ??= new List<NodeInput>();

            return new SignalGateProcessor("#Microsoft.VideoAnalyzer.SignalGateProcessor", name, inputs?.ToList(), activationEvaluationWindow, activationSignalOffset, minimumActivationTime, maximumActivationTime);
        }

        /// <summary> Initializes a new instance of SpatialAnalysisOperationBase. </summary>
        /// <param name="type"> The Type discriminator for the derived types. </param>
        /// <returns> A new <see cref="Models.SpatialAnalysisOperationBase"/> instance for mocking. </returns>
        public static SpatialAnalysisOperationBase SpatialAnalysisOperationBase(string type = null)
        {
            return new UnknownSpatialAnalysisOperationBase(type);
        }

        /// <summary> Initializes a new instance of SpatialAnalysisCustomOperation. </summary>
        /// <param name="extensionConfiguration"> Custom configuration to pass to the Azure Cognitive Services Spatial Analysis module. </param>
        /// <returns> A new <see cref="Models.SpatialAnalysisCustomOperation"/> instance for mocking. </returns>
        public static SpatialAnalysisCustomOperation SpatialAnalysisCustomOperation(string extensionConfiguration = null)
        {
            return new SpatialAnalysisCustomOperation("#Microsoft.VideoAnalyzer.SpatialAnalysisCustomOperation", extensionConfiguration);
        }

        /// <summary> Initializes a new instance of SpatialAnalysisTypedOperationBase. </summary>
        /// <param name="debug"> If set to &apos;true&apos;, enables debugging mode for this operation. </param>
        /// <param name="calibrationConfiguration"> Advanced calibration configuration. </param>
        /// <param name="cameraConfiguration"> Advanced camera configuration. </param>
        /// <param name="cameraCalibratorNodeConfiguration"> Advanced camera calibrator configuration. </param>
        /// <param name="detectorNodeConfiguration"> Advanced detector node configuration. </param>
        /// <param name="trackerNodeConfiguration"> Advanced tracker node configuration. </param>
        /// <param name="enableFaceMaskClassifier"> If set to &apos;true&apos;, enables face mask detection for this operation. </param>
        /// <returns> A new <see cref="Models.SpatialAnalysisTypedOperationBase"/> instance for mocking. </returns>
        public static SpatialAnalysisTypedOperationBase SpatialAnalysisTypedOperationBase(string debug = null, string calibrationConfiguration = null, string cameraConfiguration = null, string cameraCalibratorNodeConfiguration = null, string detectorNodeConfiguration = null, string trackerNodeConfiguration = null, string enableFaceMaskClassifier = null)
        {
            return new SpatialAnalysisTypedOperationBase("SpatialAnalysisTypedOperationBase", debug, calibrationConfiguration, cameraConfiguration, cameraCalibratorNodeConfiguration, detectorNodeConfiguration, trackerNodeConfiguration, enableFaceMaskClassifier);
        }

        /// <summary> Initializes a new instance of SpatialAnalysisOperationEventBase. </summary>
        /// <param name="threshold"> The event threshold. </param>
        /// <param name="focus"> The operation focus type. </param>
        /// <returns> A new <see cref="Models.SpatialAnalysisOperationEventBase"/> instance for mocking. </returns>
        public static SpatialAnalysisOperationEventBase SpatialAnalysisOperationEventBase(string threshold = null, SpatialAnalysisOperationFocus? focus = null)
        {
            return new SpatialAnalysisOperationEventBase(threshold, focus);
        }

        /// <summary> Initializes a new instance of SpatialAnalysisPersonCountEvent. </summary>
        /// <param name="threshold"> The event threshold. </param>
        /// <param name="focus"> The operation focus type. </param>
        /// <param name="trigger"> The event trigger type. </param>
        /// <param name="outputFrequency"> The event or interval output frequency. </param>
        /// <returns> A new <see cref="Models.SpatialAnalysisPersonCountEvent"/> instance for mocking. </returns>
        public static SpatialAnalysisPersonCountEvent SpatialAnalysisPersonCountEvent(string threshold = null, SpatialAnalysisOperationFocus? focus = null, SpatialAnalysisPersonCountEventTrigger? trigger = null, string outputFrequency = null)
        {
            return new SpatialAnalysisPersonCountEvent(threshold, focus, trigger, outputFrequency);
        }

        /// <summary> Initializes a new instance of SpatialAnalysisPersonCountZoneEvents. </summary>
        /// <param name="zone">
        /// The named zone.
        /// Please note <see cref="NamedPolygonBase"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="NamedPolygonString"/>.
        /// </param>
        /// <param name="events"> The event configuration. </param>
        /// <returns> A new <see cref="Models.SpatialAnalysisPersonCountZoneEvents"/> instance for mocking. </returns>
        public static SpatialAnalysisPersonCountZoneEvents SpatialAnalysisPersonCountZoneEvents(NamedPolygonBase zone = null, IEnumerable<SpatialAnalysisPersonCountEvent> events = null)
        {
            events ??= new List<SpatialAnalysisPersonCountEvent>();

            return new SpatialAnalysisPersonCountZoneEvents(zone, events?.ToList());
        }

        /// <summary> Initializes a new instance of SpatialAnalysisPersonCountOperation. </summary>
        /// <param name="debug"> If set to &apos;true&apos;, enables debugging mode for this operation. </param>
        /// <param name="calibrationConfiguration"> Advanced calibration configuration. </param>
        /// <param name="cameraConfiguration"> Advanced camera configuration. </param>
        /// <param name="cameraCalibratorNodeConfiguration"> Advanced camera calibrator configuration. </param>
        /// <param name="detectorNodeConfiguration"> Advanced detector node configuration. </param>
        /// <param name="trackerNodeConfiguration"> Advanced tracker node configuration. </param>
        /// <param name="enableFaceMaskClassifier"> If set to &apos;true&apos;, enables face mask detection for this operation. </param>
        /// <param name="zones"> The list of zones and optional events. </param>
        /// <returns> A new <see cref="Models.SpatialAnalysisPersonCountOperation"/> instance for mocking. </returns>
        public static SpatialAnalysisPersonCountOperation SpatialAnalysisPersonCountOperation(string debug = null, string calibrationConfiguration = null, string cameraConfiguration = null, string cameraCalibratorNodeConfiguration = null, string detectorNodeConfiguration = null, string trackerNodeConfiguration = null, string enableFaceMaskClassifier = null, IEnumerable<SpatialAnalysisPersonCountZoneEvents> zones = null)
        {
            zones ??= new List<SpatialAnalysisPersonCountZoneEvents>();

            return new SpatialAnalysisPersonCountOperation("#Microsoft.VideoAnalyzer.SpatialAnalysisPersonCountOperation", debug, calibrationConfiguration, cameraConfiguration, cameraCalibratorNodeConfiguration, detectorNodeConfiguration, trackerNodeConfiguration, enableFaceMaskClassifier, zones?.ToList());
        }

        /// <summary> Initializes a new instance of SpatialAnalysisPersonZoneCrossingEvent. </summary>
        /// <param name="threshold"> The event threshold. </param>
        /// <param name="focus"> The operation focus type. </param>
        /// <param name="eventType"> The event type. </param>
        /// <returns> A new <see cref="Models.SpatialAnalysisPersonZoneCrossingEvent"/> instance for mocking. </returns>
        public static SpatialAnalysisPersonZoneCrossingEvent SpatialAnalysisPersonZoneCrossingEvent(string threshold = null, SpatialAnalysisOperationFocus? focus = null, SpatialAnalysisPersonZoneCrossingEventType? eventType = null)
        {
            return new SpatialAnalysisPersonZoneCrossingEvent(threshold, focus, eventType);
        }

        /// <summary> Initializes a new instance of SpatialAnalysisPersonZoneCrossingZoneEvents. </summary>
        /// <param name="zone">
        /// The named zone.
        /// Please note <see cref="NamedPolygonBase"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="NamedPolygonString"/>.
        /// </param>
        /// <param name="events"> The event configuration. </param>
        /// <returns> A new <see cref="Models.SpatialAnalysisPersonZoneCrossingZoneEvents"/> instance for mocking. </returns>
        public static SpatialAnalysisPersonZoneCrossingZoneEvents SpatialAnalysisPersonZoneCrossingZoneEvents(NamedPolygonBase zone = null, IEnumerable<SpatialAnalysisPersonZoneCrossingEvent> events = null)
        {
            events ??= new List<SpatialAnalysisPersonZoneCrossingEvent>();

            return new SpatialAnalysisPersonZoneCrossingZoneEvents(zone, events?.ToList());
        }

        /// <summary> Initializes a new instance of SpatialAnalysisPersonZoneCrossingOperation. </summary>
        /// <param name="debug"> If set to &apos;true&apos;, enables debugging mode for this operation. </param>
        /// <param name="calibrationConfiguration"> Advanced calibration configuration. </param>
        /// <param name="cameraConfiguration"> Advanced camera configuration. </param>
        /// <param name="cameraCalibratorNodeConfiguration"> Advanced camera calibrator configuration. </param>
        /// <param name="detectorNodeConfiguration"> Advanced detector node configuration. </param>
        /// <param name="trackerNodeConfiguration"> Advanced tracker node configuration. </param>
        /// <param name="enableFaceMaskClassifier"> If set to &apos;true&apos;, enables face mask detection for this operation. </param>
        /// <param name="zones"> The list of zones with optional events. </param>
        /// <returns> A new <see cref="Models.SpatialAnalysisPersonZoneCrossingOperation"/> instance for mocking. </returns>
        public static SpatialAnalysisPersonZoneCrossingOperation SpatialAnalysisPersonZoneCrossingOperation(string debug = null, string calibrationConfiguration = null, string cameraConfiguration = null, string cameraCalibratorNodeConfiguration = null, string detectorNodeConfiguration = null, string trackerNodeConfiguration = null, string enableFaceMaskClassifier = null, IEnumerable<SpatialAnalysisPersonZoneCrossingZoneEvents> zones = null)
        {
            zones ??= new List<SpatialAnalysisPersonZoneCrossingZoneEvents>();

            return new SpatialAnalysisPersonZoneCrossingOperation("#Microsoft.VideoAnalyzer.SpatialAnalysisPersonZoneCrossingOperation", debug, calibrationConfiguration, cameraConfiguration, cameraCalibratorNodeConfiguration, detectorNodeConfiguration, trackerNodeConfiguration, enableFaceMaskClassifier, zones?.ToList());
        }

        /// <summary> Initializes a new instance of SpatialAnalysisPersonDistanceEvent. </summary>
        /// <param name="threshold"> The event threshold. </param>
        /// <param name="focus"> The operation focus type. </param>
        /// <param name="trigger"> The event trigger type. </param>
        /// <param name="outputFrequency"> The event or interval output frequency. </param>
        /// <param name="minimumDistanceThreshold"> The minimum distance threshold. </param>
        /// <param name="maximumDistanceThreshold"> The maximum distance threshold. </param>
        /// <returns> A new <see cref="Models.SpatialAnalysisPersonDistanceEvent"/> instance for mocking. </returns>
        public static SpatialAnalysisPersonDistanceEvent SpatialAnalysisPersonDistanceEvent(string threshold = null, SpatialAnalysisOperationFocus? focus = null, SpatialAnalysisPersonDistanceEventTrigger? trigger = null, string outputFrequency = null, string minimumDistanceThreshold = null, string maximumDistanceThreshold = null)
        {
            return new SpatialAnalysisPersonDistanceEvent(threshold, focus, trigger, outputFrequency, minimumDistanceThreshold, maximumDistanceThreshold);
        }

        /// <summary> Initializes a new instance of SpatialAnalysisPersonDistanceZoneEvents. </summary>
        /// <param name="zone">
        /// The named zone.
        /// Please note <see cref="NamedPolygonBase"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="NamedPolygonString"/>.
        /// </param>
        /// <param name="events"> The event configuration. </param>
        /// <returns> A new <see cref="Models.SpatialAnalysisPersonDistanceZoneEvents"/> instance for mocking. </returns>
        public static SpatialAnalysisPersonDistanceZoneEvents SpatialAnalysisPersonDistanceZoneEvents(NamedPolygonBase zone = null, IEnumerable<SpatialAnalysisPersonDistanceEvent> events = null)
        {
            events ??= new List<SpatialAnalysisPersonDistanceEvent>();

            return new SpatialAnalysisPersonDistanceZoneEvents(zone, events?.ToList());
        }

        /// <summary> Initializes a new instance of SpatialAnalysisPersonDistanceOperation. </summary>
        /// <param name="debug"> If set to &apos;true&apos;, enables debugging mode for this operation. </param>
        /// <param name="calibrationConfiguration"> Advanced calibration configuration. </param>
        /// <param name="cameraConfiguration"> Advanced camera configuration. </param>
        /// <param name="cameraCalibratorNodeConfiguration"> Advanced camera calibrator configuration. </param>
        /// <param name="detectorNodeConfiguration"> Advanced detector node configuration. </param>
        /// <param name="trackerNodeConfiguration"> Advanced tracker node configuration. </param>
        /// <param name="enableFaceMaskClassifier"> If set to &apos;true&apos;, enables face mask detection for this operation. </param>
        /// <param name="zones"> The list of zones with optional events. </param>
        /// <returns> A new <see cref="Models.SpatialAnalysisPersonDistanceOperation"/> instance for mocking. </returns>
        public static SpatialAnalysisPersonDistanceOperation SpatialAnalysisPersonDistanceOperation(string debug = null, string calibrationConfiguration = null, string cameraConfiguration = null, string cameraCalibratorNodeConfiguration = null, string detectorNodeConfiguration = null, string trackerNodeConfiguration = null, string enableFaceMaskClassifier = null, IEnumerable<SpatialAnalysisPersonDistanceZoneEvents> zones = null)
        {
            zones ??= new List<SpatialAnalysisPersonDistanceZoneEvents>();

            return new SpatialAnalysisPersonDistanceOperation("#Microsoft.VideoAnalyzer.SpatialAnalysisPersonDistanceOperation", debug, calibrationConfiguration, cameraConfiguration, cameraCalibratorNodeConfiguration, detectorNodeConfiguration, trackerNodeConfiguration, enableFaceMaskClassifier, zones?.ToList());
        }

        /// <summary> Initializes a new instance of SpatialAnalysisPersonLineCrossingEvent. </summary>
        /// <param name="threshold"> The event threshold. </param>
        /// <param name="focus"> The operation focus type. </param>
        /// <returns> A new <see cref="Models.SpatialAnalysisPersonLineCrossingEvent"/> instance for mocking. </returns>
        public static SpatialAnalysisPersonLineCrossingEvent SpatialAnalysisPersonLineCrossingEvent(string threshold = null, SpatialAnalysisOperationFocus? focus = null)
        {
            return new SpatialAnalysisPersonLineCrossingEvent(threshold, focus);
        }

        /// <summary> Initializes a new instance of SpatialAnalysisPersonLineCrossingLineEvents. </summary>
        /// <param name="line">
        /// The named line.
        /// Please note <see cref="NamedLineBase"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="NamedLineString"/>.
        /// </param>
        /// <param name="events"> The event configuration. </param>
        /// <returns> A new <see cref="Models.SpatialAnalysisPersonLineCrossingLineEvents"/> instance for mocking. </returns>
        public static SpatialAnalysisPersonLineCrossingLineEvents SpatialAnalysisPersonLineCrossingLineEvents(NamedLineBase line = null, IEnumerable<SpatialAnalysisPersonLineCrossingEvent> events = null)
        {
            events ??= new List<SpatialAnalysisPersonLineCrossingEvent>();

            return new SpatialAnalysisPersonLineCrossingLineEvents(line, events?.ToList());
        }

        /// <summary> Initializes a new instance of SpatialAnalysisPersonLineCrossingOperation. </summary>
        /// <param name="debug"> If set to &apos;true&apos;, enables debugging mode for this operation. </param>
        /// <param name="calibrationConfiguration"> Advanced calibration configuration. </param>
        /// <param name="cameraConfiguration"> Advanced camera configuration. </param>
        /// <param name="cameraCalibratorNodeConfiguration"> Advanced camera calibrator configuration. </param>
        /// <param name="detectorNodeConfiguration"> Advanced detector node configuration. </param>
        /// <param name="trackerNodeConfiguration"> Advanced tracker node configuration. </param>
        /// <param name="enableFaceMaskClassifier"> If set to &apos;true&apos;, enables face mask detection for this operation. </param>
        /// <param name="lines"> The list of lines with optional events. </param>
        /// <returns> A new <see cref="Models.SpatialAnalysisPersonLineCrossingOperation"/> instance for mocking. </returns>
        public static SpatialAnalysisPersonLineCrossingOperation SpatialAnalysisPersonLineCrossingOperation(string debug = null, string calibrationConfiguration = null, string cameraConfiguration = null, string cameraCalibratorNodeConfiguration = null, string detectorNodeConfiguration = null, string trackerNodeConfiguration = null, string enableFaceMaskClassifier = null, IEnumerable<SpatialAnalysisPersonLineCrossingLineEvents> lines = null)
        {
            lines ??= new List<SpatialAnalysisPersonLineCrossingLineEvents>();

            return new SpatialAnalysisPersonLineCrossingOperation("#Microsoft.VideoAnalyzer.SpatialAnalysisPersonLineCrossingOperation", debug, calibrationConfiguration, cameraConfiguration, cameraCalibratorNodeConfiguration, detectorNodeConfiguration, trackerNodeConfiguration, enableFaceMaskClassifier, lines?.ToList());
        }

        /// <summary> Initializes a new instance of RemoteDeviceAdapter. </summary>
        /// <param name="name"> The unique identifier for the remote device adapter. </param>
        /// <param name="systemData"> Read-only system metadata associated with this object. </param>
        /// <param name="properties"> Properties of the remote device adapter. </param>
        /// <returns> A new <see cref="Models.RemoteDeviceAdapter"/> instance for mocking. </returns>
        public static RemoteDeviceAdapter RemoteDeviceAdapter(string name = null, SystemData systemData = null, RemoteDeviceAdapterProperties properties = null)
        {
            return new RemoteDeviceAdapter(name, systemData, properties);
        }

        /// <summary> Initializes a new instance of RemoteDeviceAdapterProperties. </summary>
        /// <param name="description"> An optional description for the remote device adapter. </param>
        /// <param name="target"> The IoT device to which this remote device will connect. </param>
        /// <param name="iotHubDeviceConnection"> Information that enables communication between the IoT Hub and the IoT device - allowing this edge module to act as a transparent gateway between the two. </param>
        /// <returns> A new <see cref="Models.RemoteDeviceAdapterProperties"/> instance for mocking. </returns>
        public static RemoteDeviceAdapterProperties RemoteDeviceAdapterProperties(string description = null, RemoteDeviceAdapterTarget target = null, IotHubDeviceConnection iotHubDeviceConnection = null)
        {
            return new RemoteDeviceAdapterProperties(description, target, iotHubDeviceConnection);
        }

        /// <summary> Initializes a new instance of IotHubDeviceConnection. </summary>
        /// <param name="deviceId"> The name of the IoT device configured and managed in IoT Hub. (case-sensitive). </param>
        /// <param name="credentials">
        /// IoT device connection credentials. Currently IoT device symmetric key credentials are supported.
        /// Please note <see cref="CredentialsBase"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="HttpHeaderCredentials"/>, <see cref="SymmetricKeyCredentials"/> and <see cref="UsernamePasswordCredentials"/>.
        /// </param>
        /// <returns> A new <see cref="Models.IotHubDeviceConnection"/> instance for mocking. </returns>
        public static IotHubDeviceConnection IotHubDeviceConnection(string deviceId = null, CredentialsBase credentials = null)
        {
            return new IotHubDeviceConnection(deviceId, credentials);
        }

        /// <summary> Initializes a new instance of RemoteDeviceAdapterCollection. </summary>
        /// <param name="value"> An array of remote device adapters. </param>
        /// <param name="continuationToken"> A continuation token to use in subsequent calls to enumerate through the remote device adapter collection. This is used when the collection contains too many results to return in one response. </param>
        /// <returns> A new <see cref="Models.RemoteDeviceAdapterCollection"/> instance for mocking. </returns>
        public static RemoteDeviceAdapterCollection RemoteDeviceAdapterCollection(IEnumerable<RemoteDeviceAdapter> value = null, string continuationToken = null)
        {
            value ??= new List<RemoteDeviceAdapter>();

            return new RemoteDeviceAdapterCollection(value?.ToList(), continuationToken);
        }

        /// <summary> Initializes a new instance of CognitiveServicesVisionProcessor. </summary>
        /// <param name="name"> Node name. Must be unique within the topology. </param>
        /// <param name="inputs"> An array of upstream node references within the topology to be used as inputs for this node. </param>
        /// <param name="endpoint">
        /// Endpoint to which this processor should connect.
        /// Please note <see cref="EndpointBase"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="TlsEndpoint"/> and <see cref="UnsecuredEndpoint"/>.
        /// </param>
        /// <param name="image"> Describes the parameters of the image that is sent as input to the endpoint. </param>
        /// <param name="samplingOptions"> Describes the sampling options to be applied when forwarding samples to the extension. </param>
        /// <param name="operation">
        /// Describes the Spatial Analysis operation to be used in the Cognitive Services Vision processor.
        /// Please note <see cref="SpatialAnalysisOperationBase"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="SpatialAnalysisCustomOperation"/>, <see cref="SpatialAnalysisPersonCountOperation"/>, <see cref="SpatialAnalysisPersonDistanceOperation"/>, <see cref="SpatialAnalysisPersonLineCrossingOperation"/>, <see cref="SpatialAnalysisPersonZoneCrossingOperation"/> and <see cref="SpatialAnalysisTypedOperationBase"/>.
        /// </param>
        /// <returns> A new <see cref="Models.CognitiveServicesVisionProcessor"/> instance for mocking. </returns>
        public static CognitiveServicesVisionProcessor CognitiveServicesVisionProcessor(string name = null, IEnumerable<NodeInput> inputs = null, EndpointBase endpoint = null, ImageProperties image = null, SamplingOptions samplingOptions = null, SpatialAnalysisOperationBase operation = null)
        {
            inputs ??= new List<NodeInput>();

            return new CognitiveServicesVisionProcessor("#Microsoft.VideoAnalyzer.CognitiveServicesVisionProcessor", name, inputs?.ToList(), endpoint, image, samplingOptions, operation);
        }

        /// <summary> Initializes a new instance of DiscoveredOnvifDeviceCollection. </summary>
        /// <param name="value"> An array of ONVIF devices that have been discovered in the same subnet as the IoT Edge device. </param>
        /// <returns> A new <see cref="Models.DiscoveredOnvifDeviceCollection"/> instance for mocking. </returns>
        public static DiscoveredOnvifDeviceCollection DiscoveredOnvifDeviceCollection(IEnumerable<DiscoveredOnvifDevice> value = null)
        {
            value ??= new List<DiscoveredOnvifDevice>();

            return new DiscoveredOnvifDeviceCollection(value?.ToList());
        }

        /// <summary> Initializes a new instance of DiscoveredOnvifDevice. </summary>
        /// <param name="serviceIdentifier"> The unique identifier of the ONVIF device that was discovered in the same subnet as the IoT Edge device. </param>
        /// <param name="remoteIPAddress"> The IP address of the ONVIF device that was discovered in the same subnet as the IoT Edge device. </param>
        /// <param name="scopes"> An array of hostnames for the ONVIF discovered devices that are in the same subnet as the IoT Edge device. </param>
        /// <param name="endpoints"> An array of media profile endpoints that the ONVIF discovered device supports. </param>
        /// <returns> A new <see cref="Models.DiscoveredOnvifDevice"/> instance for mocking. </returns>
        public static DiscoveredOnvifDevice DiscoveredOnvifDevice(string serviceIdentifier = null, string remoteIPAddress = null, IEnumerable<string> scopes = null, IEnumerable<string> endpoints = null)
        {
            scopes ??= new List<string>();
            endpoints ??= new List<string>();

            return new DiscoveredOnvifDevice(serviceIdentifier, remoteIPAddress, scopes?.ToList(), endpoints?.ToList());
        }

        /// <summary> Initializes a new instance of OnvifDevice. </summary>
        /// <param name="hostname"> The hostname of the ONVIF device. </param>
        /// <param name="systemDateTime"> The system date and time of the ONVIF device. </param>
        /// <param name="dns"> The ONVIF device DNS properties. </param>
        /// <param name="mediaProfiles"> An array of of ONVIF media profiles supported by the ONVIF device. </param>
        /// <returns> A new <see cref="Models.OnvifDevice"/> instance for mocking. </returns>
        public static OnvifDevice OnvifDevice(OnvifHostName hostname = null, OnvifSystemDateTime systemDateTime = null, OnvifDns dns = null, IEnumerable<MediaProfile> mediaProfiles = null)
        {
            mediaProfiles ??= new List<MediaProfile>();

            return new OnvifDevice(hostname, systemDateTime, dns, mediaProfiles?.ToList());
        }

        /// <summary> Initializes a new instance of OnvifHostName. </summary>
        /// <param name="fromDhcp"> Result value showing if the ONVIF device is configured to use DHCP. </param>
        /// <param name="hostname"> The hostname of the ONVIF device. </param>
        /// <returns> A new <see cref="Models.OnvifHostName"/> instance for mocking. </returns>
        public static OnvifHostName OnvifHostName(bool? fromDhcp = null, string hostname = null)
        {
            return new OnvifHostName(fromDhcp, hostname);
        }

        /// <summary> Initializes a new instance of OnvifSystemDateTime. </summary>
        /// <param name="type"> An enum value determining whether the date time was configured using NTP or manual. </param>
        /// <param name="time"> The device datetime returned when calling the request. </param>
        /// <param name="timeZone"> The timezone of the ONVIF device datetime. </param>
        /// <returns> A new <see cref="Models.OnvifSystemDateTime"/> instance for mocking. </returns>
        public static OnvifSystemDateTime OnvifSystemDateTime(OnvifSystemDateTimeType? type = null, string time = null, string timeZone = null)
        {
            return new OnvifSystemDateTime(type, time, timeZone);
        }

        /// <summary> Initializes a new instance of OnvifDns. </summary>
        /// <param name="fromDhcp"> Result value showing if the ONVIF device is configured to use DHCP. </param>
        /// <param name="ipv4Address"> An array of IPv4 address for the discovered ONVIF device. </param>
        /// <param name="ipv6Address"> An array of IPv6 address for the discovered ONVIF device. </param>
        /// <returns> A new <see cref="Models.OnvifDns"/> instance for mocking. </returns>
        public static OnvifDns OnvifDns(bool? fromDhcp = null, IEnumerable<string> ipv4Address = null, IEnumerable<string> ipv6Address = null)
        {
            ipv4Address ??= new List<string>();
            ipv6Address ??= new List<string>();

            return new OnvifDns(fromDhcp, ipv4Address?.ToList(), ipv6Address?.ToList());
        }

        /// <summary> Initializes a new instance of MediaProfile. </summary>
        /// <param name="name"> The name of the Media Profile. </param>
        /// <param name="mediaUri"> Object representing the URI that will be used to request for media streaming. </param>
        /// <param name="videoEncoderConfiguration"> The Video encoder configuration. </param>
        /// <returns> A new <see cref="Models.MediaProfile"/> instance for mocking. </returns>
        public static MediaProfile MediaProfile(string name = null, object mediaUri = null, VideoEncoderConfiguration videoEncoderConfiguration = null)
        {
            return new MediaProfile(name, mediaUri, videoEncoderConfiguration);
        }

        /// <summary> Initializes a new instance of VideoEncoderConfiguration. </summary>
        /// <param name="encoding"> The video codec used by the Media Profile. </param>
        /// <param name="quality"> Relative value representing the quality of the video. </param>
        /// <param name="resolution"> The Video Resolution. </param>
        /// <param name="rateControl"> The Video&apos;s rate control. </param>
        /// <param name="h264"> The H264 Configuration. </param>
        /// <param name="mpeg4"> The H264 Configuration. </param>
        /// <returns> A new <see cref="Models.VideoEncoderConfiguration"/> instance for mocking. </returns>
        public static VideoEncoderConfiguration VideoEncoderConfiguration(VideoEncoding? encoding = null, float? quality = null, VideoResolution resolution = null, RateControl rateControl = null, H264Configuration h264 = null, Mpeg4Configuration mpeg4 = null)
        {
            return new VideoEncoderConfiguration(encoding, quality, resolution, rateControl, h264, mpeg4);
        }

        /// <summary> Initializes a new instance of VideoResolution. </summary>
        /// <param name="width"> The number of columns of the Video image. </param>
        /// <param name="height"> The number of lines of the Video image. </param>
        /// <returns> A new <see cref="Models.VideoResolution"/> instance for mocking. </returns>
        public static VideoResolution VideoResolution(float? width = null, float? height = null)
        {
            return new VideoResolution(width, height);
        }

        /// <summary> Initializes a new instance of RateControl. </summary>
        /// <param name="bitRateLimit"> the maximum output bitrate in kbps. </param>
        /// <param name="encodingInterval"> Interval at which images are encoded and transmitted. </param>
        /// <param name="frameRateLimit"> Maximum output framerate in fps. </param>
        /// <param name="guaranteedFrameRate"> A value of true indicates that frame rate is a fixed value rather than an upper limit, and that the video encoder shall prioritize frame rate over all other adaptable configuration values such as bitrate. </param>
        /// <returns> A new <see cref="Models.RateControl"/> instance for mocking. </returns>
        public static RateControl RateControl(float? bitRateLimit = null, float? encodingInterval = null, float? frameRateLimit = null, bool? guaranteedFrameRate = null)
        {
            return new RateControl(bitRateLimit, encodingInterval, frameRateLimit, guaranteedFrameRate);
        }

        /// <summary> Initializes a new instance of H264Configuration. </summary>
        /// <param name="govLength"> Group of Video frames length. </param>
        /// <param name="profile"> The H264 Profile. </param>
        /// <returns> A new <see cref="Models.H264Configuration"/> instance for mocking. </returns>
        public static H264Configuration H264Configuration(float? govLength = null, H264Profile? profile = null)
        {
            return new H264Configuration(govLength, profile);
        }

        /// <summary> Initializes a new instance of Mpeg4Configuration. </summary>
        /// <param name="govLength"> Group of Video frames length. </param>
        /// <param name="profile"> The MPEG4 Profile. </param>
        /// <returns> A new <see cref="Models.Mpeg4Configuration"/> instance for mocking. </returns>
        public static Mpeg4Configuration Mpeg4Configuration(float? govLength = null, Mpeg4Profile? profile = null)
        {
            return new Mpeg4Configuration(govLength, profile);
        }

        /// <summary> Initializes a new instance of MediaUri. </summary>
        /// <param name="uri"> URI that can be used for media streaming. </param>
        /// <returns> A new <see cref="Models.MediaUri"/> instance for mocking. </returns>
        public static MediaUri MediaUri(string uri = null)
        {
            return new MediaUri(uri);
        }

        /// <summary> Initializes a new instance of MethodRequest. </summary>
        /// <param name="methodName"> Direct method method name. </param>
        /// <param name="apiVersion"> Video Analyzer API version. </param>
        /// <returns> A new <see cref="Models.MethodRequest"/> instance for mocking. </returns>
        public static MethodRequest MethodRequest(string methodName = null, string apiVersion = null)
        {
            return new UnknownMethodRequest(methodName, apiVersion);
        }

        /// <summary> Initializes a new instance of PipelineTopologySetRequest. </summary>
        /// <param name="apiVersion"> Video Analyzer API version. </param>
        /// <param name="pipelineTopology">
        /// Pipeline topology describes the processing steps to be applied when processing media for a particular outcome. The topology should be defined according to the scenario to be achieved and can be reused across many pipeline instances which share the same processing characteristics. For instance, a pipeline topology which acquires data from a RTSP camera, process it with an specific AI model and stored the data on the cloud can be reused across many different cameras, as long as the same processing should be applied across all the cameras. Individual instance properties can be defined through the use of user-defined parameters, which allow for a topology to be parameterized, thus allowing individual pipelines to refer to different values, such as individual cameras RTSP endpoints and credentials. Overall a topology is composed of the following:
        /// 
        ///   - Parameters: list of user defined parameters that can be references across the topology nodes.
        ///   - Sources: list of one or more data sources nodes such as an RTSP source which allows for media to be ingested from cameras.
        ///   - Processors: list of nodes which perform data analysis or transformations.
        ///   -Sinks: list of one or more data sinks which allow for data to be stored or exported to other destinations.
        /// </param>
        /// <returns> A new <see cref="Models.PipelineTopologySetRequest"/> instance for mocking. </returns>
        public static PipelineTopologySetRequest PipelineTopologySetRequest(string apiVersion = null, PipelineTopology pipelineTopology = null)
        {
            return new PipelineTopologySetRequest("pipelineTopologySet", apiVersion, pipelineTopology);
        }

        /// <summary> Initializes a new instance of LivePipelineSetRequest. </summary>
        /// <param name="apiVersion"> Video Analyzer API version. </param>
        /// <param name="livePipeline"> Live Pipeline represents an unique instance of a pipeline topology which is used for real-time content ingestion and analysis. </param>
        /// <returns> A new <see cref="Models.LivePipelineSetRequest"/> instance for mocking. </returns>
        public static LivePipelineSetRequest LivePipelineSetRequest(string apiVersion = null, LivePipeline livePipeline = null)
        {
            return new LivePipelineSetRequest("livePipelineSet", apiVersion, livePipeline);
        }

        /// <summary> Initializes a new instance of MethodRequestEmptyBodyBase. </summary>
        /// <param name="apiVersion"> Video Analyzer API version. </param>
        /// <param name="name"> Resource name. </param>
        /// <returns> A new <see cref="Models.MethodRequestEmptyBodyBase"/> instance for mocking. </returns>
        public static MethodRequestEmptyBodyBase MethodRequestEmptyBodyBase(string apiVersion = null, string name = null)
        {
            return new MethodRequestEmptyBodyBase("MethodRequestEmptyBodyBase", apiVersion, name);
        }

        /// <summary> Initializes a new instance of PipelineTopologyListRequest. </summary>
        /// <param name="apiVersion"> Video Analyzer API version. </param>
        /// <returns> A new <see cref="Models.PipelineTopologyListRequest"/> instance for mocking. </returns>
        public static PipelineTopologyListRequest PipelineTopologyListRequest(string apiVersion = null)
        {
            return new PipelineTopologyListRequest("pipelineTopologyList", apiVersion);
        }

        /// <summary> Initializes a new instance of PipelineTopologyGetRequest. </summary>
        /// <param name="apiVersion"> Video Analyzer API version. </param>
        /// <param name="name"> Resource name. </param>
        /// <returns> A new <see cref="Models.PipelineTopologyGetRequest"/> instance for mocking. </returns>
        public static PipelineTopologyGetRequest PipelineTopologyGetRequest(string apiVersion = null, string name = null)
        {
            return new PipelineTopologyGetRequest("pipelineTopologyGet", apiVersion, name);
        }

        /// <summary> Initializes a new instance of PipelineTopologyDeleteRequest. </summary>
        /// <param name="apiVersion"> Video Analyzer API version. </param>
        /// <param name="name"> Resource name. </param>
        /// <returns> A new <see cref="Models.PipelineTopologyDeleteRequest"/> instance for mocking. </returns>
        public static PipelineTopologyDeleteRequest PipelineTopologyDeleteRequest(string apiVersion = null, string name = null)
        {
            return new PipelineTopologyDeleteRequest("pipelineTopologyDelete", apiVersion, name);
        }

        /// <summary> Initializes a new instance of LivePipelineListRequest. </summary>
        /// <param name="apiVersion"> Video Analyzer API version. </param>
        /// <returns> A new <see cref="Models.LivePipelineListRequest"/> instance for mocking. </returns>
        public static LivePipelineListRequest LivePipelineListRequest(string apiVersion = null)
        {
            return new LivePipelineListRequest("livePipelineList", apiVersion);
        }

        /// <summary> Initializes a new instance of LivePipelineGetRequest. </summary>
        /// <param name="apiVersion"> Video Analyzer API version. </param>
        /// <param name="name"> Resource name. </param>
        /// <returns> A new <see cref="Models.LivePipelineGetRequest"/> instance for mocking. </returns>
        public static LivePipelineGetRequest LivePipelineGetRequest(string apiVersion = null, string name = null)
        {
            return new LivePipelineGetRequest("livePipelineGet", apiVersion, name);
        }

        /// <summary> Initializes a new instance of LivePipelineActivateRequest. </summary>
        /// <param name="apiVersion"> Video Analyzer API version. </param>
        /// <param name="name"> Resource name. </param>
        /// <returns> A new <see cref="Models.LivePipelineActivateRequest"/> instance for mocking. </returns>
        public static LivePipelineActivateRequest LivePipelineActivateRequest(string apiVersion = null, string name = null)
        {
            return new LivePipelineActivateRequest("livePipelineActivate", apiVersion, name);
        }

        /// <summary> Initializes a new instance of LivePipelineDeactivateRequest. </summary>
        /// <param name="apiVersion"> Video Analyzer API version. </param>
        /// <param name="name"> Resource name. </param>
        /// <returns> A new <see cref="Models.LivePipelineDeactivateRequest"/> instance for mocking. </returns>
        public static LivePipelineDeactivateRequest LivePipelineDeactivateRequest(string apiVersion = null, string name = null)
        {
            return new LivePipelineDeactivateRequest("livePipelineDeactivate", apiVersion, name);
        }

        /// <summary> Initializes a new instance of LivePipelineDeleteRequest. </summary>
        /// <param name="apiVersion"> Video Analyzer API version. </param>
        /// <param name="name"> Resource name. </param>
        /// <returns> A new <see cref="Models.LivePipelineDeleteRequest"/> instance for mocking. </returns>
        public static LivePipelineDeleteRequest LivePipelineDeleteRequest(string apiVersion = null, string name = null)
        {
            return new LivePipelineDeleteRequest("livePipelineDelete", apiVersion, name);
        }

        /// <summary> Initializes a new instance of RemoteDeviceAdapterSetRequest. </summary>
        /// <param name="apiVersion"> Video Analyzer API version. </param>
        /// <param name="remoteDeviceAdapter"> The Video Analyzer edge module can act as a transparent gateway for video, enabling IoT devices to send video to the cloud from behind a firewall. A remote device adapter should be created for each such IoT device. Communication between the cloud and IoT device would then flow via the Video Analyzer edge module. </param>
        /// <returns> A new <see cref="Models.RemoteDeviceAdapterSetRequest"/> instance for mocking. </returns>
        public static RemoteDeviceAdapterSetRequest RemoteDeviceAdapterSetRequest(string apiVersion = null, RemoteDeviceAdapter remoteDeviceAdapter = null)
        {
            return new RemoteDeviceAdapterSetRequest("remoteDeviceAdapterSet", apiVersion, remoteDeviceAdapter);
        }

        /// <summary> Initializes a new instance of RemoteDeviceAdapterListRequest. </summary>
        /// <param name="apiVersion"> Video Analyzer API version. </param>
        /// <returns> A new <see cref="Models.RemoteDeviceAdapterListRequest"/> instance for mocking. </returns>
        public static RemoteDeviceAdapterListRequest RemoteDeviceAdapterListRequest(string apiVersion = null)
        {
            return new RemoteDeviceAdapterListRequest("remoteDeviceAdapterList", apiVersion);
        }

        /// <summary> Initializes a new instance of RemoteDeviceAdapterGetRequest. </summary>
        /// <param name="apiVersion"> Video Analyzer API version. </param>
        /// <param name="name"> Resource name. </param>
        /// <returns> A new <see cref="Models.RemoteDeviceAdapterGetRequest"/> instance for mocking. </returns>
        public static RemoteDeviceAdapterGetRequest RemoteDeviceAdapterGetRequest(string apiVersion = null, string name = null)
        {
            return new RemoteDeviceAdapterGetRequest("remoteDeviceAdapterGet", apiVersion, name);
        }

        /// <summary> Initializes a new instance of RemoteDeviceAdapterDeleteRequest. </summary>
        /// <param name="apiVersion"> Video Analyzer API version. </param>
        /// <param name="name"> Resource name. </param>
        /// <returns> A new <see cref="Models.RemoteDeviceAdapterDeleteRequest"/> instance for mocking. </returns>
        public static RemoteDeviceAdapterDeleteRequest RemoteDeviceAdapterDeleteRequest(string apiVersion = null, string name = null)
        {
            return new RemoteDeviceAdapterDeleteRequest("remoteDeviceAdapterDelete", apiVersion, name);
        }

        /// <summary> Initializes a new instance of OnvifDeviceDiscoverRequest. </summary>
        /// <param name="apiVersion"> Video Analyzer API version. </param>
        /// <param name="discoveryDuration"> The amount of time that the ONVIF device discovery will wait for supported device responses. </param>
        /// <returns> A new <see cref="Models.OnvifDeviceDiscoverRequest"/> instance for mocking. </returns>
        public static OnvifDeviceDiscoverRequest OnvifDeviceDiscoverRequest(string apiVersion = null, string discoveryDuration = null)
        {
            return new OnvifDeviceDiscoverRequest("onvifDeviceDiscover", apiVersion, discoveryDuration);
        }

        /// <summary> Initializes a new instance of OnvifDeviceGetRequest. </summary>
        /// <param name="apiVersion"> Video Analyzer API version. </param>
        /// <param name="endpoint">
        /// Base class for endpoints.
        /// Please note <see cref="EndpointBase"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="TlsEndpoint"/> and <see cref="UnsecuredEndpoint"/>.
        /// </param>
        /// <returns> A new <see cref="Models.OnvifDeviceGetRequest"/> instance for mocking. </returns>
        public static OnvifDeviceGetRequest OnvifDeviceGetRequest(string apiVersion = null, EndpointBase endpoint = null)
        {
            return new OnvifDeviceGetRequest("onvifDeviceGet", apiVersion, endpoint);
        }
    }
}

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.

// <auto-generated/>

#nullable disable

using System;
using System.Collections.Generic;
using System.Linq;
using Azure.Core;

namespace Azure.Communication.CallAutomation
{
    /// <summary> Options of live transcription. </summary>
    public partial class TranscriptionOptions
    {
        /// <summary> Initializes a new instance of <see cref="TranscriptionOptions"/>. </summary>
        /// <param name="locale"> Defines the locale for the data e.g en-CA, en-AU. </param>
        /// <param name="streamingTransport"> Transport URL for live transcription. </param>
        public TranscriptionOptions(string locale, StreamingTransport streamingTransport = default)
        {
            Locale = locale;
            TranscriptionTransport = streamingTransport == default ? StreamingTransport.Websocket : streamingTransport;
        }

        /// <summary> Initializes a new instance of <see cref="TranscriptionOptions"/>. </summary>
        /// <param name="streamingTransport"> Transport URL for live transcription. </param>
        public TranscriptionOptions(StreamingTransport streamingTransport = default)
        {
            TranscriptionTransport = streamingTransport == default ? StreamingTransport.Websocket : streamingTransport;
        }

        /// <summary> Transport URL for live transcription. </summary>
        public Uri TransportUri { get; set; }
        /// <summary> The type of transport to be used for live transcription, eg. Websocket. </summary>
        public StreamingTransport TranscriptionTransport { get; set; }
        /// <summary> Defines the locale for the data e.g en-CA, en-AU. </summary>
        public string Locale { get; }
        /// <summary> Determines if the transcription should be started immediately after call is answered or not. </summary>
        public bool? StartTranscription { get; set; }
        /// <summary> Endpoint where the custom model was deployed. </summary>
        public string SpeechRecognitionModelEndpointId { get; set; }
        /// <summary> Enables intermediate results for the transcribed speech. </summary>
        public bool? EnableIntermediateResults { get; set; }
        /// <summary> PII redaction configuration options. </summary>
        public PiiRedactionOptions PiiRedactionOptions { get; set; }
        /// <summary> Indicating if sentiment analysis should be used. </summary>
        public bool? EnableSentimentAnalysis { get; set; }
        /// <summary>  List of locales for Language Identification. Supports upto 4 locales in the format: ["en-us", "fr-fr", "hi-in"] etc. </summary>
        public IList<string> Locales { get; set; }
        /// <summary> Summarization configuration options. </summary>
        public SummarizationOptions SummarizationOptions { get; set; }
    }
}

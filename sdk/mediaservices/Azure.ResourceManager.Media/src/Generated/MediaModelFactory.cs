// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.

// <auto-generated/>

#nullable disable

using System;
using System.Collections.Generic;
using System.Linq;
using System.Net;
using Azure.Core;
using Azure.ResourceManager.Media;
using Azure.ResourceManager.Models;
using Azure.ResourceManager.Resources.Models;

namespace Azure.ResourceManager.Media.Models
{
    /// <summary> Model factory for generated models. </summary>
    public static partial class MediaModelFactory
    {
        /// <summary> Initializes a new instance of MediaServicesAccountFilterData. </summary>
        /// <param name="id"> The id. </param>
        /// <param name="name"> The name. </param>
        /// <param name="resourceType"> The resourceType. </param>
        /// <param name="systemData"> The systemData. </param>
        /// <param name="presentationTimeRange"> The presentation time range. </param>
        /// <param name="firstQualityBitrate"> The first quality. </param>
        /// <param name="tracks"> The tracks selection conditions. </param>
        /// <returns> A new <see cref="Media.MediaServicesAccountFilterData"/> instance for mocking. </returns>
        public static MediaServicesAccountFilterData MediaServicesAccountFilterData(ResourceIdentifier id = null, string name = null, ResourceType resourceType = default, SystemData systemData = null, PresentationTimeRange presentationTimeRange = null, int firstQualityBitrate = default, IEnumerable<FilterTrackSelection> tracks = null)
        {
            tracks ??= new List<FilterTrackSelection>();

            return new MediaServicesAccountFilterData(id, name, resourceType, systemData, presentationTimeRange, new FirstQuality(firstQualityBitrate), tracks?.ToList());
        }

        /// <summary> Initializes a new instance of PresentationTimeRange. </summary>
        /// <param name="startTimestamp"> The absolute start time boundary. </param>
        /// <param name="endTimestamp"> The absolute end time boundary. </param>
        /// <param name="presentationWindowDuration"> The relative to end sliding window. </param>
        /// <param name="liveBackoffDuration"> The relative to end right edge. </param>
        /// <param name="timescale"> The time scale of time stamps. </param>
        /// <param name="forceEndTimestamp"> The indicator of forcing existing of end time stamp. </param>
        /// <returns> A new <see cref="Models.PresentationTimeRange"/> instance for mocking. </returns>
        public static PresentationTimeRange PresentationTimeRange(long? startTimestamp = null, long? endTimestamp = null, long? presentationWindowDuration = null, long? liveBackoffDuration = null, long? timescale = null, bool? forceEndTimestamp = null)
        {
            return new PresentationTimeRange(startTimestamp, endTimestamp, presentationWindowDuration, liveBackoffDuration, timescale, forceEndTimestamp);
        }

        /// <summary> Initializes a new instance of MediaServicesAccountData. </summary>
        /// <param name="id"> The id. </param>
        /// <param name="name"> The name. </param>
        /// <param name="resourceType"> The resourceType. </param>
        /// <param name="systemData"> The systemData. </param>
        /// <param name="tags"> The tags. </param>
        /// <param name="location"> The location. </param>
        /// <param name="identity"> The Managed Identity for the Media Services account. </param>
        /// <param name="mediaServicesAccountId"> The Media Services account ID. </param>
        /// <param name="storageAccounts"> The storage accounts for this resource. </param>
        /// <param name="storageAuthentication"></param>
        /// <param name="encryption"> The account encryption properties. </param>
        /// <param name="keyDeliveryAccessControl"> The Key Delivery properties for Media Services account. </param>
        /// <param name="publicNetworkAccess"> Whether or not public network access is allowed for resources under the Media Services account. </param>
        /// <param name="provisioningState"> Provisioning state of the Media Services account. </param>
        /// <param name="privateEndpointConnections"> The Private Endpoint Connections created for the Media Service account. </param>
        /// <returns> A new <see cref="Media.MediaServicesAccountData"/> instance for mocking. </returns>
        public static MediaServicesAccountData MediaServicesAccountData(ResourceIdentifier id = null, string name = null, ResourceType resourceType = default, SystemData systemData = null, IDictionary<string, string> tags = null, AzureLocation location = default, ManagedServiceIdentity identity = null, Guid? mediaServicesAccountId = null, IEnumerable<MediaServicesStorageAccount> storageAccounts = null, MediaStorageAuthentication? storageAuthentication = null, AccountEncryption encryption = null, MediaAccessControl keyDeliveryAccessControl = null, MediaServicesPublicNetworkAccess? publicNetworkAccess = null, MediaServicesProvisioningState? provisioningState = null, IEnumerable<MediaServicesPrivateEndpointConnectionData> privateEndpointConnections = null)
        {
            tags ??= new Dictionary<string, string>();
            storageAccounts ??= new List<MediaServicesStorageAccount>();
            privateEndpointConnections ??= new List<MediaServicesPrivateEndpointConnectionData>();

            return new MediaServicesAccountData(id, name, resourceType, systemData, tags, location, identity, mediaServicesAccountId, storageAccounts?.ToList(), storageAuthentication, encryption, new MediaKeyDelivery(keyDeliveryAccessControl), publicNetworkAccess, provisioningState, privateEndpointConnections?.ToList());
        }

        /// <summary> Initializes a new instance of MediaServicesStorageAccount. </summary>
        /// <param name="id"> The ID of the storage account resource. Media Services relies on tables and queues as well as blobs, so the primary storage account must be a Standard Storage account (either Microsoft.ClassicStorage or Microsoft.Storage). Blob only storage accounts can be added as secondary storage accounts. </param>
        /// <param name="accountType"> The type of the storage account. </param>
        /// <param name="identity"> The storage account identity. </param>
        /// <param name="status"> The current status of the storage account mapping. </param>
        /// <returns> A new <see cref="Models.MediaServicesStorageAccount"/> instance for mocking. </returns>
        public static MediaServicesStorageAccount MediaServicesStorageAccount(ResourceIdentifier id = null, MediaServicesStorageAccountType accountType = default, ResourceIdentity identity = null, string status = null)
        {
            return new MediaServicesStorageAccount(id, accountType, identity, status);
        }

        /// <summary> Initializes a new instance of ResourceIdentity. </summary>
        /// <param name="userAssignedIdentity"> The user assigned managed identity&apos;s ARM ID to use when accessing a resource. </param>
        /// <param name="useSystemAssignedIdentity"> Indicates whether to use System Assigned Managed Identity. Mutual exclusive with User Assigned Managed Identity. </param>
        /// <returns> A new <see cref="Models.ResourceIdentity"/> instance for mocking. </returns>
        public static ResourceIdentity ResourceIdentity(string userAssignedIdentity = null, bool useSystemAssignedIdentity = default)
        {
            return new ResourceIdentity(userAssignedIdentity, useSystemAssignedIdentity);
        }

        /// <summary> Initializes a new instance of AccountEncryption. </summary>
        /// <param name="keyType"> The type of key used to encrypt the Account Key. </param>
        /// <param name="keyVaultProperties"> The properties of the key used to encrypt the account. </param>
        /// <param name="identity"> The Key Vault identity. </param>
        /// <param name="status"> The current status of the Key Vault mapping. </param>
        /// <returns> A new <see cref="Models.AccountEncryption"/> instance for mocking. </returns>
        public static AccountEncryption AccountEncryption(AccountEncryptionKeyType keyType = default, KeyVaultProperties keyVaultProperties = null, ResourceIdentity identity = null, string status = null)
        {
            return new AccountEncryption(keyType, keyVaultProperties, identity, status);
        }

        /// <summary> Initializes a new instance of KeyVaultProperties. </summary>
        /// <param name="keyIdentifier"> The URL of the Key Vault key used to encrypt the account. The key may either be versioned (for example https://vault/keys/mykey/version1) or reference a key without a version (for example https://vault/keys/mykey). </param>
        /// <param name="currentKeyIdentifier"> The current key used to encrypt the Media Services account, including the key version. </param>
        /// <returns> A new <see cref="Models.KeyVaultProperties"/> instance for mocking. </returns>
        public static KeyVaultProperties KeyVaultProperties(string keyIdentifier = null, string currentKeyIdentifier = null)
        {
            return new KeyVaultProperties(keyIdentifier, currentKeyIdentifier);
        }

        /// <summary> Initializes a new instance of MediaAccessControl. </summary>
        /// <param name="defaultAction"> The behavior for IP access control in Key Delivery. </param>
        /// <param name="ipAllowList"> The IP allow list for access control in Key Delivery. If the default action is set to &apos;Allow&apos;, the IP allow list must be empty. </param>
        /// <returns> A new <see cref="Models.MediaAccessControl"/> instance for mocking. </returns>
        public static MediaAccessControl MediaAccessControl(IPAccessControlDefaultAction? defaultAction = null, IEnumerable<IPAddress> ipAllowList = null)
        {
            ipAllowList ??= new List<IPAddress>();

            return new MediaAccessControl(defaultAction, ipAllowList?.ToList());
        }

        /// <summary> Initializes a new instance of MediaServicesPrivateEndpointConnectionData. </summary>
        /// <param name="id"> The id. </param>
        /// <param name="name"> The name. </param>
        /// <param name="resourceType"> The resourceType. </param>
        /// <param name="systemData"> The systemData. </param>
        /// <param name="privateEndpointId"> The resource of private end point. </param>
        /// <param name="connectionState"> A collection of information about the state of the connection between service consumer and provider. </param>
        /// <param name="provisioningState"> The provisioning state of the private endpoint connection resource. </param>
        /// <returns> A new <see cref="Media.MediaServicesPrivateEndpointConnectionData"/> instance for mocking. </returns>
        public static MediaServicesPrivateEndpointConnectionData MediaServicesPrivateEndpointConnectionData(ResourceIdentifier id = null, string name = null, ResourceType resourceType = default, SystemData systemData = null, ResourceIdentifier privateEndpointId = null, MediaPrivateLinkServiceConnectionState connectionState = null, MediaPrivateEndpointConnectionProvisioningState? provisioningState = null)
        {
            return new MediaServicesPrivateEndpointConnectionData(id, name, resourceType, systemData, ResourceManagerModelFactory.SubResource(privateEndpointId), connectionState, provisioningState);
        }

        /// <summary> Initializes a new instance of MediaPrivateLinkServiceConnectionState. </summary>
        /// <param name="status"> Indicates whether the connection has been Approved/Rejected/Removed by the owner of the service. </param>
        /// <param name="description"> The reason for approval/rejection of the connection. </param>
        /// <param name="actionsRequired"> A message indicating if changes on the service provider require any updates on the consumer. </param>
        /// <returns> A new <see cref="Models.MediaPrivateLinkServiceConnectionState"/> instance for mocking. </returns>
        public static MediaPrivateLinkServiceConnectionState MediaPrivateLinkServiceConnectionState(MediaPrivateEndpointServiceConnectionStatus? status = null, string description = null, string actionsRequired = null)
        {
            return new MediaPrivateLinkServiceConnectionState(status, description, actionsRequired);
        }

        /// <summary> Initializes a new instance of MediaServicesEdgePolicies. </summary>
        /// <param name="usageDataCollectionPolicy"></param>
        /// <returns> A new <see cref="Models.MediaServicesEdgePolicies"/> instance for mocking. </returns>
        public static MediaServicesEdgePolicies MediaServicesEdgePolicies(EdgeUsageDataCollectionPolicy usageDataCollectionPolicy = null)
        {
            return new MediaServicesEdgePolicies(usageDataCollectionPolicy);
        }

        /// <summary> Initializes a new instance of EdgeUsageDataCollectionPolicy. </summary>
        /// <param name="dataCollectionFrequency"> Usage data collection frequency in ISO 8601 duration format e.g. PT10M , PT5H. </param>
        /// <param name="dataReportingFrequency"> Usage data reporting frequency in ISO 8601 duration format e.g. PT10M , PT5H. </param>
        /// <param name="maxAllowedUnreportedUsageDuration"> Maximum time for which the functionality of the device will not be hampered for not reporting the usage data. </param>
        /// <param name="eventHubDetails"> Details of Event Hub where the usage will be reported. </param>
        /// <returns> A new <see cref="Models.EdgeUsageDataCollectionPolicy"/> instance for mocking. </returns>
        public static EdgeUsageDataCollectionPolicy EdgeUsageDataCollectionPolicy(string dataCollectionFrequency = null, string dataReportingFrequency = null, TimeSpan? maxAllowedUnreportedUsageDuration = null, EdgeUsageDataEventHub eventHubDetails = null)
        {
            return new EdgeUsageDataCollectionPolicy(dataCollectionFrequency, dataReportingFrequency, maxAllowedUnreportedUsageDuration, eventHubDetails);
        }

        /// <summary> Initializes a new instance of EdgeUsageDataEventHub. </summary>
        /// <param name="name"> Name of the Event Hub where usage will be reported. </param>
        /// <param name="namespace"> Namespace of the Event Hub where usage will be reported. </param>
        /// <param name="token"> SAS token needed to interact with Event Hub. </param>
        /// <returns> A new <see cref="Models.EdgeUsageDataEventHub"/> instance for mocking. </returns>
        public static EdgeUsageDataEventHub EdgeUsageDataEventHub(string name = null, string @namespace = null, string token = null)
        {
            return new EdgeUsageDataEventHub(name, @namespace, token);
        }

        /// <summary> Initializes a new instance of MediaServicesPrivateLinkResourceData. </summary>
        /// <param name="id"> The id. </param>
        /// <param name="name"> The name. </param>
        /// <param name="resourceType"> The resourceType. </param>
        /// <param name="systemData"> The systemData. </param>
        /// <param name="groupId"> The private link resource group id. </param>
        /// <param name="requiredMembers"> The private link resource required member names. </param>
        /// <param name="requiredZoneNames"> The private link resource Private link DNS zone name. </param>
        /// <returns> A new <see cref="Media.MediaServicesPrivateLinkResourceData"/> instance for mocking. </returns>
        public static MediaServicesPrivateLinkResourceData MediaServicesPrivateLinkResourceData(ResourceIdentifier id = null, string name = null, ResourceType resourceType = default, SystemData systemData = null, string groupId = null, IEnumerable<string> requiredMembers = null, IEnumerable<string> requiredZoneNames = null)
        {
            requiredMembers ??= new List<string>();
            requiredZoneNames ??= new List<string>();

            return new MediaServicesPrivateLinkResourceData(id, name, resourceType, systemData, groupId, requiredMembers?.ToList(), requiredZoneNames?.ToList());
        }

        /// <summary> Initializes a new instance of MediaServicesNameAvailabilityResult. </summary>
        /// <param name="isNameAvailable"> Specifies if the name is available. </param>
        /// <param name="reason"> Specifies the reason if the name is not available. </param>
        /// <param name="message"> Specifies the detailed reason if the name is not available. </param>
        /// <returns> A new <see cref="Models.MediaServicesNameAvailabilityResult"/> instance for mocking. </returns>
        public static MediaServicesNameAvailabilityResult MediaServicesNameAvailabilityResult(bool isNameAvailable = default, string reason = null, string message = null)
        {
            return new MediaServicesNameAvailabilityResult(isNameAvailable, reason, message);
        }

        /// <summary> Initializes a new instance of MediaAssetData. </summary>
        /// <param name="id"> The id. </param>
        /// <param name="name"> The name. </param>
        /// <param name="resourceType"> The resourceType. </param>
        /// <param name="systemData"> The systemData. </param>
        /// <param name="assetId"> The Asset ID. </param>
        /// <param name="createdOn"> The creation date of the Asset. </param>
        /// <param name="lastModifiedOn"> The last modified date of the Asset. </param>
        /// <param name="alternateId"> The alternate ID of the Asset. </param>
        /// <param name="description"> The Asset description. </param>
        /// <param name="container"> The name of the asset blob container. </param>
        /// <param name="storageAccountName"> The name of the storage account. </param>
        /// <param name="storageEncryptionFormat"> The Asset encryption format. One of None or MediaStorageEncryption. </param>
        /// <returns> A new <see cref="Media.MediaAssetData"/> instance for mocking. </returns>
        public static MediaAssetData MediaAssetData(ResourceIdentifier id = null, string name = null, ResourceType resourceType = default, SystemData systemData = null, Guid? assetId = null, DateTimeOffset? createdOn = null, DateTimeOffset? lastModifiedOn = null, string alternateId = null, string description = null, string container = null, string storageAccountName = null, MediaAssetStorageEncryptionFormat? storageEncryptionFormat = null)
        {
            return new MediaAssetData(id, name, resourceType, systemData, assetId, createdOn, lastModifiedOn, alternateId, description, container, storageAccountName, storageEncryptionFormat);
        }

        /// <summary> Initializes a new instance of StorageEncryptedAssetDecryptionInfo. </summary>
        /// <param name="key"> The Asset File storage encryption key. </param>
        /// <param name="assetFileEncryptionMetadata"> Asset File encryption metadata. </param>
        /// <returns> A new <see cref="Models.StorageEncryptedAssetDecryptionInfo"/> instance for mocking. </returns>
        public static StorageEncryptedAssetDecryptionInfo StorageEncryptedAssetDecryptionInfo(byte[] key = null, IEnumerable<MediaAssetFileEncryptionMetadata> assetFileEncryptionMetadata = null)
        {
            assetFileEncryptionMetadata ??= new List<MediaAssetFileEncryptionMetadata>();

            return new StorageEncryptedAssetDecryptionInfo(key, assetFileEncryptionMetadata?.ToList());
        }

        /// <summary> Initializes a new instance of MediaAssetFileEncryptionMetadata. </summary>
        /// <param name="initializationVector"> The Asset File initialization vector. </param>
        /// <param name="assetFileName"> The Asset File name. </param>
        /// <param name="assetFileId"> The Asset File Id. </param>
        /// <returns> A new <see cref="Models.MediaAssetFileEncryptionMetadata"/> instance for mocking. </returns>
        public static MediaAssetFileEncryptionMetadata MediaAssetFileEncryptionMetadata(string initializationVector = null, string assetFileName = null, Guid assetFileId = default)
        {
            return new MediaAssetFileEncryptionMetadata(initializationVector, assetFileName, assetFileId);
        }

        /// <summary> Initializes a new instance of MediaAssetStreamingLocator. </summary>
        /// <param name="name"> Streaming Locator name. </param>
        /// <param name="assetName"> Asset Name. </param>
        /// <param name="createdOn"> The creation time of the Streaming Locator. </param>
        /// <param name="startOn"> The start time of the Streaming Locator. </param>
        /// <param name="endOn"> The end time of the Streaming Locator. </param>
        /// <param name="streamingLocatorId"> StreamingLocatorId of the Streaming Locator. </param>
        /// <param name="streamingPolicyName"> Name of the Streaming Policy used by this Streaming Locator. </param>
        /// <param name="defaultContentKeyPolicyName"> Name of the default ContentKeyPolicy used by this Streaming Locator. </param>
        /// <returns> A new <see cref="Models.MediaAssetStreamingLocator"/> instance for mocking. </returns>
        public static MediaAssetStreamingLocator MediaAssetStreamingLocator(string name = null, string assetName = null, DateTimeOffset? createdOn = null, DateTimeOffset? startOn = null, DateTimeOffset? endOn = null, Guid? streamingLocatorId = null, string streamingPolicyName = null, string defaultContentKeyPolicyName = null)
        {
            return new MediaAssetStreamingLocator(name, assetName, createdOn, startOn, endOn, streamingLocatorId, streamingPolicyName, defaultContentKeyPolicyName);
        }

        /// <summary> Initializes a new instance of MediaAssetFilterData. </summary>
        /// <param name="id"> The id. </param>
        /// <param name="name"> The name. </param>
        /// <param name="resourceType"> The resourceType. </param>
        /// <param name="systemData"> The systemData. </param>
        /// <param name="presentationTimeRange"> The presentation time range. </param>
        /// <param name="firstQualityBitrate"> The first quality. </param>
        /// <param name="tracks"> The tracks selection conditions. </param>
        /// <returns> A new <see cref="Media.MediaAssetFilterData"/> instance for mocking. </returns>
        public static MediaAssetFilterData MediaAssetFilterData(ResourceIdentifier id = null, string name = null, ResourceType resourceType = default, SystemData systemData = null, PresentationTimeRange presentationTimeRange = null, int firstQualityBitrate = default, IEnumerable<FilterTrackSelection> tracks = null)
        {
            tracks ??= new List<FilterTrackSelection>();

            return new MediaAssetFilterData(id, name, resourceType, systemData, presentationTimeRange, new FirstQuality(firstQualityBitrate), tracks?.ToList());
        }

        /// <summary> Initializes a new instance of MediaAssetTrackData. </summary>
        /// <param name="id"> The id. </param>
        /// <param name="name"> The name. </param>
        /// <param name="resourceType"> The resourceType. </param>
        /// <param name="systemData"> The systemData. </param>
        /// <param name="track">
        /// Detailed information about a track in the asset.
        /// Please note <see cref="MediaAssetTrackBase"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="AudioTrack"/>, <see cref="TextTrack"/> and <see cref="VideoTrack"/>.
        /// </param>
        /// <param name="provisioningState"> Provisioning state of the asset track. </param>
        /// <returns> A new <see cref="Media.MediaAssetTrackData"/> instance for mocking. </returns>
        public static MediaAssetTrackData MediaAssetTrackData(ResourceIdentifier id = null, string name = null, ResourceType resourceType = default, SystemData systemData = null, MediaAssetTrackBase track = null, MediaServicesProvisioningState? provisioningState = null)
        {
            return new MediaAssetTrackData(id, name, resourceType, systemData, track, provisioningState);
        }

        /// <summary> Initializes a new instance of MediaAssetTrackBase. </summary>
        /// <param name="odataType"> The discriminator for derived types. </param>
        /// <returns> A new <see cref="Models.MediaAssetTrackBase"/> instance for mocking. </returns>
        public static MediaAssetTrackBase MediaAssetTrackBase(string odataType = null)
        {
            return new UnknownTrackBase(odataType);
        }

        /// <summary> Initializes a new instance of ContentKeyPolicyData. </summary>
        /// <param name="id"> The id. </param>
        /// <param name="name"> The name. </param>
        /// <param name="resourceType"> The resourceType. </param>
        /// <param name="systemData"> The systemData. </param>
        /// <param name="policyId"> The legacy Policy ID. </param>
        /// <param name="createdOn"> The creation date of the Policy. </param>
        /// <param name="lastModifiedOn"> The last modified date of the Policy. </param>
        /// <param name="description"> A description for the Policy. </param>
        /// <param name="options"> The Key Policy options. </param>
        /// <returns> A new <see cref="Media.ContentKeyPolicyData"/> instance for mocking. </returns>
        public static ContentKeyPolicyData ContentKeyPolicyData(ResourceIdentifier id = null, string name = null, ResourceType resourceType = default, SystemData systemData = null, Guid? policyId = null, DateTimeOffset? createdOn = null, DateTimeOffset? lastModifiedOn = null, string description = null, IEnumerable<ContentKeyPolicyOption> options = null)
        {
            options ??= new List<ContentKeyPolicyOption>();

            return new ContentKeyPolicyData(id, name, resourceType, systemData, policyId, createdOn, lastModifiedOn, description, options?.ToList());
        }

        /// <summary> Initializes a new instance of ContentKeyPolicyProperties. </summary>
        /// <param name="policyId"> The legacy Policy ID. </param>
        /// <param name="createdOn"> The creation date of the Policy. </param>
        /// <param name="lastModifiedOn"> The last modified date of the Policy. </param>
        /// <param name="description"> A description for the Policy. </param>
        /// <param name="options"> The Key Policy options. </param>
        /// <returns> A new <see cref="Models.ContentKeyPolicyProperties"/> instance for mocking. </returns>
        public static ContentKeyPolicyProperties ContentKeyPolicyProperties(Guid? policyId = null, DateTimeOffset? createdOn = null, DateTimeOffset? lastModifiedOn = null, string description = null, IEnumerable<ContentKeyPolicyOption> options = null)
        {
            options ??= new List<ContentKeyPolicyOption>();

            return new ContentKeyPolicyProperties(policyId, createdOn, lastModifiedOn, description, options?.ToList());
        }

        /// <summary> Initializes a new instance of ContentKeyPolicyOption. </summary>
        /// <param name="policyOptionId"> The legacy Policy Option ID. </param>
        /// <param name="name"> The Policy Option description. </param>
        /// <param name="configuration">
        /// The key delivery configuration.
        /// Please note <see cref="ContentKeyPolicyConfiguration"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="ContentKeyPolicyClearKeyConfiguration"/>, <see cref="ContentKeyPolicyFairPlayConfiguration"/>, <see cref="ContentKeyPolicyPlayReadyConfiguration"/>, <see cref="ContentKeyPolicyUnknownConfiguration"/> and <see cref="ContentKeyPolicyWidevineConfiguration"/>.
        /// </param>
        /// <param name="restriction">
        /// The requirements that must be met to deliver keys with this configuration
        /// Please note <see cref="ContentKeyPolicyRestriction"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="ContentKeyPolicyOpenRestriction"/>, <see cref="ContentKeyPolicyTokenRestriction"/> and <see cref="ContentKeyPolicyUnknownRestriction"/>.
        /// </param>
        /// <returns> A new <see cref="Models.ContentKeyPolicyOption"/> instance for mocking. </returns>
        public static ContentKeyPolicyOption ContentKeyPolicyOption(Guid? policyOptionId = null, string name = null, ContentKeyPolicyConfiguration configuration = null, ContentKeyPolicyRestriction restriction = null)
        {
            return new ContentKeyPolicyOption(policyOptionId, name, configuration, restriction);
        }

        /// <summary> Initializes a new instance of ContentKeyPolicyConfiguration. </summary>
        /// <param name="odataType"> The discriminator for derived types. </param>
        /// <returns> A new <see cref="Models.ContentKeyPolicyConfiguration"/> instance for mocking. </returns>
        public static ContentKeyPolicyConfiguration ContentKeyPolicyConfiguration(string odataType = null)
        {
            return new UnknownContentKeyPolicyConfiguration(odataType);
        }

        /// <summary> Initializes a new instance of ContentKeyPolicyRestriction. </summary>
        /// <param name="odataType"> The discriminator for derived types. </param>
        /// <returns> A new <see cref="Models.ContentKeyPolicyRestriction"/> instance for mocking. </returns>
        public static ContentKeyPolicyRestriction ContentKeyPolicyRestriction(string odataType = null)
        {
            return new UnknownContentKeyPolicyRestriction(odataType);
        }

        /// <summary> Initializes a new instance of MediaTransformData. </summary>
        /// <param name="id"> The id. </param>
        /// <param name="name"> The name. </param>
        /// <param name="resourceType"> The resourceType. </param>
        /// <param name="systemData"> The systemData. </param>
        /// <param name="createdOn"> The UTC date and time when the Transform was created, in &apos;YYYY-MM-DDThh:mm:ssZ&apos; format. </param>
        /// <param name="description"> An optional verbose description of the Transform. </param>
        /// <param name="lastModifiedOn"> The UTC date and time when the Transform was last updated, in &apos;YYYY-MM-DDThh:mm:ssZ&apos; format. </param>
        /// <param name="outputs"> An array of one or more TransformOutputs that the Transform should generate. </param>
        /// <returns> A new <see cref="Media.MediaTransformData"/> instance for mocking. </returns>
        public static MediaTransformData MediaTransformData(ResourceIdentifier id = null, string name = null, ResourceType resourceType = default, SystemData systemData = null, DateTimeOffset? createdOn = null, string description = null, DateTimeOffset? lastModifiedOn = null, IEnumerable<MediaTransformOutput> outputs = null)
        {
            outputs ??= new List<MediaTransformOutput>();

            return new MediaTransformData(id, name, resourceType, systemData, createdOn, description, lastModifiedOn, outputs?.ToList());
        }

        /// <summary> Initializes a new instance of MediaTransformOutput. </summary>
        /// <param name="onError"> A Transform can define more than one outputs. This property defines what the service should do when one output fails - either continue to produce other outputs, or, stop the other outputs. The overall Job state will not reflect failures of outputs that are specified with &apos;ContinueJob&apos;. The default is &apos;StopProcessingJob&apos;. </param>
        /// <param name="relativePriority"> Sets the relative priority of the TransformOutputs within a Transform. This sets the priority that the service uses for processing TransformOutputs. The default priority is Normal. </param>
        /// <param name="preset">
        /// Preset that describes the operations that will be used to modify, transcode, or extract insights from the source file to generate the output.
        /// Please note <see cref="MediaTransformPreset"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="AudioAnalyzerPreset"/>, <see cref="BuiltInStandardEncoderPreset"/>, <see cref="StandardEncoderPreset"/> and <see cref="VideoAnalyzerPreset"/>.
        /// </param>
        /// <returns> A new <see cref="Models.MediaTransformOutput"/> instance for mocking. </returns>
        public static MediaTransformOutput MediaTransformOutput(MediaTransformOnErrorType? onError = null, MediaJobPriority? relativePriority = null, MediaTransformPreset preset = null)
        {
            return new MediaTransformOutput(onError, relativePriority, preset);
        }

        /// <summary> Initializes a new instance of MediaTransformPreset. </summary>
        /// <param name="odataType"> The discriminator for derived types. </param>
        /// <returns> A new <see cref="Models.MediaTransformPreset"/> instance for mocking. </returns>
        public static MediaTransformPreset MediaTransformPreset(string odataType = null)
        {
            return new UnknownPreset(odataType);
        }

        /// <summary> Initializes a new instance of MediaJobData. </summary>
        /// <param name="id"> The id. </param>
        /// <param name="name"> The name. </param>
        /// <param name="resourceType"> The resourceType. </param>
        /// <param name="systemData"> The systemData. </param>
        /// <param name="createdOn"> The UTC date and time when the customer has created the Job, in &apos;YYYY-MM-DDThh:mm:ssZ&apos; format. </param>
        /// <param name="state"> The current state of the job. </param>
        /// <param name="description"> Optional customer supplied description of the Job. </param>
        /// <param name="input">
        /// The inputs for the Job.
        /// Please note <see cref="MediaJobInputBasicProperties"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="MediaJobInputAsset"/>, <see cref="MediaJobInputClip"/>, <see cref="MediaJobInputHttp"/>, <see cref="MediaJobInputSequence"/> and <see cref="MediaJobInputs"/>.
        /// </param>
        /// <param name="lastModifiedOn"> The UTC date and time when the customer has last updated the Job, in &apos;YYYY-MM-DDThh:mm:ssZ&apos; format. </param>
        /// <param name="outputs">
        /// The outputs for the Job.
        /// Please note <see cref="MediaJobOutput"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="MediaJobOutputAsset"/>.
        /// </param>
        /// <param name="priority"> Priority with which the job should be processed. Higher priority jobs are processed before lower priority jobs. If not set, the default is normal. </param>
        /// <param name="correlationData"> Customer provided key, value pairs that will be returned in Job and JobOutput state events. </param>
        /// <param name="startOn"> The UTC date and time at which this Job began processing. </param>
        /// <param name="endOn"> The UTC date and time at which this Job finished processing. </param>
        /// <returns> A new <see cref="Media.MediaJobData"/> instance for mocking. </returns>
        public static MediaJobData MediaJobData(ResourceIdentifier id = null, string name = null, ResourceType resourceType = default, SystemData systemData = null, DateTimeOffset? createdOn = null, MediaJobState? state = null, string description = null, MediaJobInputBasicProperties input = null, DateTimeOffset? lastModifiedOn = null, IEnumerable<MediaJobOutput> outputs = null, MediaJobPriority? priority = null, IDictionary<string, string> correlationData = null, DateTimeOffset? startOn = null, DateTimeOffset? endOn = null)
        {
            outputs ??= new List<MediaJobOutput>();
            correlationData ??= new Dictionary<string, string>();

            return new MediaJobData(id, name, resourceType, systemData, createdOn, state, description, input, lastModifiedOn, outputs?.ToList(), priority, correlationData, startOn, endOn);
        }

        /// <summary> Initializes a new instance of MediaJobInputBasicProperties. </summary>
        /// <param name="odataType"> The discriminator for derived types. </param>
        /// <returns> A new <see cref="Models.MediaJobInputBasicProperties"/> instance for mocking. </returns>
        public static MediaJobInputBasicProperties MediaJobInputBasicProperties(string odataType = null)
        {
            return new UnknownJobInput(odataType);
        }

        /// <summary> Initializes a new instance of MediaJobOutput. </summary>
        /// <param name="odataType"> The discriminator for derived types. </param>
        /// <param name="error"> If the JobOutput is in the Error state, it contains the details of the error. </param>
        /// <param name="presetOverride">
        /// A preset used to override the preset in the corresponding transform output.
        /// Please note <see cref="MediaTransformPreset"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="AudioAnalyzerPreset"/>, <see cref="BuiltInStandardEncoderPreset"/>, <see cref="StandardEncoderPreset"/> and <see cref="VideoAnalyzerPreset"/>.
        /// </param>
        /// <param name="state"> Describes the state of the JobOutput. </param>
        /// <param name="progress"> If the JobOutput is in a Processing state, this contains the Job completion percentage. The value is an estimate and not intended to be used to predict Job completion times. To determine if the JobOutput is complete, use the State property. </param>
        /// <param name="label"> A label that is assigned to a JobOutput in order to help uniquely identify it. This is useful when your Transform has more than one TransformOutput, whereby your Job has more than one JobOutput. In such cases, when you submit the Job, you will add two or more JobOutputs, in the same order as TransformOutputs in the Transform. Subsequently, when you retrieve the Job, either through events or on a GET request, you can use the label to easily identify the JobOutput. If a label is not provided, a default value of &apos;{presetName}_{outputIndex}&apos; will be used, where the preset name is the name of the preset in the corresponding TransformOutput and the output index is the relative index of the this JobOutput within the Job. Note that this index is the same as the relative index of the corresponding TransformOutput within its Transform. </param>
        /// <param name="startOn"> The UTC date and time at which this Job Output began processing. </param>
        /// <param name="endOn"> The UTC date and time at which this Job Output finished processing. </param>
        /// <returns> A new <see cref="Models.MediaJobOutput"/> instance for mocking. </returns>
        public static MediaJobOutput MediaJobOutput(string odataType = null, MediaJobError error = null, MediaTransformPreset presetOverride = null, MediaJobState? state = null, int? progress = null, string label = null, DateTimeOffset? startOn = null, DateTimeOffset? endOn = null)
        {
            return new UnknownJobOutput(odataType, error, presetOverride, state, progress, label, startOn, endOn);
        }

        /// <summary> Initializes a new instance of MediaJobError. </summary>
        /// <param name="code"> Error code describing the error. </param>
        /// <param name="message"> A human-readable language-dependent representation of the error. </param>
        /// <param name="category"> Helps with categorization of errors. </param>
        /// <param name="retry"> Indicates that it may be possible to retry the Job. If retry is unsuccessful, please contact Azure support via Azure Portal. </param>
        /// <param name="details"> An array of details about specific errors that led to this reported error. </param>
        /// <returns> A new <see cref="Models.MediaJobError"/> instance for mocking. </returns>
        public static MediaJobError MediaJobError(MediaJobErrorCode? code = null, string message = null, MediaJobErrorCategory? category = null, MediaJobRetry? retry = null, IEnumerable<MediaJobErrorDetail> details = null)
        {
            details ??= new List<MediaJobErrorDetail>();

            return new MediaJobError(code, message, category, retry, details?.ToList());
        }

        /// <summary> Initializes a new instance of MediaJobErrorDetail. </summary>
        /// <param name="code"> Code describing the error detail. </param>
        /// <param name="message"> A human-readable representation of the error. </param>
        /// <returns> A new <see cref="Models.MediaJobErrorDetail"/> instance for mocking. </returns>
        public static MediaJobErrorDetail MediaJobErrorDetail(string code = null, string message = null)
        {
            return new MediaJobErrorDetail(code, message);
        }

        /// <summary> Initializes a new instance of StreamingPolicyData. </summary>
        /// <param name="id"> The id. </param>
        /// <param name="name"> The name. </param>
        /// <param name="resourceType"> The resourceType. </param>
        /// <param name="systemData"> The systemData. </param>
        /// <param name="createdOn"> Creation time of Streaming Policy. </param>
        /// <param name="defaultContentKeyPolicyName"> Default ContentKey used by current Streaming Policy. </param>
        /// <param name="envelopeEncryption"> Configuration of EnvelopeEncryption. </param>
        /// <param name="commonEncryptionCenc"> Configuration of CommonEncryptionCenc. </param>
        /// <param name="commonEncryptionCbcs"> Configuration of CommonEncryptionCbcs. </param>
        /// <param name="noEncryptionEnabledProtocols"> Configurations of NoEncryption. </param>
        /// <returns> A new <see cref="Media.StreamingPolicyData"/> instance for mocking. </returns>
        public static StreamingPolicyData StreamingPolicyData(ResourceIdentifier id = null, string name = null, ResourceType resourceType = default, SystemData systemData = null, DateTimeOffset? createdOn = null, string defaultContentKeyPolicyName = null, EnvelopeEncryption envelopeEncryption = null, CommonEncryptionCenc commonEncryptionCenc = null, CommonEncryptionCbcs commonEncryptionCbcs = null, MediaEnabledProtocols noEncryptionEnabledProtocols = null)
        {
            return new StreamingPolicyData(id, name, resourceType, systemData, createdOn, defaultContentKeyPolicyName, envelopeEncryption, commonEncryptionCenc, commonEncryptionCbcs, new NoEncryption(noEncryptionEnabledProtocols));
        }

        /// <summary> Initializes a new instance of EnvelopeEncryption. </summary>
        /// <param name="enabledProtocols"> Representing supported protocols. </param>
        /// <param name="clearTracks"> Representing which tracks should not be encrypted. </param>
        /// <param name="contentKeys"> Representing default content key for each encryption scheme and separate content keys for specific tracks. </param>
        /// <param name="customKeyAcquisitionUriTemplate"> Template for the URL of the custom service delivering keys to end user players.  Not required when using Azure Media Services for issuing keys.  The template supports replaceable tokens that the service will update at runtime with the value specific to the request.  The currently supported token values are {AlternativeMediaId}, which is replaced with the value of StreamingLocatorId.AlternativeMediaId, and {ContentKeyId}, which is replaced with the value of identifier of the key being requested. </param>
        /// <returns> A new <see cref="Models.EnvelopeEncryption"/> instance for mocking. </returns>
        public static EnvelopeEncryption EnvelopeEncryption(MediaEnabledProtocols enabledProtocols = null, IEnumerable<MediaTrackSelection> clearTracks = null, StreamingPolicyContentKeys contentKeys = null, string customKeyAcquisitionUriTemplate = null)
        {
            clearTracks ??= new List<MediaTrackSelection>();

            return new EnvelopeEncryption(enabledProtocols, clearTracks?.ToList(), contentKeys, customKeyAcquisitionUriTemplate);
        }

        /// <summary> Initializes a new instance of MediaTrackSelection. </summary>
        /// <param name="trackSelections"> TrackSelections is a track property condition list which can specify track(s). </param>
        /// <returns> A new <see cref="Models.MediaTrackSelection"/> instance for mocking. </returns>
        public static MediaTrackSelection MediaTrackSelection(IEnumerable<TrackPropertyCondition> trackSelections = null)
        {
            trackSelections ??= new List<TrackPropertyCondition>();

            return new MediaTrackSelection(trackSelections?.ToList());
        }

        /// <summary> Initializes a new instance of TrackPropertyCondition. </summary>
        /// <param name="property"> Track property type. </param>
        /// <param name="operation"> Track property condition operation. </param>
        /// <param name="value"> Track property value. </param>
        /// <returns> A new <see cref="Models.TrackPropertyCondition"/> instance for mocking. </returns>
        public static TrackPropertyCondition TrackPropertyCondition(TrackPropertyType property = default, TrackPropertyCompareOperation operation = default, string value = null)
        {
            return new TrackPropertyCondition(property, operation, value);
        }

        /// <summary> Initializes a new instance of StreamingPolicyContentKeys. </summary>
        /// <param name="defaultKey"> Default content key for an encryption scheme. </param>
        /// <param name="keyToTrackMappings"> Representing tracks needs separate content key. </param>
        /// <returns> A new <see cref="Models.StreamingPolicyContentKeys"/> instance for mocking. </returns>
        public static StreamingPolicyContentKeys StreamingPolicyContentKeys(EncryptionSchemeDefaultKey defaultKey = null, IEnumerable<StreamingPolicyContentKey> keyToTrackMappings = null)
        {
            keyToTrackMappings ??= new List<StreamingPolicyContentKey>();

            return new StreamingPolicyContentKeys(defaultKey, keyToTrackMappings?.ToList());
        }

        /// <summary> Initializes a new instance of EncryptionSchemeDefaultKey. </summary>
        /// <param name="label"> Label can be used to specify Content Key when creating a Streaming Locator. </param>
        /// <param name="policyName"> Policy used by Default Key. </param>
        /// <returns> A new <see cref="Models.EncryptionSchemeDefaultKey"/> instance for mocking. </returns>
        public static EncryptionSchemeDefaultKey EncryptionSchemeDefaultKey(string label = null, string policyName = null)
        {
            return new EncryptionSchemeDefaultKey(label, policyName);
        }

        /// <summary> Initializes a new instance of StreamingPolicyContentKey. </summary>
        /// <param name="label"> Label can be used to specify Content Key when creating a Streaming Locator. </param>
        /// <param name="policyName"> Policy used by Content Key. </param>
        /// <param name="tracks"> Tracks which use this content key. </param>
        /// <returns> A new <see cref="Models.StreamingPolicyContentKey"/> instance for mocking. </returns>
        public static StreamingPolicyContentKey StreamingPolicyContentKey(string label = null, string policyName = null, IEnumerable<MediaTrackSelection> tracks = null)
        {
            tracks ??= new List<MediaTrackSelection>();

            return new StreamingPolicyContentKey(label, policyName, tracks?.ToList());
        }

        /// <summary> Initializes a new instance of CommonEncryptionCenc. </summary>
        /// <param name="enabledProtocols"> Representing supported protocols. </param>
        /// <param name="clearTracks"> Representing which tracks should not be encrypted. </param>
        /// <param name="contentKeys"> Representing default content key for each encryption scheme and separate content keys for specific tracks. </param>
        /// <param name="drm"> Configuration of DRMs for CommonEncryptionCenc encryption scheme. </param>
        /// <param name="clearKeyEncryptionCustomKeysAcquisitionUriTemplate"> Optional configuration supporting ClearKey in CommonEncryptionCenc encryption scheme. </param>
        /// <returns> A new <see cref="Models.CommonEncryptionCenc"/> instance for mocking. </returns>
        public static CommonEncryptionCenc CommonEncryptionCenc(MediaEnabledProtocols enabledProtocols = null, IEnumerable<MediaTrackSelection> clearTracks = null, StreamingPolicyContentKeys contentKeys = null, CencDrmConfiguration drm = null, string clearKeyEncryptionCustomKeysAcquisitionUriTemplate = null)
        {
            clearTracks ??= new List<MediaTrackSelection>();

            return new CommonEncryptionCenc(enabledProtocols, clearTracks?.ToList(), contentKeys, drm, new ClearKeyEncryptionConfiguration(clearKeyEncryptionCustomKeysAcquisitionUriTemplate));
        }

        /// <summary> Initializes a new instance of CencDrmConfiguration. </summary>
        /// <param name="playReady"> PlayReady configurations. </param>
        /// <param name="widevineCustomLicenseAcquisitionUriTemplate"> Widevine configurations. </param>
        /// <returns> A new <see cref="Models.CencDrmConfiguration"/> instance for mocking. </returns>
        public static CencDrmConfiguration CencDrmConfiguration(StreamingPolicyPlayReadyConfiguration playReady = null, string widevineCustomLicenseAcquisitionUriTemplate = null)
        {
            return new CencDrmConfiguration(playReady, new StreamingPolicyWidevineConfiguration(widevineCustomLicenseAcquisitionUriTemplate));
        }

        /// <summary> Initializes a new instance of StreamingPolicyPlayReadyConfiguration. </summary>
        /// <param name="customLicenseAcquisitionUriTemplate"> Template for the URL of the custom service delivering licenses to end user players.  Not required when using Azure Media Services for issuing licenses.  The template supports replaceable tokens that the service will update at runtime with the value specific to the request.  The currently supported token values are {AlternativeMediaId}, which is replaced with the value of StreamingLocatorId.AlternativeMediaId, and {ContentKeyId}, which is replaced with the value of identifier of the key being requested. </param>
        /// <param name="playReadyCustomAttributes"> Custom attributes for PlayReady. </param>
        /// <returns> A new <see cref="Models.StreamingPolicyPlayReadyConfiguration"/> instance for mocking. </returns>
        public static StreamingPolicyPlayReadyConfiguration StreamingPolicyPlayReadyConfiguration(string customLicenseAcquisitionUriTemplate = null, string playReadyCustomAttributes = null)
        {
            return new StreamingPolicyPlayReadyConfiguration(customLicenseAcquisitionUriTemplate, playReadyCustomAttributes);
        }

        /// <summary> Initializes a new instance of CommonEncryptionCbcs. </summary>
        /// <param name="enabledProtocols"> Representing supported protocols. </param>
        /// <param name="clearTracks"> Representing which tracks should not be encrypted. </param>
        /// <param name="contentKeys"> Representing default content key for each encryption scheme and separate content keys for specific tracks. </param>
        /// <param name="drm"> Configuration of DRMs for current encryption scheme. </param>
        /// <param name="clearKeyEncryptionCustomKeysAcquisitionUriTemplate"> Optional configuration supporting ClearKey in CommonEncryptionCbcs encryption scheme. </param>
        /// <returns> A new <see cref="Models.CommonEncryptionCbcs"/> instance for mocking. </returns>
        public static CommonEncryptionCbcs CommonEncryptionCbcs(MediaEnabledProtocols enabledProtocols = null, IEnumerable<MediaTrackSelection> clearTracks = null, StreamingPolicyContentKeys contentKeys = null, CbcsDrmConfiguration drm = null, string clearKeyEncryptionCustomKeysAcquisitionUriTemplate = null)
        {
            clearTracks ??= new List<MediaTrackSelection>();

            return new CommonEncryptionCbcs(enabledProtocols, clearTracks?.ToList(), contentKeys, drm, new ClearKeyEncryptionConfiguration(clearKeyEncryptionCustomKeysAcquisitionUriTemplate));
        }

        /// <summary> Initializes a new instance of CbcsDrmConfiguration. </summary>
        /// <param name="fairPlay"> FairPlay configurations. </param>
        /// <param name="playReady"> PlayReady configurations. </param>
        /// <param name="widevineCustomLicenseAcquisitionUriTemplate"> Widevine configurations. </param>
        /// <returns> A new <see cref="Models.CbcsDrmConfiguration"/> instance for mocking. </returns>
        public static CbcsDrmConfiguration CbcsDrmConfiguration(StreamingPolicyFairPlayConfiguration fairPlay = null, StreamingPolicyPlayReadyConfiguration playReady = null, string widevineCustomLicenseAcquisitionUriTemplate = null)
        {
            return new CbcsDrmConfiguration(fairPlay, playReady, new StreamingPolicyWidevineConfiguration(widevineCustomLicenseAcquisitionUriTemplate));
        }

        /// <summary> Initializes a new instance of StreamingPolicyFairPlayConfiguration. </summary>
        /// <param name="customLicenseAcquisitionUriTemplate"> Template for the URL of the custom service delivering licenses to end user players.  Not required when using Azure Media Services for issuing licenses.  The template supports replaceable tokens that the service will update at runtime with the value specific to the request.  The currently supported token values are {AlternativeMediaId}, which is replaced with the value of StreamingLocatorId.AlternativeMediaId, and {ContentKeyId}, which is replaced with the value of identifier of the key being requested. </param>
        /// <param name="allowPersistentLicense"> All license to be persistent or not. </param>
        /// <returns> A new <see cref="Models.StreamingPolicyFairPlayConfiguration"/> instance for mocking. </returns>
        public static StreamingPolicyFairPlayConfiguration StreamingPolicyFairPlayConfiguration(string customLicenseAcquisitionUriTemplate = null, bool allowPersistentLicense = default)
        {
            return new StreamingPolicyFairPlayConfiguration(customLicenseAcquisitionUriTemplate, allowPersistentLicense);
        }

        /// <summary> Initializes a new instance of StreamingLocatorData. </summary>
        /// <param name="id"> The id. </param>
        /// <param name="name"> The name. </param>
        /// <param name="resourceType"> The resourceType. </param>
        /// <param name="systemData"> The systemData. </param>
        /// <param name="assetName"> Asset Name. </param>
        /// <param name="createdOn"> The creation time of the Streaming Locator. </param>
        /// <param name="startOn"> The start time of the Streaming Locator. </param>
        /// <param name="endOn"> The end time of the Streaming Locator. </param>
        /// <param name="streamingLocatorId"> The StreamingLocatorId of the Streaming Locator. </param>
        /// <param name="streamingPolicyName"> Name of the Streaming Policy used by this Streaming Locator. Either specify the name of Streaming Policy you created or use one of the predefined Streaming Policies. The predefined Streaming Policies available are: &apos;Predefined_DownloadOnly&apos;, &apos;Predefined_ClearStreamingOnly&apos;, &apos;Predefined_DownloadAndClearStreaming&apos;, &apos;Predefined_ClearKey&apos;, &apos;Predefined_MultiDrmCencStreaming&apos; and &apos;Predefined_MultiDrmStreaming&apos;. </param>
        /// <param name="defaultContentKeyPolicyName"> Name of the default ContentKeyPolicy used by this Streaming Locator. </param>
        /// <param name="contentKeys"> The ContentKeys used by this Streaming Locator. </param>
        /// <param name="alternativeMediaId"> Alternative Media ID of this Streaming Locator. </param>
        /// <param name="filters"> A list of asset or account filters which apply to this streaming locator. </param>
        /// <returns> A new <see cref="Media.StreamingLocatorData"/> instance for mocking. </returns>
        public static StreamingLocatorData StreamingLocatorData(ResourceIdentifier id = null, string name = null, ResourceType resourceType = default, SystemData systemData = null, string assetName = null, DateTimeOffset? createdOn = null, DateTimeOffset? startOn = null, DateTimeOffset? endOn = null, Guid? streamingLocatorId = null, string streamingPolicyName = null, string defaultContentKeyPolicyName = null, IEnumerable<StreamingLocatorContentKey> contentKeys = null, string alternativeMediaId = null, IEnumerable<string> filters = null)
        {
            contentKeys ??= new List<StreamingLocatorContentKey>();
            filters ??= new List<string>();

            return new StreamingLocatorData(id, name, resourceType, systemData, assetName, createdOn, startOn, endOn, streamingLocatorId, streamingPolicyName, defaultContentKeyPolicyName, contentKeys?.ToList(), alternativeMediaId, filters?.ToList());
        }

        /// <summary> Initializes a new instance of StreamingLocatorContentKey. </summary>
        /// <param name="id"> ID of Content Key. </param>
        /// <param name="keyType"> Encryption type of Content Key. </param>
        /// <param name="labelReferenceInStreamingPolicy"> Label of Content Key as specified in the Streaming Policy. </param>
        /// <param name="value"> Value of Content Key. </param>
        /// <param name="policyName"> ContentKeyPolicy used by Content Key. </param>
        /// <param name="tracks"> Tracks which use this Content Key. </param>
        /// <returns> A new <see cref="Models.StreamingLocatorContentKey"/> instance for mocking. </returns>
        public static StreamingLocatorContentKey StreamingLocatorContentKey(Guid id = default, StreamingLocatorContentKeyType? keyType = null, string labelReferenceInStreamingPolicy = null, string value = null, string policyName = null, IEnumerable<MediaTrackSelection> tracks = null)
        {
            tracks ??= new List<MediaTrackSelection>();

            return new StreamingLocatorContentKey(id, keyType, labelReferenceInStreamingPolicy, value, policyName, tracks?.ToList());
        }

        /// <summary> Initializes a new instance of StreamingPathsResult. </summary>
        /// <param name="streamingPaths"> Streaming Paths supported by current Streaming Locator. </param>
        /// <param name="downloadPaths"> Download Paths supported by current Streaming Locator. </param>
        /// <returns> A new <see cref="Models.StreamingPathsResult"/> instance for mocking. </returns>
        public static StreamingPathsResult StreamingPathsResult(IEnumerable<StreamingPath> streamingPaths = null, IEnumerable<string> downloadPaths = null)
        {
            streamingPaths ??= new List<StreamingPath>();
            downloadPaths ??= new List<string>();

            return new StreamingPathsResult(streamingPaths?.ToList(), downloadPaths?.ToList());
        }

        /// <summary> Initializes a new instance of StreamingPath. </summary>
        /// <param name="streamingProtocol"> Streaming protocol. </param>
        /// <param name="encryptionScheme"> Encryption scheme. </param>
        /// <param name="paths"> Streaming paths for each protocol and encryptionScheme pair. </param>
        /// <returns> A new <see cref="Models.StreamingPath"/> instance for mocking. </returns>
        public static StreamingPath StreamingPath(StreamingPolicyStreamingProtocol streamingProtocol = default, StreamingPathEncryptionScheme encryptionScheme = default, IEnumerable<string> paths = null)
        {
            paths ??= new List<string>();

            return new StreamingPath(streamingProtocol, encryptionScheme, paths?.ToList());
        }

        /// <summary> Initializes a new instance of MediaLiveEventData. </summary>
        /// <param name="id"> The id. </param>
        /// <param name="name"> The name. </param>
        /// <param name="resourceType"> The resourceType. </param>
        /// <param name="systemData"> The systemData. </param>
        /// <param name="tags"> The tags. </param>
        /// <param name="location"> The location. </param>
        /// <param name="description"> A description for the live event. </param>
        /// <param name="input"> Live event input settings. It defines how the live event receives input from a contribution encoder. </param>
        /// <param name="preview"> Live event preview settings. Preview allows live event producers to preview the live streaming content without creating any live output. </param>
        /// <param name="encoding"> Encoding settings for the live event. It configures whether a live encoder is used for the live event and settings for the live encoder if it is used. </param>
        /// <param name="transcriptions"> Live transcription settings for the live event. See https://go.microsoft.com/fwlink/?linkid=2133742 for more information about the live transcription feature. </param>
        /// <param name="provisioningState"> The provisioning state of the live event. </param>
        /// <param name="resourceState"> The resource state of the live event. See https://go.microsoft.com/fwlink/?linkid=2139012 for more information. </param>
        /// <param name="crossSiteAccessPolicies"> Live event cross site access policies. </param>
        /// <param name="useStaticHostname"> Specifies whether a static hostname would be assigned to the live event preview and ingest endpoints. This value can only be updated if the live event is in Standby state. </param>
        /// <param name="hostnamePrefix"> When useStaticHostname is set to true, the hostnamePrefix specifies the first part of the hostname assigned to the live event preview and ingest endpoints. The final hostname would be a combination of this prefix, the media service account name and a short code for the Azure Media Services data center. </param>
        /// <param name="streamOptions"> The options to use for the LiveEvent. This value is specified at creation time and cannot be updated. The valid values for the array entry values are &apos;Default&apos; and &apos;LowLatency&apos;. </param>
        /// <param name="createdOn"> The creation time for the live event. </param>
        /// <param name="lastModifiedOn"> The last modified time of the live event. </param>
        /// <returns> A new <see cref="Media.MediaLiveEventData"/> instance for mocking. </returns>
        public static MediaLiveEventData MediaLiveEventData(ResourceIdentifier id = null, string name = null, ResourceType resourceType = default, SystemData systemData = null, IDictionary<string, string> tags = null, AzureLocation location = default, string description = null, LiveEventInput input = null, LiveEventPreview preview = null, LiveEventEncoding encoding = null, IEnumerable<LiveEventTranscription> transcriptions = null, string provisioningState = null, LiveEventResourceState? resourceState = null, CrossSiteAccessPolicies crossSiteAccessPolicies = null, bool? useStaticHostname = null, string hostnamePrefix = null, IEnumerable<StreamOptionsFlag> streamOptions = null, DateTimeOffset? createdOn = null, DateTimeOffset? lastModifiedOn = null)
        {
            tags ??= new Dictionary<string, string>();
            transcriptions ??= new List<LiveEventTranscription>();
            streamOptions ??= new List<StreamOptionsFlag>();

            return new MediaLiveEventData(id, name, resourceType, systemData, tags, location, description, input, preview, encoding, transcriptions?.ToList(), provisioningState, resourceState, crossSiteAccessPolicies, useStaticHostname, hostnamePrefix, streamOptions?.ToList(), createdOn, lastModifiedOn);
        }

        /// <summary> Initializes a new instance of IPRange. </summary>
        /// <param name="name"> The friendly name for the IP address range. </param>
        /// <param name="address"> The IP address. </param>
        /// <param name="subnetPrefixLength"> The subnet mask prefix length (see CIDR notation). </param>
        /// <returns> A new <see cref="Models.IPRange"/> instance for mocking. </returns>
        public static IPRange IPRange(string name = null, IPAddress address = null, int? subnetPrefixLength = null)
        {
            return new IPRange(name, address, subnetPrefixLength);
        }

        /// <summary> Initializes a new instance of LiveEventEndpoint. </summary>
        /// <param name="protocol"> The endpoint protocol. </param>
        /// <param name="uri"> The endpoint URL. </param>
        /// <returns> A new <see cref="Models.LiveEventEndpoint"/> instance for mocking. </returns>
        public static LiveEventEndpoint LiveEventEndpoint(string protocol = null, Uri uri = null)
        {
            return new LiveEventEndpoint(protocol, uri);
        }

        /// <summary> Initializes a new instance of LiveEventPreview. </summary>
        /// <param name="endpoints"> The endpoints for preview. Do not share the preview URL with the live event audience. </param>
        /// <param name="ipAllowedIPs"> The access control for live event preview. </param>
        /// <param name="previewLocator"> The identifier of the preview locator in Guid format. Specifying this at creation time allows the caller to know the preview locator url before the event is created. If omitted, the service will generate a random identifier. This value cannot be updated once the live event is created. </param>
        /// <param name="streamingPolicyName"> The name of streaming policy used for the live event preview. This value is specified at creation time and cannot be updated. </param>
        /// <param name="alternativeMediaId"> An alternative media identifier associated with the streaming locator created for the preview. This value is specified at creation time and cannot be updated. The identifier can be used in the CustomLicenseAcquisitionUrlTemplate or the CustomKeyAcquisitionUrlTemplate of the StreamingPolicy specified in the StreamingPolicyName field. </param>
        /// <returns> A new <see cref="Models.LiveEventPreview"/> instance for mocking. </returns>
        public static LiveEventPreview LiveEventPreview(IEnumerable<LiveEventEndpoint> endpoints = null, IEnumerable<IPRange> ipAllowedIPs = null, string previewLocator = null, string streamingPolicyName = null, string alternativeMediaId = null)
        {
            endpoints ??= new List<LiveEventEndpoint>();
            ipAllowedIPs ??= new List<IPRange>();

            return new LiveEventPreview(endpoints?.ToList(), new LiveEventPreviewAccessControl(new IPAccessControl(ipAllowedIPs?.ToList())), previewLocator, streamingPolicyName, alternativeMediaId);
        }

        /// <summary> Initializes a new instance of LiveEventEncoding. </summary>
        /// <param name="encodingType"> Live event type. When encodingType is set to PassthroughBasic or PassthroughStandard, the service simply passes through the incoming video and audio layer(s) to the output. When encodingType is set to Standard or Premium1080p, a live encoder transcodes the incoming stream into multiple bitrates or layers. See https://go.microsoft.com/fwlink/?linkid=2095101 for more information. This property cannot be modified after the live event is created. </param>
        /// <param name="presetName"> The optional encoding preset name, used when encodingType is not None. This value is specified at creation time and cannot be updated. If the encodingType is set to Standard, then the default preset name is Default720p. Else if the encodingType is set to Premium1080p, the default preset is Default1080p. </param>
        /// <param name="stretchMode"> Specifies how the input video will be resized to fit the desired output resolution(s). Default is None. </param>
        /// <param name="keyFrameInterval"> Use an ISO 8601 time value between 0.5 to 20 seconds to specify the output fragment length for the video and audio tracks of an encoding live event. For example, use PT2S to indicate 2 seconds. For the video track it also defines the key frame interval, or the length of a GoP (group of pictures).   If this value is not set for an encoding live event, the fragment duration defaults to 2 seconds. The value cannot be set for pass-through live events. </param>
        /// <returns> A new <see cref="Models.LiveEventEncoding"/> instance for mocking. </returns>
        public static LiveEventEncoding LiveEventEncoding(LiveEventEncodingType? encodingType = null, string presetName = null, InputVideoStretchMode? stretchMode = null, TimeSpan? keyFrameInterval = null)
        {
            return new LiveEventEncoding(encodingType, presetName, stretchMode, keyFrameInterval);
        }

        /// <summary> Initializes a new instance of LiveEventTranscription. </summary>
        /// <param name="language"> Specifies the language (locale) to be used for speech-to-text transcription  it should match the spoken language in the audio track. The value should be in BCP-47 format (e.g: &apos;en-US&apos;). See https://go.microsoft.com/fwlink/?linkid=2133742 for more information about the live transcription feature and the list of supported languages. </param>
        /// <param name="inputTrackSelection"> Provides a mechanism to select the audio track in the input live feed, to which speech-to-text transcription is applied. This property is reserved for future use, any value set on this property will be ignored. </param>
        /// <param name="trackName"> Describes a transcription track in the output of a live event, generated using speech-to-text transcription. This property is reserved for future use, any value set on this property will be ignored. </param>
        /// <returns> A new <see cref="Models.LiveEventTranscription"/> instance for mocking. </returns>
        public static LiveEventTranscription LiveEventTranscription(string language = null, IEnumerable<LiveEventInputTrackSelection> inputTrackSelection = null, string trackName = null)
        {
            inputTrackSelection ??= new List<LiveEventInputTrackSelection>();

            return new LiveEventTranscription(language, inputTrackSelection?.ToList(), new LiveEventOutputTranscriptionTrack(trackName));
        }

        /// <summary> Initializes a new instance of LiveEventInputTrackSelection. </summary>
        /// <param name="property"> Property name to select. This property is reserved for future use, any value set on this property will be ignored. </param>
        /// <param name="operation"> Comparing operation. This property is reserved for future use, any value set on this property will be ignored. </param>
        /// <param name="value"> Property value to select. This property is reserved for future use, any value set on this property will be ignored. </param>
        /// <returns> A new <see cref="Models.LiveEventInputTrackSelection"/> instance for mocking. </returns>
        public static LiveEventInputTrackSelection LiveEventInputTrackSelection(string property = null, string operation = null, string value = null)
        {
            return new LiveEventInputTrackSelection(property, operation, value);
        }

        /// <summary> Initializes a new instance of CrossSiteAccessPolicies. </summary>
        /// <param name="clientAccessPolicy"> The content of clientaccesspolicy.xml used by Silverlight. </param>
        /// <param name="crossDomainPolicy"> The content of crossdomain.xml used by Silverlight. </param>
        /// <returns> A new <see cref="Models.CrossSiteAccessPolicies"/> instance for mocking. </returns>
        public static CrossSiteAccessPolicies CrossSiteAccessPolicies(string clientAccessPolicy = null, string crossDomainPolicy = null)
        {
            return new CrossSiteAccessPolicies(clientAccessPolicy, crossDomainPolicy);
        }

        /// <summary> Initializes a new instance of MediaLiveOutputData. </summary>
        /// <param name="id"> The id. </param>
        /// <param name="name"> The name. </param>
        /// <param name="resourceType"> The resourceType. </param>
        /// <param name="systemData"> The systemData. </param>
        /// <param name="description"> The description of the live output. </param>
        /// <param name="assetName"> The asset that the live output will write to. </param>
        /// <param name="archiveWindowLength"> ISO 8601 time between 1 minute to 25 hours to indicate the maximum content length that can be archived in the asset for this live output. This also sets the maximum content length for the rewind window. For example, use PT1H30M to indicate 1 hour and 30 minutes of archive window. </param>
        /// <param name="rewindWindowLength"> ISO 8601 time between 1 minute to the duration of archiveWindowLength to control seek-able window length during Live. The service won&apos;t use this property once LiveOutput stops. The archived VOD will have full content with original ArchiveWindowLength. For example, use PT1H30M to indicate 1 hour and 30 minutes of rewind window length. Service will use implicit default value 30m only if Live Event enables LL. </param>
        /// <param name="manifestName"> The manifest file name. If not provided, the service will generate one automatically. </param>
        /// <param name="hlsFragmentsPerTsSegment"> HTTP Live Streaming (HLS) packing setting for the live output. </param>
        /// <param name="outputSnapTime"> The initial timestamp that the live output will start at, any content before this value will not be archived. </param>
        /// <param name="createdOn"> The creation time the live output. </param>
        /// <param name="lastModifiedOn"> The time the live output was last modified. </param>
        /// <param name="provisioningState"> The provisioning state of the live output. </param>
        /// <param name="resourceState"> The resource state of the live output. </param>
        /// <returns> A new <see cref="Media.MediaLiveOutputData"/> instance for mocking. </returns>
        public static MediaLiveOutputData MediaLiveOutputData(ResourceIdentifier id = null, string name = null, ResourceType resourceType = default, SystemData systemData = null, string description = null, string assetName = null, TimeSpan? archiveWindowLength = null, TimeSpan? rewindWindowLength = null, string manifestName = null, int? hlsFragmentsPerTsSegment = null, long? outputSnapTime = null, DateTimeOffset? createdOn = null, DateTimeOffset? lastModifiedOn = null, string provisioningState = null, LiveOutputResourceState? resourceState = null)
        {
            return new MediaLiveOutputData(id, name, resourceType, systemData, description, assetName, archiveWindowLength, rewindWindowLength, manifestName, new Hls(hlsFragmentsPerTsSegment), outputSnapTime, createdOn, lastModifiedOn, provisioningState, resourceState);
        }

        /// <summary> Initializes a new instance of StreamingEndpointData. </summary>
        /// <param name="id"> The id. </param>
        /// <param name="name"> The name. </param>
        /// <param name="resourceType"> The resourceType. </param>
        /// <param name="systemData"> The systemData. </param>
        /// <param name="tags"> The tags. </param>
        /// <param name="location"> The location. </param>
        /// <param name="sku"> The streaming endpoint sku. </param>
        /// <param name="description"> The streaming endpoint description. </param>
        /// <param name="scaleUnits"> The number of scale units. Use the Scale operation to adjust this value. </param>
        /// <param name="availabilitySetName"> This feature is deprecated, do not set a value for this property. </param>
        /// <param name="accessControl"> The access control definition of the streaming endpoint. </param>
        /// <param name="maxCacheAge"> Max cache age. </param>
        /// <param name="customHostNames"> The custom host names of the streaming endpoint. </param>
        /// <param name="hostName"> The streaming endpoint host name. </param>
        /// <param name="isCdnEnabled"> The CDN enabled flag. </param>
        /// <param name="cdnProvider"> The CDN provider name. </param>
        /// <param name="cdnProfile"> The CDN profile name. </param>
        /// <param name="provisioningState"> The provisioning state of the streaming endpoint. </param>
        /// <param name="resourceState"> The resource state of the streaming endpoint. </param>
        /// <param name="crossSiteAccessPolicies"> The streaming endpoint access policies. </param>
        /// <param name="freeTrialEndOn"> The free trial expiration time. </param>
        /// <param name="createdOn"> The exact time the streaming endpoint was created. </param>
        /// <param name="lastModifiedOn"> The exact time the streaming endpoint was last modified. </param>
        /// <returns> A new <see cref="Media.StreamingEndpointData"/> instance for mocking. </returns>
        public static StreamingEndpointData StreamingEndpointData(ResourceIdentifier id = null, string name = null, ResourceType resourceType = default, SystemData systemData = null, IDictionary<string, string> tags = null, AzureLocation location = default, StreamingEndpointCurrentSku sku = null, string description = null, int? scaleUnits = null, string availabilitySetName = null, StreamingEndpointAccessControl accessControl = null, long? maxCacheAge = null, IEnumerable<string> customHostNames = null, string hostName = null, bool? isCdnEnabled = null, string cdnProvider = null, string cdnProfile = null, string provisioningState = null, StreamingEndpointResourceState? resourceState = null, CrossSiteAccessPolicies crossSiteAccessPolicies = null, DateTimeOffset? freeTrialEndOn = null, DateTimeOffset? createdOn = null, DateTimeOffset? lastModifiedOn = null)
        {
            tags ??= new Dictionary<string, string>();
            customHostNames ??= new List<string>();

            return new StreamingEndpointData(id, name, resourceType, systemData, tags, location, sku, description, scaleUnits, availabilitySetName, accessControl, maxCacheAge, customHostNames?.ToList(), hostName, isCdnEnabled, cdnProvider, cdnProfile, provisioningState, resourceState, crossSiteAccessPolicies, freeTrialEndOn, createdOn, lastModifiedOn);
        }

        /// <summary> Initializes a new instance of StreamingEndpointAccessControl. </summary>
        /// <param name="akamaiSignatureHeaderAuthenticationKeyList"> The access control of Akamai. </param>
        /// <param name="allowedIPs"> The IP access control of the streaming endpoint. </param>
        /// <returns> A new <see cref="Models.StreamingEndpointAccessControl"/> instance for mocking. </returns>
        public static StreamingEndpointAccessControl StreamingEndpointAccessControl(IEnumerable<AkamaiSignatureHeaderAuthenticationKey> akamaiSignatureHeaderAuthenticationKeyList = null, IEnumerable<IPRange> allowedIPs = null)
        {
            akamaiSignatureHeaderAuthenticationKeyList ??= new List<AkamaiSignatureHeaderAuthenticationKey>();
            allowedIPs ??= new List<IPRange>();

            return new StreamingEndpointAccessControl(new AkamaiAccessControl(akamaiSignatureHeaderAuthenticationKeyList?.ToList()), new IPAccessControl(allowedIPs?.ToList()));
        }

        /// <summary> Initializes a new instance of AkamaiSignatureHeaderAuthenticationKey. </summary>
        /// <param name="identifier"> identifier of the key. </param>
        /// <param name="base64Key"> authentication key. </param>
        /// <param name="expireOn"> The expiration time of the authentication key. </param>
        /// <returns> A new <see cref="Models.AkamaiSignatureHeaderAuthenticationKey"/> instance for mocking. </returns>
        public static AkamaiSignatureHeaderAuthenticationKey AkamaiSignatureHeaderAuthenticationKey(string identifier = null, string base64Key = null, DateTimeOffset? expireOn = null)
        {
            return new AkamaiSignatureHeaderAuthenticationKey(identifier, base64Key, expireOn);
        }

        /// <summary> Initializes a new instance of StreamingEndpointCurrentSku. </summary>
        /// <param name="name"> The streaming endpoint sku name. </param>
        /// <param name="capacity"> The streaming endpoint sku capacity. </param>
        /// <returns> A new <see cref="Models.StreamingEndpointCurrentSku"/> instance for mocking. </returns>
        public static StreamingEndpointCurrentSku StreamingEndpointCurrentSku(string name = null, int? capacity = null)
        {
            return new StreamingEndpointCurrentSku(name, capacity);
        }

        /// <summary> Initializes a new instance of StreamingEndpointSkuInfo. </summary>
        /// <param name="resourceType"></param>
        /// <param name="capacity"> The streaming endpoint sku capacity. </param>
        /// <param name="skuName"> The streaming endpoint sku. </param>
        /// <returns> A new <see cref="Models.StreamingEndpointSkuInfo"/> instance for mocking. </returns>
        public static StreamingEndpointSkuInfo StreamingEndpointSkuInfo(ResourceType? resourceType = null, StreamingEndpointCapacity capacity = null, string skuName = null)
        {
            return new StreamingEndpointSkuInfo(resourceType, capacity, new StreamingEndpointSku(skuName));
        }

        /// <summary> Initializes a new instance of StreamingEndpointCapacity. </summary>
        /// <param name="scaleType"></param>
        /// <param name="default"> The streaming endpoint default capacity. </param>
        /// <param name="minimum"> The streaming endpoint minimum capacity. </param>
        /// <param name="maximum"> The streaming endpoint maximum capacity. </param>
        /// <returns> A new <see cref="Models.StreamingEndpointCapacity"/> instance for mocking. </returns>
        public static StreamingEndpointCapacity StreamingEndpointCapacity(string scaleType = null, int? @default = null, int? minimum = null, int? maximum = null)
        {
            return new StreamingEndpointCapacity(scaleType, @default, minimum, maximum);
        }

        /// <summary> Initializes a new instance of HlsSettings. </summary>
        /// <param name="isDefault"> The default for the HLS setting. </param>
        /// <param name="isForced"> The forced for the HLS setting. </param>
        /// <param name="characteristics"> The characteristics for the HLS setting. </param>
        /// <returns> A new <see cref="Models.HlsSettings"/> instance for mocking. </returns>
        public static HlsSettings HlsSettings(bool? isDefault = null, bool? isForced = null, string characteristics = null)
        {
            return new HlsSettings(isDefault, isForced, characteristics);
        }

        /// <summary> Initializes a new instance of AudioTrack. </summary>
        /// <param name="fileName"> The file name to the source file. This file is located in the storage container of the asset. </param>
        /// <param name="displayName"> The display name of the audio track on a video player. In HLS, this maps to the NAME attribute of EXT-X-MEDIA. </param>
        /// <param name="languageCode"> The RFC5646 language code for the audio track. </param>
        /// <param name="hlsSettings"> The HLS specific setting for the audio track. </param>
        /// <param name="dashRole"> The DASH specific setting for the audio track. </param>
        /// <param name="mpeg4TrackId"> The MPEG-4 audio track ID for the audio track. </param>
        /// <param name="bitRate"> The stream bit rate for the audio track. </param>
        /// <returns> A new <see cref="Models.AudioTrack"/> instance for mocking. </returns>
        public static AudioTrack AudioTrack(string fileName = null, string displayName = null, string languageCode = null, HlsSettings hlsSettings = null, string dashRole = null, int? mpeg4TrackId = null, int? bitRate = null)
        {
            return new AudioTrack("#Microsoft.Media.AudioTrack", fileName, displayName, languageCode, hlsSettings, new TrackDashSettings(dashRole), mpeg4TrackId, bitRate);
        }

        /// <summary> Initializes a new instance of VideoTrack. </summary>
        /// <returns> A new <see cref="Models.VideoTrack"/> instance for mocking. </returns>
        public static VideoTrack VideoTrack()
        {
            return new VideoTrack("#Microsoft.Media.VideoTrack");
        }

        /// <summary> Initializes a new instance of TextTrack. </summary>
        /// <param name="fileName"> The file name to the source file. This file is located in the storage container of the asset. </param>
        /// <param name="displayName"> The display name of the text track on a video player. In HLS, this maps to the NAME attribute of EXT-X-MEDIA. </param>
        /// <param name="languageCode"> The RFC5646 language code for the text track. </param>
        /// <param name="playerVisibility"> When PlayerVisibility is set to &quot;Visible&quot;, the text track will be present in the DASH manifest or HLS playlist when requested by a client. When the PlayerVisibility is set to &quot;Hidden&quot;, the text will not be available to the client. The default value is &quot;Visible&quot;. </param>
        /// <param name="hlsSettings"> The HLS specific setting for the text track. </param>
        /// <returns> A new <see cref="Models.TextTrack"/> instance for mocking. </returns>
        public static TextTrack TextTrack(string fileName = null, string displayName = null, string languageCode = null, PlayerVisibility? playerVisibility = null, HlsSettings hlsSettings = null)
        {
            return new TextTrack("#Microsoft.Media.TextTrack", fileName, displayName, languageCode, playerVisibility, hlsSettings);
        }

        /// <summary> Initializes a new instance of ContentKeyPolicyPlayReadyContentKeyLocation. </summary>
        /// <param name="odataType"> The discriminator for derived types. </param>
        /// <returns> A new <see cref="Models.ContentKeyPolicyPlayReadyContentKeyLocation"/> instance for mocking. </returns>
        public static ContentKeyPolicyPlayReadyContentKeyLocation ContentKeyPolicyPlayReadyContentKeyLocation(string odataType = null)
        {
            return new UnknownContentKeyPolicyPlayReadyContentKeyLocation(odataType);
        }

        /// <summary> Initializes a new instance of ContentKeyPolicyPlayReadyContentEncryptionKeyFromHeader. </summary>
        /// <returns> A new <see cref="Models.ContentKeyPolicyPlayReadyContentEncryptionKeyFromHeader"/> instance for mocking. </returns>
        public static ContentKeyPolicyPlayReadyContentEncryptionKeyFromHeader ContentKeyPolicyPlayReadyContentEncryptionKeyFromHeader()
        {
            return new ContentKeyPolicyPlayReadyContentEncryptionKeyFromHeader("#Microsoft.Media.ContentKeyPolicyPlayReadyContentEncryptionKeyFromHeader");
        }

        /// <summary> Initializes a new instance of ContentKeyPolicyPlayReadyContentEncryptionKeyFromKeyIdentifier. </summary>
        /// <param name="keyId"> The content key ID. </param>
        /// <returns> A new <see cref="Models.ContentKeyPolicyPlayReadyContentEncryptionKeyFromKeyIdentifier"/> instance for mocking. </returns>
        public static ContentKeyPolicyPlayReadyContentEncryptionKeyFromKeyIdentifier ContentKeyPolicyPlayReadyContentEncryptionKeyFromKeyIdentifier(Guid? keyId = null)
        {
            return new ContentKeyPolicyPlayReadyContentEncryptionKeyFromKeyIdentifier("#Microsoft.Media.ContentKeyPolicyPlayReadyContentEncryptionKeyFromKeyIdentifier", keyId);
        }

        /// <summary> Initializes a new instance of ContentKeyPolicyPlayReadyPlayRight. </summary>
        /// <param name="firstPlayExpiration"> The amount of time that the license is valid after the license is first used to play content. </param>
        /// <param name="scmsRestriction"> Configures the Serial Copy Management System (SCMS) in the license. Must be between 0 and 3 inclusive. </param>
        /// <param name="agcAndColorStripeRestriction"> Configures Automatic Gain Control (AGC) and Color Stripe in the license. Must be between 0 and 3 inclusive. </param>
        /// <param name="explicitAnalogTelevisionOutputRestriction"> Configures the Explicit Analog Television Output Restriction in the license. Configuration data must be between 0 and 3 inclusive. </param>
        /// <param name="hasDigitalVideoOnlyContentRestriction"> Enables the Image Constraint For Analog Component Video Restriction in the license. </param>
        /// <param name="hasImageConstraintForAnalogComponentVideoRestriction"> Enables the Image Constraint For Analog Component Video Restriction in the license. </param>
        /// <param name="hasImageConstraintForAnalogComputerMonitorRestriction"> Enables the Image Constraint For Analog Component Video Restriction in the license. </param>
        /// <param name="allowPassingVideoContentToUnknownOutput"> Configures Unknown output handling settings of the license. </param>
        /// <param name="uncompressedDigitalVideoOutputProtectionLevel"> Specifies the output protection level for uncompressed digital video. </param>
        /// <param name="compressedDigitalVideoOutputProtectionLevel"> Specifies the output protection level for compressed digital video. </param>
        /// <param name="analogVideoOutputProtectionLevel"> Specifies the output protection level for compressed digital audio. </param>
        /// <param name="compressedDigitalAudioOutputProtectionLevel"> Specifies the output protection level for compressed digital audio. </param>
        /// <param name="uncompressedDigitalAudioOutputProtectionLevel"> Specifies the output protection level for uncompressed digital audio. </param>
        /// <returns> A new <see cref="Models.ContentKeyPolicyPlayReadyPlayRight"/> instance for mocking. </returns>
        public static ContentKeyPolicyPlayReadyPlayRight ContentKeyPolicyPlayReadyPlayRight(TimeSpan? firstPlayExpiration = null, int? scmsRestriction = null, int? agcAndColorStripeRestriction = null, ContentKeyPolicyPlayReadyExplicitAnalogTelevisionRestriction explicitAnalogTelevisionOutputRestriction = null, bool hasDigitalVideoOnlyContentRestriction = default, bool hasImageConstraintForAnalogComponentVideoRestriction = default, bool hasImageConstraintForAnalogComputerMonitorRestriction = default, ContentKeyPolicyPlayReadyUnknownOutputPassingOption allowPassingVideoContentToUnknownOutput = default, int? uncompressedDigitalVideoOutputProtectionLevel = null, int? compressedDigitalVideoOutputProtectionLevel = null, int? analogVideoOutputProtectionLevel = null, int? compressedDigitalAudioOutputProtectionLevel = null, int? uncompressedDigitalAudioOutputProtectionLevel = null)
        {
            return new ContentKeyPolicyPlayReadyPlayRight(firstPlayExpiration, scmsRestriction, agcAndColorStripeRestriction, explicitAnalogTelevisionOutputRestriction, hasDigitalVideoOnlyContentRestriction, hasImageConstraintForAnalogComponentVideoRestriction, hasImageConstraintForAnalogComputerMonitorRestriction, allowPassingVideoContentToUnknownOutput, uncompressedDigitalVideoOutputProtectionLevel, compressedDigitalVideoOutputProtectionLevel, analogVideoOutputProtectionLevel, compressedDigitalAudioOutputProtectionLevel, uncompressedDigitalAudioOutputProtectionLevel);
        }

        /// <summary> Initializes a new instance of ContentKeyPolicyTokenClaim. </summary>
        /// <param name="claimType"> Token claim type. </param>
        /// <param name="claimValue"> Token claim value. </param>
        /// <returns> A new <see cref="Models.ContentKeyPolicyTokenClaim"/> instance for mocking. </returns>
        public static ContentKeyPolicyTokenClaim ContentKeyPolicyTokenClaim(string claimType = null, string claimValue = null)
        {
            return new ContentKeyPolicyTokenClaim(claimType, claimValue);
        }

        /// <summary> Initializes a new instance of ContentKeyPolicyPlayReadyLicense. </summary>
        /// <param name="allowTestDevices"> A flag indicating whether test devices can use the license. </param>
        /// <param name="securityLevel"> The security level. </param>
        /// <param name="beginOn"> The begin date of license. </param>
        /// <param name="expireOn"> The expiration date of license. </param>
        /// <param name="relativeBeginDate"> The relative begin date of license. </param>
        /// <param name="relativeExpirationDate"> The relative expiration date of license. </param>
        /// <param name="gracePeriod"> The grace period of license. </param>
        /// <param name="playRight"> The license PlayRight. </param>
        /// <param name="licenseType"> The license type. </param>
        /// <param name="contentKeyLocation">
        /// The content key location.
        /// Please note <see cref="ContentKeyPolicyPlayReadyContentKeyLocation"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="ContentKeyPolicyPlayReadyContentEncryptionKeyFromHeader"/> and <see cref="ContentKeyPolicyPlayReadyContentEncryptionKeyFromKeyIdentifier"/>.
        /// </param>
        /// <param name="contentType"> The PlayReady content type. </param>
        /// <returns> A new <see cref="Models.ContentKeyPolicyPlayReadyLicense"/> instance for mocking. </returns>
        public static ContentKeyPolicyPlayReadyLicense ContentKeyPolicyPlayReadyLicense(bool allowTestDevices = default, PlayReadySecurityLevel? securityLevel = null, DateTimeOffset? beginOn = null, DateTimeOffset? expireOn = null, TimeSpan? relativeBeginDate = null, TimeSpan? relativeExpirationDate = null, TimeSpan? gracePeriod = null, ContentKeyPolicyPlayReadyPlayRight playRight = null, ContentKeyPolicyPlayReadyLicenseType licenseType = default, ContentKeyPolicyPlayReadyContentKeyLocation contentKeyLocation = null, ContentKeyPolicyPlayReadyContentType contentType = default)
        {
            return new ContentKeyPolicyPlayReadyLicense(allowTestDevices, securityLevel, beginOn, expireOn, relativeBeginDate, relativeExpirationDate, gracePeriod, playRight, licenseType, contentKeyLocation, contentType);
        }

        /// <summary> Initializes a new instance of ContentKeyPolicyOpenRestriction. </summary>
        /// <returns> A new <see cref="Models.ContentKeyPolicyOpenRestriction"/> instance for mocking. </returns>
        public static ContentKeyPolicyOpenRestriction ContentKeyPolicyOpenRestriction()
        {
            return new ContentKeyPolicyOpenRestriction("#Microsoft.Media.ContentKeyPolicyOpenRestriction");
        }

        /// <summary> Initializes a new instance of ContentKeyPolicyUnknownRestriction. </summary>
        /// <returns> A new <see cref="Models.ContentKeyPolicyUnknownRestriction"/> instance for mocking. </returns>
        public static ContentKeyPolicyUnknownRestriction ContentKeyPolicyUnknownRestriction()
        {
            return new ContentKeyPolicyUnknownRestriction("#Microsoft.Media.ContentKeyPolicyUnknownRestriction");
        }

        /// <summary> Initializes a new instance of ContentKeyPolicyRestrictionTokenKey. </summary>
        /// <param name="odataType"> The discriminator for derived types. </param>
        /// <returns> A new <see cref="Models.ContentKeyPolicyRestrictionTokenKey"/> instance for mocking. </returns>
        public static ContentKeyPolicyRestrictionTokenKey ContentKeyPolicyRestrictionTokenKey(string odataType = null)
        {
            return new UnknownContentKeyPolicyRestrictionTokenKey(odataType);
        }

        /// <summary> Initializes a new instance of ContentKeyPolicySymmetricTokenKey. </summary>
        /// <param name="keyValue"> The key value of the key. </param>
        /// <returns> A new <see cref="Models.ContentKeyPolicySymmetricTokenKey"/> instance for mocking. </returns>
        public static ContentKeyPolicySymmetricTokenKey ContentKeyPolicySymmetricTokenKey(byte[] keyValue = null)
        {
            return new ContentKeyPolicySymmetricTokenKey("#Microsoft.Media.ContentKeyPolicySymmetricTokenKey", keyValue);
        }

        /// <summary> Initializes a new instance of ContentKeyPolicyRsaTokenKey. </summary>
        /// <param name="exponent"> The RSA Parameter exponent. </param>
        /// <param name="modulus"> The RSA Parameter modulus. </param>
        /// <returns> A new <see cref="Models.ContentKeyPolicyRsaTokenKey"/> instance for mocking. </returns>
        public static ContentKeyPolicyRsaTokenKey ContentKeyPolicyRsaTokenKey(byte[] exponent = null, byte[] modulus = null)
        {
            return new ContentKeyPolicyRsaTokenKey("#Microsoft.Media.ContentKeyPolicyRsaTokenKey", exponent, modulus);
        }

        /// <summary> Initializes a new instance of ContentKeyPolicyX509CertificateTokenKey. </summary>
        /// <param name="rawBody"> The raw data field of a certificate in PKCS 12 format (X509Certificate2 in .NET). </param>
        /// <returns> A new <see cref="Models.ContentKeyPolicyX509CertificateTokenKey"/> instance for mocking. </returns>
        public static ContentKeyPolicyX509CertificateTokenKey ContentKeyPolicyX509CertificateTokenKey(byte[] rawBody = null)
        {
            return new ContentKeyPolicyX509CertificateTokenKey("#Microsoft.Media.ContentKeyPolicyX509CertificateTokenKey", rawBody);
        }

        /// <summary> Initializes a new instance of ContentKeyPolicyTokenRestriction. </summary>
        /// <param name="issuer"> The token issuer. </param>
        /// <param name="audience"> The audience for the token. </param>
        /// <param name="primaryVerificationKey">
        /// The primary verification key.
        /// Please note <see cref="ContentKeyPolicyRestrictionTokenKey"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="ContentKeyPolicyRsaTokenKey"/>, <see cref="ContentKeyPolicySymmetricTokenKey"/> and <see cref="ContentKeyPolicyX509CertificateTokenKey"/>.
        /// </param>
        /// <param name="alternateVerificationKeys">
        /// A list of alternative verification keys.
        /// Please note <see cref="ContentKeyPolicyRestrictionTokenKey"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="ContentKeyPolicyRsaTokenKey"/>, <see cref="ContentKeyPolicySymmetricTokenKey"/> and <see cref="ContentKeyPolicyX509CertificateTokenKey"/>.
        /// </param>
        /// <param name="requiredClaims"> A list of required token claims. </param>
        /// <param name="restrictionTokenType"> The type of token. </param>
        /// <param name="openIdConnectDiscoveryDocument"> The OpenID connect discovery document. </param>
        /// <returns> A new <see cref="Models.ContentKeyPolicyTokenRestriction"/> instance for mocking. </returns>
        public static ContentKeyPolicyTokenRestriction ContentKeyPolicyTokenRestriction(string issuer = null, string audience = null, ContentKeyPolicyRestrictionTokenKey primaryVerificationKey = null, IEnumerable<ContentKeyPolicyRestrictionTokenKey> alternateVerificationKeys = null, IEnumerable<ContentKeyPolicyTokenClaim> requiredClaims = null, ContentKeyPolicyRestrictionTokenType restrictionTokenType = default, string openIdConnectDiscoveryDocument = null)
        {
            alternateVerificationKeys ??= new List<ContentKeyPolicyRestrictionTokenKey>();
            requiredClaims ??= new List<ContentKeyPolicyTokenClaim>();

            return new ContentKeyPolicyTokenRestriction("#Microsoft.Media.ContentKeyPolicyTokenRestriction", issuer, audience, primaryVerificationKey, alternateVerificationKeys?.ToList(), requiredClaims?.ToList(), restrictionTokenType, openIdConnectDiscoveryDocument);
        }

        /// <summary> Initializes a new instance of ContentKeyPolicyClearKeyConfiguration. </summary>
        /// <returns> A new <see cref="Models.ContentKeyPolicyClearKeyConfiguration"/> instance for mocking. </returns>
        public static ContentKeyPolicyClearKeyConfiguration ContentKeyPolicyClearKeyConfiguration()
        {
            return new ContentKeyPolicyClearKeyConfiguration("#Microsoft.Media.ContentKeyPolicyClearKeyConfiguration");
        }

        /// <summary> Initializes a new instance of ContentKeyPolicyUnknownConfiguration. </summary>
        /// <returns> A new <see cref="Models.ContentKeyPolicyUnknownConfiguration"/> instance for mocking. </returns>
        public static ContentKeyPolicyUnknownConfiguration ContentKeyPolicyUnknownConfiguration()
        {
            return new ContentKeyPolicyUnknownConfiguration("#Microsoft.Media.ContentKeyPolicyUnknownConfiguration");
        }

        /// <summary> Initializes a new instance of ContentKeyPolicyWidevineConfiguration. </summary>
        /// <param name="widevineTemplate"> The Widevine template. </param>
        /// <returns> A new <see cref="Models.ContentKeyPolicyWidevineConfiguration"/> instance for mocking. </returns>
        public static ContentKeyPolicyWidevineConfiguration ContentKeyPolicyWidevineConfiguration(string widevineTemplate = null)
        {
            return new ContentKeyPolicyWidevineConfiguration("#Microsoft.Media.ContentKeyPolicyWidevineConfiguration", widevineTemplate);
        }

        /// <summary> Initializes a new instance of ContentKeyPolicyPlayReadyConfiguration. </summary>
        /// <param name="licenses"> The PlayReady licenses. </param>
        /// <param name="responseCustomData"> The custom response data. </param>
        /// <returns> A new <see cref="Models.ContentKeyPolicyPlayReadyConfiguration"/> instance for mocking. </returns>
        public static ContentKeyPolicyPlayReadyConfiguration ContentKeyPolicyPlayReadyConfiguration(IEnumerable<ContentKeyPolicyPlayReadyLicense> licenses = null, BinaryData responseCustomData = null)
        {
            licenses ??= new List<ContentKeyPolicyPlayReadyLicense>();

            return new ContentKeyPolicyPlayReadyConfiguration("#Microsoft.Media.ContentKeyPolicyPlayReadyConfiguration", licenses?.ToList(), responseCustomData);
        }

        /// <summary> Initializes a new instance of ContentKeyPolicyFairPlayConfiguration. </summary>
        /// <param name="applicationSecretKey"> The key that must be used as FairPlay Application Secret key. </param>
        /// <param name="fairPlayPfxPassword"> The password encrypting FairPlay certificate in PKCS 12 (pfx) format. </param>
        /// <param name="fairPlayPfx"> The Base64 representation of FairPlay certificate in PKCS 12 (pfx) format (including private key). </param>
        /// <param name="rentalAndLeaseKeyType"> The rental and lease key type. </param>
        /// <param name="rentalDuration"> The rental duration. Must be greater than or equal to 0. </param>
        /// <param name="offlineRentalConfiguration"> Offline rental policy. </param>
        /// <returns> A new <see cref="Models.ContentKeyPolicyFairPlayConfiguration"/> instance for mocking. </returns>
        public static ContentKeyPolicyFairPlayConfiguration ContentKeyPolicyFairPlayConfiguration(byte[] applicationSecretKey = null, string fairPlayPfxPassword = null, string fairPlayPfx = null, ContentKeyPolicyFairPlayRentalAndLeaseKeyType rentalAndLeaseKeyType = default, long rentalDuration = default, ContentKeyPolicyFairPlayOfflineRentalConfiguration offlineRentalConfiguration = null)
        {
            return new ContentKeyPolicyFairPlayConfiguration("#Microsoft.Media.ContentKeyPolicyFairPlayConfiguration", applicationSecretKey, fairPlayPfxPassword, fairPlayPfx, rentalAndLeaseKeyType, rentalDuration, offlineRentalConfiguration);
        }

        /// <summary> Initializes a new instance of MediaCodecBase. </summary>
        /// <param name="odataType"> The discriminator for derived types. </param>
        /// <param name="label"> An optional label for the codec. The label can be used to control muxing behavior. </param>
        /// <returns> A new <see cref="Models.MediaCodecBase"/> instance for mocking. </returns>
        public static MediaCodecBase MediaCodecBase(string odataType = null, string label = null)
        {
            return new UnknownCodec(odataType, label);
        }

        /// <summary> Initializes a new instance of MediaAudioBase. </summary>
        /// <param name="label"> An optional label for the codec. The label can be used to control muxing behavior. </param>
        /// <param name="channels"> The number of channels in the audio. </param>
        /// <param name="samplingRate"> The sampling rate to use for encoding in hertz. </param>
        /// <param name="bitrate"> The bitrate, in bits per second, of the output encoded audio. </param>
        /// <returns> A new <see cref="Models.MediaAudioBase"/> instance for mocking. </returns>
        public static MediaAudioBase MediaAudioBase(string label = null, int? channels = null, int? samplingRate = null, int? bitrate = null)
        {
            return new MediaAudioBase("#Microsoft.Media.Audio", label, channels, samplingRate, bitrate);
        }

        /// <summary> Initializes a new instance of AacAudio. </summary>
        /// <param name="label"> An optional label for the codec. The label can be used to control muxing behavior. </param>
        /// <param name="channels"> The number of channels in the audio. </param>
        /// <param name="samplingRate"> The sampling rate to use for encoding in hertz. </param>
        /// <param name="bitrate"> The bitrate, in bits per second, of the output encoded audio. </param>
        /// <param name="profile"> The encoding profile to be used when encoding audio with AAC. </param>
        /// <returns> A new <see cref="Models.AacAudio"/> instance for mocking. </returns>
        public static AacAudio AacAudio(string label = null, int? channels = null, int? samplingRate = null, int? bitrate = null, AacAudioProfile? profile = null)
        {
            return new AacAudio("#Microsoft.Media.AacAudio", label, channels, samplingRate, bitrate, profile);
        }

        /// <summary> Initializes a new instance of MediaLayerBase. </summary>
        /// <param name="width"> The width of the output video for this layer. The value can be absolute (in pixels) or relative (in percentage). For example 50% means the output video has half as many pixels in width as the input. </param>
        /// <param name="height"> The height of the output video for this layer. The value can be absolute (in pixels) or relative (in percentage). For example 50% means the output video has half as many pixels in height as the input. </param>
        /// <param name="label"> The alphanumeric label for this layer, which can be used in multiplexing different video and audio layers, or in naming the output file. </param>
        /// <returns> A new <see cref="Models.MediaLayerBase"/> instance for mocking. </returns>
        public static MediaLayerBase MediaLayerBase(string width = null, string height = null, string label = null)
        {
            return new MediaLayerBase(width, height, label);
        }

        /// <summary> Initializes a new instance of H265VideoLayer. </summary>
        /// <param name="width"> The width of the output video for this layer. The value can be absolute (in pixels) or relative (in percentage). For example 50% means the output video has half as many pixels in width as the input. </param>
        /// <param name="height"> The height of the output video for this layer. The value can be absolute (in pixels) or relative (in percentage). For example 50% means the output video has half as many pixels in height as the input. </param>
        /// <param name="label"> The alphanumeric label for this layer, which can be used in multiplexing different video and audio layers, or in naming the output file. </param>
        /// <param name="bitrate"> The average bitrate in bits per second at which to encode the input video when generating this layer. For example: a target bitrate of 3000Kbps or 3Mbps means this value should be 3000000 This is a required field. </param>
        /// <param name="maxBitrate"> The maximum bitrate (in bits per second), at which the VBV buffer should be assumed to refill. If not specified, defaults to the same value as bitrate. </param>
        /// <param name="bFrames"> The number of B-frames to be used when encoding this layer.  If not specified, the encoder chooses an appropriate number based on the video profile and level. </param>
        /// <param name="frameRate"> The frame rate (in frames per second) at which to encode this layer. The value can be in the form of M/N where M and N are integers (For example, 30000/1001), or in the form of a number (For example, 30, or 29.97). The encoder enforces constraints on allowed frame rates based on the profile and level. If it is not specified, the encoder will use the same frame rate as the input video. </param>
        /// <param name="slices"> The number of slices to be used when encoding this layer. If not specified, default is zero, which means that encoder will use a single slice for each frame. </param>
        /// <param name="useAdaptiveBFrame"> Specifies whether or not adaptive B-frames are to be used when encoding this layer. If not specified, the encoder will turn it on whenever the video profile permits its use. </param>
        /// <returns> A new <see cref="Models.H265VideoLayer"/> instance for mocking. </returns>
        public static H265VideoLayer H265VideoLayer(string width = null, string height = null, string label = null, int bitrate = default, int? maxBitrate = null, int? bFrames = null, string frameRate = null, int? slices = null, bool? useAdaptiveBFrame = null)
        {
            return new H265VideoLayer(width, height, label, bitrate, maxBitrate, bFrames, frameRate, slices, useAdaptiveBFrame);
        }

        /// <summary> Initializes a new instance of H265Layer. </summary>
        /// <param name="width"> The width of the output video for this layer. The value can be absolute (in pixels) or relative (in percentage). For example 50% means the output video has half as many pixels in width as the input. </param>
        /// <param name="height"> The height of the output video for this layer. The value can be absolute (in pixels) or relative (in percentage). For example 50% means the output video has half as many pixels in height as the input. </param>
        /// <param name="label"> The alphanumeric label for this layer, which can be used in multiplexing different video and audio layers, or in naming the output file. </param>
        /// <param name="bitrate"> The average bitrate in bits per second at which to encode the input video when generating this layer. For example: a target bitrate of 3000Kbps or 3Mbps means this value should be 3000000 This is a required field. </param>
        /// <param name="maxBitrate"> The maximum bitrate (in bits per second), at which the VBV buffer should be assumed to refill. If not specified, defaults to the same value as bitrate. </param>
        /// <param name="bFrames"> The number of B-frames to be used when encoding this layer.  If not specified, the encoder chooses an appropriate number based on the video profile and level. </param>
        /// <param name="frameRate"> The frame rate (in frames per second) at which to encode this layer. The value can be in the form of M/N where M and N are integers (For example, 30000/1001), or in the form of a number (For example, 30, or 29.97). The encoder enforces constraints on allowed frame rates based on the profile and level. If it is not specified, the encoder will use the same frame rate as the input video. </param>
        /// <param name="slices"> The number of slices to be used when encoding this layer. If not specified, default is zero, which means that encoder will use a single slice for each frame. </param>
        /// <param name="useAdaptiveBFrame"> Specifies whether or not adaptive B-frames are to be used when encoding this layer. If not specified, the encoder will turn it on whenever the video profile permits its use. </param>
        /// <param name="profile"> We currently support Main. Default is Auto. </param>
        /// <param name="level"> We currently support Level up to 6.2. The value can be Auto, or a number that matches the H.265 profile. If not specified, the default is Auto, which lets the encoder choose the Level that is appropriate for this layer. </param>
        /// <param name="bufferWindow"> The VBV buffer window length. The value should be in ISO 8601 format. The value should be in the range [0.1-100] seconds. The default is 5 seconds (for example, PT5S). </param>
        /// <param name="crf"> The value of CRF to be used when encoding this layer. This setting takes effect when RateControlMode of video codec is set at CRF mode. The range of CRF value is between 0 and 51, where lower values would result in better quality, at the expense of higher file sizes. Higher values mean more compression, but at some point quality degradation will be noticed. Default value is 28. </param>
        /// <param name="referenceFrames"> The number of reference frames to be used when encoding this layer. If not specified, the encoder determines an appropriate number based on the encoder complexity setting. </param>
        /// <returns> A new <see cref="Models.H265Layer"/> instance for mocking. </returns>
        public static H265Layer H265Layer(string width = null, string height = null, string label = null, int bitrate = default, int? maxBitrate = null, int? bFrames = null, string frameRate = null, int? slices = null, bool? useAdaptiveBFrame = null, H265VideoProfile? profile = null, string level = null, TimeSpan? bufferWindow = null, float? crf = null, int? referenceFrames = null)
        {
            return new H265Layer(width, height, label, bitrate, maxBitrate, bFrames, frameRate, slices, useAdaptiveBFrame, profile, level, bufferWindow, crf, referenceFrames);
        }

        /// <summary> Initializes a new instance of MediaVideoBase. </summary>
        /// <param name="label"> An optional label for the codec. The label can be used to control muxing behavior. </param>
        /// <param name="keyFrameInterval"> The distance between two key frames. The value should be non-zero in the range [0.5, 20] seconds, specified in ISO 8601 format. The default is 2 seconds(PT2S). Note that this setting is ignored if VideoSyncMode.Passthrough is set, where the KeyFrameInterval value will follow the input source setting. </param>
        /// <param name="stretchMode"> The resizing mode - how the input video will be resized to fit the desired output resolution(s). Default is AutoSize. </param>
        /// <param name="syncMode"> The Video Sync Mode. </param>
        /// <returns> A new <see cref="Models.MediaVideoBase"/> instance for mocking. </returns>
        public static MediaVideoBase MediaVideoBase(string label = null, TimeSpan? keyFrameInterval = null, InputVideoStretchMode? stretchMode = null, VideoSyncMode? syncMode = null)
        {
            return new MediaVideoBase("#Microsoft.Media.Video", label, keyFrameInterval, stretchMode, syncMode);
        }

        /// <summary> Initializes a new instance of H265Video. </summary>
        /// <param name="label"> An optional label for the codec. The label can be used to control muxing behavior. </param>
        /// <param name="keyFrameInterval"> The distance between two key frames. The value should be non-zero in the range [0.5, 20] seconds, specified in ISO 8601 format. The default is 2 seconds(PT2S). Note that this setting is ignored if VideoSyncMode.Passthrough is set, where the KeyFrameInterval value will follow the input source setting. </param>
        /// <param name="stretchMode"> The resizing mode - how the input video will be resized to fit the desired output resolution(s). Default is AutoSize. </param>
        /// <param name="syncMode"> The Video Sync Mode. </param>
        /// <param name="useSceneChangeDetection"> Specifies whether or not the encoder should insert key frames at scene changes. If not specified, the default is false. This flag should be set to true only when the encoder is being configured to produce a single output video. </param>
        /// <param name="complexity"> Tells the encoder how to choose its encoding settings.  Quality will provide for a higher compression ratio but at a higher cost and longer compute time.  Speed will produce a relatively larger file but is faster and more economical. The default value is Balanced. </param>
        /// <param name="layers"> The collection of output H.265 layers to be produced by the encoder. </param>
        /// <returns> A new <see cref="Models.H265Video"/> instance for mocking. </returns>
        public static H265Video H265Video(string label = null, TimeSpan? keyFrameInterval = null, InputVideoStretchMode? stretchMode = null, VideoSyncMode? syncMode = null, bool? useSceneChangeDetection = null, H265Complexity? complexity = null, IEnumerable<H265Layer> layers = null)
        {
            layers ??= new List<H265Layer>();

            return new H265Video("#Microsoft.Media.H265Video", label, keyFrameInterval, stretchMode, syncMode, useSceneChangeDetection, complexity, layers?.ToList());
        }

        /// <summary> Initializes a new instance of TrackDescriptor. </summary>
        /// <param name="odataType"> The discriminator for derived types. </param>
        /// <returns> A new <see cref="Models.TrackDescriptor"/> instance for mocking. </returns>
        public static TrackDescriptor TrackDescriptor(string odataType = null)
        {
            return new UnknownTrackDescriptor(odataType);
        }

        /// <summary> Initializes a new instance of AudioTrackDescriptor. </summary>
        /// <param name="channelMapping"> Optional designation for single channel audio tracks.  Can be used to combine the tracks into stereo or multi-channel audio tracks. </param>
        /// <returns> A new <see cref="Models.AudioTrackDescriptor"/> instance for mocking. </returns>
        public static AudioTrackDescriptor AudioTrackDescriptor(ChannelMapping? channelMapping = null)
        {
            return new AudioTrackDescriptor("#Microsoft.Media.AudioTrackDescriptor", channelMapping);
        }

        /// <summary> Initializes a new instance of SelectAudioTrackByAttribute. </summary>
        /// <param name="channelMapping"> Optional designation for single channel audio tracks.  Can be used to combine the tracks into stereo or multi-channel audio tracks. </param>
        /// <param name="attribute"> The TrackAttribute to filter the tracks by. </param>
        /// <param name="filter"> The type of AttributeFilter to apply to the TrackAttribute in order to select the tracks. </param>
        /// <param name="filterValue"> The value to filter the tracks by.  Only used when AttributeFilter.ValueEquals is specified for the Filter property. </param>
        /// <returns> A new <see cref="Models.SelectAudioTrackByAttribute"/> instance for mocking. </returns>
        public static SelectAudioTrackByAttribute SelectAudioTrackByAttribute(ChannelMapping? channelMapping = null, TrackAttribute attribute = default, TrackAttributeFilter filter = default, string filterValue = null)
        {
            return new SelectAudioTrackByAttribute("#Microsoft.Media.SelectAudioTrackByAttribute", channelMapping, attribute, filter, filterValue);
        }

        /// <summary> Initializes a new instance of SelectAudioTrackById. </summary>
        /// <param name="channelMapping"> Optional designation for single channel audio tracks.  Can be used to combine the tracks into stereo or multi-channel audio tracks. </param>
        /// <param name="trackId"> Track identifier to select. </param>
        /// <returns> A new <see cref="Models.SelectAudioTrackById"/> instance for mocking. </returns>
        public static SelectAudioTrackById SelectAudioTrackById(ChannelMapping? channelMapping = null, long trackId = default)
        {
            return new SelectAudioTrackById("#Microsoft.Media.SelectAudioTrackById", channelMapping, trackId);
        }

        /// <summary> Initializes a new instance of MediaJobInputDefinition. </summary>
        /// <param name="odataType"> The discriminator for derived types. </param>
        /// <param name="includedTracks">
        /// The list of TrackDescriptors which define the metadata and selection of tracks in the input.
        /// Please note <see cref="TrackDescriptor"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="AudioTrackDescriptor"/>, <see cref="SelectAudioTrackByAttribute"/>, <see cref="SelectAudioTrackById"/>, <see cref="SelectVideoTrackByAttribute"/>, <see cref="SelectVideoTrackById"/> and <see cref="VideoTrackDescriptor"/>.
        /// </param>
        /// <returns> A new <see cref="Models.MediaJobInputDefinition"/> instance for mocking. </returns>
        public static MediaJobInputDefinition MediaJobInputDefinition(string odataType = null, IEnumerable<TrackDescriptor> includedTracks = null)
        {
            includedTracks ??= new List<TrackDescriptor>();

            return new UnknownInputDefinition(odataType, includedTracks?.ToList());
        }

        /// <summary> Initializes a new instance of FromAllInputFile. </summary>
        /// <param name="includedTracks">
        /// The list of TrackDescriptors which define the metadata and selection of tracks in the input.
        /// Please note <see cref="TrackDescriptor"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="AudioTrackDescriptor"/>, <see cref="SelectAudioTrackByAttribute"/>, <see cref="SelectAudioTrackById"/>, <see cref="SelectVideoTrackByAttribute"/>, <see cref="SelectVideoTrackById"/> and <see cref="VideoTrackDescriptor"/>.
        /// </param>
        /// <returns> A new <see cref="Models.FromAllInputFile"/> instance for mocking. </returns>
        public static FromAllInputFile FromAllInputFile(IEnumerable<TrackDescriptor> includedTracks = null)
        {
            includedTracks ??= new List<TrackDescriptor>();

            return new FromAllInputFile("#Microsoft.Media.FromAllInputFile", includedTracks?.ToList());
        }

        /// <summary> Initializes a new instance of FromEachInputFile. </summary>
        /// <param name="includedTracks">
        /// The list of TrackDescriptors which define the metadata and selection of tracks in the input.
        /// Please note <see cref="TrackDescriptor"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="AudioTrackDescriptor"/>, <see cref="SelectAudioTrackByAttribute"/>, <see cref="SelectAudioTrackById"/>, <see cref="SelectVideoTrackByAttribute"/>, <see cref="SelectVideoTrackById"/> and <see cref="VideoTrackDescriptor"/>.
        /// </param>
        /// <returns> A new <see cref="Models.FromEachInputFile"/> instance for mocking. </returns>
        public static FromEachInputFile FromEachInputFile(IEnumerable<TrackDescriptor> includedTracks = null)
        {
            includedTracks ??= new List<TrackDescriptor>();

            return new FromEachInputFile("#Microsoft.Media.FromEachInputFile", includedTracks?.ToList());
        }

        /// <summary> Initializes a new instance of MediaJobInputFile. </summary>
        /// <param name="includedTracks">
        /// The list of TrackDescriptors which define the metadata and selection of tracks in the input.
        /// Please note <see cref="TrackDescriptor"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="AudioTrackDescriptor"/>, <see cref="SelectAudioTrackByAttribute"/>, <see cref="SelectAudioTrackById"/>, <see cref="SelectVideoTrackByAttribute"/>, <see cref="SelectVideoTrackById"/> and <see cref="VideoTrackDescriptor"/>.
        /// </param>
        /// <param name="filename"> Name of the file that this input definition applies to. </param>
        /// <returns> A new <see cref="Models.MediaJobInputFile"/> instance for mocking. </returns>
        public static MediaJobInputFile MediaJobInputFile(IEnumerable<TrackDescriptor> includedTracks = null, string filename = null)
        {
            includedTracks ??= new List<TrackDescriptor>();

            return new MediaJobInputFile("#Microsoft.Media.InputFile", includedTracks?.ToList(), filename);
        }

        /// <summary> Initializes a new instance of AudioAnalyzerPreset. </summary>
        /// <param name="audioLanguage"> The language for the audio payload in the input using the BCP-47 format of &apos;language tag-region&apos; (e.g: &apos;en-US&apos;).  If you know the language of your content, it is recommended that you specify it. The language must be specified explicitly for AudioAnalysisMode::Basic, since automatic language detection is not included in basic mode. If the language isn&apos;t specified or set to null, automatic language detection will choose the first language detected and process with the selected language for the duration of the file. It does not currently support dynamically switching between languages after the first language is detected. The automatic detection works best with audio recordings with clearly discernable speech. If automatic detection fails to find the language, transcription would fallback to &apos;en-US&apos;.&quot; The list of supported languages is available here: https://go.microsoft.com/fwlink/?linkid=2109463. </param>
        /// <param name="mode"> Determines the set of audio analysis operations to be performed. If unspecified, the Standard AudioAnalysisMode would be chosen. </param>
        /// <param name="experimentalOptions"> Dictionary containing key value pairs for parameters not exposed in the preset itself. </param>
        /// <returns> A new <see cref="Models.AudioAnalyzerPreset"/> instance for mocking. </returns>
        public static AudioAnalyzerPreset AudioAnalyzerPreset(string audioLanguage = null, AudioAnalysisMode? mode = null, IDictionary<string, string> experimentalOptions = null)
        {
            experimentalOptions ??= new Dictionary<string, string>();

            return new AudioAnalyzerPreset("#Microsoft.Media.AudioAnalyzerPreset", audioLanguage, mode, experimentalOptions);
        }

        /// <summary> Initializes a new instance of MediaOverlayBase. </summary>
        /// <param name="odataType"> The discriminator for derived types. </param>
        /// <param name="inputLabel"> The label of the job input which is to be used as an overlay. The Input must specify exactly one file. You can specify an image file in JPG, PNG, GIF or BMP format, or an audio file (such as a WAV, MP3, WMA or M4A file), or a video file. See https://aka.ms/mesformats for the complete list of supported audio and video file formats. </param>
        /// <param name="start"> The start position, with reference to the input video, at which the overlay starts. The value should be in ISO 8601 format. For example, PT05S to start the overlay at 5 seconds into the input video. If not specified the overlay starts from the beginning of the input video. </param>
        /// <param name="end"> The end position, with reference to the input video, at which the overlay ends. The value should be in ISO 8601 format. For example, PT30S to end the overlay at 30 seconds into the input video. If not specified or the value is greater than the input video duration, the overlay will be applied until the end of the input video if the overlay media duration is greater than the input video duration, else the overlay will last as long as the overlay media duration. </param>
        /// <param name="fadeInDuration"> The duration over which the overlay fades in onto the input video. The value should be in ISO 8601 duration format. If not specified the default behavior is to have no fade in (same as PT0S). </param>
        /// <param name="fadeOutDuration"> The duration over which the overlay fades out of the input video. The value should be in ISO 8601 duration format. If not specified the default behavior is to have no fade out (same as PT0S). </param>
        /// <param name="audioGainLevel"> The gain level of audio in the overlay. The value should be in the range [0, 1.0]. The default is 1.0. </param>
        /// <returns> A new <see cref="Models.MediaOverlayBase"/> instance for mocking. </returns>
        public static MediaOverlayBase MediaOverlayBase(string odataType = null, string inputLabel = null, TimeSpan? start = null, TimeSpan? end = null, TimeSpan? fadeInDuration = null, TimeSpan? fadeOutDuration = null, double? audioGainLevel = null)
        {
            return new UnknownOverlay(odataType, inputLabel, start, end, fadeInDuration, fadeOutDuration, audioGainLevel);
        }

        /// <summary> Initializes a new instance of AudioOverlay. </summary>
        /// <param name="inputLabel"> The label of the job input which is to be used as an overlay. The Input must specify exactly one file. You can specify an image file in JPG, PNG, GIF or BMP format, or an audio file (such as a WAV, MP3, WMA or M4A file), or a video file. See https://aka.ms/mesformats for the complete list of supported audio and video file formats. </param>
        /// <param name="start"> The start position, with reference to the input video, at which the overlay starts. The value should be in ISO 8601 format. For example, PT05S to start the overlay at 5 seconds into the input video. If not specified the overlay starts from the beginning of the input video. </param>
        /// <param name="end"> The end position, with reference to the input video, at which the overlay ends. The value should be in ISO 8601 format. For example, PT30S to end the overlay at 30 seconds into the input video. If not specified or the value is greater than the input video duration, the overlay will be applied until the end of the input video if the overlay media duration is greater than the input video duration, else the overlay will last as long as the overlay media duration. </param>
        /// <param name="fadeInDuration"> The duration over which the overlay fades in onto the input video. The value should be in ISO 8601 duration format. If not specified the default behavior is to have no fade in (same as PT0S). </param>
        /// <param name="fadeOutDuration"> The duration over which the overlay fades out of the input video. The value should be in ISO 8601 duration format. If not specified the default behavior is to have no fade out (same as PT0S). </param>
        /// <param name="audioGainLevel"> The gain level of audio in the overlay. The value should be in the range [0, 1.0]. The default is 1.0. </param>
        /// <returns> A new <see cref="Models.AudioOverlay"/> instance for mocking. </returns>
        public static AudioOverlay AudioOverlay(string inputLabel = null, TimeSpan? start = null, TimeSpan? end = null, TimeSpan? fadeInDuration = null, TimeSpan? fadeOutDuration = null, double? audioGainLevel = null)
        {
            return new AudioOverlay("#Microsoft.Media.AudioOverlay", inputLabel, start, end, fadeInDuration, fadeOutDuration, audioGainLevel);
        }

        /// <summary> Initializes a new instance of CodecCopyVideo. </summary>
        /// <param name="label"> An optional label for the codec. The label can be used to control muxing behavior. </param>
        /// <returns> A new <see cref="Models.CodecCopyVideo"/> instance for mocking. </returns>
        public static CodecCopyVideo CodecCopyVideo(string label = null)
        {
            return new CodecCopyVideo("#Microsoft.Media.CopyVideo", label);
        }

        /// <summary> Initializes a new instance of MediaImageBase. </summary>
        /// <param name="label"> An optional label for the codec. The label can be used to control muxing behavior. </param>
        /// <param name="keyFrameInterval"> The distance between two key frames. The value should be non-zero in the range [0.5, 20] seconds, specified in ISO 8601 format. The default is 2 seconds(PT2S). Note that this setting is ignored if VideoSyncMode.Passthrough is set, where the KeyFrameInterval value will follow the input source setting. </param>
        /// <param name="stretchMode"> The resizing mode - how the input video will be resized to fit the desired output resolution(s). Default is AutoSize. </param>
        /// <param name="syncMode"> The Video Sync Mode. </param>
        /// <param name="start"> The position in the input video from where to start generating thumbnails. The value can be in ISO 8601 format (For example, PT05S to start at 5 seconds), or a frame count (For example, 10 to start at the 10th frame), or a relative value to stream duration (For example, 10% to start at 10% of stream duration). Also supports a macro {Best}, which tells the encoder to select the best thumbnail from the first few seconds of the video and will only produce one thumbnail, no matter what other settings are for Step and Range. The default value is macro {Best}. </param>
        /// <param name="step"> The intervals at which thumbnails are generated. The value can be in ISO 8601 format (For example, PT05S for one image every 5 seconds), or a frame count (For example, 30 for one image every 30 frames), or a relative value to stream duration (For example, 10% for one image every 10% of stream duration). Note: Step value will affect the first generated thumbnail, which may not be exactly the one specified at transform preset start time. This is due to the encoder, which tries to select the best thumbnail between start time and Step position from start time as the first output. As the default value is 10%, it means if stream has long duration, the first generated thumbnail might be far away from the one specified at start time. Try to select reasonable value for Step if the first thumbnail is expected close to start time, or set Range value at 1 if only one thumbnail is needed at start time. </param>
        /// <param name="range"> The position relative to transform preset start time in the input video at which to stop generating thumbnails. The value can be in ISO 8601 format (For example, PT5M30S to stop at 5 minutes and 30 seconds from start time), or a frame count (For example, 300 to stop at the 300th frame from the frame at start time. If this value is 1, it means only producing one thumbnail at start time), or a relative value to the stream duration (For example, 50% to stop at half of stream duration from start time). The default value is 100%, which means to stop at the end of the stream. </param>
        /// <returns> A new <see cref="Models.MediaImageBase"/> instance for mocking. </returns>
        public static MediaImageBase MediaImageBase(string label = null, TimeSpan? keyFrameInterval = null, InputVideoStretchMode? stretchMode = null, VideoSyncMode? syncMode = null, string start = null, string step = null, string range = null)
        {
            return new MediaImageBase("#Microsoft.Media.Image", label, keyFrameInterval, stretchMode, syncMode, start, step, range);
        }

        /// <summary> Initializes a new instance of MediaFormatBase. </summary>
        /// <param name="odataType"> The discriminator for derived types. </param>
        /// <param name="filenamePattern"> The pattern of the file names for the generated output files. The following macros are supported in the file name: {Basename} - An expansion macro that will use the name of the input video file. If the base name(the file suffix is not included) of the input video file is less than 32 characters long, the base name of input video files will be used. If the length of base name of the input video file exceeds 32 characters, the base name is truncated to the first 32 characters in total length. {Extension} - The appropriate extension for this format. {Label} - The label assigned to the codec/layer. {Index} - A unique index for thumbnails. Only applicable to thumbnails. {Bitrate} - The audio/video bitrate. Not applicable to thumbnails. {Codec} - The type of the audio/video codec. {Resolution} - The video resolution. Any unsubstituted macros will be collapsed and removed from the filename. </param>
        /// <returns> A new <see cref="Models.MediaFormatBase"/> instance for mocking. </returns>
        public static MediaFormatBase MediaFormatBase(string odataType = null, string filenamePattern = null)
        {
            return new UnknownFormat(odataType, filenamePattern);
        }

        /// <summary> Initializes a new instance of OutputImageFileFormat. </summary>
        /// <param name="filenamePattern"> The pattern of the file names for the generated output files. The following macros are supported in the file name: {Basename} - An expansion macro that will use the name of the input video file. If the base name(the file suffix is not included) of the input video file is less than 32 characters long, the base name of input video files will be used. If the length of base name of the input video file exceeds 32 characters, the base name is truncated to the first 32 characters in total length. {Extension} - The appropriate extension for this format. {Label} - The label assigned to the codec/layer. {Index} - A unique index for thumbnails. Only applicable to thumbnails. {Bitrate} - The audio/video bitrate. Not applicable to thumbnails. {Codec} - The type of the audio/video codec. {Resolution} - The video resolution. Any unsubstituted macros will be collapsed and removed from the filename. </param>
        /// <returns> A new <see cref="Models.OutputImageFileFormat"/> instance for mocking. </returns>
        public static OutputImageFileFormat OutputImageFileFormat(string filenamePattern = null)
        {
            return new OutputImageFileFormat("#Microsoft.Media.ImageFormat", filenamePattern);
        }

        /// <summary> Initializes a new instance of JpgFormat. </summary>
        /// <param name="filenamePattern"> The pattern of the file names for the generated output files. The following macros are supported in the file name: {Basename} - An expansion macro that will use the name of the input video file. If the base name(the file suffix is not included) of the input video file is less than 32 characters long, the base name of input video files will be used. If the length of base name of the input video file exceeds 32 characters, the base name is truncated to the first 32 characters in total length. {Extension} - The appropriate extension for this format. {Label} - The label assigned to the codec/layer. {Index} - A unique index for thumbnails. Only applicable to thumbnails. {Bitrate} - The audio/video bitrate. Not applicable to thumbnails. {Codec} - The type of the audio/video codec. {Resolution} - The video resolution. Any unsubstituted macros will be collapsed and removed from the filename. </param>
        /// <returns> A new <see cref="Models.JpgFormat"/> instance for mocking. </returns>
        public static JpgFormat JpgFormat(string filenamePattern = null)
        {
            return new JpgFormat("#Microsoft.Media.JpgFormat", filenamePattern);
        }

        /// <summary> Initializes a new instance of PngFormat. </summary>
        /// <param name="filenamePattern"> The pattern of the file names for the generated output files. The following macros are supported in the file name: {Basename} - An expansion macro that will use the name of the input video file. If the base name(the file suffix is not included) of the input video file is less than 32 characters long, the base name of input video files will be used. If the length of base name of the input video file exceeds 32 characters, the base name is truncated to the first 32 characters in total length. {Extension} - The appropriate extension for this format. {Label} - The label assigned to the codec/layer. {Index} - A unique index for thumbnails. Only applicable to thumbnails. {Bitrate} - The audio/video bitrate. Not applicable to thumbnails. {Codec} - The type of the audio/video codec. {Resolution} - The video resolution. Any unsubstituted macros will be collapsed and removed from the filename. </param>
        /// <returns> A new <see cref="Models.PngFormat"/> instance for mocking. </returns>
        public static PngFormat PngFormat(string filenamePattern = null)
        {
            return new PngFormat("#Microsoft.Media.PngFormat", filenamePattern);
        }

        /// <summary> Initializes a new instance of CodecCopyAudio. </summary>
        /// <param name="label"> An optional label for the codec. The label can be used to control muxing behavior. </param>
        /// <returns> A new <see cref="Models.CodecCopyAudio"/> instance for mocking. </returns>
        public static CodecCopyAudio CodecCopyAudio(string label = null)
        {
            return new CodecCopyAudio("#Microsoft.Media.CopyAudio", label);
        }

        /// <summary> Initializes a new instance of DeinterlaceSettings. </summary>
        /// <param name="parity"> The field parity for de-interlacing, defaults to Auto. </param>
        /// <param name="mode"> The deinterlacing mode. Defaults to AutoPixelAdaptive. </param>
        /// <returns> A new <see cref="Models.DeinterlaceSettings"/> instance for mocking. </returns>
        public static DeinterlaceSettings DeinterlaceSettings(DeinterlaceParity? parity = null, DeinterlaceMode? mode = null)
        {
            return new DeinterlaceSettings(parity, mode);
        }

        /// <summary> Initializes a new instance of RectangularWindow. </summary>
        /// <param name="left"> The number of pixels from the left-margin. This can be absolute pixel value (e.g 100), or relative to the size of the video (For example, 50%). </param>
        /// <param name="top"> The number of pixels from the top-margin. This can be absolute pixel value (e.g 100), or relative to the size of the video (For example, 50%). </param>
        /// <param name="width"> The width of the rectangular region in pixels. This can be absolute pixel value (e.g 100), or relative to the size of the video (For example, 50%). </param>
        /// <param name="height"> The height of the rectangular region in pixels. This can be absolute pixel value (e.g 100), or relative to the size of the video (For example, 50%). </param>
        /// <returns> A new <see cref="Models.RectangularWindow"/> instance for mocking. </returns>
        public static RectangularWindow RectangularWindow(string left = null, string top = null, string width = null, string height = null)
        {
            return new RectangularWindow(left, top, width, height);
        }

        /// <summary> Initializes a new instance of FilteringOperations. </summary>
        /// <param name="deinterlace"> The de-interlacing settings. </param>
        /// <param name="rotation"> The rotation, if any, to be applied to the input video, before it is encoded. Default is Auto. </param>
        /// <param name="crop"> The parameters for the rectangular window with which to crop the input video. </param>
        /// <param name="overlays">
        /// The properties of overlays to be applied to the input video. These could be audio, image or video overlays.
        /// Please note <see cref="MediaOverlayBase"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="AudioOverlay"/> and <see cref="VideoOverlay"/>.
        /// </param>
        /// <returns> A new <see cref="Models.FilteringOperations"/> instance for mocking. </returns>
        public static FilteringOperations FilteringOperations(DeinterlaceSettings deinterlace = null, RotationSetting? rotation = null, RectangularWindow crop = null, IEnumerable<MediaOverlayBase> overlays = null)
        {
            overlays ??= new List<MediaOverlayBase>();

            return new FilteringOperations(deinterlace, rotation, crop, overlays?.ToList());
        }

        /// <summary> Initializes a new instance of VideoLayer. </summary>
        /// <param name="width"> The width of the output video for this layer. The value can be absolute (in pixels) or relative (in percentage). For example 50% means the output video has half as many pixels in width as the input. </param>
        /// <param name="height"> The height of the output video for this layer. The value can be absolute (in pixels) or relative (in percentage). For example 50% means the output video has half as many pixels in height as the input. </param>
        /// <param name="label"> The alphanumeric label for this layer, which can be used in multiplexing different video and audio layers, or in naming the output file. </param>
        /// <param name="bitrate"> The average bitrate in bits per second at which to encode the input video when generating this layer. This is a required field. </param>
        /// <param name="maxBitrate"> The maximum bitrate (in bits per second), at which the VBV buffer should be assumed to refill. If not specified, defaults to the same value as bitrate. </param>
        /// <param name="bFrames"> The number of B-frames to be used when encoding this layer.  If not specified, the encoder chooses an appropriate number based on the video profile and level. </param>
        /// <param name="frameRate"> The frame rate (in frames per second) at which to encode this layer. The value can be in the form of M/N where M and N are integers (For example, 30000/1001), or in the form of a number (For example, 30, or 29.97). The encoder enforces constraints on allowed frame rates based on the profile and level. If it is not specified, the encoder will use the same frame rate as the input video. </param>
        /// <param name="slices"> The number of slices to be used when encoding this layer. If not specified, default is zero, which means that encoder will use a single slice for each frame. </param>
        /// <param name="useAdaptiveBFrame"> Whether or not adaptive B-frames are to be used when encoding this layer. If not specified, the encoder will turn it on whenever the video profile permits its use. </param>
        /// <returns> A new <see cref="Models.VideoLayer"/> instance for mocking. </returns>
        public static VideoLayer VideoLayer(string width = null, string height = null, string label = null, int bitrate = default, int? maxBitrate = null, int? bFrames = null, string frameRate = null, int? slices = null, bool? useAdaptiveBFrame = null)
        {
            return new VideoLayer(width, height, label, bitrate, maxBitrate, bFrames, frameRate, slices, useAdaptiveBFrame);
        }

        /// <summary> Initializes a new instance of H264Layer. </summary>
        /// <param name="width"> The width of the output video for this layer. The value can be absolute (in pixels) or relative (in percentage). For example 50% means the output video has half as many pixels in width as the input. </param>
        /// <param name="height"> The height of the output video for this layer. The value can be absolute (in pixels) or relative (in percentage). For example 50% means the output video has half as many pixels in height as the input. </param>
        /// <param name="label"> The alphanumeric label for this layer, which can be used in multiplexing different video and audio layers, or in naming the output file. </param>
        /// <param name="bitrate"> The average bitrate in bits per second at which to encode the input video when generating this layer. This is a required field. </param>
        /// <param name="maxBitrate"> The maximum bitrate (in bits per second), at which the VBV buffer should be assumed to refill. If not specified, defaults to the same value as bitrate. </param>
        /// <param name="bFrames"> The number of B-frames to be used when encoding this layer.  If not specified, the encoder chooses an appropriate number based on the video profile and level. </param>
        /// <param name="frameRate"> The frame rate (in frames per second) at which to encode this layer. The value can be in the form of M/N where M and N are integers (For example, 30000/1001), or in the form of a number (For example, 30, or 29.97). The encoder enforces constraints on allowed frame rates based on the profile and level. If it is not specified, the encoder will use the same frame rate as the input video. </param>
        /// <param name="slices"> The number of slices to be used when encoding this layer. If not specified, default is zero, which means that encoder will use a single slice for each frame. </param>
        /// <param name="useAdaptiveBFrame"> Whether or not adaptive B-frames are to be used when encoding this layer. If not specified, the encoder will turn it on whenever the video profile permits its use. </param>
        /// <param name="profile"> We currently support Baseline, Main, High, High422, High444. Default is Auto. </param>
        /// <param name="level"> We currently support Level up to 6.2. The value can be Auto, or a number that matches the H.264 profile. If not specified, the default is Auto, which lets the encoder choose the Level that is appropriate for this layer. </param>
        /// <param name="bufferWindow"> The VBV buffer window length. The value should be in ISO 8601 format. The value should be in the range [0.1-100] seconds. The default is 5 seconds (for example, PT5S). </param>
        /// <param name="constantRateFactor"> The value of CRF to be used when encoding this layer. This setting takes effect when RateControlMode of video codec is set at CRF mode. The range of CRF value is between 0 and 51, where lower values would result in better quality, at the expense of higher file sizes. Higher values mean more compression, but at some point quality degradation will be noticed. Default value is 23. </param>
        /// <param name="referenceFrames"> The number of reference frames to be used when encoding this layer. If not specified, the encoder determines an appropriate number based on the encoder complexity setting. </param>
        /// <param name="entropyMode"> The entropy mode to be used for this layer. If not specified, the encoder chooses the mode that is appropriate for the profile and level. </param>
        /// <returns> A new <see cref="Models.H264Layer"/> instance for mocking. </returns>
        public static H264Layer H264Layer(string width = null, string height = null, string label = null, int bitrate = default, int? maxBitrate = null, int? bFrames = null, string frameRate = null, int? slices = null, bool? useAdaptiveBFrame = null, H264VideoProfile? profile = null, string level = null, TimeSpan? bufferWindow = null, float? constantRateFactor = null, int? referenceFrames = null, LayerEntropyMode? entropyMode = null)
        {
            return new H264Layer(width, height, label, bitrate, maxBitrate, bFrames, frameRate, slices, useAdaptiveBFrame, profile, level, bufferWindow, constantRateFactor, referenceFrames, entropyMode);
        }

        /// <summary> Initializes a new instance of H264Video. </summary>
        /// <param name="label"> An optional label for the codec. The label can be used to control muxing behavior. </param>
        /// <param name="keyFrameInterval"> The distance between two key frames. The value should be non-zero in the range [0.5, 20] seconds, specified in ISO 8601 format. The default is 2 seconds(PT2S). Note that this setting is ignored if VideoSyncMode.Passthrough is set, where the KeyFrameInterval value will follow the input source setting. </param>
        /// <param name="stretchMode"> The resizing mode - how the input video will be resized to fit the desired output resolution(s). Default is AutoSize. </param>
        /// <param name="syncMode"> The Video Sync Mode. </param>
        /// <param name="complexity"> Tells the encoder how to choose its encoding settings. The default value is Balanced. </param>
        /// <param name="layers"> The collection of output H.264 layers to be produced by the encoder. </param>
        /// <param name="rateControlMode"> The video rate control mode. </param>
        /// <param name="useSceneChangeDetection"> Whether or not the encoder should insert key frames at scene changes. If not specified, the default is false. This flag should be set to true only when the encoder is being configured to produce a single output video. </param>
        /// <returns> A new <see cref="Models.H264Video"/> instance for mocking. </returns>
        public static H264Video H264Video(string label = null, TimeSpan? keyFrameInterval = null, InputVideoStretchMode? stretchMode = null, VideoSyncMode? syncMode = null, H264Complexity? complexity = null, IEnumerable<H264Layer> layers = null, H264RateControlMode? rateControlMode = null, bool? useSceneChangeDetection = null)
        {
            layers ??= new List<H264Layer>();

            return new H264Video("#Microsoft.Media.H264Video", label, keyFrameInterval, stretchMode, syncMode, complexity, layers?.ToList(), rateControlMode, useSceneChangeDetection);
        }

        /// <summary> Initializes a new instance of JpgImage. </summary>
        /// <param name="label"> An optional label for the codec. The label can be used to control muxing behavior. </param>
        /// <param name="keyFrameInterval"> The distance between two key frames. The value should be non-zero in the range [0.5, 20] seconds, specified in ISO 8601 format. The default is 2 seconds(PT2S). Note that this setting is ignored if VideoSyncMode.Passthrough is set, where the KeyFrameInterval value will follow the input source setting. </param>
        /// <param name="stretchMode"> The resizing mode - how the input video will be resized to fit the desired output resolution(s). Default is AutoSize. </param>
        /// <param name="syncMode"> The Video Sync Mode. </param>
        /// <param name="start"> The position in the input video from where to start generating thumbnails. The value can be in ISO 8601 format (For example, PT05S to start at 5 seconds), or a frame count (For example, 10 to start at the 10th frame), or a relative value to stream duration (For example, 10% to start at 10% of stream duration). Also supports a macro {Best}, which tells the encoder to select the best thumbnail from the first few seconds of the video and will only produce one thumbnail, no matter what other settings are for Step and Range. The default value is macro {Best}. </param>
        /// <param name="step"> The intervals at which thumbnails are generated. The value can be in ISO 8601 format (For example, PT05S for one image every 5 seconds), or a frame count (For example, 30 for one image every 30 frames), or a relative value to stream duration (For example, 10% for one image every 10% of stream duration). Note: Step value will affect the first generated thumbnail, which may not be exactly the one specified at transform preset start time. This is due to the encoder, which tries to select the best thumbnail between start time and Step position from start time as the first output. As the default value is 10%, it means if stream has long duration, the first generated thumbnail might be far away from the one specified at start time. Try to select reasonable value for Step if the first thumbnail is expected close to start time, or set Range value at 1 if only one thumbnail is needed at start time. </param>
        /// <param name="range"> The position relative to transform preset start time in the input video at which to stop generating thumbnails. The value can be in ISO 8601 format (For example, PT5M30S to stop at 5 minutes and 30 seconds from start time), or a frame count (For example, 300 to stop at the 300th frame from the frame at start time. If this value is 1, it means only producing one thumbnail at start time), or a relative value to the stream duration (For example, 50% to stop at half of stream duration from start time). The default value is 100%, which means to stop at the end of the stream. </param>
        /// <param name="layers"> A collection of output JPEG image layers to be produced by the encoder. </param>
        /// <param name="spriteColumn"> Sets the number of columns used in thumbnail sprite image.  The number of rows are automatically calculated and a VTT file is generated with the coordinate mappings for each thumbnail in the sprite. Note: this value should be a positive integer and a proper value is recommended so that the output image resolution will not go beyond JPEG maximum pixel resolution limit 65535x65535. </param>
        /// <returns> A new <see cref="Models.JpgImage"/> instance for mocking. </returns>
        public static JpgImage JpgImage(string label = null, TimeSpan? keyFrameInterval = null, InputVideoStretchMode? stretchMode = null, VideoSyncMode? syncMode = null, string start = null, string step = null, string range = null, IEnumerable<JpgLayer> layers = null, int? spriteColumn = null)
        {
            layers ??= new List<JpgLayer>();

            return new JpgImage("#Microsoft.Media.JpgImage", label, keyFrameInterval, stretchMode, syncMode, start, step, range, layers?.ToList(), spriteColumn);
        }

        /// <summary> Initializes a new instance of JpgLayer. </summary>
        /// <param name="width"> The width of the output video for this layer. The value can be absolute (in pixels) or relative (in percentage). For example 50% means the output video has half as many pixels in width as the input. </param>
        /// <param name="height"> The height of the output video for this layer. The value can be absolute (in pixels) or relative (in percentage). For example 50% means the output video has half as many pixels in height as the input. </param>
        /// <param name="label"> The alphanumeric label for this layer, which can be used in multiplexing different video and audio layers, or in naming the output file. </param>
        /// <param name="quality"> The compression quality of the JPEG output. Range is from 0-100 and the default is 70. </param>
        /// <returns> A new <see cref="Models.JpgLayer"/> instance for mocking. </returns>
        public static JpgLayer JpgLayer(string width = null, string height = null, string label = null, int? quality = null)
        {
            return new JpgLayer(width, height, label, quality);
        }

        /// <summary> Initializes a new instance of MultiBitrateFormat. </summary>
        /// <param name="filenamePattern"> The pattern of the file names for the generated output files. The following macros are supported in the file name: {Basename} - An expansion macro that will use the name of the input video file. If the base name(the file suffix is not included) of the input video file is less than 32 characters long, the base name of input video files will be used. If the length of base name of the input video file exceeds 32 characters, the base name is truncated to the first 32 characters in total length. {Extension} - The appropriate extension for this format. {Label} - The label assigned to the codec/layer. {Index} - A unique index for thumbnails. Only applicable to thumbnails. {Bitrate} - The audio/video bitrate. Not applicable to thumbnails. {Codec} - The type of the audio/video codec. {Resolution} - The video resolution. Any unsubstituted macros will be collapsed and removed from the filename. </param>
        /// <param name="outputFiles"> The list of output files to produce.  Each entry in the list is a set of audio and video layer labels to be muxed together . </param>
        /// <returns> A new <see cref="Models.MultiBitrateFormat"/> instance for mocking. </returns>
        public static MultiBitrateFormat MultiBitrateFormat(string filenamePattern = null, IEnumerable<MediaOutputFile> outputFiles = null)
        {
            outputFiles ??= new List<MediaOutputFile>();

            return new MultiBitrateFormat("#Microsoft.Media.MultiBitrateFormat", filenamePattern, outputFiles?.ToList());
        }

        /// <summary> Initializes a new instance of Mp4Format. </summary>
        /// <param name="filenamePattern"> The pattern of the file names for the generated output files. The following macros are supported in the file name: {Basename} - An expansion macro that will use the name of the input video file. If the base name(the file suffix is not included) of the input video file is less than 32 characters long, the base name of input video files will be used. If the length of base name of the input video file exceeds 32 characters, the base name is truncated to the first 32 characters in total length. {Extension} - The appropriate extension for this format. {Label} - The label assigned to the codec/layer. {Index} - A unique index for thumbnails. Only applicable to thumbnails. {Bitrate} - The audio/video bitrate. Not applicable to thumbnails. {Codec} - The type of the audio/video codec. {Resolution} - The video resolution. Any unsubstituted macros will be collapsed and removed from the filename. </param>
        /// <param name="outputFiles"> The list of output files to produce.  Each entry in the list is a set of audio and video layer labels to be muxed together . </param>
        /// <returns> A new <see cref="Models.Mp4Format"/> instance for mocking. </returns>
        public static Mp4Format Mp4Format(string filenamePattern = null, IEnumerable<MediaOutputFile> outputFiles = null)
        {
            outputFiles ??= new List<MediaOutputFile>();

            return new Mp4Format("#Microsoft.Media.Mp4Format", filenamePattern, outputFiles?.ToList());
        }

        /// <summary> Initializes a new instance of PngImage. </summary>
        /// <param name="label"> An optional label for the codec. The label can be used to control muxing behavior. </param>
        /// <param name="keyFrameInterval"> The distance between two key frames. The value should be non-zero in the range [0.5, 20] seconds, specified in ISO 8601 format. The default is 2 seconds(PT2S). Note that this setting is ignored if VideoSyncMode.Passthrough is set, where the KeyFrameInterval value will follow the input source setting. </param>
        /// <param name="stretchMode"> The resizing mode - how the input video will be resized to fit the desired output resolution(s). Default is AutoSize. </param>
        /// <param name="syncMode"> The Video Sync Mode. </param>
        /// <param name="start"> The position in the input video from where to start generating thumbnails. The value can be in ISO 8601 format (For example, PT05S to start at 5 seconds), or a frame count (For example, 10 to start at the 10th frame), or a relative value to stream duration (For example, 10% to start at 10% of stream duration). Also supports a macro {Best}, which tells the encoder to select the best thumbnail from the first few seconds of the video and will only produce one thumbnail, no matter what other settings are for Step and Range. The default value is macro {Best}. </param>
        /// <param name="step"> The intervals at which thumbnails are generated. The value can be in ISO 8601 format (For example, PT05S for one image every 5 seconds), or a frame count (For example, 30 for one image every 30 frames), or a relative value to stream duration (For example, 10% for one image every 10% of stream duration). Note: Step value will affect the first generated thumbnail, which may not be exactly the one specified at transform preset start time. This is due to the encoder, which tries to select the best thumbnail between start time and Step position from start time as the first output. As the default value is 10%, it means if stream has long duration, the first generated thumbnail might be far away from the one specified at start time. Try to select reasonable value for Step if the first thumbnail is expected close to start time, or set Range value at 1 if only one thumbnail is needed at start time. </param>
        /// <param name="range"> The position relative to transform preset start time in the input video at which to stop generating thumbnails. The value can be in ISO 8601 format (For example, PT5M30S to stop at 5 minutes and 30 seconds from start time), or a frame count (For example, 300 to stop at the 300th frame from the frame at start time. If this value is 1, it means only producing one thumbnail at start time), or a relative value to the stream duration (For example, 50% to stop at half of stream duration from start time). The default value is 100%, which means to stop at the end of the stream. </param>
        /// <param name="layers"> A collection of output PNG image layers to be produced by the encoder. </param>
        /// <returns> A new <see cref="Models.PngImage"/> instance for mocking. </returns>
        public static PngImage PngImage(string label = null, TimeSpan? keyFrameInterval = null, InputVideoStretchMode? stretchMode = null, VideoSyncMode? syncMode = null, string start = null, string step = null, string range = null, IEnumerable<PngLayer> layers = null)
        {
            layers ??= new List<PngLayer>();

            return new PngImage("#Microsoft.Media.PngImage", label, keyFrameInterval, stretchMode, syncMode, start, step, range, layers?.ToList());
        }

        /// <summary> Initializes a new instance of PngLayer. </summary>
        /// <param name="width"> The width of the output video for this layer. The value can be absolute (in pixels) or relative (in percentage). For example 50% means the output video has half as many pixels in width as the input. </param>
        /// <param name="height"> The height of the output video for this layer. The value can be absolute (in pixels) or relative (in percentage). For example 50% means the output video has half as many pixels in height as the input. </param>
        /// <param name="label"> The alphanumeric label for this layer, which can be used in multiplexing different video and audio layers, or in naming the output file. </param>
        /// <returns> A new <see cref="Models.PngLayer"/> instance for mocking. </returns>
        public static PngLayer PngLayer(string width = null, string height = null, string label = null)
        {
            return new PngLayer(width, height, label);
        }

        /// <summary> Initializes a new instance of BuiltInStandardEncoderPreset. </summary>
        /// <param name="configurations"> Optional configuration settings for encoder. Configurations is only supported for ContentAwareEncoding and H265ContentAwareEncoding BuiltInStandardEncoderPreset. </param>
        /// <param name="presetName"> The built-in preset to be used for encoding videos. </param>
        /// <returns> A new <see cref="Models.BuiltInStandardEncoderPreset"/> instance for mocking. </returns>
        public static BuiltInStandardEncoderPreset BuiltInStandardEncoderPreset(EncoderPresetConfigurations configurations = null, EncoderNamedPreset presetName = default)
        {
            return new BuiltInStandardEncoderPreset("#Microsoft.Media.BuiltInStandardEncoderPreset", configurations, presetName);
        }

        /// <summary> Initializes a new instance of EncoderPresetConfigurations. </summary>
        /// <param name="complexity"> Allows you to configure the encoder settings to control the balance between speed and quality. Example: set Complexity as Speed for faster encoding but less compression efficiency. </param>
        /// <param name="interleaveOutput"> Sets the interleave mode of the output to control how audio and video are stored in the container format. Example: set InterleavedOutput as NonInterleavedOutput to produce audio-only and video-only outputs in separate MP4 files. </param>
        /// <param name="keyFrameIntervalInSeconds"> The key frame interval in seconds. Example: set KeyFrameIntervalInSeconds as 2 to reduce the playback buffering for some players. </param>
        /// <param name="maxBitrateBps"> The maximum bitrate in bits per second (threshold for the top video layer). Example: set MaxBitrateBps as 6000000 to avoid producing very high bitrate outputs for contents with high complexity. </param>
        /// <param name="maxHeight"> The maximum height of output video layers. Example: set MaxHeight as 720 to produce output layers up to 720P even if the input is 4K. </param>
        /// <param name="maxLayers"> The maximum number of output video layers. Example: set MaxLayers as 4 to make sure at most 4 output layers are produced to control the overall cost of the encoding job. </param>
        /// <param name="minBitrateBps"> The minimum bitrate in bits per second (threshold for the bottom video layer). Example: set MinBitrateBps as 200000 to have a bottom layer that covers users with low network bandwidth. </param>
        /// <param name="minHeight"> The minimum height of output video layers. Example: set MinHeight as 360 to avoid output layers of smaller resolutions like 180P. </param>
        /// <returns> A new <see cref="Models.EncoderPresetConfigurations"/> instance for mocking. </returns>
        public static EncoderPresetConfigurations EncoderPresetConfigurations(EncodingComplexity? complexity = null, InterleaveOutput? interleaveOutput = null, float? keyFrameIntervalInSeconds = null, int? maxBitrateBps = null, int? maxHeight = null, int? maxLayers = null, int? minBitrateBps = null, int? minHeight = null)
        {
            return new EncoderPresetConfigurations(complexity, interleaveOutput, keyFrameIntervalInSeconds, maxBitrateBps, maxHeight, maxLayers, minBitrateBps, minHeight);
        }

        /// <summary> Initializes a new instance of StandardEncoderPreset. </summary>
        /// <param name="filters"> One or more filtering operations that are applied to the input media before encoding. </param>
        /// <param name="codecs">
        /// The list of codecs to be used when encoding the input video.
        /// Please note <see cref="MediaCodecBase"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="AacAudio"/>, <see cref="MediaAudioBase"/>, <see cref="CodecCopyAudio"/>, <see cref="CodecCopyVideo"/>, <see cref="H264Video"/>, <see cref="H265Video"/>, <see cref="MediaImageBase"/>, <see cref="JpgImage"/>, <see cref="PngImage"/> and <see cref="MediaVideoBase"/>.
        /// </param>
        /// <param name="formats">
        /// The list of outputs to be produced by the encoder.
        /// Please note <see cref="MediaFormatBase"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="OutputImageFileFormat"/>, <see cref="JpgFormat"/>, <see cref="Mp4Format"/>, <see cref="MultiBitrateFormat"/>, <see cref="PngFormat"/> and <see cref="TransportStreamFormat"/>.
        /// </param>
        /// <returns> A new <see cref="Models.StandardEncoderPreset"/> instance for mocking. </returns>
        public static StandardEncoderPreset StandardEncoderPreset(FilteringOperations filters = null, IEnumerable<MediaCodecBase> codecs = null, IEnumerable<MediaFormatBase> formats = null)
        {
            codecs ??= new List<MediaCodecBase>();
            formats ??= new List<MediaFormatBase>();

            return new StandardEncoderPreset("#Microsoft.Media.StandardEncoderPreset", filters, codecs?.ToList(), formats?.ToList());
        }

        /// <summary> Initializes a new instance of VideoAnalyzerPreset. </summary>
        /// <param name="audioLanguage"> The language for the audio payload in the input using the BCP-47 format of &apos;language tag-region&apos; (e.g: &apos;en-US&apos;).  If you know the language of your content, it is recommended that you specify it. The language must be specified explicitly for AudioAnalysisMode::Basic, since automatic language detection is not included in basic mode. If the language isn&apos;t specified or set to null, automatic language detection will choose the first language detected and process with the selected language for the duration of the file. It does not currently support dynamically switching between languages after the first language is detected. The automatic detection works best with audio recordings with clearly discernable speech. If automatic detection fails to find the language, transcription would fallback to &apos;en-US&apos;.&quot; The list of supported languages is available here: https://go.microsoft.com/fwlink/?linkid=2109463. </param>
        /// <param name="mode"> Determines the set of audio analysis operations to be performed. If unspecified, the Standard AudioAnalysisMode would be chosen. </param>
        /// <param name="experimentalOptions"> Dictionary containing key value pairs for parameters not exposed in the preset itself. </param>
        /// <param name="insightsToExtract"> Defines the type of insights that you want the service to generate. The allowed values are &apos;AudioInsightsOnly&apos;, &apos;VideoInsightsOnly&apos;, and &apos;AllInsights&apos;. The default is AllInsights. If you set this to AllInsights and the input is audio only, then only audio insights are generated. Similarly if the input is video only, then only video insights are generated. It is recommended that you not use AudioInsightsOnly if you expect some of your inputs to be video only; or use VideoInsightsOnly if you expect some of your inputs to be audio only. Your Jobs in such conditions would error out. </param>
        /// <returns> A new <see cref="Models.VideoAnalyzerPreset"/> instance for mocking. </returns>
        public static VideoAnalyzerPreset VideoAnalyzerPreset(string audioLanguage = null, AudioAnalysisMode? mode = null, IDictionary<string, string> experimentalOptions = null, InsightsType? insightsToExtract = null)
        {
            experimentalOptions ??= new Dictionary<string, string>();

            return new VideoAnalyzerPreset("#Microsoft.Media.VideoAnalyzerPreset", audioLanguage, mode, experimentalOptions, insightsToExtract);
        }

        /// <summary> Initializes a new instance of TransportStreamFormat. </summary>
        /// <param name="filenamePattern"> The pattern of the file names for the generated output files. The following macros are supported in the file name: {Basename} - An expansion macro that will use the name of the input video file. If the base name(the file suffix is not included) of the input video file is less than 32 characters long, the base name of input video files will be used. If the length of base name of the input video file exceeds 32 characters, the base name is truncated to the first 32 characters in total length. {Extension} - The appropriate extension for this format. {Label} - The label assigned to the codec/layer. {Index} - A unique index for thumbnails. Only applicable to thumbnails. {Bitrate} - The audio/video bitrate. Not applicable to thumbnails. {Codec} - The type of the audio/video codec. {Resolution} - The video resolution. Any unsubstituted macros will be collapsed and removed from the filename. </param>
        /// <param name="outputFiles"> The list of output files to produce.  Each entry in the list is a set of audio and video layer labels to be muxed together . </param>
        /// <returns> A new <see cref="Models.TransportStreamFormat"/> instance for mocking. </returns>
        public static TransportStreamFormat TransportStreamFormat(string filenamePattern = null, IEnumerable<MediaOutputFile> outputFiles = null)
        {
            outputFiles ??= new List<MediaOutputFile>();

            return new TransportStreamFormat("#Microsoft.Media.TransportStreamFormat", filenamePattern, outputFiles?.ToList());
        }

        /// <summary> Initializes a new instance of VideoOverlay. </summary>
        /// <param name="inputLabel"> The label of the job input which is to be used as an overlay. The Input must specify exactly one file. You can specify an image file in JPG, PNG, GIF or BMP format, or an audio file (such as a WAV, MP3, WMA or M4A file), or a video file. See https://aka.ms/mesformats for the complete list of supported audio and video file formats. </param>
        /// <param name="start"> The start position, with reference to the input video, at which the overlay starts. The value should be in ISO 8601 format. For example, PT05S to start the overlay at 5 seconds into the input video. If not specified the overlay starts from the beginning of the input video. </param>
        /// <param name="end"> The end position, with reference to the input video, at which the overlay ends. The value should be in ISO 8601 format. For example, PT30S to end the overlay at 30 seconds into the input video. If not specified or the value is greater than the input video duration, the overlay will be applied until the end of the input video if the overlay media duration is greater than the input video duration, else the overlay will last as long as the overlay media duration. </param>
        /// <param name="fadeInDuration"> The duration over which the overlay fades in onto the input video. The value should be in ISO 8601 duration format. If not specified the default behavior is to have no fade in (same as PT0S). </param>
        /// <param name="fadeOutDuration"> The duration over which the overlay fades out of the input video. The value should be in ISO 8601 duration format. If not specified the default behavior is to have no fade out (same as PT0S). </param>
        /// <param name="audioGainLevel"> The gain level of audio in the overlay. The value should be in the range [0, 1.0]. The default is 1.0. </param>
        /// <param name="position"> The location in the input video where the overlay is applied. </param>
        /// <param name="opacity"> The opacity of the overlay. This is a value in the range [0 - 1.0]. Default is 1.0 which mean the overlay is opaque. </param>
        /// <param name="cropRectangle"> An optional rectangular window used to crop the overlay image or video. </param>
        /// <returns> A new <see cref="Models.VideoOverlay"/> instance for mocking. </returns>
        public static VideoOverlay VideoOverlay(string inputLabel = null, TimeSpan? start = null, TimeSpan? end = null, TimeSpan? fadeInDuration = null, TimeSpan? fadeOutDuration = null, double? audioGainLevel = null, RectangularWindow position = null, double? opacity = null, RectangularWindow cropRectangle = null)
        {
            return new VideoOverlay("#Microsoft.Media.VideoOverlay", inputLabel, start, end, fadeInDuration, fadeOutDuration, audioGainLevel, position, opacity, cropRectangle);
        }

        /// <summary> Initializes a new instance of VideoTrackDescriptor. </summary>
        /// <returns> A new <see cref="Models.VideoTrackDescriptor"/> instance for mocking. </returns>
        public static VideoTrackDescriptor VideoTrackDescriptor()
        {
            return new VideoTrackDescriptor("#Microsoft.Media.VideoTrackDescriptor");
        }

        /// <summary> Initializes a new instance of SelectVideoTrackByAttribute. </summary>
        /// <param name="attribute"> The TrackAttribute to filter the tracks by. </param>
        /// <param name="filter"> The type of AttributeFilter to apply to the TrackAttribute in order to select the tracks. </param>
        /// <param name="filterValue"> The value to filter the tracks by.  Only used when AttributeFilter.ValueEquals is specified for the Filter property. For TrackAttribute.Bitrate, this should be an integer value in bits per second (e.g: &apos;1500000&apos;).  The TrackAttribute.Language is not supported for video tracks. </param>
        /// <returns> A new <see cref="Models.SelectVideoTrackByAttribute"/> instance for mocking. </returns>
        public static SelectVideoTrackByAttribute SelectVideoTrackByAttribute(TrackAttribute attribute = default, TrackAttributeFilter filter = default, string filterValue = null)
        {
            return new SelectVideoTrackByAttribute("#Microsoft.Media.SelectVideoTrackByAttribute", attribute, filter, filterValue);
        }

        /// <summary> Initializes a new instance of SelectVideoTrackById. </summary>
        /// <param name="trackId"> Track identifier to select. </param>
        /// <returns> A new <see cref="Models.SelectVideoTrackById"/> instance for mocking. </returns>
        public static SelectVideoTrackById SelectVideoTrackById(long trackId = default)
        {
            return new SelectVideoTrackById("#Microsoft.Media.SelectVideoTrackById", trackId);
        }

        /// <summary> Initializes a new instance of MediaJobInputClip. </summary>
        /// <param name="files"> List of files. Required for JobInputHttp. Maximum of 4000 characters each. Query strings will not be returned in service responses to prevent sensitive data exposure. </param>
        /// <param name="start">
        /// Defines a point on the timeline of the input media at which processing will start. Defaults to the beginning of the input media.
        /// Please note <see cref="ClipTime"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="AbsoluteClipTime"/> and <see cref="UtcClipTime"/>.
        /// </param>
        /// <param name="end">
        /// Defines a point on the timeline of the input media at which processing will end. Defaults to the end of the input media.
        /// Please note <see cref="ClipTime"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="AbsoluteClipTime"/> and <see cref="UtcClipTime"/>.
        /// </param>
        /// <param name="label"> A label that is assigned to a JobInputClip, that is used to satisfy a reference used in the Transform. For example, a Transform can be authored so as to take an image file with the label &apos;xyz&apos; and apply it as an overlay onto the input video before it is encoded. When submitting a Job, exactly one of the JobInputs should be the image file, and it should have the label &apos;xyz&apos;. </param>
        /// <param name="inputDefinitions">
        /// Defines a list of InputDefinitions. For each InputDefinition, it defines a list of track selections and related metadata.
        /// Please note <see cref="MediaJobInputDefinition"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="FromAllInputFile"/>, <see cref="FromEachInputFile"/> and <see cref="MediaJobInputFile"/>.
        /// </param>
        /// <returns> A new <see cref="Models.MediaJobInputClip"/> instance for mocking. </returns>
        public static MediaJobInputClip MediaJobInputClip(IEnumerable<string> files = null, ClipTime start = null, ClipTime end = null, string label = null, IEnumerable<MediaJobInputDefinition> inputDefinitions = null)
        {
            files ??= new List<string>();
            inputDefinitions ??= new List<MediaJobInputDefinition>();

            return new MediaJobInputClip("#Microsoft.Media.JobInputClip", files?.ToList(), start, end, label, inputDefinitions?.ToList());
        }

        /// <summary> Initializes a new instance of ClipTime. </summary>
        /// <param name="odataType"> The discriminator for derived types. </param>
        /// <returns> A new <see cref="Models.ClipTime"/> instance for mocking. </returns>
        public static ClipTime ClipTime(string odataType = null)
        {
            return new UnknownClipTime(odataType);
        }

        /// <summary> Initializes a new instance of AbsoluteClipTime. </summary>
        /// <param name="time"> The time position on the timeline of the input media. It is usually specified as an ISO8601 period. e.g PT30S for 30 seconds. </param>
        /// <returns> A new <see cref="Models.AbsoluteClipTime"/> instance for mocking. </returns>
        public static AbsoluteClipTime AbsoluteClipTime(TimeSpan time = default)
        {
            return new AbsoluteClipTime("#Microsoft.Media.AbsoluteClipTime", time);
        }

        /// <summary> Initializes a new instance of UtcClipTime. </summary>
        /// <param name="time"> The time position on the timeline of the input media based on Utc time. </param>
        /// <returns> A new <see cref="Models.UtcClipTime"/> instance for mocking. </returns>
        public static UtcClipTime UtcClipTime(DateTimeOffset time = default)
        {
            return new UtcClipTime("#Microsoft.Media.UtcClipTime", time);
        }

        /// <summary> Initializes a new instance of MediaJobInputs. </summary>
        /// <param name="inputs">
        /// List of inputs to a Job.
        /// Please note <see cref="MediaJobInputBasicProperties"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="MediaJobInputAsset"/>, <see cref="MediaJobInputClip"/>, <see cref="MediaJobInputHttp"/>, <see cref="MediaJobInputSequence"/> and <see cref="MediaJobInputs"/>.
        /// </param>
        /// <returns> A new <see cref="Models.MediaJobInputs"/> instance for mocking. </returns>
        public static MediaJobInputs MediaJobInputs(IEnumerable<MediaJobInputBasicProperties> inputs = null)
        {
            inputs ??= new List<MediaJobInputBasicProperties>();

            return new MediaJobInputs("#Microsoft.Media.JobInputs", inputs?.ToList());
        }

        /// <summary> Initializes a new instance of MediaJobInputAsset. </summary>
        /// <param name="files"> List of files. Required for JobInputHttp. Maximum of 4000 characters each. Query strings will not be returned in service responses to prevent sensitive data exposure. </param>
        /// <param name="start">
        /// Defines a point on the timeline of the input media at which processing will start. Defaults to the beginning of the input media.
        /// Please note <see cref="ClipTime"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="AbsoluteClipTime"/> and <see cref="UtcClipTime"/>.
        /// </param>
        /// <param name="end">
        /// Defines a point on the timeline of the input media at which processing will end. Defaults to the end of the input media.
        /// Please note <see cref="ClipTime"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="AbsoluteClipTime"/> and <see cref="UtcClipTime"/>.
        /// </param>
        /// <param name="label"> A label that is assigned to a JobInputClip, that is used to satisfy a reference used in the Transform. For example, a Transform can be authored so as to take an image file with the label &apos;xyz&apos; and apply it as an overlay onto the input video before it is encoded. When submitting a Job, exactly one of the JobInputs should be the image file, and it should have the label &apos;xyz&apos;. </param>
        /// <param name="inputDefinitions">
        /// Defines a list of InputDefinitions. For each InputDefinition, it defines a list of track selections and related metadata.
        /// Please note <see cref="MediaJobInputDefinition"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="FromAllInputFile"/>, <see cref="FromEachInputFile"/> and <see cref="MediaJobInputFile"/>.
        /// </param>
        /// <param name="assetName"> The name of the input Asset. </param>
        /// <returns> A new <see cref="Models.MediaJobInputAsset"/> instance for mocking. </returns>
        public static MediaJobInputAsset MediaJobInputAsset(IEnumerable<string> files = null, ClipTime start = null, ClipTime end = null, string label = null, IEnumerable<MediaJobInputDefinition> inputDefinitions = null, string assetName = null)
        {
            files ??= new List<string>();
            inputDefinitions ??= new List<MediaJobInputDefinition>();

            return new MediaJobInputAsset("#Microsoft.Media.JobInputAsset", files?.ToList(), start, end, label, inputDefinitions?.ToList(), assetName);
        }

        /// <summary> Initializes a new instance of MediaJobInputHttp. </summary>
        /// <param name="files"> List of files. Required for JobInputHttp. Maximum of 4000 characters each. Query strings will not be returned in service responses to prevent sensitive data exposure. </param>
        /// <param name="start">
        /// Defines a point on the timeline of the input media at which processing will start. Defaults to the beginning of the input media.
        /// Please note <see cref="ClipTime"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="AbsoluteClipTime"/> and <see cref="UtcClipTime"/>.
        /// </param>
        /// <param name="end">
        /// Defines a point on the timeline of the input media at which processing will end. Defaults to the end of the input media.
        /// Please note <see cref="ClipTime"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="AbsoluteClipTime"/> and <see cref="UtcClipTime"/>.
        /// </param>
        /// <param name="label"> A label that is assigned to a JobInputClip, that is used to satisfy a reference used in the Transform. For example, a Transform can be authored so as to take an image file with the label &apos;xyz&apos; and apply it as an overlay onto the input video before it is encoded. When submitting a Job, exactly one of the JobInputs should be the image file, and it should have the label &apos;xyz&apos;. </param>
        /// <param name="inputDefinitions">
        /// Defines a list of InputDefinitions. For each InputDefinition, it defines a list of track selections and related metadata.
        /// Please note <see cref="MediaJobInputDefinition"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="FromAllInputFile"/>, <see cref="FromEachInputFile"/> and <see cref="MediaJobInputFile"/>.
        /// </param>
        /// <param name="baseUri"> Base URI for HTTPS job input. It will be concatenated with provided file names. If no base uri is given, then the provided file list is assumed to be fully qualified uris. Maximum length of 4000 characters. The query strings will not be returned in service responses to prevent sensitive data exposure. </param>
        /// <returns> A new <see cref="Models.MediaJobInputHttp"/> instance for mocking. </returns>
        public static MediaJobInputHttp MediaJobInputHttp(IEnumerable<string> files = null, ClipTime start = null, ClipTime end = null, string label = null, IEnumerable<MediaJobInputDefinition> inputDefinitions = null, Uri baseUri = null)
        {
            files ??= new List<string>();
            inputDefinitions ??= new List<MediaJobInputDefinition>();

            return new MediaJobInputHttp("#Microsoft.Media.JobInputHttp", files?.ToList(), start, end, label, inputDefinitions?.ToList(), baseUri);
        }

        /// <summary> Initializes a new instance of MediaJobOutputAsset. </summary>
        /// <param name="error"> If the JobOutput is in the Error state, it contains the details of the error. </param>
        /// <param name="presetOverride">
        /// A preset used to override the preset in the corresponding transform output.
        /// Please note <see cref="MediaTransformPreset"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="AudioAnalyzerPreset"/>, <see cref="BuiltInStandardEncoderPreset"/>, <see cref="StandardEncoderPreset"/> and <see cref="VideoAnalyzerPreset"/>.
        /// </param>
        /// <param name="state"> Describes the state of the JobOutput. </param>
        /// <param name="progress"> If the JobOutput is in a Processing state, this contains the Job completion percentage. The value is an estimate and not intended to be used to predict Job completion times. To determine if the JobOutput is complete, use the State property. </param>
        /// <param name="label"> A label that is assigned to a JobOutput in order to help uniquely identify it. This is useful when your Transform has more than one TransformOutput, whereby your Job has more than one JobOutput. In such cases, when you submit the Job, you will add two or more JobOutputs, in the same order as TransformOutputs in the Transform. Subsequently, when you retrieve the Job, either through events or on a GET request, you can use the label to easily identify the JobOutput. If a label is not provided, a default value of &apos;{presetName}_{outputIndex}&apos; will be used, where the preset name is the name of the preset in the corresponding TransformOutput and the output index is the relative index of the this JobOutput within the Job. Note that this index is the same as the relative index of the corresponding TransformOutput within its Transform. </param>
        /// <param name="startOn"> The UTC date and time at which this Job Output began processing. </param>
        /// <param name="endOn"> The UTC date and time at which this Job Output finished processing. </param>
        /// <param name="assetName"> The name of the output Asset. </param>
        /// <returns> A new <see cref="Models.MediaJobOutputAsset"/> instance for mocking. </returns>
        public static MediaJobOutputAsset MediaJobOutputAsset(MediaJobError error = null, MediaTransformPreset presetOverride = null, MediaJobState? state = null, int? progress = null, string label = null, DateTimeOffset? startOn = null, DateTimeOffset? endOn = null, string assetName = null)
        {
            return new MediaJobOutputAsset("#Microsoft.Media.JobOutputAsset", error, presetOverride, state, progress, label, startOn, endOn, assetName);
        }

        /// <summary> Initializes a new instance of MediaJobInputSequence. </summary>
        /// <param name="inputs">
        /// JobInputs that make up the timeline.
        /// Please note <see cref="MediaJobInputClip"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="MediaJobInputAsset"/> and <see cref="MediaJobInputHttp"/>.
        /// </param>
        /// <returns> A new <see cref="Models.MediaJobInputSequence"/> instance for mocking. </returns>
        public static MediaJobInputSequence MediaJobInputSequence(IEnumerable<MediaJobInputClip> inputs = null)
        {
            inputs ??= new List<MediaJobInputClip>();

            return new MediaJobInputSequence("#Microsoft.Media.JobInputSequence", inputs?.ToList());
        }
    }
}

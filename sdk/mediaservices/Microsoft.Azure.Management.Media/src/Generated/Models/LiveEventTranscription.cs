// <auto-generated>
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License. See License.txt in the project root for
// license information.
//
// Code generated by Microsoft (R) AutoRest Code Generator.
// Changes may cause incorrect behavior and will be lost if the code is
// regenerated.
// </auto-generated>

namespace Microsoft.Azure.Management.Media.Models
{
    using Newtonsoft.Json;
    using System.Collections;
    using System.Collections.Generic;
    using System.Linq;

    /// <summary>
    /// Describes the transcription tracks in the output of a Live Event,
    /// generated using speech-to-text transcription.
    /// </summary>
    public partial class LiveEventTranscription
    {
        /// <summary>
        /// Initializes a new instance of the LiveEventTranscription class.
        /// </summary>
        public LiveEventTranscription()
        {
            CustomInit();
        }

        /// <summary>
        /// Initializes a new instance of the LiveEventTranscription class.
        /// </summary>
        /// <param name="language">Specifies the language (locale) used for
        /// speech-to-text transcription � it should match the spoken language
        /// in the audio track. The value should be in BCP-47 format of
        /// 'language tag-region' (e.g: 'en-US'). The list of supported
        /// languages are 'en-US' and 'en-GB'.</param>
        /// <param name="inputTrackSelection">Provides a mechanism to select
        /// the audio track in the input live feed, to which speech-to-text
        /// transcription is applied.</param>
        /// <param name="outputTranscriptionTrack">Describes a transcription
        /// track in the output of a Live Event, generated using speech-to-text
        /// transcription.</param>
        public LiveEventTranscription(string language = default(string), IList<LiveEventInputTrackSelection> inputTrackSelection = default(IList<LiveEventInputTrackSelection>), LiveEventOutputTranscriptionTrack outputTranscriptionTrack = default(LiveEventOutputTranscriptionTrack))
        {
            Language = language;
            InputTrackSelection = inputTrackSelection;
            OutputTranscriptionTrack = outputTranscriptionTrack;
            CustomInit();
        }

        /// <summary>
        /// An initialization method that performs custom operations like setting defaults
        /// </summary>
        partial void CustomInit();

        /// <summary>
        /// Gets or sets specifies the language (locale) used for
        /// speech-to-text transcription � it should match the spoken language
        /// in the audio track. The value should be in BCP-47 format of
        /// 'language tag-region' (e.g: 'en-US'). The list of supported
        /// languages are 'en-US' and 'en-GB'.
        /// </summary>
        [JsonProperty(PropertyName = "language")]
        public string Language { get; set; }

        /// <summary>
        /// Gets or sets provides a mechanism to select the audio track in the
        /// input live feed, to which speech-to-text transcription is applied.
        /// </summary>
        [JsonProperty(PropertyName = "inputTrackSelection")]
        public IList<LiveEventInputTrackSelection> InputTrackSelection { get; set; }

        /// <summary>
        /// Gets or sets describes a transcription track in the output of a
        /// Live Event, generated using speech-to-text transcription.
        /// </summary>
        [JsonProperty(PropertyName = "outputTranscriptionTrack")]
        public LiveEventOutputTranscriptionTrack OutputTranscriptionTrack { get; set; }

        /// <summary>
        /// Validate the object.
        /// </summary>
        /// <exception cref="Rest.ValidationException">
        /// Thrown if validation fails
        /// </exception>
        public virtual void Validate()
        {
            if (OutputTranscriptionTrack != null)
            {
                OutputTranscriptionTrack.Validate();
            }
        }
    }
}

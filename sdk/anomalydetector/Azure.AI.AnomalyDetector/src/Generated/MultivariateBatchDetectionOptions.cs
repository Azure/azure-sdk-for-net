// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.

// <auto-generated/>

#nullable disable

using System;
using Azure.Core;

namespace Azure.AI.AnomalyDetector
{
    /// <summary>
    /// Detection request for batch inference. This is an asynchronous inference that
    /// will need another API to get detection results.
    /// </summary>
    public partial class MultivariateBatchDetectionOptions
    {
        /// <summary> Initializes a new instance of <see cref="MultivariateBatchDetectionOptions"/>. </summary>
        /// <param name="dataSource">
        /// Source link to the input data to indicate an accessible Azure Storage URI.
        /// It either points to an Azure Blob Storage folder or points to a CSV file in
        /// Azure Blob Storage, based on your data schema selection. The data schema should
        /// be exactly the same as those used in the training phase. The input data must
        /// contain at least slidingWindow entries preceding the start time of the data
        /// to be detected.
        /// </param>
        /// <param name="startTime">
        /// Start date/time of data for detection, which should
        /// be in ISO 8601 format.
        /// </param>
        /// <param name="endTime">
        /// End date/time of data for detection, which should
        /// be in ISO 8601 format.
        /// </param>
        /// <exception cref="ArgumentNullException"> <paramref name="dataSource"/> is null. </exception>
        public MultivariateBatchDetectionOptions(Uri dataSource, DateTimeOffset startTime, DateTimeOffset endTime)
        {
            Argument.AssertNotNull(dataSource, nameof(dataSource));

            DataSource = dataSource;
            StartTime = startTime;
            EndTime = endTime;
        }

        /// <summary> Initializes a new instance of <see cref="MultivariateBatchDetectionOptions"/>. </summary>
        /// <param name="dataSource">
        /// Source link to the input data to indicate an accessible Azure Storage URI.
        /// It either points to an Azure Blob Storage folder or points to a CSV file in
        /// Azure Blob Storage, based on your data schema selection. The data schema should
        /// be exactly the same as those used in the training phase. The input data must
        /// contain at least slidingWindow entries preceding the start time of the data
        /// to be detected.
        /// </param>
        /// <param name="topContributorCount"> Number of top contributed variables for one anomalous time stamp in the response. </param>
        /// <param name="startTime">
        /// Start date/time of data for detection, which should
        /// be in ISO 8601 format.
        /// </param>
        /// <param name="endTime">
        /// End date/time of data for detection, which should
        /// be in ISO 8601 format.
        /// </param>
        internal MultivariateBatchDetectionOptions(Uri dataSource, int? topContributorCount, DateTimeOffset startTime, DateTimeOffset endTime)
        {
            DataSource = dataSource;
            TopContributorCount = topContributorCount;
            StartTime = startTime;
            EndTime = endTime;
        }

        /// <summary>
        /// Source link to the input data to indicate an accessible Azure Storage URI.
        /// It either points to an Azure Blob Storage folder or points to a CSV file in
        /// Azure Blob Storage, based on your data schema selection. The data schema should
        /// be exactly the same as those used in the training phase. The input data must
        /// contain at least slidingWindow entries preceding the start time of the data
        /// to be detected.
        /// </summary>
        public Uri DataSource { get; set; }
        /// <summary> Number of top contributed variables for one anomalous time stamp in the response. </summary>
        public int? TopContributorCount { get; set; }
        /// <summary>
        /// Start date/time of data for detection, which should
        /// be in ISO 8601 format.
        /// </summary>
        public DateTimeOffset StartTime { get; set; }
        /// <summary>
        /// End date/time of data for detection, which should
        /// be in ISO 8601 format.
        /// </summary>
        public DateTimeOffset EndTime { get; set; }
    }
}

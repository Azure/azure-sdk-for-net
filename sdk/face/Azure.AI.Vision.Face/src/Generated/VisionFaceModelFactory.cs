// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.

// <auto-generated/>

#nullable disable

using System;
using System.Collections.Generic;
using System.Linq;

namespace Azure.AI.Vision.Face
{
    /// <summary> A factory class for creating instances of the models for mocking. </summary>
    public static partial class VisionFaceModelFactory
    {

        /// <summary> Response for detect API. </summary>
        /// <param name="faceId"> Unique faceId of the detected face, created by detection API and it will expire 24 hours after the detection call. To return this, it requires 'returnFaceId' parameter to be true. </param>
        /// <param name="recognitionModel"> The 'recognitionModel' associated with this faceId. This is only returned when 'returnRecognitionModel' is explicitly set as true. </param>
        /// <param name="faceRectangle"> A rectangle area for the face location on image. </param>
        /// <param name="faceLandmarks"> An array of 27-point face landmarks pointing to the important positions of face components. To return this, it requires 'returnFaceLandmarks' parameter to be true. </param>
        /// <param name="faceAttributes"> Face attributes for detected face. </param>
        /// <returns> A new <see cref="Face.FaceDetectionResult"/> instance for mocking. </returns>
        public static FaceDetectionResult FaceDetectionResult(Guid? faceId = default, FaceRecognitionModel? recognitionModel = default, FaceRectangle faceRectangle = default, FaceLandmarks faceLandmarks = default, FaceAttributes faceAttributes = default)
        {
            return new FaceDetectionResult(
                faceId,
                recognitionModel,
                faceRectangle,
                faceLandmarks,
                faceAttributes,
                additionalBinaryDataProperties: null);
        }

        /// <summary> A rectangle within which a face can be found. </summary>
        /// <param name="top"> The distance from the top edge if the image to the top edge of the rectangle, in pixels. </param>
        /// <param name="left"> The distance from the left edge if the image to the left edge of the rectangle, in pixels. </param>
        /// <param name="width"> The width of the rectangle, in pixels. </param>
        /// <param name="height"> The height of the rectangle, in pixels. </param>
        /// <returns> A new <see cref="Face.FaceRectangle"/> instance for mocking. </returns>
        public static FaceRectangle FaceRectangle(int top = default, int left = default, int width = default, int height = default)
        {
            return new FaceRectangle(top, left, width, height, additionalBinaryDataProperties: null);
        }

        /// <summary> A collection of 27-point face landmarks pointing to the important positions of face components. </summary>
        /// <param name="pupilLeft"> The coordinates of the left eye pupil. </param>
        /// <param name="pupilRight"> The coordinates of the right eye pupil. </param>
        /// <param name="noseTip"> The coordinates of the nose tip. </param>
        /// <param name="mouthLeft"> The coordinates of the mouth left. </param>
        /// <param name="mouthRight"> The coordinates of the mouth right. </param>
        /// <param name="eyebrowLeftOuter"> The coordinates of the left eyebrow outer. </param>
        /// <param name="eyebrowLeftInner"> The coordinates of the left eyebrow inner. </param>
        /// <param name="eyeLeftOuter"> The coordinates of the left eye outer. </param>
        /// <param name="eyeLeftTop"> The coordinates of the left eye top. </param>
        /// <param name="eyeLeftBottom"> The coordinates of the left eye bottom. </param>
        /// <param name="eyeLeftInner"> The coordinates of the left eye inner. </param>
        /// <param name="eyebrowRightInner"> The coordinates of the right eyebrow inner. </param>
        /// <param name="eyebrowRightOuter"> The coordinates of the right eyebrow outer. </param>
        /// <param name="eyeRightInner"> The coordinates of the right eye inner. </param>
        /// <param name="eyeRightTop"> The coordinates of the right eye top. </param>
        /// <param name="eyeRightBottom"> The coordinates of the right eye bottom. </param>
        /// <param name="eyeRightOuter"> The coordinates of the right eye outer. </param>
        /// <param name="noseRootLeft"> The coordinates of the nose root left. </param>
        /// <param name="noseRootRight"> The coordinates of the nose root right. </param>
        /// <param name="noseLeftAlarTop"> The coordinates of the nose left alar top. </param>
        /// <param name="noseRightAlarTop"> The coordinates of the nose right alar top. </param>
        /// <param name="noseLeftAlarOutTip"> The coordinates of the nose left alar out tip. </param>
        /// <param name="noseRightAlarOutTip"> The coordinates of the nose right alar out tip. </param>
        /// <param name="upperLipTop"> The coordinates of the upper lip top. </param>
        /// <param name="upperLipBottom"> The coordinates of the upper lip bottom. </param>
        /// <param name="underLipTop"> The coordinates of the under lip top. </param>
        /// <param name="underLipBottom"> The coordinates of the under lip bottom. </param>
        /// <returns> A new <see cref="Face.FaceLandmarks"/> instance for mocking. </returns>
        public static FaceLandmarks FaceLandmarks(LandmarkCoordinate pupilLeft = default, LandmarkCoordinate pupilRight = default, LandmarkCoordinate noseTip = default, LandmarkCoordinate mouthLeft = default, LandmarkCoordinate mouthRight = default, LandmarkCoordinate eyebrowLeftOuter = default, LandmarkCoordinate eyebrowLeftInner = default, LandmarkCoordinate eyeLeftOuter = default, LandmarkCoordinate eyeLeftTop = default, LandmarkCoordinate eyeLeftBottom = default, LandmarkCoordinate eyeLeftInner = default, LandmarkCoordinate eyebrowRightInner = default, LandmarkCoordinate eyebrowRightOuter = default, LandmarkCoordinate eyeRightInner = default, LandmarkCoordinate eyeRightTop = default, LandmarkCoordinate eyeRightBottom = default, LandmarkCoordinate eyeRightOuter = default, LandmarkCoordinate noseRootLeft = default, LandmarkCoordinate noseRootRight = default, LandmarkCoordinate noseLeftAlarTop = default, LandmarkCoordinate noseRightAlarTop = default, LandmarkCoordinate noseLeftAlarOutTip = default, LandmarkCoordinate noseRightAlarOutTip = default, LandmarkCoordinate upperLipTop = default, LandmarkCoordinate upperLipBottom = default, LandmarkCoordinate underLipTop = default, LandmarkCoordinate underLipBottom = default)
        {
            return new FaceLandmarks(
                pupilLeft,
                pupilRight,
                noseTip,
                mouthLeft,
                mouthRight,
                eyebrowLeftOuter,
                eyebrowLeftInner,
                eyeLeftOuter,
                eyeLeftTop,
                eyeLeftBottom,
                eyeLeftInner,
                eyebrowRightInner,
                eyebrowRightOuter,
                eyeRightInner,
                eyeRightTop,
                eyeRightBottom,
                eyeRightOuter,
                noseRootLeft,
                noseRootRight,
                noseLeftAlarTop,
                noseRightAlarTop,
                noseLeftAlarOutTip,
                noseRightAlarOutTip,
                upperLipTop,
                upperLipBottom,
                underLipTop,
                underLipBottom,
                additionalBinaryDataProperties: null);
        }

        /// <summary> Landmark coordinates within an image. </summary>
        /// <param name="x"> The horizontal component, in pixels. </param>
        /// <param name="y"> The vertical component, in pixels. </param>
        /// <returns> A new <see cref="Face.LandmarkCoordinate"/> instance for mocking. </returns>
        public static LandmarkCoordinate LandmarkCoordinate(float x = default, float y = default)
        {
            return new LandmarkCoordinate(x, y, additionalBinaryDataProperties: null);
        }

        /// <summary> Face attributes for the detected face. </summary>
        /// <param name="age"> Age in years. </param>
        /// <param name="smile"> Smile intensity, a number between [0,1]. </param>
        /// <param name="facialHair"> Properties describing facial hair attributes. </param>
        /// <param name="glasses"> Glasses type if any of the face. </param>
        /// <param name="headPose"> 3-D roll/yaw/pitch angles for face direction. </param>
        /// <param name="hair"> Properties describing hair attributes. </param>
        /// <param name="occlusion"> Properties describing occlusions on a given face. </param>
        /// <param name="accessories"> Properties describing any accessories on a given face. </param>
        /// <param name="blur"> Properties describing any presence of blur within the image. </param>
        /// <param name="exposure"> Properties describing exposure level of the image. </param>
        /// <param name="noise"> Properties describing noise level of the image. </param>
        /// <param name="mask"> Properties describing the presence of a mask on a given face. </param>
        /// <param name="qualityForRecognition"> Properties describing the overall image quality regarding whether the image being used in the detection is of sufficient quality to attempt face recognition on. </param>
        /// <returns> A new <see cref="Face.FaceAttributes"/> instance for mocking. </returns>
        public static FaceAttributes FaceAttributes(float? age = default, float? smile = default, FacialHair facialHair = default, GlassesType? glasses = default, HeadPose headPose = default, HairProperties hair = default, OcclusionProperties occlusion = default, IEnumerable<AccessoryItem> accessories = default, BlurProperties blur = default, ExposureProperties exposure = default, NoiseProperties noise = default, MaskProperties mask = default, QualityForRecognition? qualityForRecognition = default)
        {
            accessories ??= new ChangeTrackingList<AccessoryItem>();

            return new FaceAttributes(
                age,
                smile,
                facialHair,
                glasses,
                headPose,
                hair,
                occlusion,
                accessories?.ToList(),
                blur,
                exposure,
                noise,
                mask,
                qualityForRecognition,
                additionalBinaryDataProperties: null);
        }

        /// <summary> Properties describing facial hair attributes. </summary>
        /// <param name="moustache"> A number ranging from 0 to 1 indicating a level of confidence associated with a property. </param>
        /// <param name="beard"> A number ranging from 0 to 1 indicating a level of confidence associated with a property. </param>
        /// <param name="sideburns"> A number ranging from 0 to 1 indicating a level of confidence associated with a property. </param>
        /// <returns> A new <see cref="Face.FacialHair"/> instance for mocking. </returns>
        public static FacialHair FacialHair(float moustache = default, float beard = default, float sideburns = default)
        {
            return new FacialHair(moustache, beard, sideburns, additionalBinaryDataProperties: null);
        }

        /// <summary> 3-D roll/yaw/pitch angles for face direction. </summary>
        /// <param name="pitch"> Value of angles. </param>
        /// <param name="roll"> Value of angles. </param>
        /// <param name="yaw"> Value of angles. </param>
        /// <returns> A new <see cref="Face.HeadPose"/> instance for mocking. </returns>
        public static HeadPose HeadPose(float pitch = default, float roll = default, float yaw = default)
        {
            return new HeadPose(pitch, roll, yaw, additionalBinaryDataProperties: null);
        }

        /// <summary> Properties describing hair attributes. </summary>
        /// <param name="bald"> A number describing confidence level of whether the person is bald. </param>
        /// <param name="invisible"> A boolean value describing whether the hair is visible in the image. </param>
        /// <param name="hairColor"> An array of candidate colors and confidence level in the presence of each. </param>
        /// <returns> A new <see cref="Face.HairProperties"/> instance for mocking. </returns>
        public static HairProperties HairProperties(float bald = default, bool invisible = default, IEnumerable<HairColor> hairColor = default)
        {
            hairColor ??= new ChangeTrackingList<HairColor>();

            return new HairProperties(bald, invisible, hairColor?.ToList(), additionalBinaryDataProperties: null);
        }

        /// <summary> An array of candidate colors and confidence level in the presence of each. </summary>
        /// <param name="color"> Name of the hair color. </param>
        /// <param name="confidence"> Confidence level of the color. Range between [0,1]. </param>
        /// <returns> A new <see cref="Face.HairColor"/> instance for mocking. </returns>
        public static HairColor HairColor(HairColorType color = default, float confidence = default)
        {
            return new HairColor(color, confidence, additionalBinaryDataProperties: null);
        }

        /// <summary> Properties describing occlusions on a given face. </summary>
        /// <param name="foreheadOccluded"> A boolean value indicating whether forehead is occluded. </param>
        /// <param name="eyeOccluded"> A boolean value indicating whether eyes are occluded. </param>
        /// <param name="mouthOccluded"> A boolean value indicating whether the mouth is occluded. </param>
        /// <returns> A new <see cref="Face.OcclusionProperties"/> instance for mocking. </returns>
        public static OcclusionProperties OcclusionProperties(bool foreheadOccluded = default, bool eyeOccluded = default, bool mouthOccluded = default)
        {
            return new OcclusionProperties(foreheadOccluded, eyeOccluded, mouthOccluded, additionalBinaryDataProperties: null);
        }

        /// <summary> Accessory item and corresponding confidence level. </summary>
        /// <param name="type"> Type of the accessory. </param>
        /// <param name="confidence"> Confidence level of the accessory type. Range between [0,1]. </param>
        /// <returns> A new <see cref="Face.AccessoryItem"/> instance for mocking. </returns>
        public static AccessoryItem AccessoryItem(AccessoryType @type = default, float confidence = default)
        {
            return new AccessoryItem(@type, confidence, additionalBinaryDataProperties: null);
        }

        /// <summary> Properties describing any presence of blur within the image. </summary>
        /// <param name="blurLevel"> An enum value indicating level of blurriness. </param>
        /// <param name="value"> A number indicating level of blurriness ranging from 0 to 1. </param>
        /// <returns> A new <see cref="Face.BlurProperties"/> instance for mocking. </returns>
        public static BlurProperties BlurProperties(BlurLevel blurLevel = default, float value = default)
        {
            return new BlurProperties(blurLevel, value, additionalBinaryDataProperties: null);
        }

        /// <summary> Properties describing exposure level of the image. </summary>
        /// <param name="exposureLevel"> An enum value indicating level of exposure. </param>
        /// <param name="value"> A number indicating level of exposure level ranging from 0 to 1. [0, 0.25) is under exposure. [0.25, 0.75) is good exposure. [0.75, 1] is over exposure. </param>
        /// <returns> A new <see cref="Face.ExposureProperties"/> instance for mocking. </returns>
        public static ExposureProperties ExposureProperties(ExposureLevel exposureLevel = default, float value = default)
        {
            return new ExposureProperties(exposureLevel, value, additionalBinaryDataProperties: null);
        }

        /// <summary> Properties describing noise level of the image. </summary>
        /// <param name="noiseLevel"> An enum value indicating level of noise. </param>
        /// <param name="value"> A number indicating level of noise level ranging from 0 to 1. [0, 0.25) is under exposure. [0.25, 0.75) is good exposure. [0.75, 1] is over exposure. [0, 0.3) is low noise level. [0.3, 0.7) is medium noise level. [0.7, 1] is high noise level. </param>
        /// <returns> A new <see cref="Face.NoiseProperties"/> instance for mocking. </returns>
        public static NoiseProperties NoiseProperties(NoiseLevel noiseLevel = default, float value = default)
        {
            return new NoiseProperties(noiseLevel, value, additionalBinaryDataProperties: null);
        }

        /// <summary> Properties describing the presence of a mask on a given face. </summary>
        /// <param name="noseAndMouthCovered"> A boolean value indicating whether nose and mouth are covered. </param>
        /// <param name="type"> Type of the mask. </param>
        /// <returns> A new <see cref="Face.MaskProperties"/> instance for mocking. </returns>
        public static MaskProperties MaskProperties(bool noseAndMouthCovered = default, MaskType @type = default)
        {
            return new MaskProperties(noseAndMouthCovered, @type, additionalBinaryDataProperties: null);
        }

        /// <summary> Response body for find similar face operation. </summary>
        /// <param name="confidence"> Confidence value of the candidate. The higher confidence, the more similar. Range between [0,1]. </param>
        /// <param name="faceId"> faceId of candidate face when find by faceIds. faceId is created by "Detect" and will expire 24 hours after the detection call. </param>
        /// <param name="persistedFaceId"> persistedFaceId of candidate face when find by faceListId or largeFaceListId. persistedFaceId in face list/large face list is persisted and will not expire. </param>
        /// <returns> A new <see cref="Face.FaceFindSimilarResult"/> instance for mocking. </returns>
        public static FaceFindSimilarResult FaceFindSimilarResult(float confidence = default, Guid? faceId = default, Guid? persistedFaceId = default)
        {
            return new FaceFindSimilarResult(confidence, faceId, persistedFaceId, additionalBinaryDataProperties: null);
        }

        /// <summary> Verify result. </summary>
        /// <param name="isIdentical"> True if the two faces belong to the same person or the face belongs to the person, otherwise false. </param>
        /// <param name="confidence"> A number indicates the similarity confidence of whether two faces belong to the same person, or whether the face belongs to the person. By default, isIdentical is set to True if similarity confidence is greater than or equal to 0.5. This is useful for advanced users to override 'isIdentical' and fine-tune the result on their own data. </param>
        /// <returns> A new <see cref="Face.FaceVerificationResult"/> instance for mocking. </returns>
        public static FaceVerificationResult FaceVerificationResult(bool isIdentical = default, float confidence = default)
        {
            return new FaceVerificationResult(isIdentical, confidence, additionalBinaryDataProperties: null);
        }

        /// <summary> Response body for group face operation. </summary>
        /// <param name="groups"> A partition of the original faces based on face similarity. Groups are ranked by number of faces. </param>
        /// <param name="messyGroup"> Face ids array of faces that cannot find any similar faces from original faces. </param>
        /// <returns> A new <see cref="Face.FaceGroupingResult"/> instance for mocking. </returns>
        public static FaceGroupingResult FaceGroupingResult(IEnumerable<IList<Guid>> groups = default, IEnumerable<Guid> messyGroup = default)
        {
            groups ??= new ChangeTrackingList<IList<Guid>>();
            messyGroup ??= new ChangeTrackingList<Guid>();

            return new FaceGroupingResult(groups?.ToList(), messyGroup?.ToList(), additionalBinaryDataProperties: null);
        }

        /// <summary> Identify result. </summary>
        /// <param name="faceId"> faceId of the query face. </param>
        /// <param name="candidates"> Identified person candidates for that face (ranked by confidence). Array size should be no larger than input maxNumOfCandidatesReturned. If no person is identified, will return an empty array. </param>
        /// <returns> A new <see cref="Face.FaceIdentificationResult"/> instance for mocking. </returns>
        public static FaceIdentificationResult FaceIdentificationResult(Guid faceId = default, IEnumerable<FaceIdentificationCandidate> candidates = default)
        {
            candidates ??= new ChangeTrackingList<FaceIdentificationCandidate>();

            return new FaceIdentificationResult(faceId, candidates?.ToList(), additionalBinaryDataProperties: null);
        }

        /// <summary> Candidate for identify call. </summary>
        /// <param name="personId"> personId of candidate person. </param>
        /// <param name="confidence"> Confidence value of the candidate. The higher confidence, the more similar. Range between [0,1]. </param>
        /// <returns> A new <see cref="Face.FaceIdentificationCandidate"/> instance for mocking. </returns>
        public static FaceIdentificationCandidate FaceIdentificationCandidate(Guid personId = default, float confidence = default)
        {
            return new FaceIdentificationCandidate(personId, confidence, additionalBinaryDataProperties: null);
        }

        /// <summary> Request model for creating liveness session. </summary>
        /// <param name="livenessOperationMode"> Type of liveness mode the client should follow. </param>
        /// <param name="deviceCorrelationIdSetInClient"> Whether or not to allow client to set their own 'deviceCorrelationId' via the Vision SDK. Default is false, and 'deviceCorrelationId' must be set in this request body. </param>
        /// <param name="enableSessionImage"> Whether or not store the session image. </param>
        /// <param name="livenessModelVersion"> The model version used for liveness classification. This is an optional parameter, and if this is not specified, then the latest supported model version will be chosen. </param>
        /// <param name="deviceCorrelationId"> Unique Guid per each end-user device. This is to provide rate limiting and anti-hammering. If 'deviceCorrelationIdSetInClient' is true in this request, this 'deviceCorrelationId' must be null. </param>
        /// <param name="authTokenTimeToLiveInSeconds"> Seconds the session should last for. Range is 60 to 86400 seconds. Default value is 600. </param>
        /// <returns> A new <see cref="Face.CreateLivenessSessionContent"/> instance for mocking. </returns>
        public static CreateLivenessSessionContent CreateLivenessSessionContent(LivenessOperationMode livenessOperationMode = default, bool? deviceCorrelationIdSetInClient = default, bool? enableSessionImage = default, LivenessModel? livenessModelVersion = default, string deviceCorrelationId = default, int? authTokenTimeToLiveInSeconds = default)
        {
            return new CreateLivenessSessionContent(
                livenessOperationMode,
                deviceCorrelationIdSetInClient,
                enableSessionImage,
                livenessModelVersion,
                deviceCorrelationId,
                authTokenTimeToLiveInSeconds,
                additionalBinaryDataProperties: null);
        }

        /// <summary> Session result of detect liveness. </summary>
        /// <param name="sessionId"> The unique ID to reference this session. </param>
        /// <param name="authToken"> Bearer token to provide authentication for the Vision SDK running on a client application. This Bearer token has limited permissions to perform only the required action and expires after the TTL time. It is also auditable. </param>
        /// <param name="status"> The current status of the session. </param>
        /// <param name="modelVersion"> The model version used for liveness classification. This is an optional parameter, and if this is not specified, then the latest supported model version will be chosen. </param>
        /// <param name="results"> The results of the liveness session. </param>
        /// <returns> A new <see cref="Face.LivenessSession"/> instance for mocking. </returns>
        public static LivenessSession LivenessSession(string sessionId = default, string authToken = default, OperationState status = default, LivenessModel? modelVersion = default, LivenessSessionResults results = default)
        {
            return new LivenessSession(
                sessionId,
                authToken,
                status,
                modelVersion,
                results,
                additionalBinaryDataProperties: null);
        }

        /// <summary> The results of the liveness session. </summary>
        /// <param name="attempts"> The attempts data of underlying liveness call with the session. </param>
        /// <returns> A new <see cref="Face.LivenessSessionResults"/> instance for mocking. </returns>
        public static LivenessSessionResults LivenessSessionResults(IEnumerable<LivenessSessionAttempt> attempts = default)
        {
            attempts ??= new ChangeTrackingList<LivenessSessionAttempt>();

            return new LivenessSessionResults(attempts?.ToList(), additionalBinaryDataProperties: null);
        }

        /// <summary> The liveness session attempt. </summary>
        /// <param name="attemptId"> The attempt ID, start from 1. </param>
        /// <param name="attemptStatus"> The status of the attempt. </param>
        /// <param name="result"> The result of the liveness call, will be null if there is error. </param>
        /// <param name="error"> The error of the liveness call, will be null if there is result. </param>
        /// <returns> A new <see cref="Face.LivenessSessionAttempt"/> instance for mocking. </returns>
        public static LivenessSessionAttempt LivenessSessionAttempt(int attemptId = default, OperationState attemptStatus = default, LivenessResult result = default, LivenessError error = default)
        {
            return new LivenessSessionAttempt(attemptId, attemptStatus, result, error, additionalBinaryDataProperties: null);
        }

        /// <summary> The results of the liveness classification. </summary>
        /// <param name="livenessDecision"> The liveness classification for the target face. </param>
        /// <param name="targets"> Targets used for liveness classification. </param>
        /// <param name="digest"> The server calculated digest for this request. If the client reported digest differs from the server calculated digest, then the message integrity between the client and service has been compromised and the result should not be trusted. For more information, see how to guides on how to leverage this value to secure your end-to-end solution. </param>
        /// <param name="sessionImageId"> The image ID of the session request. </param>
        /// <returns> A new <see cref="Face.LivenessResult"/> instance for mocking. </returns>
        public static LivenessResult LivenessResult(FaceLivenessDecision? livenessDecision = default, LivenessDecisionTargets targets = default, string digest = default, string sessionImageId = default)
        {
            return new LivenessResult(livenessDecision, targets, digest, sessionImageId, additionalBinaryDataProperties: null);
        }

        /// <summary> The targets used for liveness classification. </summary>
        /// <param name="color"> The target from color image used for liveness classification. </param>
        /// <returns> A new <see cref="Face.LivenessDecisionTargets"/> instance for mocking. </returns>
        public static LivenessDecisionTargets LivenessDecisionTargets(LivenessColorDecisionTarget color = default)
        {
            return new LivenessDecisionTargets(color, additionalBinaryDataProperties: null);
        }

        /// <summary> The target from color image used for liveness classification. </summary>
        /// <param name="faceRectangle"> The face region where the liveness classification was made on. </param>
        /// <returns> A new <see cref="Face.LivenessColorDecisionTarget"/> instance for mocking. </returns>
        public static LivenessColorDecisionTarget LivenessColorDecisionTarget(FaceRectangle faceRectangle = default)
        {
            return new LivenessColorDecisionTarget(faceRectangle, additionalBinaryDataProperties: null);
        }

        /// <summary> The error of the liveness classification. </summary>
        /// <param name="code"> The error code. </param>
        /// <param name="message"> The error message. </param>
        /// <param name="targets"> Targets used for liveness classification. </param>
        /// <returns> A new <see cref="Face.LivenessError"/> instance for mocking. </returns>
        public static LivenessError LivenessError(string code = default, string message = default, LivenessDecisionTargets targets = default)
        {
            return new LivenessError(code, message, targets, additionalBinaryDataProperties: null);
        }

        /// <summary> Request of liveness with verify session creation. </summary>
        /// <param name="livenessOperationMode"> Type of liveness mode the client should follow. </param>
        /// <param name="deviceCorrelationIdSetInClient"> Whether or not to allow client to set their own 'deviceCorrelationId' via the Vision SDK. Default is false, and 'deviceCorrelationId' must be set in this request body. </param>
        /// <param name="enableSessionImage"> Whether or not store the session image. </param>
        /// <param name="livenessModelVersion"> The model version used for liveness classification. This is an optional parameter, and if this is not specified, then the latest supported model version will be chosen. </param>
        /// <param name="returnVerifyImageHash"> Whether or not return the verify image hash. </param>
        /// <param name="verifyConfidenceThreshold"> Threshold for confidence of the face verification. Please refer to the documentation for more details. https://learn.microsoft.com/legal/cognitive-services/face/characteristics-and-limitations?context=%2Fazure%2Fai-services%2Fcomputer-vision%2Fcontext%2Fcontext#recognition-confidence-score. </param>
        /// <param name="verifyImage"> The image stream for verify. Content-Disposition header field for this part must have filename. </param>
        /// <param name="deviceCorrelationId"> Unique Guid per each end-user device. This is to provide rate limiting and anti-hammering. If 'deviceCorrelationIdSetInClient' is true in this request, this 'deviceCorrelationId' must be null. </param>
        /// <param name="authTokenTimeToLiveInSeconds"> Seconds the session should last for. Range is 60 to 86400 seconds. Default value is 600. </param>
        /// <returns> A new <see cref="Face.CreateLivenessWithVerifySessionContent"/> instance for mocking. </returns>
        public static CreateLivenessWithVerifySessionContent CreateLivenessWithVerifySessionContent(LivenessOperationMode livenessOperationMode = default, bool? deviceCorrelationIdSetInClient = default, bool? enableSessionImage = default, LivenessModel? livenessModelVersion = default, bool? returnVerifyImageHash = default, float? verifyConfidenceThreshold = default, BinaryData verifyImage = default, string deviceCorrelationId = default, int? authTokenTimeToLiveInSeconds = default)
        {
            return new CreateLivenessWithVerifySessionContent(
                livenessOperationMode,
                deviceCorrelationIdSetInClient,
                enableSessionImage,
                livenessModelVersion,
                returnVerifyImageHash,
                verifyConfidenceThreshold,
                verifyImage,
                deviceCorrelationId,
                authTokenTimeToLiveInSeconds,
                additionalBinaryDataProperties: null);
        }

        /// <summary> Session result of detect liveness with verify. </summary>
        /// <param name="sessionId"> The unique ID to reference this session. </param>
        /// <param name="authToken"> Bearer token to provide authentication for the Vision SDK running on a client application. This Bearer token has limited permissions to perform only the required action and expires after the TTL time. It is also auditable. </param>
        /// <param name="status"> The current status of the session. </param>
        /// <param name="modelVersion"> The model version used for liveness classification. This is an optional parameter, and if this is not specified, then the latest supported model version will be chosen. </param>
        /// <param name="results"> The results of the liveness with verify session. </param>
        /// <returns> A new <see cref="Face.LivenessWithVerifySession"/> instance for mocking. </returns>
        public static LivenessWithVerifySession LivenessWithVerifySession(string sessionId = default, string authToken = default, OperationState status = default, LivenessModel? modelVersion = default, LivenessWithVerifySessionResults results = default)
        {
            return new LivenessWithVerifySession(
                sessionId,
                authToken,
                status,
                modelVersion,
                results,
                additionalBinaryDataProperties: null);
        }

        /// <summary> The results of the liveness with verify session. </summary>
        /// <param name="verifyReferences"> The references used for face verification. </param>
        /// <param name="attempts"> The attempts data of underlying liveness with verify call with the session. </param>
        /// <returns> A new <see cref="Face.LivenessWithVerifySessionResults"/> instance for mocking. </returns>
        public static LivenessWithVerifySessionResults LivenessWithVerifySessionResults(IEnumerable<LivenessWithVerifyReference> verifyReferences = default, IEnumerable<LivenessWithVerifySessionAttempt> attempts = default)
        {
            verifyReferences ??= new ChangeTrackingList<LivenessWithVerifyReference>();
            attempts ??= new ChangeTrackingList<LivenessWithVerifySessionAttempt>();

            return new LivenessWithVerifySessionResults(verifyReferences?.ToList(), attempts?.ToList(), additionalBinaryDataProperties: null);
        }

        /// <summary> The detail of face for verification. </summary>
        /// <param name="referenceType"> The image type which contains the face rectangle where the liveness classification was made on. </param>
        /// <param name="faceRectangle"> The face region where the comparison image's classification was made. </param>
        /// <param name="qualityForRecognition"> Quality of face image for recognition. </param>
        /// <returns> A new <see cref="Face.LivenessWithVerifyReference"/> instance for mocking. </returns>
        public static LivenessWithVerifyReference LivenessWithVerifyReference(FaceImageType referenceType = default, FaceRectangle faceRectangle = default, QualityForRecognition qualityForRecognition = default)
        {
            return new LivenessWithVerifyReference(referenceType, faceRectangle, qualityForRecognition, additionalBinaryDataProperties: null);
        }

        /// <summary> The liveness with verify session attempt. </summary>
        /// <param name="attemptId"> The attempt ID, start from 1. </param>
        /// <param name="attemptStatus"> The status of the attempt. </param>
        /// <param name="result"> The result of the liveness with verify call, will be null if there is error. </param>
        /// <param name="error"> The error of the liveness with verify call, will be null if there is result. </param>
        /// <returns> A new <see cref="Face.LivenessWithVerifySessionAttempt"/> instance for mocking. </returns>
        public static LivenessWithVerifySessionAttempt LivenessWithVerifySessionAttempt(int attemptId = default, OperationState attemptStatus = default, LivenessWithVerifyResult result = default, LivenessError error = default)
        {
            return new LivenessWithVerifySessionAttempt(attemptId, attemptStatus, result, error, additionalBinaryDataProperties: null);
        }

        /// <summary> The results of the liveness with verify call. </summary>
        /// <param name="livenessDecision"> The liveness classification for the target face. </param>
        /// <param name="targets"> Targets used for liveness classification. </param>
        /// <param name="digest"> The server calculated digest for this request. If the client reported digest differs from the server calculated digest, then the message integrity between the client and service has been compromised and the result should not be trusted. For more information, see how to guides on how to leverage this value to secure your end-to-end solution. </param>
        /// <param name="sessionImageId"> The image ID of the session request. </param>
        /// <param name="verifyResult"> The face verification output. Only available when the request is liveness with verify. </param>
        /// <param name="verifyImageHash"> The sha256 hash of the verify-image in the request. </param>
        /// <returns> A new <see cref="Face.LivenessWithVerifyResult"/> instance for mocking. </returns>
        public static LivenessWithVerifyResult LivenessWithVerifyResult(FaceLivenessDecision? livenessDecision = default, LivenessDecisionTargets targets = default, string digest = default, string sessionImageId = default, LivenessWithVerifyOutputs verifyResult = default, string verifyImageHash = default)
        {
            return new LivenessWithVerifyResult(
                livenessDecision,
                targets,
                digest,
                sessionImageId,
                verifyResult,
                verifyImageHash,
                additionalBinaryDataProperties: null);
        }

        /// <summary> The face verification output. </summary>
        /// <param name="matchConfidence"> The target face liveness face and comparison image face verification confidence. </param>
        /// <param name="isIdentical"> Whether the target liveness face and comparison image face match. </param>
        /// <returns> A new <see cref="Face.LivenessWithVerifyOutputs"/> instance for mocking. </returns>
        public static LivenessWithVerifyOutputs LivenessWithVerifyOutputs(float matchConfidence = default, bool isIdentical = default)
        {
            return new LivenessWithVerifyOutputs(matchConfidence, isIdentical, additionalBinaryDataProperties: null);
        }

        /// <summary> Large face list is a list of faces, up to 1,000,000 faces. </summary>
        /// <param name="name"> User defined name, maximum length is 128. </param>
        /// <param name="userData"> Optional user defined data. Length should not exceed 16K. </param>
        /// <param name="recognitionModel"> Name of recognition model. Recognition model is used when the face features are extracted and associated with detected faceIds. </param>
        /// <param name="largeFaceListId"> Valid character is letter in lower case or digit or '-' or '_', maximum length is 64. </param>
        /// <returns> A new <see cref="Face.LargeFaceList"/> instance for mocking. </returns>
        public static LargeFaceList LargeFaceList(string name = default, string userData = default, FaceRecognitionModel? recognitionModel = default, string largeFaceListId = default)
        {
            return new LargeFaceList(name, userData, recognitionModel, largeFaceListId, additionalBinaryDataProperties: null);
        }

        /// <summary> Training result of a container. </summary>
        /// <param name="status"> Training status of the container. </param>
        /// <param name="createdDateTime"> A combined UTC date and time string that describes the created time of the person group, large person group or large face list. </param>
        /// <param name="lastActionDateTime"> A combined UTC date and time string that describes the last modify time of the person group, large person group or large face list, could be null value when the group is not successfully trained. </param>
        /// <param name="lastSuccessfulTrainingDateTime"> A combined UTC date and time string that describes the last successful training time of the person group, large person group or large face list. </param>
        /// <param name="message"> Show failure message when training failed (omitted when training succeed). </param>
        /// <returns> A new <see cref="Face.FaceTrainingResult"/> instance for mocking. </returns>
        public static FaceTrainingResult FaceTrainingResult(FaceOperationStatus status = default, DateTimeOffset createdDateTime = default, DateTimeOffset lastActionDateTime = default, DateTimeOffset lastSuccessfulTrainingDateTime = default, string message = default)
        {
            return new FaceTrainingResult(
                status,
                createdDateTime,
                lastActionDateTime,
                lastSuccessfulTrainingDateTime,
                message,
                additionalBinaryDataProperties: null);
        }

        /// <summary> Response body for adding face. </summary>
        /// <param name="persistedFaceId"> Persisted Face ID of the added face, which is persisted and will not expire. Different from faceId which is created in "Detect" and will expire in 24 hours after the detection call. </param>
        /// <returns> A new <see cref="Face.AddFaceResult"/> instance for mocking. </returns>
        public static AddFaceResult AddFaceResult(Guid persistedFaceId = default)
        {
            return new AddFaceResult(persistedFaceId, additionalBinaryDataProperties: null);
        }

        /// <summary> Face resource for large face list. </summary>
        /// <param name="persistedFaceId"> Face ID of the face. </param>
        /// <param name="userData"> User-provided data attached to the face. The length limit is 1K. </param>
        /// <returns> A new <see cref="Face.LargeFaceListFace"/> instance for mocking. </returns>
        public static LargeFaceListFace LargeFaceListFace(Guid persistedFaceId = default, string userData = default)
        {
            return new LargeFaceListFace(persistedFaceId, userData, additionalBinaryDataProperties: null);
        }

        /// <summary> The container of the uploaded person data, including face recognition feature, and up to 1,000,000 people. </summary>
        /// <param name="name"> User defined name, maximum length is 128. </param>
        /// <param name="userData"> Optional user defined data. Length should not exceed 16K. </param>
        /// <param name="recognitionModel"> Name of recognition model. Recognition model is used when the face features are extracted and associated with detected faceIds. </param>
        /// <param name="largePersonGroupId"> ID of the container. </param>
        /// <returns> A new <see cref="Face.LargePersonGroup"/> instance for mocking. </returns>
        public static LargePersonGroup LargePersonGroup(string name = default, string userData = default, FaceRecognitionModel? recognitionModel = default, string largePersonGroupId = default)
        {
            return new LargePersonGroup(name, userData, recognitionModel, largePersonGroupId, additionalBinaryDataProperties: null);
        }

        /// <summary> Response of create person. </summary>
        /// <param name="personId"> Person ID of the person. </param>
        /// <returns> A new <see cref="Face.CreatePersonResult"/> instance for mocking. </returns>
        public static CreatePersonResult CreatePersonResult(Guid personId = default)
        {
            return new CreatePersonResult(personId, additionalBinaryDataProperties: null);
        }

        /// <summary> The person in a specified large person group. To add face to this person, please call "Add Large Person Group Person Face". </summary>
        /// <param name="personId"> ID of the person. </param>
        /// <param name="name"> User defined name, maximum length is 128. </param>
        /// <param name="userData"> Optional user defined data. Length should not exceed 16K. </param>
        /// <param name="persistedFaceIds"> Face ids of registered faces in the person. </param>
        /// <returns> A new <see cref="Face.LargePersonGroupPerson"/> instance for mocking. </returns>
        public static LargePersonGroupPerson LargePersonGroupPerson(Guid personId = default, string name = default, string userData = default, IEnumerable<Guid> persistedFaceIds = default)
        {
            persistedFaceIds ??= new ChangeTrackingList<Guid>();

            return new LargePersonGroupPerson(personId, name, userData, persistedFaceIds?.ToList(), additionalBinaryDataProperties: null);
        }

        /// <summary> Face resource for large person group person. </summary>
        /// <param name="persistedFaceId"> Face ID of the face. </param>
        /// <param name="userData"> User-provided data attached to the face. The length limit is 1K. </param>
        /// <returns> A new <see cref="Face.LargePersonGroupPersonFace"/> instance for mocking. </returns>
        public static LargePersonGroupPersonFace LargePersonGroupPersonFace(Guid persistedFaceId = default, string userData = default)
        {
            return new LargePersonGroupPersonFace(persistedFaceId, userData, additionalBinaryDataProperties: null);
        }
    }
}

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.

// <auto-generated/>

#nullable disable

using System;
using System.Collections.Generic;

namespace Azure.ResourceManager.MachineLearning.Models
{
    /// <summary> Azure ML batch inferencing server configurations. </summary>
    public partial class AzureMLBatchInferencingServer : InferencingServer
    {
        /// <summary> Initializes a new instance of <see cref="AzureMLBatchInferencingServer"/>. </summary>
        public AzureMLBatchInferencingServer()
        {
            ServerType = InferencingServerType.AzureMLBatch;
        }

        /// <summary> Initializes a new instance of <see cref="AzureMLBatchInferencingServer"/>. </summary>
        /// <param name="serverType"> [Required] Inferencing server type for various targets. </param>
        /// <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        /// <param name="codeConfiguration"> Code configuration for AML batch inferencing server. </param>
        internal AzureMLBatchInferencingServer(InferencingServerType serverType, IDictionary<string, BinaryData> serializedAdditionalRawData, MachineLearningCodeConfiguration codeConfiguration) : base(serverType, serializedAdditionalRawData)
        {
            CodeConfiguration = codeConfiguration;
            ServerType = serverType;
        }

        /// <summary> Code configuration for AML batch inferencing server. </summary>
        public MachineLearningCodeConfiguration CodeConfiguration { get; set; }
    }
}

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.

// <auto-generated/>

#nullable disable

using System.Collections.Generic;

namespace Azure.ResourceManager.MachineLearning.Models
{
    /// <summary>
    /// Batch inference settings per deployment.
    /// Serialized Name: BatchDeployment
    /// </summary>
    public partial class MachineLearningBatchDeploymentProperties : MachineLearningEndpointDeploymentProperties
    {
        /// <summary> Initializes a new instance of MachineLearningBatchDeploymentProperties. </summary>
        public MachineLearningBatchDeploymentProperties()
        {
        }

        /// <summary> Initializes a new instance of MachineLearningBatchDeploymentProperties. </summary>
        /// <param name="codeConfiguration">
        /// Code configuration for the endpoint deployment.
        /// Serialized Name: EndpointDeploymentPropertiesBase.codeConfiguration
        /// </param>
        /// <param name="description">
        /// Description of the endpoint deployment.
        /// Serialized Name: EndpointDeploymentPropertiesBase.description
        /// </param>
        /// <param name="environmentId">
        /// ARM resource ID or AssetId of the environment specification for the endpoint deployment.
        /// Serialized Name: EndpointDeploymentPropertiesBase.environmentId
        /// </param>
        /// <param name="environmentVariables">
        /// Environment variables configuration for the deployment.
        /// Serialized Name: EndpointDeploymentPropertiesBase.environmentVariables
        /// </param>
        /// <param name="properties">
        /// Property dictionary. Properties can be added, but not removed or altered.
        /// Serialized Name: EndpointDeploymentPropertiesBase.properties
        /// </param>
        /// <param name="compute">
        /// Compute target for batch inference operation.
        /// Serialized Name: BatchDeployment.compute
        /// </param>
        /// <param name="errorThreshold">
        /// Error threshold, if the error count for the entire input goes above this value,
        /// the batch inference will be aborted. Range is [-1, int.MaxValue].
        /// For FileDataset, this value is the count of file failures.
        /// For TabularDataset, this value is the count of record failures.
        /// If set to -1 (the lower bound), all failures during batch inference will be ignored.
        /// Serialized Name: BatchDeployment.errorThreshold
        /// </param>
        /// <param name="loggingLevel">
        /// Logging level for batch inference operation.
        /// Serialized Name: BatchDeployment.loggingLevel
        /// </param>
        /// <param name="maxConcurrencyPerInstance">
        /// Indicates maximum number of parallelism per instance.
        /// Serialized Name: BatchDeployment.maxConcurrencyPerInstance
        /// </param>
        /// <param name="miniBatchSize">
        /// Size of the mini-batch passed to each batch invocation.
        /// For FileDataset, this is the number of files per mini-batch.
        /// For TabularDataset, this is the size of the records in bytes, per mini-batch.
        /// Serialized Name: BatchDeployment.miniBatchSize
        /// </param>
        /// <param name="model">
        /// Reference to the model asset for the endpoint deployment.
        /// Serialized Name: BatchDeployment.model
        /// Please note <see cref="MachineLearningAssetReferenceBase"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="MachineLearningDataPathAssetReference"/>, <see cref="MachineLearningIdAssetReference"/> and <see cref="MachineLearningOutputPathAssetReference"/>.
        /// </param>
        /// <param name="outputAction">
        /// Indicates how the output will be organized.
        /// Serialized Name: BatchDeployment.outputAction
        /// </param>
        /// <param name="outputFileName">
        /// Customized output file name for append_row output action.
        /// Serialized Name: BatchDeployment.outputFileName
        /// </param>
        /// <param name="provisioningState">
        /// Provisioning state for the endpoint deployment.
        /// Serialized Name: BatchDeployment.provisioningState
        /// </param>
        /// <param name="resources">
        /// Indicates compute configuration for the job.
        /// If not provided, will default to the defaults defined in ResourceConfiguration.
        /// Serialized Name: BatchDeployment.resources
        /// </param>
        /// <param name="retrySettings">
        /// Retry Settings for the batch inference operation.
        /// If not provided, will default to the defaults defined in BatchRetrySettings.
        /// Serialized Name: BatchDeployment.retrySettings
        /// </param>
        internal MachineLearningBatchDeploymentProperties(MachineLearningCodeConfiguration codeConfiguration, string description, string environmentId, IDictionary<string, string> environmentVariables, IDictionary<string, string> properties, string compute, int? errorThreshold, MachineLearningBatchLoggingLevel? loggingLevel, int? maxConcurrencyPerInstance, long? miniBatchSize, MachineLearningAssetReferenceBase model, MachineLearningBatchOutputAction? outputAction, string outputFileName, MachineLearningDeploymentProvisioningState? provisioningState, MachineLearningDeploymentResourceConfiguration resources, MachineLearningBatchRetrySettings retrySettings) : base(codeConfiguration, description, environmentId, environmentVariables, properties)
        {
            Compute = compute;
            ErrorThreshold = errorThreshold;
            LoggingLevel = loggingLevel;
            MaxConcurrencyPerInstance = maxConcurrencyPerInstance;
            MiniBatchSize = miniBatchSize;
            Model = model;
            OutputAction = outputAction;
            OutputFileName = outputFileName;
            ProvisioningState = provisioningState;
            Resources = resources;
            RetrySettings = retrySettings;
        }

        /// <summary>
        /// Compute target for batch inference operation.
        /// Serialized Name: BatchDeployment.compute
        /// </summary>
        public string Compute { get; set; }
        /// <summary>
        /// Error threshold, if the error count for the entire input goes above this value,
        /// the batch inference will be aborted. Range is [-1, int.MaxValue].
        /// For FileDataset, this value is the count of file failures.
        /// For TabularDataset, this value is the count of record failures.
        /// If set to -1 (the lower bound), all failures during batch inference will be ignored.
        /// Serialized Name: BatchDeployment.errorThreshold
        /// </summary>
        public int? ErrorThreshold { get; set; }
        /// <summary>
        /// Logging level for batch inference operation.
        /// Serialized Name: BatchDeployment.loggingLevel
        /// </summary>
        public MachineLearningBatchLoggingLevel? LoggingLevel { get; set; }
        /// <summary>
        /// Indicates maximum number of parallelism per instance.
        /// Serialized Name: BatchDeployment.maxConcurrencyPerInstance
        /// </summary>
        public int? MaxConcurrencyPerInstance { get; set; }
        /// <summary>
        /// Size of the mini-batch passed to each batch invocation.
        /// For FileDataset, this is the number of files per mini-batch.
        /// For TabularDataset, this is the size of the records in bytes, per mini-batch.
        /// Serialized Name: BatchDeployment.miniBatchSize
        /// </summary>
        public long? MiniBatchSize { get; set; }
        /// <summary>
        /// Reference to the model asset for the endpoint deployment.
        /// Serialized Name: BatchDeployment.model
        /// Please note <see cref="MachineLearningAssetReferenceBase"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="MachineLearningDataPathAssetReference"/>, <see cref="MachineLearningIdAssetReference"/> and <see cref="MachineLearningOutputPathAssetReference"/>.
        /// </summary>
        public MachineLearningAssetReferenceBase Model { get; set; }
        /// <summary>
        /// Indicates how the output will be organized.
        /// Serialized Name: BatchDeployment.outputAction
        /// </summary>
        public MachineLearningBatchOutputAction? OutputAction { get; set; }
        /// <summary>
        /// Customized output file name for append_row output action.
        /// Serialized Name: BatchDeployment.outputFileName
        /// </summary>
        public string OutputFileName { get; set; }
        /// <summary>
        /// Provisioning state for the endpoint deployment.
        /// Serialized Name: BatchDeployment.provisioningState
        /// </summary>
        public MachineLearningDeploymentProvisioningState? ProvisioningState { get; }
        /// <summary>
        /// Indicates compute configuration for the job.
        /// If not provided, will default to the defaults defined in ResourceConfiguration.
        /// Serialized Name: BatchDeployment.resources
        /// </summary>
        public MachineLearningDeploymentResourceConfiguration Resources { get; set; }
        /// <summary>
        /// Retry Settings for the batch inference operation.
        /// If not provided, will default to the defaults defined in BatchRetrySettings.
        /// Serialized Name: BatchDeployment.retrySettings
        /// </summary>
        public MachineLearningBatchRetrySettings RetrySettings { get; set; }
    }
}

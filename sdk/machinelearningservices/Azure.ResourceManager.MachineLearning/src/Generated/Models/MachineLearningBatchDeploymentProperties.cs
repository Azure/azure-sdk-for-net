// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.

// <auto-generated/>

#nullable disable

using System;
using System.Collections.Generic;

namespace Azure.ResourceManager.MachineLearning.Models
{
    /// <summary> Batch inference settings per deployment. </summary>
    public partial class MachineLearningBatchDeploymentProperties : MachineLearningEndpointDeploymentProperties
    {
        /// <summary> Initializes a new instance of <see cref="MachineLearningBatchDeploymentProperties"/>. </summary>
        public MachineLearningBatchDeploymentProperties()
        {
        }

        /// <summary> Initializes a new instance of <see cref="MachineLearningBatchDeploymentProperties"/>. </summary>
        /// <param name="codeConfiguration"> Code configuration for the endpoint deployment. </param>
        /// <param name="description"> Description of the endpoint deployment. </param>
        /// <param name="environmentId"> ARM resource ID of the environment specification for the endpoint deployment. </param>
        /// <param name="environmentVariables"> Environment variables configuration for the deployment. </param>
        /// <param name="properties"> Property dictionary. Properties can be added, but not removed or altered. </param>
        /// <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        /// <param name="compute"> Compute target for batch inference operation. </param>
        /// <param name="deploymentConfiguration">
        /// Properties relevant to different deployment types.
        /// Please note <see cref="BatchDeploymentConfiguration"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="BatchPipelineComponentDeploymentConfiguration"/>.
        /// </param>
        /// <param name="errorThreshold">
        /// Error threshold, if the error count for the entire input goes above this value,
        /// the batch inference will be aborted. Range is [-1, int.MaxValue].
        /// For FileDataset, this value is the count of file failures.
        /// For TabularDataset, this value is the count of record failures.
        /// If set to -1 (the lower bound), all failures during batch inference will be ignored.
        /// </param>
        /// <param name="loggingLevel"> Logging level for batch inference operation. </param>
        /// <param name="maxConcurrencyPerInstance"> Indicates maximum number of parallelism per instance. </param>
        /// <param name="miniBatchSize">
        /// Size of the mini-batch passed to each batch invocation.
        /// For FileDataset, this is the number of files per mini-batch.
        /// For TabularDataset, this is the size of the records in bytes, per mini-batch.
        /// </param>
        /// <param name="model">
        /// Reference to the model asset for the endpoint deployment.
        /// Please note <see cref="MachineLearningAssetReferenceBase"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="MachineLearningDataPathAssetReference"/>, <see cref="MachineLearningOutputPathAssetReference"/> and <see cref="MachineLearningIdAssetReference"/>.
        /// </param>
        /// <param name="outputAction"> Indicates how the output will be organized. </param>
        /// <param name="outputFileName"> Customized output file name for append_row output action. </param>
        /// <param name="provisioningState"> Provisioning state for the endpoint deployment. </param>
        /// <param name="resources">
        /// Indicates compute configuration for the job.
        /// If not provided, will default to the defaults defined in ResourceConfiguration.
        /// </param>
        /// <param name="retrySettings">
        /// Retry Settings for the batch inference operation.
        /// If not provided, will default to the defaults defined in BatchRetrySettings.
        /// </param>
        internal MachineLearningBatchDeploymentProperties(MachineLearningCodeConfiguration codeConfiguration, string description, string environmentId, IDictionary<string, string> environmentVariables, IDictionary<string, string> properties, IDictionary<string, BinaryData> serializedAdditionalRawData, string compute, BatchDeploymentConfiguration deploymentConfiguration, int? errorThreshold, MachineLearningBatchLoggingLevel? loggingLevel, int? maxConcurrencyPerInstance, long? miniBatchSize, MachineLearningAssetReferenceBase model, MachineLearningBatchOutputAction? outputAction, string outputFileName, MachineLearningDeploymentProvisioningState? provisioningState, MachineLearningDeploymentResourceConfiguration resources, MachineLearningBatchRetrySettings retrySettings) : base(codeConfiguration, description, environmentId, environmentVariables, properties, serializedAdditionalRawData)
        {
            Compute = compute;
            DeploymentConfiguration = deploymentConfiguration;
            ErrorThreshold = errorThreshold;
            LoggingLevel = loggingLevel;
            MaxConcurrencyPerInstance = maxConcurrencyPerInstance;
            MiniBatchSize = miniBatchSize;
            Model = model;
            OutputAction = outputAction;
            OutputFileName = outputFileName;
            ProvisioningState = provisioningState;
            Resources = resources;
            RetrySettings = retrySettings;
        }

        /// <summary> Compute target for batch inference operation. </summary>
        public string Compute { get; set; }
        /// <summary>
        /// Properties relevant to different deployment types.
        /// Please note <see cref="BatchDeploymentConfiguration"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="BatchPipelineComponentDeploymentConfiguration"/>.
        /// </summary>
        public BatchDeploymentConfiguration DeploymentConfiguration { get; set; }
        /// <summary>
        /// Error threshold, if the error count for the entire input goes above this value,
        /// the batch inference will be aborted. Range is [-1, int.MaxValue].
        /// For FileDataset, this value is the count of file failures.
        /// For TabularDataset, this value is the count of record failures.
        /// If set to -1 (the lower bound), all failures during batch inference will be ignored.
        /// </summary>
        public int? ErrorThreshold { get; set; }
        /// <summary> Logging level for batch inference operation. </summary>
        public MachineLearningBatchLoggingLevel? LoggingLevel { get; set; }
        /// <summary> Indicates maximum number of parallelism per instance. </summary>
        public int? MaxConcurrencyPerInstance { get; set; }
        /// <summary>
        /// Size of the mini-batch passed to each batch invocation.
        /// For FileDataset, this is the number of files per mini-batch.
        /// For TabularDataset, this is the size of the records in bytes, per mini-batch.
        /// </summary>
        public long? MiniBatchSize { get; set; }
        /// <summary>
        /// Reference to the model asset for the endpoint deployment.
        /// Please note <see cref="MachineLearningAssetReferenceBase"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="MachineLearningDataPathAssetReference"/>, <see cref="MachineLearningOutputPathAssetReference"/> and <see cref="MachineLearningIdAssetReference"/>.
        /// </summary>
        public MachineLearningAssetReferenceBase Model { get; set; }
        /// <summary> Indicates how the output will be organized. </summary>
        public MachineLearningBatchOutputAction? OutputAction { get; set; }
        /// <summary> Customized output file name for append_row output action. </summary>
        public string OutputFileName { get; set; }
        /// <summary> Provisioning state for the endpoint deployment. </summary>
        public MachineLearningDeploymentProvisioningState? ProvisioningState { get; }
        /// <summary>
        /// Indicates compute configuration for the job.
        /// If not provided, will default to the defaults defined in ResourceConfiguration.
        /// </summary>
        public MachineLearningDeploymentResourceConfiguration Resources { get; set; }
        /// <summary>
        /// Retry Settings for the batch inference operation.
        /// If not provided, will default to the defaults defined in BatchRetrySettings.
        /// </summary>
        public MachineLearningBatchRetrySettings RetrySettings { get; set; }
    }
}

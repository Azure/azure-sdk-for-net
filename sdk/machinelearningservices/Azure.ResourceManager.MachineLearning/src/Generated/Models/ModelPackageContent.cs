// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.

// <auto-generated/>

#nullable disable

using System;
using System.Collections.Generic;

namespace Azure.ResourceManager.MachineLearning.Models
{
    /// <summary> Model package operation request properties. </summary>
    public partial class ModelPackageContent
    {
        /// <summary>
        /// Keeps track of any properties unknown to the library.
        /// <para>
        /// To assign an object to the value of this property use <see cref="BinaryData.FromObjectAsJson{T}(T, System.Text.Json.JsonSerializerOptions?)"/>.
        /// </para>
        /// <para>
        /// To assign an already formatted json string to this property use <see cref="BinaryData.FromString(string)"/>.
        /// </para>
        /// <para>
        /// Examples:
        /// <list type="bullet">
        /// <item>
        /// <term>BinaryData.FromObjectAsJson("foo")</term>
        /// <description>Creates a payload of "foo".</description>
        /// </item>
        /// <item>
        /// <term>BinaryData.FromString("\"foo\"")</term>
        /// <description>Creates a payload of "foo".</description>
        /// </item>
        /// <item>
        /// <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
        /// <description>Creates a payload of { "key": "value" }.</description>
        /// </item>
        /// <item>
        /// <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
        /// <description>Creates a payload of { "key": "value" }.</description>
        /// </item>
        /// </list>
        /// </para>
        /// </summary>
        private IDictionary<string, BinaryData> _serializedAdditionalRawData;

        /// <summary> Initializes a new instance of <see cref="ModelPackageContent"/>. </summary>
        /// <param name="inferencingServer">
        /// [Required] Inferencing server configurations.
        /// Please note <see cref="Models.InferencingServer"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="AzureMLBatchInferencingServer"/>, <see cref="AzureMLOnlineInferencingServer"/>, <see cref="CustomInferencingServer"/> and <see cref="TritonInferencingServer"/>.
        /// </param>
        /// <param name="targetEnvironmentId"> [Required] Arm ID of the target environment to be created by package operation. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="inferencingServer"/> or <paramref name="targetEnvironmentId"/> is null. </exception>
        public ModelPackageContent(InferencingServer inferencingServer, string targetEnvironmentId)
        {
            Argument.AssertNotNull(inferencingServer, nameof(inferencingServer));
            Argument.AssertNotNull(targetEnvironmentId, nameof(targetEnvironmentId));

            EnvironmentVariables = new ChangeTrackingDictionary<string, string>();
            InferencingServer = inferencingServer;
            Inputs = new ChangeTrackingList<ModelPackageInput>();
            Tags = new ChangeTrackingDictionary<string, string>();
            TargetEnvironmentId = targetEnvironmentId;
        }

        /// <summary> Initializes a new instance of <see cref="ModelPackageContent"/>. </summary>
        /// <param name="baseEnvironmentSource">
        /// Base environment to start with.
        /// Please note <see cref="Models.BaseEnvironmentSource"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="BaseEnvironmentType"/>.
        /// </param>
        /// <param name="environmentVariables"> Collection of environment variables. </param>
        /// <param name="inferencingServer">
        /// [Required] Inferencing server configurations.
        /// Please note <see cref="Models.InferencingServer"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="AzureMLBatchInferencingServer"/>, <see cref="AzureMLOnlineInferencingServer"/>, <see cref="CustomInferencingServer"/> and <see cref="TritonInferencingServer"/>.
        /// </param>
        /// <param name="inputs"> Collection of inputs. </param>
        /// <param name="modelConfiguration"> Model configuration including the mount mode. </param>
        /// <param name="tags"> Tag dictionary. Tags can be added, removed, and updated. </param>
        /// <param name="targetEnvironmentId"> [Required] Arm ID of the target environment to be created by package operation. </param>
        /// <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        internal ModelPackageContent(BaseEnvironmentSource baseEnvironmentSource, IDictionary<string, string> environmentVariables, InferencingServer inferencingServer, IList<ModelPackageInput> inputs, ModelConfiguration modelConfiguration, IDictionary<string, string> tags, string targetEnvironmentId, IDictionary<string, BinaryData> serializedAdditionalRawData)
        {
            BaseEnvironmentSource = baseEnvironmentSource;
            EnvironmentVariables = environmentVariables;
            InferencingServer = inferencingServer;
            Inputs = inputs;
            ModelConfiguration = modelConfiguration;
            Tags = tags;
            TargetEnvironmentId = targetEnvironmentId;
            _serializedAdditionalRawData = serializedAdditionalRawData;
        }

        /// <summary> Initializes a new instance of <see cref="ModelPackageContent"/> for deserialization. </summary>
        internal ModelPackageContent()
        {
        }

        /// <summary>
        /// Base environment to start with.
        /// Please note <see cref="Models.BaseEnvironmentSource"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="BaseEnvironmentType"/>.
        /// </summary>
        public BaseEnvironmentSource BaseEnvironmentSource { get; set; }
        /// <summary> Collection of environment variables. </summary>
        public IDictionary<string, string> EnvironmentVariables { get; set; }
        /// <summary>
        /// [Required] Inferencing server configurations.
        /// Please note <see cref="Models.InferencingServer"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="AzureMLBatchInferencingServer"/>, <see cref="AzureMLOnlineInferencingServer"/>, <see cref="CustomInferencingServer"/> and <see cref="TritonInferencingServer"/>.
        /// </summary>
        public InferencingServer InferencingServer { get; }
        /// <summary> Collection of inputs. </summary>
        public IList<ModelPackageInput> Inputs { get; set; }
        /// <summary> Model configuration including the mount mode. </summary>
        public ModelConfiguration ModelConfiguration { get; set; }
        /// <summary> Tag dictionary. Tags can be added, removed, and updated. </summary>
        public IDictionary<string, string> Tags { get; set; }
        /// <summary> [Required] Arm ID of the target environment to be created by package operation. </summary>
        public string TargetEnvironmentId { get; }
    }
}

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.

// <auto-generated/>

#nullable disable

using System;
using System.Collections.Generic;
using Azure.Analytics.Synapse.Spark.Models;

namespace Azure.Analytics.Synapse.Spark
{
    /// <summary> Model factory for read-only models. </summary>
    public static partial class SparkModelFactory
    {
        /// <summary> Initializes new instance of SparkBatchJobCollection class. </summary>
        /// <param name="from"> The start index of fetched sessions. </param>
        /// <param name="total"> Number of sessions fetched. </param>
        /// <param name="sessions"> Batch list. </param>
        /// <returns> A new <see cref="Models.SparkBatchJobCollection"/> instance for mocking. </returns>
        public static SparkBatchJobCollection SparkBatchJobCollection(int @from = default, int total = default, IReadOnlyList<SparkBatchJob> sessions = default)
        {
            sessions ??= new List<SparkBatchJob>();
            return new SparkBatchJobCollection(@from, total, sessions);
        }

        /// <summary> Initializes new instance of SparkBatchJob class. </summary>
        /// <param name="livyInfo"> . </param>
        /// <param name="name"> The batch name. </param>
        /// <param name="workspaceName"> The workspace name. </param>
        /// <param name="sparkPoolName"> The Spark pool name. </param>
        /// <param name="submitterName"> The submitter name. </param>
        /// <param name="submitterId"> The submitter identifier. </param>
        /// <param name="artifactId"> The artifact identifier. </param>
        /// <param name="jobType"> The job type. </param>
        /// <param name="result"> The Spark batch job result. </param>
        /// <param name="scheduler"> The scheduler information. </param>
        /// <param name="plugin"> The plugin information. </param>
        /// <param name="errors"> The error information. </param>
        /// <param name="tags"> The tags. </param>
        /// <param name="id"> The session Id. </param>
        /// <param name="appId"> The application id of this session. </param>
        /// <param name="appInfo"> The detailed application info. </param>
        /// <param name="state"> The batch state. </param>
        /// <param name="logLines"> The log lines. </param>
        /// <returns> A new <see cref="Models.SparkBatchJob"/> instance for mocking. </returns>
        public static SparkBatchJob SparkBatchJob(SparkBatchJobState livyInfo = default, string name = default, string workspaceName = default, string sparkPoolName = default, string submitterName = default, string submitterId = default, string artifactId = default, SparkJobType? jobType = default, SparkBatchJobResultType? result = default, SparkScheduler scheduler = default, SparkServicePlugin plugin = default, IReadOnlyList<SparkServiceError> errors = default, IReadOnlyDictionary<string, string> tags = default, int id = default, string appId = default, IReadOnlyDictionary<string, string> appInfo = default, string state = default, IReadOnlyList<string> logLines = default)
        {
            errors ??= new List<SparkServiceError>();
            tags ??= new Dictionary<string, string>();
            appInfo ??= new Dictionary<string, string>();
            logLines ??= new List<string>();
            return new SparkBatchJob(livyInfo, name, workspaceName, sparkPoolName, submitterName, submitterId, artifactId, jobType, result, scheduler, plugin, errors, tags, id, appId, appInfo, state, logLines);
        }

        /// <summary> Initializes new instance of SparkBatchJobState class. </summary>
        /// <param name="notStartedAt"> the time that at which &quot;not_started&quot; livy state was first seen. </param>
        /// <param name="startingAt"> the time that at which &quot;starting&quot; livy state was first seen. </param>
        /// <param name="runningAt"> the time that at which &quot;running&quot; livy state was first seen. </param>
        /// <param name="deadAt"> time that at which &quot;dead&quot; livy state was first seen. </param>
        /// <param name="successAt"> the time that at which &quot;success&quot; livy state was first seen. </param>
        /// <param name="terminatedAt"> the time that at which &quot;killed&quot; livy state was first seen. </param>
        /// <param name="recoveringAt"> the time that at which &quot;recovering&quot; livy state was first seen. </param>
        /// <param name="currentState"> the Spark job state. </param>
        /// <param name="jobCreationRequest"> . </param>
        /// <returns> A new <see cref="Models.SparkBatchJobState"/> instance for mocking. </returns>
        public static SparkBatchJobState SparkBatchJobState(DateTimeOffset? notStartedAt = default, DateTimeOffset? startingAt = default, DateTimeOffset? runningAt = default, DateTimeOffset? deadAt = default, DateTimeOffset? successAt = default, DateTimeOffset? terminatedAt = default, DateTimeOffset? recoveringAt = default, string currentState = default, SparkRequest jobCreationRequest = default)
        {
            return new SparkBatchJobState(notStartedAt, startingAt, runningAt, deadAt, successAt, terminatedAt, recoveringAt, currentState, jobCreationRequest);
        }

        /// <summary> Initializes new instance of SparkRequest class. </summary>
        /// <param name="name"> . </param>
        /// <param name="file"> . </param>
        /// <param name="className"> . </param>
        /// <param name="arguments"> . </param>
        /// <param name="jars"> . </param>
        /// <param name="pythonFiles"> . </param>
        /// <param name="files"> . </param>
        /// <param name="archives"> . </param>
        /// <param name="configuration"> Dictionary of &lt;string&gt;. </param>
        /// <param name="driverMemory"> . </param>
        /// <param name="driverCores"> . </param>
        /// <param name="executorMemory"> . </param>
        /// <param name="executorCores"> . </param>
        /// <param name="executorCount"> . </param>
        /// <returns> A new <see cref="Models.SparkRequest"/> instance for mocking. </returns>
        public static SparkRequest SparkRequest(string name = default, string file = default, string className = default, IReadOnlyList<string> arguments = default, IReadOnlyList<string> jars = default, IReadOnlyList<string> pythonFiles = default, IReadOnlyList<string> files = default, IReadOnlyList<string> archives = default, IReadOnlyDictionary<string, string> configuration = default, string driverMemory = default, int? driverCores = default, string executorMemory = default, int? executorCores = default, int? executorCount = default)
        {
            arguments ??= new List<string>();
            jars ??= new List<string>();
            pythonFiles ??= new List<string>();
            files ??= new List<string>();
            archives ??= new List<string>();
            configuration ??= new Dictionary<string, string>();
            return new SparkRequest(name, file, className, arguments, jars, pythonFiles, files, archives, configuration, driverMemory, driverCores, executorMemory, executorCores, executorCount);
        }

        /// <summary> Initializes new instance of SparkScheduler class. </summary>
        /// <param name="submittedAt"> . </param>
        /// <param name="scheduledAt"> . </param>
        /// <param name="endedAt"> . </param>
        /// <param name="cancellationRequestedAt"> . </param>
        /// <param name="currentState"> . </param>
        /// <returns> A new <see cref="Models.SparkScheduler"/> instance for mocking. </returns>
        public static SparkScheduler SparkScheduler(DateTimeOffset? submittedAt = default, DateTimeOffset? scheduledAt = default, DateTimeOffset? endedAt = default, DateTimeOffset? cancellationRequestedAt = default, SchedulerCurrentState? currentState = default)
        {
            return new SparkScheduler(submittedAt, scheduledAt, endedAt, cancellationRequestedAt, currentState);
        }

        /// <summary> Initializes new instance of SparkServicePlugin class. </summary>
        /// <param name="preparationStartedAt"> . </param>
        /// <param name="resourceAcquisitionStartedAt"> . </param>
        /// <param name="submissionStartedAt"> . </param>
        /// <param name="monitoringStartedAt"> . </param>
        /// <param name="cleanupStartedAt"> . </param>
        /// <param name="currentState"> . </param>
        /// <returns> A new <see cref="Models.SparkServicePlugin"/> instance for mocking. </returns>
        public static SparkServicePlugin SparkServicePlugin(DateTimeOffset? preparationStartedAt = default, DateTimeOffset? resourceAcquisitionStartedAt = default, DateTimeOffset? submissionStartedAt = default, DateTimeOffset? monitoringStartedAt = default, DateTimeOffset? cleanupStartedAt = default, PluginCurrentState? currentState = default)
        {
            return new SparkServicePlugin(preparationStartedAt, resourceAcquisitionStartedAt, submissionStartedAt, monitoringStartedAt, cleanupStartedAt, currentState);
        }

        /// <summary> Initializes new instance of SparkServiceError class. </summary>
        /// <param name="message"> . </param>
        /// <param name="errorCode"> . </param>
        /// <param name="source"> . </param>
        /// <returns> A new <see cref="Models.SparkServiceError"/> instance for mocking. </returns>
        public static SparkServiceError SparkServiceError(string message = default, string errorCode = default, SparkErrorSource? source = default)
        {
            return new SparkServiceError(message, errorCode, source);
        }

        /// <summary> Initializes new instance of SparkSessionCollection class. </summary>
        /// <param name="from"> . </param>
        /// <param name="total"> . </param>
        /// <param name="sessions"> . </param>
        /// <returns> A new <see cref="Models.SparkSessionCollection"/> instance for mocking. </returns>
        public static SparkSessionCollection SparkSessionCollection(int @from = default, int total = default, IReadOnlyList<SparkSession> sessions = default)
        {
            sessions ??= new List<SparkSession>();
            return new SparkSessionCollection(@from, total, sessions);
        }

        /// <summary> Initializes new instance of SparkSession class. </summary>
        /// <param name="livyInfo"> . </param>
        /// <param name="name"> . </param>
        /// <param name="workspaceName"> . </param>
        /// <param name="sparkPoolName"> . </param>
        /// <param name="submitterName"> . </param>
        /// <param name="submitterId"> . </param>
        /// <param name="artifactId"> . </param>
        /// <param name="jobType"> The job type. </param>
        /// <param name="result"> . </param>
        /// <param name="scheduler"> . </param>
        /// <param name="plugin"> . </param>
        /// <param name="errors"> . </param>
        /// <param name="tags"> Dictionary of &lt;string&gt;. </param>
        /// <param name="id"> . </param>
        /// <param name="appId"> . </param>
        /// <param name="appInfo"> Dictionary of &lt;string&gt;. </param>
        /// <param name="state"> . </param>
        /// <param name="logLines"> . </param>
        /// <returns> A new <see cref="Models.SparkSession"/> instance for mocking. </returns>
        public static SparkSession SparkSession(SparkSessionState livyInfo = default, string name = default, string workspaceName = default, string sparkPoolName = default, string submitterName = default, string submitterId = default, string artifactId = default, SparkJobType? jobType = default, SparkSessionResultType? result = default, SparkScheduler scheduler = default, SparkServicePlugin plugin = default, IReadOnlyList<SparkServiceError> errors = default, IReadOnlyDictionary<string, string> tags = default, int id = default, string appId = default, IReadOnlyDictionary<string, string> appInfo = default, string state = default, IReadOnlyList<string> logLines = default)
        {
            errors ??= new List<SparkServiceError>();
            tags ??= new Dictionary<string, string>();
            appInfo ??= new Dictionary<string, string>();
            logLines ??= new List<string>();
            return new SparkSession(livyInfo, name, workspaceName, sparkPoolName, submitterName, submitterId, artifactId, jobType, result, scheduler, plugin, errors, tags, id, appId, appInfo, state, logLines);
        }

        /// <summary> Initializes new instance of SparkSessionState class. </summary>
        /// <param name="notStartedAt"> . </param>
        /// <param name="startingAt"> . </param>
        /// <param name="idleAt"> . </param>
        /// <param name="deadAt"> . </param>
        /// <param name="shuttingDownAt"> . </param>
        /// <param name="terminatedAt"> . </param>
        /// <param name="recoveringAt"> . </param>
        /// <param name="busyAt"> . </param>
        /// <param name="errorAt"> . </param>
        /// <param name="currentState"> . </param>
        /// <param name="jobCreationRequest"> . </param>
        /// <returns> A new <see cref="Models.SparkSessionState"/> instance for mocking. </returns>
        public static SparkSessionState SparkSessionState(DateTimeOffset? notStartedAt = default, DateTimeOffset? startingAt = default, DateTimeOffset? idleAt = default, DateTimeOffset? deadAt = default, DateTimeOffset? shuttingDownAt = default, DateTimeOffset? terminatedAt = default, DateTimeOffset? recoveringAt = default, DateTimeOffset? busyAt = default, DateTimeOffset? errorAt = default, string currentState = default, SparkRequest jobCreationRequest = default)
        {
            return new SparkSessionState(notStartedAt, startingAt, idleAt, deadAt, shuttingDownAt, terminatedAt, recoveringAt, busyAt, errorAt, currentState, jobCreationRequest);
        }

        /// <summary> Initializes new instance of SparkStatementCollection class. </summary>
        /// <param name="total"> . </param>
        /// <param name="statements"> . </param>
        /// <returns> A new <see cref="Models.SparkStatementCollection"/> instance for mocking. </returns>
        public static SparkStatementCollection SparkStatementCollection(int total = default, IReadOnlyList<SparkStatement> statements = default)
        {
            statements ??= new List<SparkStatement>();
            return new SparkStatementCollection(total, statements);
        }

        /// <summary> Initializes new instance of SparkStatement class. </summary>
        /// <param name="id"> . </param>
        /// <param name="code"> . </param>
        /// <param name="state"> . </param>
        /// <param name="output"> . </param>
        /// <returns> A new <see cref="Models.SparkStatement"/> instance for mocking. </returns>
        public static SparkStatement SparkStatement(int id = default, string code = default, string state = default, SparkStatementOutput output = default)
        {
            return new SparkStatement(id, code, state, output);
        }

        /// <summary> Initializes new instance of SparkStatementOutput class. </summary>
        /// <param name="status"> . </param>
        /// <param name="executionCount"> . </param>
        /// <param name="data"> Any object. </param>
        /// <param name="errorName"> . </param>
        /// <param name="errorValue"> . </param>
        /// <param name="traceback"> . </param>
        /// <returns> A new <see cref="Models.SparkStatementOutput"/> instance for mocking. </returns>
        public static SparkStatementOutput SparkStatementOutput(string status = default, int executionCount = default, object data = default, string errorName = default, string errorValue = default, IReadOnlyList<string> traceback = default)
        {
            traceback ??= new List<string>();
            return new SparkStatementOutput(status, executionCount, data, errorName, errorValue, traceback);
        }

        /// <summary> Initializes new instance of SparkStatementCancellationResult class. </summary>
        /// <param name="message"> The msg property from the Livy API. The value is always &quot;canceled&quot;. </param>
        /// <returns> A new <see cref="Models.SparkStatementCancellationResult"/> instance for mocking. </returns>
        public static SparkStatementCancellationResult SparkStatementCancellationResult(string message = default)
        {
            return new SparkStatementCancellationResult(message);
        }
    }
}

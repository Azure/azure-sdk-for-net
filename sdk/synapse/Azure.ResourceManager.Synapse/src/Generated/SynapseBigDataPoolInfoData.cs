// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.

// <auto-generated/>

#nullable disable

using System;
using System.Collections.Generic;
using Azure.Core;
using Azure.ResourceManager.Models;
using Azure.ResourceManager.Synapse.Models;

namespace Azure.ResourceManager.Synapse
{
    /// <summary> A class representing the SynapseBigDataPoolInfo data model. </summary>
    public partial class SynapseBigDataPoolInfoData : TrackedResourceData
    {
        /// <summary> Initializes a new instance of SynapseBigDataPoolInfoData. </summary>
        /// <param name="location"> The location. </param>
        public SynapseBigDataPoolInfoData(AzureLocation location) : base(location)
        {
            CustomLibraries = new ChangeTrackingList<BigDataPoolLibraryInfo>();
        }

        /// <summary> Initializes a new instance of SynapseBigDataPoolInfoData. </summary>
        /// <param name="id"> The id. </param>
        /// <param name="name"> The name. </param>
        /// <param name="resourceType"> The resourceType. </param>
        /// <param name="systemData"> The systemData. </param>
        /// <param name="tags"> The tags. </param>
        /// <param name="location"> The location. </param>
        /// <param name="provisioningState">
        /// The state of the Big Data pool.
        /// Serialized Name: BigDataPoolResourceInfo.properties.provisioningState
        /// </param>
        /// <param name="autoScale">
        /// Auto-scaling properties
        /// Serialized Name: BigDataPoolResourceInfo.properties.autoScale
        /// </param>
        /// <param name="createdOn">
        /// The time when the Big Data pool was created.
        /// Serialized Name: BigDataPoolResourceInfo.properties.creationDate
        /// </param>
        /// <param name="autoPause">
        /// Auto-pausing properties
        /// Serialized Name: BigDataPoolResourceInfo.properties.autoPause
        /// </param>
        /// <param name="isComputeIsolationEnabled">
        /// Whether compute isolation is required or not.
        /// Serialized Name: BigDataPoolResourceInfo.properties.isComputeIsolationEnabled
        /// </param>
        /// <param name="isAutotuneEnabled">
        /// Whether autotune is required or not.
        /// Serialized Name: BigDataPoolResourceInfo.properties.isAutotuneEnabled
        /// </param>
        /// <param name="sessionLevelPackagesEnabled">
        /// Whether session level packages enabled.
        /// Serialized Name: BigDataPoolResourceInfo.properties.sessionLevelPackagesEnabled
        /// </param>
        /// <param name="cacheSize">
        /// The cache size
        /// Serialized Name: BigDataPoolResourceInfo.properties.cacheSize
        /// </param>
        /// <param name="dynamicExecutorAllocation">
        /// Dynamic Executor Allocation
        /// Serialized Name: BigDataPoolResourceInfo.properties.dynamicExecutorAllocation
        /// </param>
        /// <param name="sparkEventsFolder">
        /// The Spark events folder
        /// Serialized Name: BigDataPoolResourceInfo.properties.sparkEventsFolder
        /// </param>
        /// <param name="nodeCount">
        /// The number of nodes in the Big Data pool.
        /// Serialized Name: BigDataPoolResourceInfo.properties.nodeCount
        /// </param>
        /// <param name="libraryRequirements">
        /// Library version requirements
        /// Serialized Name: BigDataPoolResourceInfo.properties.libraryRequirements
        /// </param>
        /// <param name="customLibraries">
        /// List of custom libraries/packages associated with the spark pool.
        /// Serialized Name: BigDataPoolResourceInfo.properties.customLibraries
        /// </param>
        /// <param name="sparkConfigProperties">
        /// Spark configuration file to specify additional properties
        /// Serialized Name: BigDataPoolResourceInfo.properties.sparkConfigProperties
        /// </param>
        /// <param name="sparkVersion">
        /// The Apache Spark version.
        /// Serialized Name: BigDataPoolResourceInfo.properties.sparkVersion
        /// </param>
        /// <param name="defaultSparkLogFolder">
        /// The default folder where Spark logs will be written.
        /// Serialized Name: BigDataPoolResourceInfo.properties.defaultSparkLogFolder
        /// </param>
        /// <param name="nodeSize">
        /// The level of compute power that each node in the Big Data pool has.
        /// Serialized Name: BigDataPoolResourceInfo.properties.nodeSize
        /// </param>
        /// <param name="nodeSizeFamily">
        /// The kind of nodes that the Big Data pool provides.
        /// Serialized Name: BigDataPoolResourceInfo.properties.nodeSizeFamily
        /// </param>
        /// <param name="lastSucceededTimestamp">
        /// The time when the Big Data pool was updated successfully.
        /// Serialized Name: BigDataPoolResourceInfo.properties.lastSucceededTimestamp
        /// </param>
        internal SynapseBigDataPoolInfoData(ResourceIdentifier id, string name, ResourceType resourceType, SystemData systemData, IDictionary<string, string> tags, AzureLocation location, string provisioningState, BigDataPoolAutoScaleProperties autoScale, DateTimeOffset? createdOn, BigDataPoolAutoPauseProperties autoPause, bool? isComputeIsolationEnabled, bool? isAutotuneEnabled, bool? sessionLevelPackagesEnabled, int? cacheSize, SynapseDynamicExecutorAllocation dynamicExecutorAllocation, string sparkEventsFolder, int? nodeCount, BigDataPoolLibraryRequirements libraryRequirements, IList<BigDataPoolLibraryInfo> customLibraries, BigDataPoolSparkConfigProperties sparkConfigProperties, string sparkVersion, string defaultSparkLogFolder, BigDataPoolNodeSize? nodeSize, BigDataPoolNodeSizeFamily? nodeSizeFamily, DateTimeOffset? lastSucceededTimestamp) : base(id, name, resourceType, systemData, tags, location)
        {
            ProvisioningState = provisioningState;
            AutoScale = autoScale;
            CreatedOn = createdOn;
            AutoPause = autoPause;
            IsComputeIsolationEnabled = isComputeIsolationEnabled;
            IsAutotuneEnabled = isAutotuneEnabled;
            SessionLevelPackagesEnabled = sessionLevelPackagesEnabled;
            CacheSize = cacheSize;
            DynamicExecutorAllocation = dynamicExecutorAllocation;
            SparkEventsFolder = sparkEventsFolder;
            NodeCount = nodeCount;
            LibraryRequirements = libraryRequirements;
            CustomLibraries = customLibraries;
            SparkConfigProperties = sparkConfigProperties;
            SparkVersion = sparkVersion;
            DefaultSparkLogFolder = defaultSparkLogFolder;
            NodeSize = nodeSize;
            NodeSizeFamily = nodeSizeFamily;
            LastSucceededTimestamp = lastSucceededTimestamp;
        }

        /// <summary>
        /// The state of the Big Data pool.
        /// Serialized Name: BigDataPoolResourceInfo.properties.provisioningState
        /// </summary>
        public string ProvisioningState { get; set; }
        /// <summary>
        /// Auto-scaling properties
        /// Serialized Name: BigDataPoolResourceInfo.properties.autoScale
        /// </summary>
        public BigDataPoolAutoScaleProperties AutoScale { get; set; }
        /// <summary>
        /// The time when the Big Data pool was created.
        /// Serialized Name: BigDataPoolResourceInfo.properties.creationDate
        /// </summary>
        public DateTimeOffset? CreatedOn { get; }
        /// <summary>
        /// Auto-pausing properties
        /// Serialized Name: BigDataPoolResourceInfo.properties.autoPause
        /// </summary>
        public BigDataPoolAutoPauseProperties AutoPause { get; set; }
        /// <summary>
        /// Whether compute isolation is required or not.
        /// Serialized Name: BigDataPoolResourceInfo.properties.isComputeIsolationEnabled
        /// </summary>
        public bool? IsComputeIsolationEnabled { get; set; }
        /// <summary>
        /// Whether autotune is required or not.
        /// Serialized Name: BigDataPoolResourceInfo.properties.isAutotuneEnabled
        /// </summary>
        public bool? IsAutotuneEnabled { get; set; }
        /// <summary>
        /// Whether session level packages enabled.
        /// Serialized Name: BigDataPoolResourceInfo.properties.sessionLevelPackagesEnabled
        /// </summary>
        public bool? SessionLevelPackagesEnabled { get; set; }
        /// <summary>
        /// The cache size
        /// Serialized Name: BigDataPoolResourceInfo.properties.cacheSize
        /// </summary>
        public int? CacheSize { get; set; }
        /// <summary>
        /// Dynamic Executor Allocation
        /// Serialized Name: BigDataPoolResourceInfo.properties.dynamicExecutorAllocation
        /// </summary>
        public SynapseDynamicExecutorAllocation DynamicExecutorAllocation { get; set; }
        /// <summary>
        /// The Spark events folder
        /// Serialized Name: BigDataPoolResourceInfo.properties.sparkEventsFolder
        /// </summary>
        public string SparkEventsFolder { get; set; }
        /// <summary>
        /// The number of nodes in the Big Data pool.
        /// Serialized Name: BigDataPoolResourceInfo.properties.nodeCount
        /// </summary>
        public int? NodeCount { get; set; }
        /// <summary>
        /// Library version requirements
        /// Serialized Name: BigDataPoolResourceInfo.properties.libraryRequirements
        /// </summary>
        public BigDataPoolLibraryRequirements LibraryRequirements { get; set; }
        /// <summary>
        /// List of custom libraries/packages associated with the spark pool.
        /// Serialized Name: BigDataPoolResourceInfo.properties.customLibraries
        /// </summary>
        public IList<BigDataPoolLibraryInfo> CustomLibraries { get; }
        /// <summary>
        /// Spark configuration file to specify additional properties
        /// Serialized Name: BigDataPoolResourceInfo.properties.sparkConfigProperties
        /// </summary>
        public BigDataPoolSparkConfigProperties SparkConfigProperties { get; set; }
        /// <summary>
        /// The Apache Spark version.
        /// Serialized Name: BigDataPoolResourceInfo.properties.sparkVersion
        /// </summary>
        public string SparkVersion { get; set; }
        /// <summary>
        /// The default folder where Spark logs will be written.
        /// Serialized Name: BigDataPoolResourceInfo.properties.defaultSparkLogFolder
        /// </summary>
        public string DefaultSparkLogFolder { get; set; }
        /// <summary>
        /// The level of compute power that each node in the Big Data pool has.
        /// Serialized Name: BigDataPoolResourceInfo.properties.nodeSize
        /// </summary>
        public BigDataPoolNodeSize? NodeSize { get; set; }
        /// <summary>
        /// The kind of nodes that the Big Data pool provides.
        /// Serialized Name: BigDataPoolResourceInfo.properties.nodeSizeFamily
        /// </summary>
        public BigDataPoolNodeSizeFamily? NodeSizeFamily { get; set; }
        /// <summary>
        /// The time when the Big Data pool was updated successfully.
        /// Serialized Name: BigDataPoolResourceInfo.properties.lastSucceededTimestamp
        /// </summary>
        public DateTimeOffset? LastSucceededTimestamp { get; }
    }
}

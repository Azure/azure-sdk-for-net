// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.

// <auto-generated/>

#nullable disable

using System;
using System.Collections.Generic;

namespace Azure.AI.ContentSafety
{
    /// <summary> The request of analyzing potential direct or indirect injection attacks. </summary>
    public partial class ShieldPromptOptions
    {
        /// <summary> Keeps track of any properties unknown to the library. </summary>
        private protected readonly IDictionary<string, BinaryData> _additionalBinaryDataProperties;

        /// <summary> Initializes a new instance of <see cref="ShieldPromptOptions"/>. </summary>
        public ShieldPromptOptions()
        {
            Documents = new ChangeTrackingList<string>();
        }

        /// <summary> Initializes a new instance of <see cref="ShieldPromptOptions"/>. </summary>
        /// <param name="userPrompt"> The user prompt to be analyzed, which may contain direct injection attacks. </param>
        /// <param name="documents"> The documents to be analyzed, which may contain direct or indirect injection attacks. </param>
        /// <param name="additionalBinaryDataProperties"> Keeps track of any properties unknown to the library. </param>
        internal ShieldPromptOptions(string userPrompt, IList<string> documents, IDictionary<string, BinaryData> additionalBinaryDataProperties)
        {
            UserPrompt = userPrompt;
            Documents = documents;
            _additionalBinaryDataProperties = additionalBinaryDataProperties;
        }

        /// <summary> The user prompt to be analyzed, which may contain direct injection attacks. </summary>
        public string UserPrompt { get; set; }

        /// <summary> The documents to be analyzed, which may contain direct or indirect injection attacks. </summary>
        public IList<string> Documents { get; }
    }
}

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.

// <auto-generated/>

#nullable disable

using System;
using System.Collections.Generic;
using System.Linq;

namespace Azure.AI.OpenAI
{
    /// <summary> Model factory for models. </summary>
    public static partial class AIOpenAIModelFactory
    {
        /// <summary> Initializes a new instance of <see cref="OpenAI.AudioTranscriptionOptions"/>. </summary>
        /// <param name="audioData">
        /// The audio data to transcribe. This must be the binary content of a file in one of the supported media formats:
        ///  flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, webm.
        /// </param>
        /// <param name="filename"> The optional filename or descriptive identifier to associate with with the audio data. </param>
        /// <param name="responseFormat"> The requested format of the transcription response data, which will influence the content and detail of the result. </param>
        /// <param name="language">
        /// The primary spoken language of the audio data to be transcribed, supplied as a two-letter ISO-639-1 language code
        /// such as 'en' or 'fr'.
        /// Providing this known input language is optional but may improve the accuracy and/or latency of transcription.
        /// </param>
        /// <param name="prompt">
        /// An optional hint to guide the model's style or continue from a prior audio segment. The written language of the
        /// prompt should match the primary spoken language of the audio data.
        /// </param>
        /// <param name="temperature">
        /// The sampling temperature, between 0 and 1.
        /// Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.
        /// If set to 0, the model will use log probability to automatically increase the temperature until certain thresholds are hit.
        /// </param>
        /// <param name="timestampGranularities">
        /// The timestamp granularities to populate for this transcription.
        /// `response_format` must be set `verbose_json` to use timestamp granularities.
        /// Either or both of these options are supported: `word`, or `segment`.
        /// Note: There is no additional latency for segment timestamps, but generating word timestamps incurs additional latency.
        /// </param>
        /// <param name="deploymentName"> The model to use for this transcription request. </param>
        /// <returns> A new <see cref="OpenAI.AudioTranscriptionOptions"/> instance for mocking. </returns>
        public static AudioTranscriptionOptions AudioTranscriptionOptions(BinaryData audioData = null, string filename = null, AudioTranscriptionFormat? responseFormat = null, string language = null, string prompt = null, float? temperature = null, IEnumerable<AudioTranscriptionTimestampGranularity> timestampGranularities = null, string deploymentName = null)
        {
            timestampGranularities ??= new List<AudioTranscriptionTimestampGranularity>();

            return new AudioTranscriptionOptions(
                audioData,
                filename,
                responseFormat,
                language,
                prompt,
                temperature,
                timestampGranularities?.ToList(),
                deploymentName,
                serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.AudioTranscription"/>. </summary>
        /// <param name="text"> The transcribed text for the provided audio data. </param>
        /// <param name="internalAudioTaskLabel"> The label that describes which operation type generated the accompanying response data. </param>
        /// <param name="language">
        /// The spoken language that was detected in the transcribed audio data.
        /// This is expressed as a two-letter ISO-639-1 language code like 'en' or 'fr'.
        /// </param>
        /// <param name="duration"> The total duration of the audio processed to produce accompanying transcription information. </param>
        /// <param name="segments"> A collection of information about the timing, probabilities, and other detail of each processed audio segment. </param>
        /// <param name="words"> A collection of information about the timing of each processed word. </param>
        /// <returns> A new <see cref="OpenAI.AudioTranscription"/> instance for mocking. </returns>
        public static AudioTranscription AudioTranscription(string text = null, AudioTaskLabel? internalAudioTaskLabel = null, string language = null, TimeSpan? duration = null, IEnumerable<AudioTranscriptionSegment> segments = null, IEnumerable<AudioTranscriptionWord> words = null)
        {
            segments ??= new List<AudioTranscriptionSegment>();
            words ??= new List<AudioTranscriptionWord>();

            return new AudioTranscription(
                text,
                internalAudioTaskLabel,
                language,
                duration,
                segments?.ToList(),
                words?.ToList(),
                serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.AudioTranscriptionSegment"/>. </summary>
        /// <param name="id"> The 0-based index of this segment within a transcription. </param>
        /// <param name="start"> The time at which this segment started relative to the beginning of the transcribed audio. </param>
        /// <param name="end"> The time at which this segment ended relative to the beginning of the transcribed audio. </param>
        /// <param name="text"> The transcribed text that was part of this audio segment. </param>
        /// <param name="temperature"> The temperature score associated with this audio segment. </param>
        /// <param name="averageLogProbability"> The average log probability associated with this audio segment. </param>
        /// <param name="compressionRatio"> The compression ratio of this audio segment. </param>
        /// <param name="noSpeechProbability"> The probability of no speech detection within this audio segment. </param>
        /// <param name="tokens"> The token IDs matching the transcribed text in this audio segment. </param>
        /// <param name="seek">
        /// The seek position associated with the processing of this audio segment.
        /// Seek positions are expressed as hundredths of seconds.
        /// The model may process several segments from a single seek position, so while the seek position will never represent
        /// a later time than the segment's start, the segment's start may represent a significantly later time than the
        /// segment's associated seek position.
        /// </param>
        /// <returns> A new <see cref="OpenAI.AudioTranscriptionSegment"/> instance for mocking. </returns>
        public static AudioTranscriptionSegment AudioTranscriptionSegment(int id = default, TimeSpan start = default, TimeSpan end = default, string text = null, float temperature = default, float averageLogProbability = default, float compressionRatio = default, float noSpeechProbability = default, IEnumerable<int> tokens = null, int seek = default)
        {
            tokens ??= new List<int>();

            return new AudioTranscriptionSegment(
                id,
                start,
                end,
                text,
                temperature,
                averageLogProbability,
                compressionRatio,
                noSpeechProbability,
                tokens?.ToList(),
                seek,
                serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.AudioTranscriptionWord"/>. </summary>
        /// <param name="word"> The textual content of the word. </param>
        /// <param name="start"> The start time of the word relative to the beginning of the audio, expressed in seconds. </param>
        /// <param name="end"> The end time of the word relative to the beginning of the audio, expressed in seconds. </param>
        /// <returns> A new <see cref="OpenAI.AudioTranscriptionWord"/> instance for mocking. </returns>
        public static AudioTranscriptionWord AudioTranscriptionWord(string word = null, TimeSpan start = default, TimeSpan end = default)
        {
            return new AudioTranscriptionWord(word, start, end, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.AudioTranslationOptions"/>. </summary>
        /// <param name="audioData">
        /// The audio data to translate. This must be the binary content of a file in one of the supported media formats:
        ///  flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, webm.
        /// </param>
        /// <param name="filename"> The optional filename or descriptive identifier to associate with with the audio data. </param>
        /// <param name="responseFormat"> The requested format of the translation response data, which will influence the content and detail of the result. </param>
        /// <param name="prompt">
        /// An optional hint to guide the model's style or continue from a prior audio segment. The written language of the
        /// prompt should match the primary spoken language of the audio data.
        /// </param>
        /// <param name="temperature">
        /// The sampling temperature, between 0 and 1.
        /// Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.
        /// If set to 0, the model will use log probability to automatically increase the temperature until certain thresholds are hit.
        /// </param>
        /// <param name="deploymentName"> The model to use for this translation request. </param>
        /// <returns> A new <see cref="OpenAI.AudioTranslationOptions"/> instance for mocking. </returns>
        public static AudioTranslationOptions AudioTranslationOptions(BinaryData audioData = null, string filename = null, AudioTranslationFormat? responseFormat = null, string prompt = null, float? temperature = null, string deploymentName = null)
        {
            return new AudioTranslationOptions(
                audioData,
                filename,
                responseFormat,
                prompt,
                temperature,
                deploymentName,
                serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.AudioTranslation"/>. </summary>
        /// <param name="text"> The translated text for the provided audio data. </param>
        /// <param name="internalAudioTaskLabel"> The label that describes which operation type generated the accompanying response data. </param>
        /// <param name="language">
        /// The spoken language that was detected in the translated audio data.
        /// This is expressed as a two-letter ISO-639-1 language code like 'en' or 'fr'.
        /// </param>
        /// <param name="duration"> The total duration of the audio processed to produce accompanying translation information. </param>
        /// <param name="segments"> A collection of information about the timing, probabilities, and other detail of each processed audio segment. </param>
        /// <returns> A new <see cref="OpenAI.AudioTranslation"/> instance for mocking. </returns>
        public static AudioTranslation AudioTranslation(string text = null, AudioTaskLabel? internalAudioTaskLabel = null, string language = null, TimeSpan? duration = null, IEnumerable<AudioTranslationSegment> segments = null)
        {
            segments ??= new List<AudioTranslationSegment>();

            return new AudioTranslation(
                text,
                internalAudioTaskLabel,
                language,
                duration,
                segments?.ToList(),
                serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.AudioTranslationSegment"/>. </summary>
        /// <param name="id"> The 0-based index of this segment within a translation. </param>
        /// <param name="start"> The time at which this segment started relative to the beginning of the translated audio. </param>
        /// <param name="end"> The time at which this segment ended relative to the beginning of the translated audio. </param>
        /// <param name="text"> The translated text that was part of this audio segment. </param>
        /// <param name="temperature"> The temperature score associated with this audio segment. </param>
        /// <param name="averageLogProbability"> The average log probability associated with this audio segment. </param>
        /// <param name="compressionRatio"> The compression ratio of this audio segment. </param>
        /// <param name="noSpeechProbability"> The probability of no speech detection within this audio segment. </param>
        /// <param name="tokens"> The token IDs matching the translated text in this audio segment. </param>
        /// <param name="seek">
        /// The seek position associated with the processing of this audio segment.
        /// Seek positions are expressed as hundredths of seconds.
        /// The model may process several segments from a single seek position, so while the seek position will never represent
        /// a later time than the segment's start, the segment's start may represent a significantly later time than the
        /// segment's associated seek position.
        /// </param>
        /// <returns> A new <see cref="OpenAI.AudioTranslationSegment"/> instance for mocking. </returns>
        public static AudioTranslationSegment AudioTranslationSegment(int id = default, TimeSpan start = default, TimeSpan end = default, string text = null, float temperature = default, float averageLogProbability = default, float compressionRatio = default, float noSpeechProbability = default, IEnumerable<int> tokens = null, int seek = default)
        {
            tokens ??= new List<int>();

            return new AudioTranslationSegment(
                id,
                start,
                end,
                text,
                temperature,
                averageLogProbability,
                compressionRatio,
                noSpeechProbability,
                tokens?.ToList(),
                seek,
                serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.Completions"/>. </summary>
        /// <param name="id"> A unique identifier associated with this completions response. </param>
        /// <param name="created">
        /// The first timestamp associated with generation activity for this completions response,
        /// represented as seconds since the beginning of the Unix epoch of 00:00 on 1 Jan 1970.
        /// </param>
        /// <param name="promptFilterResults">
        /// Content filtering results for zero or more prompts in the request. In a streaming request,
        /// results for different prompts may arrive at different times or in different orders.
        /// </param>
        /// <param name="choices">
        /// The collection of completions choices associated with this completions response.
        /// Generally, `n` choices are generated per provided prompt with a default value of 1.
        /// Token limits and other settings may limit the number of choices generated.
        /// </param>
        /// <param name="usage"> Usage information for tokens processed and generated as part of this completions operation. </param>
        /// <returns> A new <see cref="OpenAI.Completions"/> instance for mocking. </returns>
        public static Completions Completions(string id = null, DateTimeOffset created = default, IEnumerable<ContentFilterResultsForPrompt> promptFilterResults = null, IEnumerable<Choice> choices = null, CompletionsUsage usage = null)
        {
            promptFilterResults ??= new List<ContentFilterResultsForPrompt>();
            choices ??= new List<Choice>();

            return new Completions(
                id,
                created,
                promptFilterResults?.ToList(),
                choices?.ToList(),
                usage,
                serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.ContentFilterResultsForPrompt"/>. </summary>
        /// <param name="promptIndex"> The index of this prompt in the set of prompt results. </param>
        /// <param name="contentFilterResults"> Content filtering results for this prompt. </param>
        /// <returns> A new <see cref="OpenAI.ContentFilterResultsForPrompt"/> instance for mocking. </returns>
        public static ContentFilterResultsForPrompt ContentFilterResultsForPrompt(int promptIndex = default, ContentFilterResultDetailsForPrompt contentFilterResults = null)
        {
            return new ContentFilterResultsForPrompt(promptIndex, contentFilterResults, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.ContentFilterResultDetailsForPrompt"/>. </summary>
        /// <param name="sexual">
        /// Describes language related to anatomical organs and genitals, romantic relationships,
        ///  acts portrayed in erotic or affectionate terms, physical sexual acts, including
        ///  those portrayed as an assault or a forced sexual violent act against one’s will,
        ///  prostitution, pornography, and abuse.
        /// </param>
        /// <param name="violence">
        /// Describes language related to physical actions intended to hurt, injure, damage, or
        /// kill someone or something; describes weapons, etc.
        /// </param>
        /// <param name="hate">
        /// Describes language attacks or uses that include pejorative or discriminatory language
        /// with reference to a person or identity group on the basis of certain differentiating
        /// attributes of these groups including but not limited to race, ethnicity, nationality,
        /// gender identity and expression, sexual orientation, religion, immigration status, ability
        /// status, personal appearance, and body size.
        /// </param>
        /// <param name="selfHarm">
        /// Describes language related to physical actions intended to purposely hurt, injure,
        /// or damage one’s body, or kill oneself.
        /// </param>
        /// <param name="profanity"> Describes whether profanity was detected. </param>
        /// <param name="customBlocklists"> Describes detection results against configured custom blocklists. </param>
        /// <param name="error">
        /// Describes an error returned if the content filtering system is
        /// down or otherwise unable to complete the operation in time.
        /// </param>
        /// <param name="jailbreak"> Whether a jailbreak attempt was detected in the prompt. </param>
        /// <param name="indirectAttack"> Whether an indirect attack was detected in the prompt. </param>
        /// <returns> A new <see cref="OpenAI.ContentFilterResultDetailsForPrompt"/> instance for mocking. </returns>
        public static ContentFilterResultDetailsForPrompt ContentFilterResultDetailsForPrompt(ContentFilterResult sexual = null, ContentFilterResult violence = null, ContentFilterResult hate = null, ContentFilterResult selfHarm = null, ContentFilterDetectionResult profanity = null, ContentFilterDetailedResults customBlocklists = null, ResponseError error = null, ContentFilterDetectionResult jailbreak = null, ContentFilterDetectionResult indirectAttack = null)
        {
            return new ContentFilterResultDetailsForPrompt(
                sexual,
                violence,
                hate,
                selfHarm,
                profanity,
                customBlocklists,
                error,
                jailbreak,
                indirectAttack,
                serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.ContentFilterResult"/>. </summary>
        /// <param name="filtered"> A value indicating whether or not the content has been filtered. </param>
        /// <param name="severity"> Ratings for the intensity and risk level of filtered content. </param>
        /// <returns> A new <see cref="OpenAI.ContentFilterResult"/> instance for mocking. </returns>
        public static ContentFilterResult ContentFilterResult(bool filtered = default, ContentFilterSeverity severity = default)
        {
            return new ContentFilterResult(filtered, severity, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.ContentFilterDetectionResult"/>. </summary>
        /// <param name="filtered"> A value indicating whether or not the content has been filtered. </param>
        /// <param name="detected"> A value indicating whether detection occurred, irrespective of severity or whether the content was filtered. </param>
        /// <returns> A new <see cref="OpenAI.ContentFilterDetectionResult"/> instance for mocking. </returns>
        public static ContentFilterDetectionResult ContentFilterDetectionResult(bool filtered = default, bool detected = default)
        {
            return new ContentFilterDetectionResult(filtered, detected, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.ContentFilterDetailedResults"/>. </summary>
        /// <param name="filtered"> A value indicating whether or not the content has been filtered. </param>
        /// <param name="details"> The collection of detailed blocklist result information. </param>
        /// <returns> A new <see cref="OpenAI.ContentFilterDetailedResults"/> instance for mocking. </returns>
        public static ContentFilterDetailedResults ContentFilterDetailedResults(bool filtered = default, IEnumerable<ContentFilterBlocklistIdResult> details = null)
        {
            details ??= new List<ContentFilterBlocklistIdResult>();

            return new ContentFilterDetailedResults(filtered, details?.ToList(), serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.ContentFilterBlocklistIdResult"/>. </summary>
        /// <param name="filtered"> A value indicating whether or not the content has been filtered. </param>
        /// <param name="id"> The ID of the custom blocklist evaluated. </param>
        /// <returns> A new <see cref="OpenAI.ContentFilterBlocklistIdResult"/> instance for mocking. </returns>
        public static ContentFilterBlocklistIdResult ContentFilterBlocklistIdResult(bool filtered = default, string id = null)
        {
            return new ContentFilterBlocklistIdResult(filtered, id, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.Choice"/>. </summary>
        /// <param name="text"> The generated text for a given completions prompt. </param>
        /// <param name="index"> The ordered index associated with this completions choice. </param>
        /// <param name="contentFilterResults">
        /// Information about the content filtering category (hate, sexual, violence, self_harm), if it
        /// has been detected, as well as the severity level (very_low, low, medium, high-scale that
        /// determines the intensity and risk level of harmful content) and if it has been filtered or not.
        /// </param>
        /// <param name="logProbabilityModel"> The log probabilities model for tokens associated with this completions choice. </param>
        /// <param name="finishReason"> Reason for finishing. </param>
        /// <returns> A new <see cref="OpenAI.Choice"/> instance for mocking. </returns>
        public static Choice Choice(string text = null, int index = default, ContentFilterResultsForChoice contentFilterResults = null, CompletionsLogProbabilityModel logProbabilityModel = null, CompletionsFinishReason? finishReason = null)
        {
            return new Choice(
                text,
                index,
                contentFilterResults,
                logProbabilityModel,
                finishReason,
                serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.ContentFilterResultsForChoice"/>. </summary>
        /// <param name="sexual">
        /// Describes language related to anatomical organs and genitals, romantic relationships,
        ///  acts portrayed in erotic or affectionate terms, physical sexual acts, including
        ///  those portrayed as an assault or a forced sexual violent act against one’s will,
        ///  prostitution, pornography, and abuse.
        /// </param>
        /// <param name="violence">
        /// Describes language related to physical actions intended to hurt, injure, damage, or
        /// kill someone or something; describes weapons, etc.
        /// </param>
        /// <param name="hate">
        /// Describes language attacks or uses that include pejorative or discriminatory language
        /// with reference to a person or identity group on the basis of certain differentiating
        /// attributes of these groups including but not limited to race, ethnicity, nationality,
        /// gender identity and expression, sexual orientation, religion, immigration status, ability
        /// status, personal appearance, and body size.
        /// </param>
        /// <param name="selfHarm">
        /// Describes language related to physical actions intended to purposely hurt, injure,
        /// or damage one’s body, or kill oneself.
        /// </param>
        /// <param name="profanity"> Describes whether profanity was detected. </param>
        /// <param name="customBlocklists"> Describes detection results against configured custom blocklists. </param>
        /// <param name="error">
        /// Describes an error returned if the content filtering system is
        /// down or otherwise unable to complete the operation in time.
        /// </param>
        /// <param name="protectedMaterialText"> Information about detection of protected text material. </param>
        /// <param name="protectedMaterialCode"> Information about detection of protected code material. </param>
        /// <returns> A new <see cref="OpenAI.ContentFilterResultsForChoice"/> instance for mocking. </returns>
        public static ContentFilterResultsForChoice ContentFilterResultsForChoice(ContentFilterResult sexual = null, ContentFilterResult violence = null, ContentFilterResult hate = null, ContentFilterResult selfHarm = null, ContentFilterDetectionResult profanity = null, ContentFilterDetailedResults customBlocklists = null, ResponseError error = null, ContentFilterDetectionResult protectedMaterialText = null, ContentFilterCitedDetectionResult protectedMaterialCode = null)
        {
            return new ContentFilterResultsForChoice(
                sexual,
                violence,
                hate,
                selfHarm,
                profanity,
                customBlocklists,
                error,
                protectedMaterialText,
                protectedMaterialCode,
                serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.ContentFilterCitedDetectionResult"/>. </summary>
        /// <param name="filtered"> A value indicating whether or not the content has been filtered. </param>
        /// <param name="detected"> A value indicating whether detection occurred, irrespective of severity or whether the content was filtered. </param>
        /// <param name="url"> The internet location associated with the detection. </param>
        /// <param name="license"> The license description associated with the detection. </param>
        /// <returns> A new <see cref="OpenAI.ContentFilterCitedDetectionResult"/> instance for mocking. </returns>
        public static ContentFilterCitedDetectionResult ContentFilterCitedDetectionResult(bool filtered = default, bool detected = default, Uri url = null, string license = null)
        {
            return new ContentFilterCitedDetectionResult(filtered, detected, url, license, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.CompletionsLogProbabilityModel"/>. </summary>
        /// <param name="tokens"> The textual forms of tokens evaluated in this probability model. </param>
        /// <param name="tokenLogProbabilities"> A collection of log probability values for the tokens in this completions data. </param>
        /// <param name="topLogProbabilities"> A mapping of tokens to maximum log probability values in this completions data. </param>
        /// <param name="textOffsets"> The text offsets associated with tokens in this completions data. </param>
        /// <returns> A new <see cref="OpenAI.CompletionsLogProbabilityModel"/> instance for mocking. </returns>
        public static CompletionsLogProbabilityModel CompletionsLogProbabilityModel(IEnumerable<string> tokens = null, IEnumerable<float?> tokenLogProbabilities = null, IEnumerable<IDictionary<string, float?>> topLogProbabilities = null, IEnumerable<int> textOffsets = null)
        {
            tokens ??= new List<string>();
            tokenLogProbabilities ??= new List<float?>();
            topLogProbabilities ??= new List<IDictionary<string, float?>>();
            textOffsets ??= new List<int>();

            return new CompletionsLogProbabilityModel(tokens?.ToList(), tokenLogProbabilities?.ToList(), topLogProbabilities?.ToList(), textOffsets?.ToList(), serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.CompletionsUsage"/>. </summary>
        /// <param name="completionTokens"> The number of tokens generated across all completions emissions. </param>
        /// <param name="promptTokens"> The number of tokens in the provided prompts for the completions request. </param>
        /// <param name="totalTokens"> The total number of tokens processed for the completions request and response. </param>
        /// <returns> A new <see cref="OpenAI.CompletionsUsage"/> instance for mocking. </returns>
        public static CompletionsUsage CompletionsUsage(int completionTokens = default, int promptTokens = default, int totalTokens = default)
        {
            return new CompletionsUsage(completionTokens, promptTokens, totalTokens, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.FunctionDefinition"/>. </summary>
        /// <param name="name"> The name of the function to be called. </param>
        /// <param name="description">
        /// A description of what the function does. The model will use this description when selecting the function and
        /// interpreting its parameters.
        /// </param>
        /// <param name="parameters"> The parameters the function accepts, described as a JSON Schema object. </param>
        /// <returns> A new <see cref="OpenAI.FunctionDefinition"/> instance for mocking. </returns>
        public static FunctionDefinition FunctionDefinition(string name = null, string description = null, BinaryData parameters = null)
        {
            return new FunctionDefinition(name, description, parameters, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.ChatCompletions"/>. </summary>
        /// <param name="id"> A unique identifier associated with this chat completions response. </param>
        /// <param name="created">
        /// The first timestamp associated with generation activity for this completions response,
        /// represented as seconds since the beginning of the Unix epoch of 00:00 on 1 Jan 1970.
        /// </param>
        /// <param name="choices">
        /// The collection of completions choices associated with this completions response.
        /// Generally, `n` choices are generated per provided prompt with a default value of 1.
        /// Token limits and other settings may limit the number of choices generated.
        /// </param>
        /// <param name="model"> The model name used for this completions request. </param>
        /// <param name="promptFilterResults">
        /// Content filtering results for zero or more prompts in the request. In a streaming request,
        /// results for different prompts may arrive at different times or in different orders.
        /// </param>
        /// <param name="systemFingerprint">
        /// Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that
        /// might impact determinism.
        /// </param>
        /// <param name="usage"> Usage information for tokens processed and generated as part of this completions operation. </param>
        /// <returns> A new <see cref="OpenAI.ChatCompletions"/> instance for mocking. </returns>
        public static ChatCompletions ChatCompletions(string id = null, DateTimeOffset created = default, IEnumerable<ChatChoice> choices = null, string model = null, IEnumerable<ContentFilterResultsForPrompt> promptFilterResults = null, string systemFingerprint = null, CompletionsUsage usage = null)
        {
            choices ??= new List<ChatChoice>();
            promptFilterResults ??= new List<ContentFilterResultsForPrompt>();

            return new ChatCompletions(
                id,
                created,
                choices?.ToList(),
                model,
                promptFilterResults?.ToList(),
                systemFingerprint,
                usage,
                serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.ChatChoice"/>. </summary>
        /// <param name="message"> The chat message for a given chat completions prompt. </param>
        /// <param name="logProbabilityInfo"> The log probability information for this choice, as enabled via the 'logprobs' request option. </param>
        /// <param name="index"> The ordered index associated with this chat completions choice. </param>
        /// <param name="finishReason"> The reason that this chat completions choice completed its generated. </param>
        /// <param name="finishDetails">
        /// The reason the model stopped generating tokens, together with any applicable details.
        /// This structured representation replaces 'finish_reason' for some models.
        /// Please note <see cref="ChatFinishDetails"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="MaxTokensFinishDetails"/> and <see cref="OpenAI.StopFinishDetails"/>.
        /// </param>
        /// <param name="internalStreamingDeltaMessage"> The delta message content for a streaming response. </param>
        /// <param name="contentFilterResults">
        /// Information about the content filtering category (hate, sexual, violence, self_harm), if it
        /// has been detected, as well as the severity level (very_low, low, medium, high-scale that
        /// determines the intensity and risk level of harmful content) and if it has been filtered or not.
        /// </param>
        /// <param name="enhancements">
        /// Represents the output results of Azure OpenAI enhancements to chat completions, as configured via the matching input
        /// provided in the request. This supplementary information is only available when using Azure OpenAI and only when the
        /// request is configured to use enhancements.
        /// </param>
        /// <returns> A new <see cref="OpenAI.ChatChoice"/> instance for mocking. </returns>
        public static ChatChoice ChatChoice(ChatResponseMessage message = null, ChatChoiceLogProbabilityInfo logProbabilityInfo = null, int index = default, CompletionsFinishReason? finishReason = null, ChatFinishDetails finishDetails = null, ChatResponseMessage internalStreamingDeltaMessage = null, ContentFilterResultsForChoice contentFilterResults = null, AzureChatEnhancements enhancements = null)
        {
            return new ChatChoice(
                message,
                logProbabilityInfo,
                index,
                finishReason,
                finishDetails,
                internalStreamingDeltaMessage,
                contentFilterResults,
                enhancements,
                serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.ChatResponseMessage"/>. </summary>
        /// <param name="role"> The chat role associated with the message. </param>
        /// <param name="content"> The content of the message. </param>
        /// <param name="toolCalls">
        /// The tool calls that must be resolved and have their outputs appended to subsequent input messages for the chat
        /// completions request to resolve as configured.
        /// Please note <see cref="ChatCompletionsToolCall"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="ChatCompletionsFunctionToolCall"/>.
        /// </param>
        /// <param name="functionCall">
        /// The function call that must be resolved and have its output appended to subsequent input messages for the chat
        /// completions request to resolve as configured.
        /// </param>
        /// <param name="azureExtensionsContext">
        /// If Azure OpenAI chat extensions are configured, this array represents the incremental steps performed by those
        /// extensions while processing the chat completions request.
        /// </param>
        /// <returns> A new <see cref="OpenAI.ChatResponseMessage"/> instance for mocking. </returns>
        public static ChatResponseMessage ChatResponseMessage(ChatRole role = default, string content = null, IEnumerable<ChatCompletionsToolCall> toolCalls = null, FunctionCall functionCall = null, AzureChatExtensionsMessageContext azureExtensionsContext = null)
        {
            toolCalls ??= new List<ChatCompletionsToolCall>();

            return new ChatResponseMessage(
                role,
                content,
                toolCalls?.ToList(),
                functionCall,
                azureExtensionsContext,
                serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.AzureChatExtensionsMessageContext"/>. </summary>
        /// <param name="citations">
        ///   The contextual information associated with the Azure chat extensions used for a chat completions request.
        ///   These messages describe the data source retrievals, plugin invocations, and other intermediate steps taken in the
        ///   course of generating a chat completions response that was augmented by capabilities from Azure OpenAI chat
        ///   extensions.
        /// </param>
        /// <param name="intent"> The detected intent from the chat history, used to pass to the next turn to carry over the context. </param>
        /// <returns> A new <see cref="OpenAI.AzureChatExtensionsMessageContext"/> instance for mocking. </returns>
        public static AzureChatExtensionsMessageContext AzureChatExtensionsMessageContext(IEnumerable<AzureChatExtensionDataSourceResponseCitation> citations = null, string intent = null)
        {
            citations ??= new List<AzureChatExtensionDataSourceResponseCitation>();

            return new AzureChatExtensionsMessageContext(citations?.ToList(), intent, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.AzureChatExtensionDataSourceResponseCitation"/>. </summary>
        /// <param name="content"> The content of the citation. </param>
        /// <param name="title"> The title of the citation. </param>
        /// <param name="url"> The URL of the citation. </param>
        /// <param name="filepath"> The file path of the citation. </param>
        /// <param name="chunkId"> The chunk ID of the citation. </param>
        /// <returns> A new <see cref="OpenAI.AzureChatExtensionDataSourceResponseCitation"/> instance for mocking. </returns>
        public static AzureChatExtensionDataSourceResponseCitation AzureChatExtensionDataSourceResponseCitation(string content = null, string title = null, string url = null, string filepath = null, string chunkId = null)
        {
            return new AzureChatExtensionDataSourceResponseCitation(
                content,
                title,
                url,
                filepath,
                chunkId,
                serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.ChatChoiceLogProbabilityInfo"/>. </summary>
        /// <param name="tokenLogProbabilityResults"> The list of log probability information entries for the choice's message content tokens, as requested via the 'logprobs' option. </param>
        /// <returns> A new <see cref="OpenAI.ChatChoiceLogProbabilityInfo"/> instance for mocking. </returns>
        public static ChatChoiceLogProbabilityInfo ChatChoiceLogProbabilityInfo(IEnumerable<ChatTokenLogProbabilityResult> tokenLogProbabilityResults = null)
        {
            tokenLogProbabilityResults ??= new List<ChatTokenLogProbabilityResult>();

            return new ChatChoiceLogProbabilityInfo(tokenLogProbabilityResults?.ToList(), serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.ChatTokenLogProbabilityResult"/>. </summary>
        /// <param name="token"> The message content token. </param>
        /// <param name="logProbability"> The log probability of the message content token. </param>
        /// <param name="utf8ByteValues"> A list of integers representing the UTF-8 bytes representation of the token. Useful in instances where characters are represented by multiple tokens and their byte representations must be combined to generate the correct text representation. Can be null if there is no bytes representation for the token. </param>
        /// <param name="topLogProbabilityEntries"> The list of most likely tokens and their log probability information, as requested via 'top_logprobs'. </param>
        /// <returns> A new <see cref="OpenAI.ChatTokenLogProbabilityResult"/> instance for mocking. </returns>
        public static ChatTokenLogProbabilityResult ChatTokenLogProbabilityResult(string token = null, float logProbability = default, IEnumerable<int> utf8ByteValues = null, IEnumerable<ChatTokenLogProbabilityInfo> topLogProbabilityEntries = null)
        {
            utf8ByteValues ??= new List<int>();
            topLogProbabilityEntries ??= new List<ChatTokenLogProbabilityInfo>();

            return new ChatTokenLogProbabilityResult(token, logProbability, utf8ByteValues?.ToList(), topLogProbabilityEntries?.ToList(), serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.ChatTokenLogProbabilityInfo"/>. </summary>
        /// <param name="token"> The message content token. </param>
        /// <param name="logProbability"> The log probability of the message content token. </param>
        /// <param name="utf8ByteValues"> A list of integers representing the UTF-8 bytes representation of the token. Useful in instances where characters are represented by multiple tokens and their byte representations must be combined to generate the correct text representation. Can be null if there is no bytes representation for the token. </param>
        /// <returns> A new <see cref="OpenAI.ChatTokenLogProbabilityInfo"/> instance for mocking. </returns>
        public static ChatTokenLogProbabilityInfo ChatTokenLogProbabilityInfo(string token = null, float logProbability = default, IEnumerable<int> utf8ByteValues = null)
        {
            utf8ByteValues ??= new List<int>();

            return new ChatTokenLogProbabilityInfo(token, logProbability, utf8ByteValues?.ToList(), serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.AzureChatEnhancements"/>. </summary>
        /// <param name="grounding"> The grounding enhancement that returns the bounding box of the objects detected in the image. </param>
        /// <returns> A new <see cref="OpenAI.AzureChatEnhancements"/> instance for mocking. </returns>
        public static AzureChatEnhancements AzureChatEnhancements(AzureGroundingEnhancement grounding = null)
        {
            return new AzureChatEnhancements(grounding, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.AzureGroundingEnhancement"/>. </summary>
        /// <param name="lines"> The lines of text detected by the grounding enhancement. </param>
        /// <returns> A new <see cref="OpenAI.AzureGroundingEnhancement"/> instance for mocking. </returns>
        public static AzureGroundingEnhancement AzureGroundingEnhancement(IEnumerable<AzureGroundingEnhancementLine> lines = null)
        {
            lines ??= new List<AzureGroundingEnhancementLine>();

            return new AzureGroundingEnhancement(lines?.ToList(), serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.AzureGroundingEnhancementLine"/>. </summary>
        /// <param name="text"> The text within the line. </param>
        /// <param name="spans"> An array of spans that represent detected objects and its bounding box information. </param>
        /// <returns> A new <see cref="OpenAI.AzureGroundingEnhancementLine"/> instance for mocking. </returns>
        public static AzureGroundingEnhancementLine AzureGroundingEnhancementLine(string text = null, IEnumerable<AzureGroundingEnhancementLineSpan> spans = null)
        {
            spans ??= new List<AzureGroundingEnhancementLineSpan>();

            return new AzureGroundingEnhancementLine(text, spans?.ToList(), serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.AzureGroundingEnhancementLineSpan"/>. </summary>
        /// <param name="text"> The text content of the span that represents the detected object. </param>
        /// <param name="offset">
        /// The character offset within the text where the span begins. This offset is defined as the position of the first
        /// character of the span, counting from the start of the text as Unicode codepoints.
        /// </param>
        /// <param name="length"> The length of the span in characters, measured in Unicode codepoints. </param>
        /// <param name="polygon"> An array of objects representing points in the polygon that encloses the detected object. </param>
        /// <returns> A new <see cref="OpenAI.AzureGroundingEnhancementLineSpan"/> instance for mocking. </returns>
        public static AzureGroundingEnhancementLineSpan AzureGroundingEnhancementLineSpan(string text = null, int offset = default, int length = default, IEnumerable<AzureGroundingEnhancementCoordinatePoint> polygon = null)
        {
            polygon ??= new List<AzureGroundingEnhancementCoordinatePoint>();

            return new AzureGroundingEnhancementLineSpan(text, offset, length, polygon?.ToList(), serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.AzureGroundingEnhancementCoordinatePoint"/>. </summary>
        /// <param name="x"> The x-coordinate (horizontal axis) of the point. </param>
        /// <param name="y"> The y-coordinate (vertical axis) of the point. </param>
        /// <returns> A new <see cref="OpenAI.AzureGroundingEnhancementCoordinatePoint"/> instance for mocking. </returns>
        public static AzureGroundingEnhancementCoordinatePoint AzureGroundingEnhancementCoordinatePoint(float x = default, float y = default)
        {
            return new AzureGroundingEnhancementCoordinatePoint(x, y, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.ImageGenerations"/>. </summary>
        /// <param name="created">
        /// A timestamp representing when this operation was started.
        /// Expressed in seconds since the Unix epoch of 1970-01-01T00:00:00+0000.
        /// </param>
        /// <param name="data"> The images generated by the operation. </param>
        /// <returns> A new <see cref="OpenAI.ImageGenerations"/> instance for mocking. </returns>
        public static ImageGenerations ImageGenerations(DateTimeOffset created = default, IEnumerable<ImageGenerationData> data = null)
        {
            data ??= new List<ImageGenerationData>();

            return new ImageGenerations(created, data?.ToList(), serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.ImageGenerationData"/>. </summary>
        /// <param name="url"> The URL that provides temporary access to download the generated image. </param>
        /// <param name="base64Data"> The complete data for an image, represented as a base64-encoded string. </param>
        /// <param name="contentFilterResults"> Information about the content filtering results. </param>
        /// <param name="revisedPrompt">
        /// The final prompt used by the model to generate the image.
        /// Only provided with dall-3-models and only when revisions were made to the prompt.
        /// </param>
        /// <param name="promptFilterResults">
        /// Information about the content filtering category (hate, sexual, violence, self_harm), if
        /// it has been detected, as well as the severity level (very_low, low, medium, high-scale
        /// that determines the intensity and risk level of harmful content) and if it has been
        /// filtered or not. Information about jailbreak content and profanity, if it has been detected,
        /// and if it has been filtered or not. And information about customer block list, if it has
        /// been filtered and its id.
        /// </param>
        /// <returns> A new <see cref="OpenAI.ImageGenerationData"/> instance for mocking. </returns>
        public static ImageGenerationData ImageGenerationData(Uri url = null, string base64Data = null, ImageGenerationContentFilterResults contentFilterResults = null, string revisedPrompt = null, ImageGenerationPromptFilterResults promptFilterResults = null)
        {
            return new ImageGenerationData(
                url,
                base64Data,
                contentFilterResults,
                revisedPrompt,
                promptFilterResults,
                serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.ImageGenerationContentFilterResults"/>. </summary>
        /// <param name="sexual">
        /// Describes language related to anatomical organs and genitals, romantic relationships,
        ///  acts portrayed in erotic or affectionate terms, physical sexual acts, including
        ///  those portrayed as an assault or a forced sexual violent act against one’s will,
        ///  prostitution, pornography, and abuse.
        /// </param>
        /// <param name="violence">
        /// Describes language related to physical actions intended to hurt, injure, damage, or
        /// kill someone or something; describes weapons, etc.
        /// </param>
        /// <param name="hate">
        /// Describes language attacks or uses that include pejorative or discriminatory language
        /// with reference to a person or identity group on the basis of certain differentiating
        /// attributes of these groups including but not limited to race, ethnicity, nationality,
        /// gender identity and expression, sexual orientation, religion, immigration status, ability
        /// status, personal appearance, and body size.
        /// </param>
        /// <param name="selfHarm">
        /// Describes language related to physical actions intended to purposely hurt, injure,
        /// or damage one’s body, or kill oneself.
        /// </param>
        /// <returns> A new <see cref="OpenAI.ImageGenerationContentFilterResults"/> instance for mocking. </returns>
        public static ImageGenerationContentFilterResults ImageGenerationContentFilterResults(ContentFilterResult sexual = null, ContentFilterResult violence = null, ContentFilterResult hate = null, ContentFilterResult selfHarm = null)
        {
            return new ImageGenerationContentFilterResults(sexual, violence, hate, selfHarm, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.ImageGenerationPromptFilterResults"/>. </summary>
        /// <param name="sexual">
        /// Describes language related to anatomical organs and genitals, romantic relationships,
        ///  acts portrayed in erotic or affectionate terms, physical sexual acts, including
        ///  those portrayed as an assault or a forced sexual violent act against one’s will,
        ///  prostitution, pornography, and abuse.
        /// </param>
        /// <param name="violence">
        /// Describes language related to physical actions intended to hurt, injure, damage, or
        /// kill someone or something; describes weapons, etc.
        /// </param>
        /// <param name="hate">
        /// Describes language attacks or uses that include pejorative or discriminatory language
        /// with reference to a person or identity group on the basis of certain differentiating
        /// attributes of these groups including but not limited to race, ethnicity, nationality,
        /// gender identity and expression, sexual orientation, religion, immigration status, ability
        /// status, personal appearance, and body size.
        /// </param>
        /// <param name="selfHarm">
        /// Describes language related to physical actions intended to purposely hurt, injure,
        /// or damage one’s body, or kill oneself.
        /// </param>
        /// <param name="profanity"> Describes whether profanity was detected. </param>
        /// <param name="jailbreak"> Whether a jailbreak attempt was detected in the prompt. </param>
        /// <returns> A new <see cref="OpenAI.ImageGenerationPromptFilterResults"/> instance for mocking. </returns>
        public static ImageGenerationPromptFilterResults ImageGenerationPromptFilterResults(ContentFilterResult sexual = null, ContentFilterResult violence = null, ContentFilterResult hate = null, ContentFilterResult selfHarm = null, ContentFilterDetectionResult profanity = null, ContentFilterDetectionResult jailbreak = null)
        {
            return new ImageGenerationPromptFilterResults(
                sexual,
                violence,
                hate,
                selfHarm,
                profanity,
                jailbreak,
                serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.SpeechGenerationOptions"/>. </summary>
        /// <param name="input"> The text to generate audio for. The maximum length is 4096 characters. </param>
        /// <param name="voice"> The voice to use for text-to-speech. </param>
        /// <param name="responseFormat"> The audio output format for the spoken text. By default, the MP3 format will be used. </param>
        /// <param name="speed"> The speed of speech for generated audio. Values are valid in the range from 0.25 to 4.0, with 1.0 the default and higher values corresponding to faster speech. </param>
        /// <param name="deploymentName"> The model to use for this text-to-speech request. </param>
        /// <returns> A new <see cref="OpenAI.SpeechGenerationOptions"/> instance for mocking. </returns>
        public static SpeechGenerationOptions SpeechGenerationOptions(string input = null, SpeechVoice voice = default, SpeechGenerationResponseFormat? responseFormat = null, float? speed = null, string deploymentName = null)
        {
            return new SpeechGenerationOptions(
                input,
                voice,
                responseFormat,
                speed,
                deploymentName,
                serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.Embeddings"/>. </summary>
        /// <param name="data"> Embedding values for the prompts submitted in the request. </param>
        /// <param name="usage"> Usage counts for tokens input using the embeddings API. </param>
        /// <returns> A new <see cref="OpenAI.Embeddings"/> instance for mocking. </returns>
        public static Embeddings Embeddings(IEnumerable<EmbeddingItem> data = null, EmbeddingsUsage usage = null)
        {
            data ??= new List<EmbeddingItem>();

            return new Embeddings(data?.ToList(), usage, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.EmbeddingItem"/>. </summary>
        /// <param name="embedding">
        /// List of embeddings value for the input prompt. These represent a measurement of the
        /// vector-based relatedness of the provided input.
        /// </param>
        /// <param name="index"> Index of the prompt to which the EmbeddingItem corresponds. </param>
        /// <returns> A new <see cref="OpenAI.EmbeddingItem"/> instance for mocking. </returns>
        public static EmbeddingItem EmbeddingItem(IEnumerable<float> embedding = null, int index = default)
        {
            embedding ??= new List<float>();

            return new EmbeddingItem(embedding?.ToList(), index, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.EmbeddingsUsage"/>. </summary>
        /// <param name="promptTokens"> Number of tokens sent in the original request. </param>
        /// <param name="totalTokens"> Total number of tokens transacted in this request/response. </param>
        /// <returns> A new <see cref="OpenAI.EmbeddingsUsage"/> instance for mocking. </returns>
        public static EmbeddingsUsage EmbeddingsUsage(int promptTokens = default, int totalTokens = default)
        {
            return new EmbeddingsUsage(promptTokens, totalTokens, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.StopFinishDetails"/>. </summary>
        /// <param name="stop"> The token sequence that the model terminated with. </param>
        /// <returns> A new <see cref="OpenAI.StopFinishDetails"/> instance for mocking. </returns>
        public static StopFinishDetails StopFinishDetails(string stop = null)
        {
            return new StopFinishDetails("stop", serializedAdditionalRawData: null, stop);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.ChatRequestSystemMessage"/>. </summary>
        /// <param name="content"> The contents of the system message. </param>
        /// <param name="name"> An optional name for the participant. </param>
        /// <returns> A new <see cref="OpenAI.ChatRequestSystemMessage"/> instance for mocking. </returns>
        public static ChatRequestSystemMessage ChatRequestSystemMessage(string content = null, string name = null)
        {
            return new ChatRequestSystemMessage(ChatRole.System, serializedAdditionalRawData: null, content, name);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.ChatRequestUserMessage"/>. </summary>
        /// <param name="content"> The contents of the user message, with available input types varying by selected model. </param>
        /// <param name="name"> An optional name for the participant. </param>
        /// <returns> A new <see cref="OpenAI.ChatRequestUserMessage"/> instance for mocking. </returns>
        public static ChatRequestUserMessage ChatRequestUserMessage(BinaryData content = null, string name = null)
        {
            return new ChatRequestUserMessage(ChatRole.User, serializedAdditionalRawData: null, content, name);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.ChatRequestAssistantMessage"/>. </summary>
        /// <param name="content"> The content of the message. </param>
        /// <param name="name"> An optional name for the participant. </param>
        /// <param name="toolCalls">
        /// The tool calls that must be resolved and have their outputs appended to subsequent input messages for the chat
        /// completions request to resolve as configured.
        /// Please note <see cref="ChatCompletionsToolCall"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="ChatCompletionsFunctionToolCall"/>.
        /// </param>
        /// <param name="functionCall">
        /// The function call that must be resolved and have its output appended to subsequent input messages for the chat
        /// completions request to resolve as configured.
        /// </param>
        /// <returns> A new <see cref="OpenAI.ChatRequestAssistantMessage"/> instance for mocking. </returns>
        public static ChatRequestAssistantMessage ChatRequestAssistantMessage(string content = null, string name = null, IEnumerable<ChatCompletionsToolCall> toolCalls = null, FunctionCall functionCall = null)
        {
            toolCalls ??= new List<ChatCompletionsToolCall>();

            return new ChatRequestAssistantMessage(
                ChatRole.Assistant,
                serializedAdditionalRawData: null,
                content,
                name,
                toolCalls?.ToList(),
                functionCall);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.ChatRequestToolMessage"/>. </summary>
        /// <param name="content"> The content of the message. </param>
        /// <param name="toolCallId"> The ID of the tool call resolved by the provided content. </param>
        /// <returns> A new <see cref="OpenAI.ChatRequestToolMessage"/> instance for mocking. </returns>
        public static ChatRequestToolMessage ChatRequestToolMessage(string content = null, string toolCallId = null)
        {
            return new ChatRequestToolMessage(ChatRole.Tool, serializedAdditionalRawData: null, content, toolCallId);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.ChatRequestFunctionMessage"/>. </summary>
        /// <param name="name"> The name of the function that was called to produce output. </param>
        /// <param name="content"> The output of the function as requested by the function call. </param>
        /// <returns> A new <see cref="OpenAI.ChatRequestFunctionMessage"/> instance for mocking. </returns>
        public static ChatRequestFunctionMessage ChatRequestFunctionMessage(string name = null, string content = null)
        {
            return new ChatRequestFunctionMessage(ChatRole.Function, serializedAdditionalRawData: null, name, content);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.ChatCompletionsFunctionToolDefinition"/>. </summary>
        /// <param name="function"> The function definition details for the function tool. </param>
        /// <returns> A new <see cref="OpenAI.ChatCompletionsFunctionToolDefinition"/> instance for mocking. </returns>
        public static ChatCompletionsFunctionToolDefinition ChatCompletionsFunctionToolDefinition(FunctionDefinition function = null)
        {
            return new ChatCompletionsFunctionToolDefinition("function", serializedAdditionalRawData: null, function);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.AzureSearchChatExtensionConfiguration"/>. </summary>
        /// <param name="parameters"> The parameters to use when configuring Azure Search. </param>
        /// <returns> A new <see cref="OpenAI.AzureSearchChatExtensionConfiguration"/> instance for mocking. </returns>
        public static AzureSearchChatExtensionConfiguration AzureSearchChatExtensionConfiguration(AzureSearchChatExtensionParameters parameters = null)
        {
            return new AzureSearchChatExtensionConfiguration(AzureChatExtensionType.AzureSearch, serializedAdditionalRawData: null, parameters);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.AzureSearchChatExtensionParameters"/>. </summary>
        /// <param name="authentication">
        /// The authentication method to use when accessing the defined data source.
        /// Each data source type supports a specific set of available authentication methods; please see the documentation of
        /// the data source for supported mechanisms.
        /// If not otherwise provided, On Your Data will attempt to use System Managed Identity (default credential)
        /// authentication.
        /// Please note <see cref="OnYourDataAuthenticationOptions"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="OpenAI.OnYourDataAccessTokenAuthenticationOptions"/>, <see cref="OpenAI.OnYourDataApiKeyAuthenticationOptions"/>, <see cref="OpenAI.OnYourDataConnectionStringAuthenticationOptions"/>, <see cref="OpenAI.OnYourDataEncodedApiKeyAuthenticationOptions"/>, <see cref="OpenAI.OnYourDataKeyAndKeyIdAuthenticationOptions"/>, <see cref="OnYourDataSystemAssignedManagedIdentityAuthenticationOptions"/> and <see cref="OpenAI.OnYourDataUserAssignedManagedIdentityAuthenticationOptions"/>.
        /// </param>
        /// <param name="documentCount"> The configured top number of documents to feature for the configured query. </param>
        /// <param name="shouldRestrictResultScope"> Whether queries should be restricted to use of indexed data. </param>
        /// <param name="strictness"> The configured strictness of the search relevance filtering. The higher of strictness, the higher of the precision but lower recall of the answer. </param>
        /// <param name="roleInformation"> Give the model instructions about how it should behave and any context it should reference when generating a response. You can describe the assistant's personality and tell it how to format responses. There's a 100 token limit for it, and it counts against the overall token limit. </param>
        /// <param name="searchEndpoint"> The absolute endpoint path for the Azure Cognitive Search resource to use. </param>
        /// <param name="indexName"> The name of the index to use as available in the referenced Azure Cognitive Search resource. </param>
        /// <param name="fieldMappingOptions"> Customized field mapping behavior to use when interacting with the search index. </param>
        /// <param name="queryType"> The query type to use with Azure Cognitive Search. </param>
        /// <param name="semanticConfiguration"> The additional semantic configuration for the query. </param>
        /// <param name="filter"> Search filter. </param>
        /// <param name="embeddingDependency">
        /// The embedding dependency for vector search.
        /// Please note <see cref="OnYourDataVectorizationSource"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="OpenAI.OnYourDataDeploymentNameVectorizationSource"/>, <see cref="OpenAI.OnYourDataEndpointVectorizationSource"/> and <see cref="OpenAI.OnYourDataModelIdVectorizationSource"/>.
        /// </param>
        /// <returns> A new <see cref="OpenAI.AzureSearchChatExtensionParameters"/> instance for mocking. </returns>
        public static AzureSearchChatExtensionParameters AzureSearchChatExtensionParameters(OnYourDataAuthenticationOptions authentication = null, int? documentCount = null, bool? shouldRestrictResultScope = null, int? strictness = null, string roleInformation = null, Uri searchEndpoint = null, string indexName = null, AzureSearchIndexFieldMappingOptions fieldMappingOptions = null, AzureSearchQueryType? queryType = null, string semanticConfiguration = null, string filter = null, OnYourDataVectorizationSource embeddingDependency = null)
        {
            return new AzureSearchChatExtensionParameters(
                authentication,
                documentCount,
                shouldRestrictResultScope,
                strictness,
                roleInformation,
                searchEndpoint,
                indexName,
                fieldMappingOptions,
                queryType,
                semanticConfiguration,
                filter,
                embeddingDependency,
                serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.OnYourDataApiKeyAuthenticationOptions"/>. </summary>
        /// <param name="key"> The API key to use for authentication. </param>
        /// <returns> A new <see cref="OpenAI.OnYourDataApiKeyAuthenticationOptions"/> instance for mocking. </returns>
        public static OnYourDataApiKeyAuthenticationOptions OnYourDataApiKeyAuthenticationOptions(string key = null)
        {
            return new OnYourDataApiKeyAuthenticationOptions(OnYourDataAuthenticationType.ApiKey, serializedAdditionalRawData: null, key);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.OnYourDataConnectionStringAuthenticationOptions"/>. </summary>
        /// <param name="connectionString"> The connection string to use for authentication. </param>
        /// <returns> A new <see cref="OpenAI.OnYourDataConnectionStringAuthenticationOptions"/> instance for mocking. </returns>
        public static OnYourDataConnectionStringAuthenticationOptions OnYourDataConnectionStringAuthenticationOptions(string connectionString = null)
        {
            return new OnYourDataConnectionStringAuthenticationOptions(OnYourDataAuthenticationType.ConnectionString, serializedAdditionalRawData: null, connectionString);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.OnYourDataKeyAndKeyIdAuthenticationOptions"/>. </summary>
        /// <param name="key"> The key to use for authentication. </param>
        /// <param name="keyId"> The key ID to use for authentication. </param>
        /// <returns> A new <see cref="OpenAI.OnYourDataKeyAndKeyIdAuthenticationOptions"/> instance for mocking. </returns>
        public static OnYourDataKeyAndKeyIdAuthenticationOptions OnYourDataKeyAndKeyIdAuthenticationOptions(string key = null, string keyId = null)
        {
            return new OnYourDataKeyAndKeyIdAuthenticationOptions(OnYourDataAuthenticationType.KeyAndKeyId, serializedAdditionalRawData: null, key, keyId);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.OnYourDataEncodedApiKeyAuthenticationOptions"/>. </summary>
        /// <param name="encodedApiKey"> The encoded API key to use for authentication. </param>
        /// <returns> A new <see cref="OpenAI.OnYourDataEncodedApiKeyAuthenticationOptions"/> instance for mocking. </returns>
        public static OnYourDataEncodedApiKeyAuthenticationOptions OnYourDataEncodedApiKeyAuthenticationOptions(string encodedApiKey = null)
        {
            return new OnYourDataEncodedApiKeyAuthenticationOptions(OnYourDataAuthenticationType.EncodedApiKey, serializedAdditionalRawData: null, encodedApiKey);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.OnYourDataAccessTokenAuthenticationOptions"/>. </summary>
        /// <param name="accessToken"> The access token to use for authentication. </param>
        /// <returns> A new <see cref="OpenAI.OnYourDataAccessTokenAuthenticationOptions"/> instance for mocking. </returns>
        public static OnYourDataAccessTokenAuthenticationOptions OnYourDataAccessTokenAuthenticationOptions(string accessToken = null)
        {
            return new OnYourDataAccessTokenAuthenticationOptions(OnYourDataAuthenticationType.AccessToken, serializedAdditionalRawData: null, accessToken);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.OnYourDataUserAssignedManagedIdentityAuthenticationOptions"/>. </summary>
        /// <param name="managedIdentityResourceId"> The resource ID of the user-assigned managed identity to use for authentication. </param>
        /// <returns> A new <see cref="OpenAI.OnYourDataUserAssignedManagedIdentityAuthenticationOptions"/> instance for mocking. </returns>
        public static OnYourDataUserAssignedManagedIdentityAuthenticationOptions OnYourDataUserAssignedManagedIdentityAuthenticationOptions(string managedIdentityResourceId = null)
        {
            return new OnYourDataUserAssignedManagedIdentityAuthenticationOptions(OnYourDataAuthenticationType.UserAssignedManagedIdentity, serializedAdditionalRawData: null, managedIdentityResourceId);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.OnYourDataEndpointVectorizationSource"/>. </summary>
        /// <param name="endpoint"> Specifies the resource endpoint URL from which embeddings should be retrieved. It should be in the format of https://YOUR_RESOURCE_NAME.openai.azure.com/openai/deployments/YOUR_DEPLOYMENT_NAME/embeddings. The api-version query parameter is not allowed. </param>
        /// <param name="authentication">
        /// Specifies the authentication options to use when retrieving embeddings from the specified endpoint.
        /// Please note <see cref="OnYourDataAuthenticationOptions"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="OpenAI.OnYourDataAccessTokenAuthenticationOptions"/>, <see cref="OpenAI.OnYourDataApiKeyAuthenticationOptions"/>, <see cref="OpenAI.OnYourDataConnectionStringAuthenticationOptions"/>, <see cref="OpenAI.OnYourDataEncodedApiKeyAuthenticationOptions"/>, <see cref="OpenAI.OnYourDataKeyAndKeyIdAuthenticationOptions"/>, <see cref="OnYourDataSystemAssignedManagedIdentityAuthenticationOptions"/> and <see cref="OpenAI.OnYourDataUserAssignedManagedIdentityAuthenticationOptions"/>.
        /// </param>
        /// <returns> A new <see cref="OpenAI.OnYourDataEndpointVectorizationSource"/> instance for mocking. </returns>
        public static OnYourDataEndpointVectorizationSource OnYourDataEndpointVectorizationSource(Uri endpoint = null, OnYourDataAuthenticationOptions authentication = null)
        {
            return new OnYourDataEndpointVectorizationSource(OnYourDataVectorizationSourceType.Endpoint, serializedAdditionalRawData: null, endpoint, authentication);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.OnYourDataDeploymentNameVectorizationSource"/>. </summary>
        /// <param name="deploymentName"> The embedding model deployment name within the same Azure OpenAI resource. This enables you to use vector search without Azure OpenAI api-key and without Azure OpenAI public network access. </param>
        /// <returns> A new <see cref="OpenAI.OnYourDataDeploymentNameVectorizationSource"/> instance for mocking. </returns>
        public static OnYourDataDeploymentNameVectorizationSource OnYourDataDeploymentNameVectorizationSource(string deploymentName = null)
        {
            return new OnYourDataDeploymentNameVectorizationSource(OnYourDataVectorizationSourceType.DeploymentName, serializedAdditionalRawData: null, deploymentName);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.OnYourDataModelIdVectorizationSource"/>. </summary>
        /// <param name="modelId"> The embedding model ID build inside the search service. Currently only supported by Elasticsearch®. </param>
        /// <returns> A new <see cref="OpenAI.OnYourDataModelIdVectorizationSource"/> instance for mocking. </returns>
        public static OnYourDataModelIdVectorizationSource OnYourDataModelIdVectorizationSource(string modelId = null)
        {
            return new OnYourDataModelIdVectorizationSource(OnYourDataVectorizationSourceType.ModelId, serializedAdditionalRawData: null, modelId);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.AzureMachineLearningIndexChatExtensionConfiguration"/>. </summary>
        /// <param name="parameters"> The parameters for the Azure Machine Learning vector index chat extension. </param>
        /// <returns> A new <see cref="OpenAI.AzureMachineLearningIndexChatExtensionConfiguration"/> instance for mocking. </returns>
        public static AzureMachineLearningIndexChatExtensionConfiguration AzureMachineLearningIndexChatExtensionConfiguration(AzureMachineLearningIndexChatExtensionParameters parameters = null)
        {
            return new AzureMachineLearningIndexChatExtensionConfiguration(AzureChatExtensionType.AzureMachineLearningIndex, serializedAdditionalRawData: null, parameters);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.AzureMachineLearningIndexChatExtensionParameters"/>. </summary>
        /// <param name="authentication">
        /// The authentication method to use when accessing the defined data source.
        /// Each data source type supports a specific set of available authentication methods; please see the documentation of
        /// the data source for supported mechanisms.
        /// If not otherwise provided, On Your Data will attempt to use System Managed Identity (default credential)
        /// authentication.
        /// Please note <see cref="OnYourDataAuthenticationOptions"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="OpenAI.OnYourDataAccessTokenAuthenticationOptions"/>, <see cref="OpenAI.OnYourDataApiKeyAuthenticationOptions"/>, <see cref="OpenAI.OnYourDataConnectionStringAuthenticationOptions"/>, <see cref="OpenAI.OnYourDataEncodedApiKeyAuthenticationOptions"/>, <see cref="OpenAI.OnYourDataKeyAndKeyIdAuthenticationOptions"/>, <see cref="OnYourDataSystemAssignedManagedIdentityAuthenticationOptions"/> and <see cref="OpenAI.OnYourDataUserAssignedManagedIdentityAuthenticationOptions"/>.
        /// </param>
        /// <param name="documentCount"> The configured top number of documents to feature for the configured query. </param>
        /// <param name="shouldRestrictResultScope"> Whether queries should be restricted to use of indexed data. </param>
        /// <param name="strictness"> The configured strictness of the search relevance filtering. The higher of strictness, the higher of the precision but lower recall of the answer. </param>
        /// <param name="roleInformation"> Give the model instructions about how it should behave and any context it should reference when generating a response. You can describe the assistant's personality and tell it how to format responses. There's a 100 token limit for it, and it counts against the overall token limit. </param>
        /// <param name="projectResourceId"> The resource ID of the Azure Machine Learning project. </param>
        /// <param name="name"> The Azure Machine Learning vector index name. </param>
        /// <param name="version"> The version of the Azure Machine Learning vector index. </param>
        /// <param name="filter"> Search filter. Only supported if the Azure Machine Learning vector index is of type AzureSearch. </param>
        /// <returns> A new <see cref="OpenAI.AzureMachineLearningIndexChatExtensionParameters"/> instance for mocking. </returns>
        public static AzureMachineLearningIndexChatExtensionParameters AzureMachineLearningIndexChatExtensionParameters(OnYourDataAuthenticationOptions authentication = null, int? documentCount = null, bool? shouldRestrictResultScope = null, int? strictness = null, string roleInformation = null, string projectResourceId = null, string name = null, string version = null, string filter = null)
        {
            return new AzureMachineLearningIndexChatExtensionParameters(
                authentication,
                documentCount,
                shouldRestrictResultScope,
                strictness,
                roleInformation,
                projectResourceId,
                name,
                version,
                filter,
                serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.AzureCosmosDBChatExtensionConfiguration"/>. </summary>
        /// <param name="parameters"> The parameters to use when configuring Azure OpenAI CosmosDB chat extensions. </param>
        /// <returns> A new <see cref="OpenAI.AzureCosmosDBChatExtensionConfiguration"/> instance for mocking. </returns>
        public static AzureCosmosDBChatExtensionConfiguration AzureCosmosDBChatExtensionConfiguration(AzureCosmosDBChatExtensionParameters parameters = null)
        {
            return new AzureCosmosDBChatExtensionConfiguration(AzureChatExtensionType.AzureCosmosDB, serializedAdditionalRawData: null, parameters);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.AzureCosmosDBChatExtensionParameters"/>. </summary>
        /// <param name="authentication">
        /// The authentication method to use when accessing the defined data source.
        /// Each data source type supports a specific set of available authentication methods; please see the documentation of
        /// the data source for supported mechanisms.
        /// If not otherwise provided, On Your Data will attempt to use System Managed Identity (default credential)
        /// authentication.
        /// Please note <see cref="OnYourDataAuthenticationOptions"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="OpenAI.OnYourDataAccessTokenAuthenticationOptions"/>, <see cref="OpenAI.OnYourDataApiKeyAuthenticationOptions"/>, <see cref="OpenAI.OnYourDataConnectionStringAuthenticationOptions"/>, <see cref="OpenAI.OnYourDataEncodedApiKeyAuthenticationOptions"/>, <see cref="OpenAI.OnYourDataKeyAndKeyIdAuthenticationOptions"/>, <see cref="OnYourDataSystemAssignedManagedIdentityAuthenticationOptions"/> and <see cref="OpenAI.OnYourDataUserAssignedManagedIdentityAuthenticationOptions"/>.
        /// </param>
        /// <param name="documentCount"> The configured top number of documents to feature for the configured query. </param>
        /// <param name="shouldRestrictResultScope"> Whether queries should be restricted to use of indexed data. </param>
        /// <param name="strictness"> The configured strictness of the search relevance filtering. The higher of strictness, the higher of the precision but lower recall of the answer. </param>
        /// <param name="roleInformation"> Give the model instructions about how it should behave and any context it should reference when generating a response. You can describe the assistant's personality and tell it how to format responses. There's a 100 token limit for it, and it counts against the overall token limit. </param>
        /// <param name="databaseName"> The MongoDB vCore database name to use with Azure Cosmos DB. </param>
        /// <param name="containerName"> The name of the Azure Cosmos DB resource container. </param>
        /// <param name="indexName"> The MongoDB vCore index name to use with Azure Cosmos DB. </param>
        /// <param name="fieldMappingOptions"> Customized field mapping behavior to use when interacting with the search index. </param>
        /// <param name="embeddingDependency">
        /// The embedding dependency for vector search.
        /// Please note <see cref="OnYourDataVectorizationSource"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="OpenAI.OnYourDataDeploymentNameVectorizationSource"/>, <see cref="OpenAI.OnYourDataEndpointVectorizationSource"/> and <see cref="OpenAI.OnYourDataModelIdVectorizationSource"/>.
        /// </param>
        /// <returns> A new <see cref="OpenAI.AzureCosmosDBChatExtensionParameters"/> instance for mocking. </returns>
        public static AzureCosmosDBChatExtensionParameters AzureCosmosDBChatExtensionParameters(OnYourDataAuthenticationOptions authentication = null, int? documentCount = null, bool? shouldRestrictResultScope = null, int? strictness = null, string roleInformation = null, string databaseName = null, string containerName = null, string indexName = null, AzureCosmosDBFieldMappingOptions fieldMappingOptions = null, OnYourDataVectorizationSource embeddingDependency = null)
        {
            return new AzureCosmosDBChatExtensionParameters(
                authentication,
                documentCount,
                shouldRestrictResultScope,
                strictness,
                roleInformation,
                databaseName,
                containerName,
                indexName,
                fieldMappingOptions,
                embeddingDependency,
                serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.ElasticsearchChatExtensionConfiguration"/>. </summary>
        /// <param name="parameters"> The parameters to use when configuring Elasticsearch®. </param>
        /// <returns> A new <see cref="OpenAI.ElasticsearchChatExtensionConfiguration"/> instance for mocking. </returns>
        public static ElasticsearchChatExtensionConfiguration ElasticsearchChatExtensionConfiguration(ElasticsearchChatExtensionParameters parameters = null)
        {
            return new ElasticsearchChatExtensionConfiguration(AzureChatExtensionType.Elasticsearch, serializedAdditionalRawData: null, parameters);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.ElasticsearchChatExtensionParameters"/>. </summary>
        /// <param name="authentication">
        /// The authentication method to use when accessing the defined data source.
        /// Each data source type supports a specific set of available authentication methods; please see the documentation of
        /// the data source for supported mechanisms.
        /// If not otherwise provided, On Your Data will attempt to use System Managed Identity (default credential)
        /// authentication.
        /// Please note <see cref="OnYourDataAuthenticationOptions"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="OpenAI.OnYourDataAccessTokenAuthenticationOptions"/>, <see cref="OpenAI.OnYourDataApiKeyAuthenticationOptions"/>, <see cref="OpenAI.OnYourDataConnectionStringAuthenticationOptions"/>, <see cref="OpenAI.OnYourDataEncodedApiKeyAuthenticationOptions"/>, <see cref="OpenAI.OnYourDataKeyAndKeyIdAuthenticationOptions"/>, <see cref="OnYourDataSystemAssignedManagedIdentityAuthenticationOptions"/> and <see cref="OpenAI.OnYourDataUserAssignedManagedIdentityAuthenticationOptions"/>.
        /// </param>
        /// <param name="documentCount"> The configured top number of documents to feature for the configured query. </param>
        /// <param name="shouldRestrictResultScope"> Whether queries should be restricted to use of indexed data. </param>
        /// <param name="strictness"> The configured strictness of the search relevance filtering. The higher of strictness, the higher of the precision but lower recall of the answer. </param>
        /// <param name="roleInformation"> Give the model instructions about how it should behave and any context it should reference when generating a response. You can describe the assistant's personality and tell it how to format responses. There's a 100 token limit for it, and it counts against the overall token limit. </param>
        /// <param name="endpoint"> The endpoint of Elasticsearch®. </param>
        /// <param name="indexName"> The index name of Elasticsearch®. </param>
        /// <param name="fieldMappingOptions"> The index field mapping options of Elasticsearch®. </param>
        /// <param name="queryType"> The query type of Elasticsearch®. </param>
        /// <param name="embeddingDependency">
        /// The embedding dependency for vector search.
        /// Please note <see cref="OnYourDataVectorizationSource"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="OpenAI.OnYourDataDeploymentNameVectorizationSource"/>, <see cref="OpenAI.OnYourDataEndpointVectorizationSource"/> and <see cref="OpenAI.OnYourDataModelIdVectorizationSource"/>.
        /// </param>
        /// <returns> A new <see cref="OpenAI.ElasticsearchChatExtensionParameters"/> instance for mocking. </returns>
        public static ElasticsearchChatExtensionParameters ElasticsearchChatExtensionParameters(OnYourDataAuthenticationOptions authentication = null, int? documentCount = null, bool? shouldRestrictResultScope = null, int? strictness = null, string roleInformation = null, Uri endpoint = null, string indexName = null, ElasticsearchIndexFieldMappingOptions fieldMappingOptions = null, ElasticsearchQueryType? queryType = null, OnYourDataVectorizationSource embeddingDependency = null)
        {
            return new ElasticsearchChatExtensionParameters(
                authentication,
                documentCount,
                shouldRestrictResultScope,
                strictness,
                roleInformation,
                endpoint,
                indexName,
                fieldMappingOptions,
                queryType,
                embeddingDependency,
                serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.PineconeChatExtensionConfiguration"/>. </summary>
        /// <param name="parameters"> The parameters to use when configuring Azure OpenAI chat extensions. </param>
        /// <returns> A new <see cref="OpenAI.PineconeChatExtensionConfiguration"/> instance for mocking. </returns>
        public static PineconeChatExtensionConfiguration PineconeChatExtensionConfiguration(PineconeChatExtensionParameters parameters = null)
        {
            return new PineconeChatExtensionConfiguration(AzureChatExtensionType.Pinecone, serializedAdditionalRawData: null, parameters);
        }

        /// <summary> Initializes a new instance of <see cref="OpenAI.PineconeChatExtensionParameters"/>. </summary>
        /// <param name="authentication">
        /// The authentication method to use when accessing the defined data source.
        /// Each data source type supports a specific set of available authentication methods; please see the documentation of
        /// the data source for supported mechanisms.
        /// If not otherwise provided, On Your Data will attempt to use System Managed Identity (default credential)
        /// authentication.
        /// Please note <see cref="OnYourDataAuthenticationOptions"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="OpenAI.OnYourDataAccessTokenAuthenticationOptions"/>, <see cref="OpenAI.OnYourDataApiKeyAuthenticationOptions"/>, <see cref="OpenAI.OnYourDataConnectionStringAuthenticationOptions"/>, <see cref="OpenAI.OnYourDataEncodedApiKeyAuthenticationOptions"/>, <see cref="OpenAI.OnYourDataKeyAndKeyIdAuthenticationOptions"/>, <see cref="OnYourDataSystemAssignedManagedIdentityAuthenticationOptions"/> and <see cref="OpenAI.OnYourDataUserAssignedManagedIdentityAuthenticationOptions"/>.
        /// </param>
        /// <param name="documentCount"> The configured top number of documents to feature for the configured query. </param>
        /// <param name="shouldRestrictResultScope"> Whether queries should be restricted to use of indexed data. </param>
        /// <param name="strictness"> The configured strictness of the search relevance filtering. The higher of strictness, the higher of the precision but lower recall of the answer. </param>
        /// <param name="roleInformation"> Give the model instructions about how it should behave and any context it should reference when generating a response. You can describe the assistant's personality and tell it how to format responses. There's a 100 token limit for it, and it counts against the overall token limit. </param>
        /// <param name="environmentName"> The environment name of Pinecone. </param>
        /// <param name="indexName"> The name of the Pinecone database index. </param>
        /// <param name="fieldMappingOptions"> Customized field mapping behavior to use when interacting with the search index. </param>
        /// <param name="embeddingDependency">
        /// The embedding dependency for vector search.
        /// Please note <see cref="OnYourDataVectorizationSource"/> is the base class. According to the scenario, a derived class of the base class might need to be assigned here, or this property needs to be casted to one of the possible derived classes.
        /// The available derived classes include <see cref="OpenAI.OnYourDataDeploymentNameVectorizationSource"/>, <see cref="OpenAI.OnYourDataEndpointVectorizationSource"/> and <see cref="OpenAI.OnYourDataModelIdVectorizationSource"/>.
        /// </param>
        /// <returns> A new <see cref="OpenAI.PineconeChatExtensionParameters"/> instance for mocking. </returns>
        public static PineconeChatExtensionParameters PineconeChatExtensionParameters(OnYourDataAuthenticationOptions authentication = null, int? documentCount = null, bool? shouldRestrictResultScope = null, int? strictness = null, string roleInformation = null, string environmentName = null, string indexName = null, PineconeFieldMappingOptions fieldMappingOptions = null, OnYourDataVectorizationSource embeddingDependency = null)
        {
            return new PineconeChatExtensionParameters(
                authentication,
                documentCount,
                shouldRestrictResultScope,
                strictness,
                roleInformation,
                environmentName,
                indexName,
                fieldMappingOptions,
                embeddingDependency,
                serializedAdditionalRawData: null);
        }
    }
}

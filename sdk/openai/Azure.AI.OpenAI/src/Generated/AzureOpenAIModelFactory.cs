// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.

// <auto-generated/>

#nullable disable

using System.Collections.Generic;
using System.Linq;

namespace Azure.AI.OpenAI
{
    /// <summary> Model factory for models. </summary>
    public static partial class AzureOpenAIModelFactory
    {
        /// <summary> Initializes a new instance of Embeddings. </summary>
        /// <param name="object"> Type of the data field. </param>
        /// <param name="data"> Embedding values for the prompts submitted in the request. </param>
        /// <param name="model"> ID of the model to use. </param>
        /// <param name="usage"> Usage counts for tokens input using the embeddings API. </param>
        /// <returns> A new <see cref="OpenAI.Embeddings"/> instance for mocking. </returns>
        public static Embeddings Embeddings(EmbeddingsObject @object = default, IEnumerable<EmbeddingItem> data = null, string model = null, EmbeddingsUsage usage = null)
        {
            data ??= new List<EmbeddingItem>();

            return new Embeddings(@object, data?.ToList(), model, usage);
        }

        /// <summary> Initializes a new instance of EmbeddingItem. </summary>
        /// <param name="object"> Name of the field in which the embedding is contained. </param>
        /// <param name="embedding"> List of embeddings value for the input prompt. These represents a measurement of releated of text strings. </param>
        /// <param name="index"> Index of the prompt to which the EmbeddingItem corresponds. </param>
        /// <returns> A new <see cref="OpenAI.EmbeddingItem"/> instance for mocking. </returns>
        public static EmbeddingItem EmbeddingItem(EmbeddingItemObject @object = default, IEnumerable<float> embedding = null, int index = default)
        {
            embedding ??= new List<float>();

            return new EmbeddingItem(@object, embedding?.ToList(), index);
        }

        /// <summary> Initializes a new instance of EmbeddingsUsage. </summary>
        /// <param name="promptTokens"> Number of tokens sent in the original request. </param>
        /// <param name="totalTokens"> Total number of tokens transacted in this request/response. </param>
        /// <returns> A new <see cref="OpenAI.EmbeddingsUsage"/> instance for mocking. </returns>
        public static EmbeddingsUsage EmbeddingsUsage(int promptTokens = default, int totalTokens = default)
        {
            return new EmbeddingsUsage(promptTokens, totalTokens);
        }

        /// <summary> Initializes a new instance of Completions. </summary>
        /// <param name="id"> Id for completion response. </param>
        /// <param name="object"> Object for completion response. </param>
        /// <param name="created"> Created time for completion response. </param>
        /// <param name="model"> Model used for completion response. </param>
        /// <param name="choices"> Array of choices returned containing text completions to prompts sent. </param>
        /// <param name="usage"> Usage counts for tokens input using the completions API. </param>
        /// <returns> A new <see cref="OpenAI.Completions"/> instance for mocking. </returns>
        public static Completions Completions(string id = null, CompletionsObject @object = default, int? created = null, string model = null, IEnumerable<Choice> choices = null, CompletionsUsage usage = null)
        {
            choices ??= new List<Choice>();

            return new Completions(id, @object, created, model, choices?.ToList(), usage);
        }

        /// <summary> Initializes a new instance of Choice. </summary>
        /// <param name="text"> Generated text for given completion prompt. </param>
        /// <param name="index"> Index. </param>
        /// <param name="logprobs"> Log Prob Model. </param>
        /// <param name="finishReason"> Reason for finishing. </param>
        /// <returns> A new <see cref="OpenAI.Choice"/> instance for mocking. </returns>
        public static Choice Choice(string text = null, int? index = null, CompletionsLogProbability logprobs = null, string finishReason = null)
        {
            return new Choice(text, index, logprobs, finishReason);
        }

        /// <summary> Initializes a new instance of CompletionsLogProbability. </summary>
        /// <param name="tokens"> Tokens. </param>
        /// <param name="tokenLogProbability"> LogProbs of Tokens. </param>
        /// <param name="topLogProbability"> Top LogProbs. </param>
        /// <param name="textOffset"> Text offset. </param>
        /// <returns> A new <see cref="OpenAI.CompletionsLogProbability"/> instance for mocking. </returns>
        public static CompletionsLogProbability CompletionsLogProbability(IEnumerable<string> tokens = null, IEnumerable<float?> tokenLogProbability = null, IEnumerable<IDictionary<string, float>> topLogProbability = null, IEnumerable<int> textOffset = null)
        {
            tokens ??= new List<string>();
            tokenLogProbability ??= new List<float?>();
            topLogProbability ??= new List<IDictionary<string, float>>();
            textOffset ??= new List<int>();

            return new CompletionsLogProbability(tokens?.ToList(), tokenLogProbability?.ToList(), topLogProbability?.ToList(), textOffset?.ToList());
        }

        /// <summary> Initializes a new instance of CompletionsUsage. </summary>
        /// <param name="completionTokens"> Number of tokens received in the completion. </param>
        /// <param name="promptTokens"> Number of tokens sent in the original request. </param>
        /// <param name="totalTokens"> Total number of tokens transacted in this request/response. </param>
        /// <returns> A new <see cref="OpenAI.CompletionsUsage"/> instance for mocking. </returns>
        public static CompletionsUsage CompletionsUsage(int completionTokens = default, int promptTokens = default, int totalTokens = default)
        {
            return new CompletionsUsage(completionTokens, promptTokens, totalTokens);
        }
    }
}

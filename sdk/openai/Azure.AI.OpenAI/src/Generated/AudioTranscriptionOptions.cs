// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.

// <auto-generated/>

#nullable disable

using System;
using Azure.Core;

namespace Azure.AI.OpenAI
{
    /// <summary> The configuration information for an audio transcription request. </summary>
    public partial class AudioTranscriptionOptions
    {
        /// <summary> Initializes a new instance of <see cref="AudioTranscriptionOptions"/>. </summary>
        /// <param name="audioData">
        /// The audio data to transcribe. This must be the binary content of a file in one of the supported media formats:
        ///  flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, webm.
        /// </param>
        /// <param name="filename"> The optional filename or descriptive identifier to associate with with the audio data. </param>
        /// <param name="responseFormat"> The requested format of the transcription response data, which will influence the content and detail of the result. </param>
        /// <param name="language">
        /// The primary spoken language of the audio data to be transcribed, supplied as a two-letter ISO-639-1 language code
        /// such as 'en' or 'fr'.
        /// Providing this known input language is optional but may improve the accuracy and/or latency of transcription.
        /// </param>
        /// <param name="prompt">
        /// An optional hint to guide the model's style or continue from a prior audio segment. The written language of the
        /// prompt should match the primary spoken language of the audio data.
        /// </param>
        /// <param name="temperature">
        /// The sampling temperature, between 0 and 1.
        /// Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.
        /// If set to 0, the model will use log probability to automatically increase the temperature until certain thresholds are hit.
        /// </param>
        /// <param name="deploymentName"> The model to use for this transcription request. </param>
        internal AudioTranscriptionOptions(BinaryData audioData, string filename, AudioTranscriptionFormat? responseFormat, string language, string prompt, float? temperature, string deploymentName)
        {
            AudioData = audioData;
            Filename = filename;
            ResponseFormat = responseFormat;
            Language = language;
            Prompt = prompt;
            Temperature = temperature;
            DeploymentName = deploymentName;
        }
        /// <summary> The optional filename or descriptive identifier to associate with with the audio data. </summary>
        public string Filename { get; set; }
        /// <summary> The requested format of the transcription response data, which will influence the content and detail of the result. </summary>
        public AudioTranscriptionFormat? ResponseFormat { get; set; }
        /// <summary>
        /// The primary spoken language of the audio data to be transcribed, supplied as a two-letter ISO-639-1 language code
        /// such as 'en' or 'fr'.
        /// Providing this known input language is optional but may improve the accuracy and/or latency of transcription.
        /// </summary>
        public string Language { get; set; }
        /// <summary>
        /// An optional hint to guide the model's style or continue from a prior audio segment. The written language of the
        /// prompt should match the primary spoken language of the audio data.
        /// </summary>
        public string Prompt { get; set; }
        /// <summary>
        /// The sampling temperature, between 0 and 1.
        /// Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.
        /// If set to 0, the model will use log probability to automatically increase the temperature until certain thresholds are hit.
        /// </summary>
        public float? Temperature { get; set; }
    }
}

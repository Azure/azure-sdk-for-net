// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.

// <auto-generated/>

#nullable disable

using System;
using System.Collections.Generic;

namespace Azure.AI.OpenAI
{
    /// <summary> The configuration information for an audio transcription request. </summary>
    public partial class AudioTranscriptionOptions
    {
        /// <summary>
        /// Keeps track of any properties unknown to the library.
        /// <para>
        /// To assign an object to the value of this property use <see cref="BinaryData.FromObjectAsJson{T}(T, System.Text.Json.JsonSerializerOptions?)"/>.
        /// </para>
        /// <para>
        /// To assign an already formatted json string to this property use <see cref="BinaryData.FromString(string)"/>.
        /// </para>
        /// <para>
        /// Examples:
        /// <list type="bullet">
        /// <item>
        /// <term>BinaryData.FromObjectAsJson("foo")</term>
        /// <description>Creates a payload of "foo".</description>
        /// </item>
        /// <item>
        /// <term>BinaryData.FromString("\"foo\"")</term>
        /// <description>Creates a payload of "foo".</description>
        /// </item>
        /// <item>
        /// <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
        /// <description>Creates a payload of { "key": "value" }.</description>
        /// </item>
        /// <item>
        /// <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
        /// <description>Creates a payload of { "key": "value" }.</description>
        /// </item>
        /// </list>
        /// </para>
        /// </summary>
        private IDictionary<string, BinaryData> _serializedAdditionalRawData;

        /// <summary> Initializes a new instance of <see cref="AudioTranscriptionOptions"/>. </summary>
        /// <param name="audioData">
        /// The audio data to transcribe. This must be the binary content of a file in one of the supported media formats:
        ///  flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, webm.
        /// </param>
        /// <exception cref="ArgumentNullException"> <paramref name="audioData"/> is null. </exception>
        public AudioTranscriptionOptions(BinaryData audioData)
        {
            Argument.AssertNotNull(audioData, nameof(audioData));

            AudioData = audioData;
        }

        /// <summary> Initializes a new instance of <see cref="AudioTranscriptionOptions"/>. </summary>
        /// <param name="audioData">
        /// The audio data to transcribe. This must be the binary content of a file in one of the supported media formats:
        ///  flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, webm.
        /// </param>
        /// <param name="filename"> The optional filename or descriptive identifier to associate with with the audio data. </param>
        /// <param name="responseFormat"> The requested format of the transcription response data, which will influence the content and detail of the result. </param>
        /// <param name="language">
        /// The primary spoken language of the audio data to be transcribed, supplied as a two-letter ISO-639-1 language code
        /// such as 'en' or 'fr'.
        /// Providing this known input language is optional but may improve the accuracy and/or latency of transcription.
        /// </param>
        /// <param name="prompt">
        /// An optional hint to guide the model's style or continue from a prior audio segment. The written language of the
        /// prompt should match the primary spoken language of the audio data.
        /// </param>
        /// <param name="temperature">
        /// The sampling temperature, between 0 and 1.
        /// Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.
        /// If set to 0, the model will use log probability to automatically increase the temperature until certain thresholds are hit.
        /// </param>
        /// <param name="timestampGranularities">
        /// The timestamp granularities to populate for this transcription.
        /// `response_format` must be set `verbose_json` to use timestamp granularities.
        /// Either or both of these options are supported: `word`, or `segment`.
        /// Note: There is no additional latency for segment timestamps, but generating word timestamps incurs additional latency.
        /// </param>
        /// <param name="deploymentName"> The model to use for this transcription request. </param>
        /// <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        internal AudioTranscriptionOptions(BinaryData audioData, string filename, AudioTranscriptionFormat? responseFormat, string language, string prompt, float? temperature, IList<AudioTranscriptionTimestampGranularity> timestampGranularities, string deploymentName, IDictionary<string, BinaryData> serializedAdditionalRawData)
        {
            AudioData = audioData;
            Filename = filename;
            ResponseFormat = responseFormat;
            Language = language;
            Prompt = prompt;
            Temperature = temperature;
            TimestampGranularities = timestampGranularities;
            DeploymentName = deploymentName;
            _serializedAdditionalRawData = serializedAdditionalRawData;
        }

        /// <summary> Initializes a new instance of <see cref="AudioTranscriptionOptions"/> for deserialization. </summary>
        internal AudioTranscriptionOptions()
        {
        }

        /// <summary>
        /// The audio data to transcribe. This must be the binary content of a file in one of the supported media formats:
        ///  flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, webm.
        /// <para>
        /// To assign a byte[] to this property use <see cref="BinaryData.FromBytes(byte[])"/>.
        /// The byte[] will be serialized to a Base64 encoded string.
        /// </para>
        /// <para>
        /// Examples:
        /// <list type="bullet">
        /// <item>
        /// <term>BinaryData.FromBytes(new byte[] { 1, 2, 3 })</term>
        /// <description>Creates a payload of "AQID".</description>
        /// </item>
        /// </list>
        /// </para>
        /// </summary>
        public BinaryData AudioData { get; }
        /// <summary> The optional filename or descriptive identifier to associate with with the audio data. </summary>
        public string Filename { get; set; }
        /// <summary> The requested format of the transcription response data, which will influence the content and detail of the result. </summary>
        public AudioTranscriptionFormat? ResponseFormat { get; set; }
        /// <summary>
        /// The primary spoken language of the audio data to be transcribed, supplied as a two-letter ISO-639-1 language code
        /// such as 'en' or 'fr'.
        /// Providing this known input language is optional but may improve the accuracy and/or latency of transcription.
        /// </summary>
        public string Language { get; set; }
        /// <summary>
        /// An optional hint to guide the model's style or continue from a prior audio segment. The written language of the
        /// prompt should match the primary spoken language of the audio data.
        /// </summary>
        public string Prompt { get; set; }
        /// <summary>
        /// The sampling temperature, between 0 and 1.
        /// Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.
        /// If set to 0, the model will use log probability to automatically increase the temperature until certain thresholds are hit.
        /// </summary>
        public float? Temperature { get; set; }
        /// <summary> The model to use for this transcription request. </summary>
        public string DeploymentName { get; set; }
    }
}

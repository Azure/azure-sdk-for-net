// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.

// <auto-generated/>

#nullable disable

using System;
using System.Collections.Generic;

namespace Azure.AI.Projects.OneDP
{
    /// <summary> A set of provider-specific configuration and behavior options for OpenAI. </summary>
    public partial class OpenAIModelOptions
    {
        /// <summary>
        /// Keeps track of any properties unknown to the library.
        /// <para>
        /// To assign an object to the value of this property use <see cref="BinaryData.FromObjectAsJson{T}(T, System.Text.Json.JsonSerializerOptions?)"/>.
        /// </para>
        /// <para>
        /// To assign an already formatted json string to this property use <see cref="BinaryData.FromString(string)"/>.
        /// </para>
        /// <para>
        /// Examples:
        /// <list type="bullet">
        /// <item>
        /// <term>BinaryData.FromObjectAsJson("foo")</term>
        /// <description>Creates a payload of "foo".</description>
        /// </item>
        /// <item>
        /// <term>BinaryData.FromString("\"foo\"")</term>
        /// <description>Creates a payload of "foo".</description>
        /// </item>
        /// <item>
        /// <term>BinaryData.FromObjectAsJson(new { key = "value" })</term>
        /// <description>Creates a payload of { "key": "value" }.</description>
        /// </item>
        /// <item>
        /// <term>BinaryData.FromString("{\"key\": \"value\"}")</term>
        /// <description>Creates a payload of { "key": "value" }.</description>
        /// </item>
        /// </list>
        /// </para>
        /// </summary>
        private IDictionary<string, BinaryData> _serializedAdditionalRawData;

        /// <summary> Initializes a new instance of <see cref="OpenAIModelOptions"/>. </summary>
        public OpenAIModelOptions()
        {
        }

        /// <summary> Initializes a new instance of <see cref="OpenAIModelOptions"/>. </summary>
        /// <param name="temperature">
        /// The sampling temperature to use that controls the apparent creativity of generated completions.
        /// Higher values will make output more random while lower values will make results more focused
        /// and deterministic.
        /// It is not recommended to modify temperature and topP for the same completions request as the
        /// interaction of these two settings is difficult to predict.
        /// </param>
        /// <param name="topP">
        /// An alternative to sampling with temperature called nucleus sampling. This value causes the
        /// model to consider the results of tokens with the provided probability mass. As an example, a
        /// value of 0.15 will cause only the tokens comprising the top 15% of probability mass to be
        /// considered.
        /// It is not recommended to modify temperature and topP for the same completions request as the
        /// interaction of these two settings is difficult to predict.
        /// </param>
        /// <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        internal OpenAIModelOptions(float? temperature, float? topP, IDictionary<string, BinaryData> serializedAdditionalRawData)
        {
            Temperature = temperature;
            TopP = topP;
            _serializedAdditionalRawData = serializedAdditionalRawData;
        }

        /// <summary>
        /// The sampling temperature to use that controls the apparent creativity of generated completions.
        /// Higher values will make output more random while lower values will make results more focused
        /// and deterministic.
        /// It is not recommended to modify temperature and topP for the same completions request as the
        /// interaction of these two settings is difficult to predict.
        /// </summary>
        public float? Temperature { get; set; }
        /// <summary>
        /// An alternative to sampling with temperature called nucleus sampling. This value causes the
        /// model to consider the results of tokens with the provided probability mass. As an example, a
        /// value of 0.15 will cause only the tokens comprising the top 15% of probability mass to be
        /// considered.
        /// It is not recommended to modify temperature and topP for the same completions request as the
        /// interaction of these two settings is difficult to predict.
        /// </summary>
        public float? TopP { get; set; }
    }
}

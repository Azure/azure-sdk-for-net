// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.

// <auto-generated/>

#nullable disable

using System;
using System.Collections.Generic;
using System.Linq;
using System.Threading;
using System.Threading.Tasks;
using Azure.Core;
using Azure.Core.Pipeline;

namespace Azure.AI.Agents.Persistent
{
    // Data plane generated client.
    /// <summary> The PersistentAgents service client. </summary>
    public partial class PersistentAgentsClient
    {
        private const string AuthorizationHeader = "Authorization";
        private readonly AzureKeyCredential _keyCredential;
        private const string AuthorizationApiKeyPrefix = "Bearer";
        private static readonly string[] AuthorizationScopes = new string[] { "https://cognitiveservices.azure.com/.default" };
        private readonly TokenCredential _tokenCredential;
        private readonly HttpPipeline _pipeline;
        private readonly Uri _endpoint;
        private readonly string _apiVersion;

        /// <summary> The ClientDiagnostics is used to provide tracing support for the client library. </summary>
        internal ClientDiagnostics ClientDiagnostics { get; }

        /// <summary> The HTTP pipeline for sending and receiving REST requests and responses. </summary>
        public virtual HttpPipeline Pipeline => _pipeline;

        /// <summary> Initializes a new instance of PersistentAgentsClient for mocking. </summary>
        protected PersistentAgentsClient()
        {
        }

        /// <summary> Initializes a new instance of PersistentAgentsClient. </summary>
        /// <param name="endpoint"> Project endpoint in the form of: https://&lt;aiservices-id&gt;.services.ai.azure.com/api/projects/&lt;project-name&gt;. </param>
        /// <param name="credential"> A credential used to authenticate to an Azure Service. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="endpoint"/> or <paramref name="credential"/> is null. </exception>
        public PersistentAgentsClient(Uri endpoint, AzureKeyCredential credential) : this(endpoint, credential, new PersistentAgentsClientOptions())
        {
        }

        /// <summary> Initializes a new instance of PersistentAgentsClient. </summary>
        /// <param name="endpoint"> Project endpoint in the form of: https://&lt;aiservices-id&gt;.services.ai.azure.com/api/projects/&lt;project-name&gt;. </param>
        /// <param name="credential"> A credential used to authenticate to an Azure Service. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="endpoint"/> or <paramref name="credential"/> is null. </exception>
        public PersistentAgentsClient(Uri endpoint, TokenCredential credential) : this(endpoint, credential, new PersistentAgentsClientOptions())
        {
        }

        /// <summary> Initializes a new instance of PersistentAgentsClient. </summary>
        /// <param name="endpoint"> Project endpoint in the form of: https://&lt;aiservices-id&gt;.services.ai.azure.com/api/projects/&lt;project-name&gt;. </param>
        /// <param name="credential"> A credential used to authenticate to an Azure Service. </param>
        /// <param name="options"> The options for configuring the client. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="endpoint"/> or <paramref name="credential"/> is null. </exception>
        public PersistentAgentsClient(Uri endpoint, AzureKeyCredential credential, PersistentAgentsClientOptions options)
        {
            Argument.AssertNotNull(endpoint, nameof(endpoint));
            Argument.AssertNotNull(credential, nameof(credential));
            options ??= new PersistentAgentsClientOptions();

            ClientDiagnostics = new ClientDiagnostics(options, true);
            _keyCredential = credential;
            _pipeline = HttpPipelineBuilder.Build(options, Array.Empty<HttpPipelinePolicy>(), new HttpPipelinePolicy[] { new AzureKeyCredentialPolicy(_keyCredential, AuthorizationHeader, AuthorizationApiKeyPrefix) }, new ResponseClassifier());
            _endpoint = endpoint;
            _apiVersion = options.Version;
        }

        /// <summary> Initializes a new instance of PersistentAgentsClient. </summary>
        /// <param name="endpoint"> Project endpoint in the form of: https://&lt;aiservices-id&gt;.services.ai.azure.com/api/projects/&lt;project-name&gt;. </param>
        /// <param name="credential"> A credential used to authenticate to an Azure Service. </param>
        /// <param name="options"> The options for configuring the client. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="endpoint"/> or <paramref name="credential"/> is null. </exception>
        public PersistentAgentsClient(Uri endpoint, TokenCredential credential, PersistentAgentsClientOptions options)
        {
            Argument.AssertNotNull(endpoint, nameof(endpoint));
            Argument.AssertNotNull(credential, nameof(credential));
            options ??= new PersistentAgentsClientOptions();

            ClientDiagnostics = new ClientDiagnostics(options, true);
            _tokenCredential = credential;
            _pipeline = HttpPipelineBuilder.Build(options, Array.Empty<HttpPipelinePolicy>(), new HttpPipelinePolicy[] { new BearerTokenAuthenticationPolicy(_tokenCredential, AuthorizationScopes) }, new ResponseClassifier());
            _endpoint = endpoint;
            _apiVersion = options.Version;
        }

        /// <summary> Creates a new agent thread and immediately starts a run using that new thread. </summary>
        /// <param name="assistantId"> The ID of the agent for which the thread should be created. </param>
        /// <param name="thread"> The details used to create the new thread. If no thread is provided, an empty one will be created. </param>
        /// <param name="overrideModelName"> The overridden model that the agent should use to run the thread. </param>
        /// <param name="overrideInstructions"> The overridden system instructions the agent should use to run the thread. </param>
        /// <param name="overrideTools"> The overridden list of enabled tools the agent should use to run the thread. </param>
        /// <param name="toolResources"> Override the tools the agent can use for this run. This is useful for modifying the behavior on a per-run basis. </param>
        /// <param name="stream">
        /// If `true`, returns a stream of events that happen during the Run as server-sent events,
        /// terminating when the Run enters a terminal state with a `data: [DONE]` message.
        /// </param>
        /// <param name="temperature">
        /// What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output
        /// more random, while lower values like 0.2 will make it more focused and deterministic.
        /// </param>
        /// <param name="topP">
        /// An alternative to sampling with temperature, called nucleus sampling, where the model
        /// considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens
        /// comprising the top 10% probability mass are considered.
        ///
        /// We generally recommend altering this or temperature but not both.
        /// </param>
        /// <param name="maxPromptTokens">
        /// The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only
        /// the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified,
        /// the run will end with status `incomplete`. See `incomplete_details` for more info.
        /// </param>
        /// <param name="maxCompletionTokens">
        /// The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only
        /// the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens
        /// specified, the run will end with status `incomplete`. See `incomplete_details` for more info.
        /// </param>
        /// <param name="truncationStrategy"> The strategy to use for dropping messages as the context windows moves forward. </param>
        /// <param name="toolChoice"> Controls whether or not and which tool is called by the model. </param>
        /// <param name="responseFormat"> Specifies the format that the model must output. </param>
        /// <param name="parallelToolCalls"> If `true` functions will run in parallel during tool use. </param>
        /// <param name="metadata"> A set of up to 16 key/value pairs that can be attached to an object, used for storing additional information about that object in a structured format. Keys may be up to 64 characters in length and values may be up to 512 characters in length. </param>
        /// <param name="cancellationToken"> The cancellation token to use. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="assistantId"/> is null. </exception>
        public virtual async Task<Response<ThreadRun>> CreateThreadAndRunAsync(string assistantId, PersistentAgentThreadCreationOptions thread = null, string overrideModelName = null, string overrideInstructions = null, IEnumerable<ToolDefinition> overrideTools = null, UpdateToolResourcesOptions toolResources = null, bool? stream = null, float? temperature = null, float? topP = null, int? maxPromptTokens = null, int? maxCompletionTokens = null, TruncationObject truncationStrategy = null, BinaryData toolChoice = null, BinaryData responseFormat = null, bool? parallelToolCalls = null, IReadOnlyDictionary<string, string> metadata = null, CancellationToken cancellationToken = default)
        {
            Argument.AssertNotNull(assistantId, nameof(assistantId));

            CreateThreadAndRunRequest createThreadAndRunRequest = new CreateThreadAndRunRequest(
                assistantId,
                thread,
                overrideModelName,
                overrideInstructions,
                overrideTools?.ToList() as IReadOnlyList<ToolDefinition> ?? new ChangeTrackingList<ToolDefinition>(),
                toolResources,
                stream,
                temperature,
                topP,
                maxPromptTokens,
                maxCompletionTokens,
                truncationStrategy,
                toolChoice,
                responseFormat,
                parallelToolCalls,
                metadata ?? new ChangeTrackingDictionary<string, string>(),
                null);
            RequestContext context = FromCancellationToken(cancellationToken);
            Response response = await CreateThreadAndRunAsync(createThreadAndRunRequest.ToRequestContent(), context).ConfigureAwait(false);
            return Response.FromValue(ThreadRun.FromResponse(response), response);
        }

        /// <summary> Creates a new agent thread and immediately starts a run using that new thread. </summary>
        /// <param name="assistantId"> The ID of the agent for which the thread should be created. </param>
        /// <param name="thread"> The details used to create the new thread. If no thread is provided, an empty one will be created. </param>
        /// <param name="overrideModelName"> The overridden model that the agent should use to run the thread. </param>
        /// <param name="overrideInstructions"> The overridden system instructions the agent should use to run the thread. </param>
        /// <param name="overrideTools"> The overridden list of enabled tools the agent should use to run the thread. </param>
        /// <param name="toolResources"> Override the tools the agent can use for this run. This is useful for modifying the behavior on a per-run basis. </param>
        /// <param name="stream">
        /// If `true`, returns a stream of events that happen during the Run as server-sent events,
        /// terminating when the Run enters a terminal state with a `data: [DONE]` message.
        /// </param>
        /// <param name="temperature">
        /// What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output
        /// more random, while lower values like 0.2 will make it more focused and deterministic.
        /// </param>
        /// <param name="topP">
        /// An alternative to sampling with temperature, called nucleus sampling, where the model
        /// considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens
        /// comprising the top 10% probability mass are considered.
        ///
        /// We generally recommend altering this or temperature but not both.
        /// </param>
        /// <param name="maxPromptTokens">
        /// The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only
        /// the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified,
        /// the run will end with status `incomplete`. See `incomplete_details` for more info.
        /// </param>
        /// <param name="maxCompletionTokens">
        /// The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only
        /// the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens
        /// specified, the run will end with status `incomplete`. See `incomplete_details` for more info.
        /// </param>
        /// <param name="truncationStrategy"> The strategy to use for dropping messages as the context windows moves forward. </param>
        /// <param name="toolChoice"> Controls whether or not and which tool is called by the model. </param>
        /// <param name="responseFormat"> Specifies the format that the model must output. </param>
        /// <param name="parallelToolCalls"> If `true` functions will run in parallel during tool use. </param>
        /// <param name="metadata"> A set of up to 16 key/value pairs that can be attached to an object, used for storing additional information about that object in a structured format. Keys may be up to 64 characters in length and values may be up to 512 characters in length. </param>
        /// <param name="cancellationToken"> The cancellation token to use. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="assistantId"/> is null. </exception>
        public virtual Response<ThreadRun> CreateThreadAndRun(string assistantId, PersistentAgentThreadCreationOptions thread = null, string overrideModelName = null, string overrideInstructions = null, IEnumerable<ToolDefinition> overrideTools = null, UpdateToolResourcesOptions toolResources = null, bool? stream = null, float? temperature = null, float? topP = null, int? maxPromptTokens = null, int? maxCompletionTokens = null, TruncationObject truncationStrategy = null, BinaryData toolChoice = null, BinaryData responseFormat = null, bool? parallelToolCalls = null, IReadOnlyDictionary<string, string> metadata = null, CancellationToken cancellationToken = default)
        {
            Argument.AssertNotNull(assistantId, nameof(assistantId));

            CreateThreadAndRunRequest createThreadAndRunRequest = new CreateThreadAndRunRequest(
                assistantId,
                thread,
                overrideModelName,
                overrideInstructions,
                overrideTools?.ToList() as IReadOnlyList<ToolDefinition> ?? new ChangeTrackingList<ToolDefinition>(),
                toolResources,
                stream,
                temperature,
                topP,
                maxPromptTokens,
                maxCompletionTokens,
                truncationStrategy,
                toolChoice,
                responseFormat,
                parallelToolCalls,
                metadata ?? new ChangeTrackingDictionary<string, string>(),
                null);
            RequestContext context = FromCancellationToken(cancellationToken);
            Response response = CreateThreadAndRun(createThreadAndRunRequest.ToRequestContent(), context);
            return Response.FromValue(ThreadRun.FromResponse(response), response);
        }

        /// <summary>
        /// [Protocol Method] Creates a new agent thread and immediately starts a run using that new thread.
        /// <list type="bullet">
        /// <item>
        /// <description>
        /// This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
        /// </description>
        /// </item>
        /// <item>
        /// <description>
        /// Please try the simpler <see cref="CreateThreadAndRunAsync(string,PersistentAgentThreadCreationOptions,string,string,IEnumerable{ToolDefinition},UpdateToolResourcesOptions,bool?,float?,float?,int?,int?,TruncationObject,BinaryData,BinaryData,bool?,IReadOnlyDictionary{string,string},CancellationToken)"/> convenience overload with strongly typed models first.
        /// </description>
        /// </item>
        /// </list>
        /// </summary>
        /// <param name="content"> The content to send as the body of the request. </param>
        /// <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="content"/> is null. </exception>
        /// <exception cref="RequestFailedException"> Service returned a non-success status code. </exception>
        /// <returns> The response returned from the service. </returns>
        public virtual async Task<Response> CreateThreadAndRunAsync(RequestContent content, RequestContext context = null)
        {
            Argument.AssertNotNull(content, nameof(content));

            using var scope = ClientDiagnostics.CreateScope("PersistentAgentsClient.CreateThreadAndRun");
            scope.Start();
            try
            {
                using HttpMessage message = CreateCreateThreadAndRunRequest(content, context);
                return await _pipeline.ProcessMessageAsync(message, context).ConfigureAwait(false);
            }
            catch (Exception e)
            {
                scope.Failed(e);
                throw;
            }
        }

        /// <summary>
        /// [Protocol Method] Creates a new agent thread and immediately starts a run using that new thread.
        /// <list type="bullet">
        /// <item>
        /// <description>
        /// This <see href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/core/Azure.Core/samples/ProtocolMethods.md">protocol method</see> allows explicit creation of the request and processing of the response for advanced scenarios.
        /// </description>
        /// </item>
        /// <item>
        /// <description>
        /// Please try the simpler <see cref="CreateThreadAndRun(string,PersistentAgentThreadCreationOptions,string,string,IEnumerable{ToolDefinition},UpdateToolResourcesOptions,bool?,float?,float?,int?,int?,TruncationObject,BinaryData,BinaryData,bool?,IReadOnlyDictionary{string,string},CancellationToken)"/> convenience overload with strongly typed models first.
        /// </description>
        /// </item>
        /// </list>
        /// </summary>
        /// <param name="content"> The content to send as the body of the request. </param>
        /// <param name="context"> The request context, which can override default behaviors of the client pipeline on a per-call basis. </param>
        /// <exception cref="ArgumentNullException"> <paramref name="content"/> is null. </exception>
        /// <exception cref="RequestFailedException"> Service returned a non-success status code. </exception>
        /// <returns> The response returned from the service. </returns>
        public virtual Response CreateThreadAndRun(RequestContent content, RequestContext context = null)
        {
            Argument.AssertNotNull(content, nameof(content));

            using var scope = ClientDiagnostics.CreateScope("PersistentAgentsClient.CreateThreadAndRun");
            scope.Start();
            try
            {
                using HttpMessage message = CreateCreateThreadAndRunRequest(content, context);
                return _pipeline.ProcessMessage(message, context);
            }
            catch (Exception e)
            {
                scope.Failed(e);
                throw;
            }
        }

        private GetAdministration _cachedGetAdministration;
        private GetThreads _cachedGetThreads;
        private GetMessages _cachedGetMessages;
        private GetRuns _cachedGetRuns;
        private GetRunSteps _cachedGetRunSteps;
        private GetFiles _cachedGetFiles;
        private GetVectorStores _cachedGetVectorStores;
        private GetVectorStoreFiles _cachedGetVectorStoreFiles;
        private GetFileBatches _cachedGetFileBatches;

        /// <summary> Initializes a new instance of GetAdministration. </summary>
        public virtual GetAdministration GetGetAdministrationClient()
        {
            return Volatile.Read(ref _cachedGetAdministration) ?? Interlocked.CompareExchange(ref _cachedGetAdministration, new GetAdministration(ClientDiagnostics, _pipeline, _keyCredential, _tokenCredential, _endpoint, _apiVersion), null) ?? _cachedGetAdministration;
        }

        /// <summary> Initializes a new instance of GetThreads. </summary>
        public virtual GetThreads GetGetThreadsClient()
        {
            return Volatile.Read(ref _cachedGetThreads) ?? Interlocked.CompareExchange(ref _cachedGetThreads, new GetThreads(ClientDiagnostics, _pipeline, _keyCredential, _tokenCredential, _endpoint, _apiVersion), null) ?? _cachedGetThreads;
        }

        /// <summary> Initializes a new instance of GetMessages. </summary>
        public virtual GetMessages GetGetMessagesClient()
        {
            return Volatile.Read(ref _cachedGetMessages) ?? Interlocked.CompareExchange(ref _cachedGetMessages, new GetMessages(ClientDiagnostics, _pipeline, _keyCredential, _tokenCredential, _endpoint, _apiVersion), null) ?? _cachedGetMessages;
        }

        /// <summary> Initializes a new instance of GetRuns. </summary>
        public virtual GetRuns GetGetRunsClient()
        {
            return Volatile.Read(ref _cachedGetRuns) ?? Interlocked.CompareExchange(ref _cachedGetRuns, new GetRuns(ClientDiagnostics, _pipeline, _keyCredential, _tokenCredential, _endpoint, _apiVersion), null) ?? _cachedGetRuns;
        }

        /// <summary> Initializes a new instance of GetRunSteps. </summary>
        public virtual GetRunSteps GetGetRunStepsClient()
        {
            return Volatile.Read(ref _cachedGetRunSteps) ?? Interlocked.CompareExchange(ref _cachedGetRunSteps, new GetRunSteps(ClientDiagnostics, _pipeline, _keyCredential, _tokenCredential, _endpoint, _apiVersion), null) ?? _cachedGetRunSteps;
        }

        /// <summary> Initializes a new instance of GetFiles. </summary>
        public virtual GetFiles GetGetFilesClient()
        {
            return Volatile.Read(ref _cachedGetFiles) ?? Interlocked.CompareExchange(ref _cachedGetFiles, new GetFiles(ClientDiagnostics, _pipeline, _keyCredential, _tokenCredential, _endpoint, _apiVersion), null) ?? _cachedGetFiles;
        }

        /// <summary> Initializes a new instance of GetVectorStores. </summary>
        public virtual GetVectorStores GetGetVectorStoresClient()
        {
            return Volatile.Read(ref _cachedGetVectorStores) ?? Interlocked.CompareExchange(ref _cachedGetVectorStores, new GetVectorStores(ClientDiagnostics, _pipeline, _keyCredential, _tokenCredential, _endpoint, _apiVersion), null) ?? _cachedGetVectorStores;
        }

        /// <summary> Initializes a new instance of GetVectorStoreFiles. </summary>
        public virtual GetVectorStoreFiles GetGetVectorStoreFilesClient()
        {
            return Volatile.Read(ref _cachedGetVectorStoreFiles) ?? Interlocked.CompareExchange(ref _cachedGetVectorStoreFiles, new GetVectorStoreFiles(ClientDiagnostics, _pipeline, _keyCredential, _tokenCredential, _endpoint, _apiVersion), null) ?? _cachedGetVectorStoreFiles;
        }

        /// <summary> Initializes a new instance of GetFileBatches. </summary>
        public virtual GetFileBatches GetGetFileBatchesClient()
        {
            return Volatile.Read(ref _cachedGetFileBatches) ?? Interlocked.CompareExchange(ref _cachedGetFileBatches, new GetFileBatches(ClientDiagnostics, _pipeline, _keyCredential, _tokenCredential, _endpoint, _apiVersion), null) ?? _cachedGetFileBatches;
        }

        internal HttpMessage CreateCreateThreadAndRunRequest(RequestContent content, RequestContext context)
        {
            var message = _pipeline.CreateMessage(context, ResponseClassifier200);
            var request = message.Request;
            request.Method = RequestMethod.Post;
            var uri = new RawRequestUriBuilder();
            uri.Reset(_endpoint);
            uri.AppendPath("/threads/runs", false);
            uri.AppendQuery("api-version", _apiVersion, true);
            request.Uri = uri;
            request.Headers.Add("Accept", "application/json");
            request.Headers.Add("Content-Type", "application/json");
            request.Content = content;
            return message;
        }

        private static RequestContext DefaultRequestContext = new RequestContext();
        internal static RequestContext FromCancellationToken(CancellationToken cancellationToken = default)
        {
            if (!cancellationToken.CanBeCanceled)
            {
                return DefaultRequestContext;
            }

            return new RequestContext() { CancellationToken = cancellationToken };
        }

        private static ResponseClassifier _responseClassifier200;
        private static ResponseClassifier ResponseClassifier200 => _responseClassifier200 ??= new StatusCodeClassifier(stackalloc ushort[] { 200 });
    }
}

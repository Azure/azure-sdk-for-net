// <auto-generated/>

#nullable disable

using System.Collections.Generic;

namespace Azure.AI.Projects.OpenAI
{
    /// <summary> The prompt agent definition. </summary>
    public partial class PromptAgentDefinition : AgentDefinition
    {
        /// <summary> The model deployment to use for this agent. </summary>
        public string Model { get; set; }

        /// <summary> A system (or developer) message inserted into the model's context. </summary>
        public string Instructions { get; set; }

        /// <summary>
        /// What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.
        /// We generally recommend altering this or `top_p` but not both.
        /// </summary>
        public float? Temperature { get; set; }

        /// <summary>
        /// An alternative to sampling with temperature, called nucleus sampling,
        /// where the model considers the results of the tokens with top_p probability
        /// mass. So 0.1 means only the tokens comprising the top 10% probability mass
        /// are considered.
        /// 
        /// We generally recommend altering this or `temperature` but not both.
        /// </summary>
        public float? TopP { get; set; }

        /// <summary> Set of structured inputs that can participate in prompt template substitution or tool argument bindings. </summary>
        public IDictionary<string, StructuredInputDefinition> StructuredInputs { get; }
    }
}

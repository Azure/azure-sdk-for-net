// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.

// <auto-generated/>

#nullable disable

using System;
using System.ClientModel.Primitives;
using System.Text.Json;
using Azure.Core;

namespace Azure.AI.VoiceLive
{
    [PersistableModelProxy(typeof(UnknownVoiceLiveServerEvent))]
    public partial class VoiceLiveServerEvent : IUtf8JsonSerializable, IJsonModel<VoiceLiveServerEvent>
    {
        void IUtf8JsonSerializable.Write(Utf8JsonWriter writer) => ((IJsonModel<VoiceLiveServerEvent>)this).Write(writer, ModelSerializationExtensions.WireOptions);

        void IJsonModel<VoiceLiveServerEvent>.Write(Utf8JsonWriter writer, ModelReaderWriterOptions options)
        {
            writer.WriteStartObject();
            JsonModelWriteCore(writer, options);
            writer.WriteEndObject();
        }

        /// <param name="writer"> The JSON writer. </param>
        /// <param name="options"> The client options for reading and writing models. </param>
        protected virtual void JsonModelWriteCore(Utf8JsonWriter writer, ModelReaderWriterOptions options)
        {
            var format = options.Format == "W" ? ((IPersistableModel<VoiceLiveServerEvent>)this).GetFormatFromOptions(options) : options.Format;
            if (format != "J")
            {
                throw new FormatException($"The model {nameof(VoiceLiveServerEvent)} does not support writing '{format}' format.");
            }

            writer.WritePropertyName("type"u8);
            writer.WriteStringValue(Type.ToString());
            if (Optional.IsDefined(EventId))
            {
                writer.WritePropertyName("event_id"u8);
                writer.WriteStringValue(EventId);
            }
            if (options.Format != "W" && _serializedAdditionalRawData != null)
            {
                foreach (var item in _serializedAdditionalRawData)
                {
                    writer.WritePropertyName(item.Key);
#if NET6_0_OR_GREATER
				writer.WriteRawValue(item.Value);
#else
                    using (JsonDocument document = JsonDocument.Parse(item.Value, ModelSerializationExtensions.JsonDocumentOptions))
                    {
                        JsonSerializer.Serialize(writer, document.RootElement);
                    }
#endif
                }
            }
        }

        VoiceLiveServerEvent IJsonModel<VoiceLiveServerEvent>.Create(ref Utf8JsonReader reader, ModelReaderWriterOptions options)
        {
            var format = options.Format == "W" ? ((IPersistableModel<VoiceLiveServerEvent>)this).GetFormatFromOptions(options) : options.Format;
            if (format != "J")
            {
                throw new FormatException($"The model {nameof(VoiceLiveServerEvent)} does not support reading '{format}' format.");
            }

            using JsonDocument document = JsonDocument.ParseValue(ref reader);
            return DeserializeVoiceLiveServerEvent(document.RootElement, options);
        }

        internal static VoiceLiveServerEvent DeserializeVoiceLiveServerEvent(JsonElement element, ModelReaderWriterOptions options = null)
        {
            options ??= ModelSerializationExtensions.WireOptions;

            if (element.ValueKind == JsonValueKind.Null)
            {
                return null;
            }
            if (element.TryGetProperty("type", out JsonElement discriminator))
            {
                switch (discriminator.GetString())
                {
                    case "conversation.item.created": return VoiceLiveServerEventConversationItemCreated.DeserializeVoiceLiveServerEventConversationItemCreated(element, options);
                    case "conversation.item.deleted": return VoiceLiveServerEventConversationItemDeleted.DeserializeVoiceLiveServerEventConversationItemDeleted(element, options);
                    case "conversation.item.input_audio_transcription.completed": return VoiceLiveServerEventConversationItemInputAudioTranscriptionCompleted.DeserializeVoiceLiveServerEventConversationItemInputAudioTranscriptionCompleted(element, options);
                    case "conversation.item.input_audio_transcription.delta": return VoiceLiveServerEventConversationItemInputAudioTranscriptionDelta.DeserializeVoiceLiveServerEventConversationItemInputAudioTranscriptionDelta(element, options);
                    case "conversation.item.input_audio_transcription.failed": return VoiceLiveServerEventConversationItemInputAudioTranscriptionFailed.DeserializeVoiceLiveServerEventConversationItemInputAudioTranscriptionFailed(element, options);
                    case "conversation.item.retrieved": return VoiceLiveServerEventConversationItemRetrieved.DeserializeVoiceLiveServerEventConversationItemRetrieved(element, options);
                    case "conversation.item.truncated": return VoiceLiveServerEventConversationItemTruncated.DeserializeVoiceLiveServerEventConversationItemTruncated(element, options);
                    case "error": return VoiceLiveServerEventError.DeserializeVoiceLiveServerEventError(element, options);
                    case "input_audio_buffer.cleared": return VoiceLiveServerEventInputAudioBufferCleared.DeserializeVoiceLiveServerEventInputAudioBufferCleared(element, options);
                    case "input_audio_buffer.committed": return VoiceLiveServerEventInputAudioBufferCommitted.DeserializeVoiceLiveServerEventInputAudioBufferCommitted(element, options);
                    case "input_audio_buffer.speech_started": return VoiceLiveServerEventInputAudioBufferSpeechStarted.DeserializeVoiceLiveServerEventInputAudioBufferSpeechStarted(element, options);
                    case "input_audio_buffer.speech_stopped": return VoiceLiveServerEventInputAudioBufferSpeechStopped.DeserializeVoiceLiveServerEventInputAudioBufferSpeechStopped(element, options);
                    case "response.animation_blendshapes.delta": return ResponseAnimationBlendshapeDeltaEvent.DeserializeResponseAnimationBlendshapeDeltaEvent(element, options);
                    case "response.animation_blendshapes.done": return ResponseAnimationBlendshapeDoneEvent.DeserializeResponseAnimationBlendshapeDoneEvent(element, options);
                    case "response.animation_viseme.delta": return ResponseAnimationVisemeDeltaEvent.DeserializeResponseAnimationVisemeDeltaEvent(element, options);
                    case "response.animation_viseme.done": return ResponseAnimationVisemeDoneEvent.DeserializeResponseAnimationVisemeDoneEvent(element, options);
                    case "response.audio_timestamp.delta": return ResponseAudioTimestampDeltaEvent.DeserializeResponseAudioTimestampDeltaEvent(element, options);
                    case "response.audio_timestamp.done": return ResponseAudioTimestampDoneEvent.DeserializeResponseAudioTimestampDoneEvent(element, options);
                    case "response.audio_transcript.delta": return VoiceLiveServerEventResponseAudioTranscriptDelta.DeserializeVoiceLiveServerEventResponseAudioTranscriptDelta(element, options);
                    case "response.audio_transcript.done": return VoiceLiveServerEventResponseAudioTranscriptDone.DeserializeVoiceLiveServerEventResponseAudioTranscriptDone(element, options);
                    case "response.audio.delta": return VoiceLiveServerEventResponseAudioDelta.DeserializeVoiceLiveServerEventResponseAudioDelta(element, options);
                    case "response.audio.done": return VoiceLiveServerEventResponseAudioDone.DeserializeVoiceLiveServerEventResponseAudioDone(element, options);
                    case "response.content_part.added": return VoiceLiveServerEventResponseContentPartAdded.DeserializeVoiceLiveServerEventResponseContentPartAdded(element, options);
                    case "response.content_part.done": return VoiceLiveServerEventResponseContentPartDone.DeserializeVoiceLiveServerEventResponseContentPartDone(element, options);
                    case "response.created": return VoiceLiveServerEventResponseCreated.DeserializeVoiceLiveServerEventResponseCreated(element, options);
                    case "response.done": return VoiceLiveServerEventResponseDone.DeserializeVoiceLiveServerEventResponseDone(element, options);
                    case "response.emotion_hypothesis": return ResponseEmotionHypothesis.DeserializeResponseEmotionHypothesis(element, options);
                    case "response.output_item.added": return VoiceLiveServerEventResponseOutputItemAdded.DeserializeVoiceLiveServerEventResponseOutputItemAdded(element, options);
                    case "response.output_item.done": return VoiceLiveServerEventResponseOutputItemDone.DeserializeVoiceLiveServerEventResponseOutputItemDone(element, options);
                    case "response.text.delta": return VoiceLiveServerEventResponseTextDelta.DeserializeVoiceLiveServerEventResponseTextDelta(element, options);
                    case "response.text.done": return VoiceLiveServerEventResponseTextDone.DeserializeVoiceLiveServerEventResponseTextDone(element, options);
                    case "session.avatar.connecting": return VoiceLiveServerEventSessionAvatarConnecting.DeserializeVoiceLiveServerEventSessionAvatarConnecting(element, options);
                    case "session.created": return VoiceLiveServerEventSessionCreated.DeserializeVoiceLiveServerEventSessionCreated(element, options);
                    case "session.updated": return VoiceLiveServerEventSessionUpdated.DeserializeVoiceLiveServerEventSessionUpdated(element, options);
                }
            }
            return UnknownVoiceLiveServerEvent.DeserializeUnknownVoiceLiveServerEvent(element, options);
        }

        BinaryData IPersistableModel<VoiceLiveServerEvent>.Write(ModelReaderWriterOptions options)
        {
            var format = options.Format == "W" ? ((IPersistableModel<VoiceLiveServerEvent>)this).GetFormatFromOptions(options) : options.Format;

            switch (format)
            {
                case "J":
                    return ModelReaderWriter.Write(this, options, AzureAIVoiceLiveContext.Default);
                default:
                    throw new FormatException($"The model {nameof(VoiceLiveServerEvent)} does not support writing '{options.Format}' format.");
            }
        }

        VoiceLiveServerEvent IPersistableModel<VoiceLiveServerEvent>.Create(BinaryData data, ModelReaderWriterOptions options)
        {
            var format = options.Format == "W" ? ((IPersistableModel<VoiceLiveServerEvent>)this).GetFormatFromOptions(options) : options.Format;

            switch (format)
            {
                case "J":
                    {
                        using JsonDocument document = JsonDocument.Parse(data, ModelSerializationExtensions.JsonDocumentOptions);
                        return DeserializeVoiceLiveServerEvent(document.RootElement, options);
                    }
                default:
                    throw new FormatException($"The model {nameof(VoiceLiveServerEvent)} does not support reading '{options.Format}' format.");
            }
        }

        string IPersistableModel<VoiceLiveServerEvent>.GetFormatFromOptions(ModelReaderWriterOptions options) => "J";

        /// <summary> Deserializes the model from a raw response. </summary>
        /// <param name="response"> The response to deserialize the model from. </param>
        internal static VoiceLiveServerEvent FromResponse(Response response)
        {
            using var document = JsonDocument.Parse(response.Content, ModelSerializationExtensions.JsonDocumentOptions);
            return DeserializeVoiceLiveServerEvent(document.RootElement);
        }

        /// <summary> Convert into a <see cref="RequestContent"/>. </summary>
        internal virtual RequestContent ToRequestContent()
        {
            var content = new Utf8JsonRequestContent();
            content.JsonWriter.WriteObjectValue(this, ModelSerializationExtensions.WireOptions);
            return content;
        }
    }
}

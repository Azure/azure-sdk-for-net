// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.

// <auto-generated/>

#nullable disable

using System.Collections.Generic;

namespace Azure.Search.Documents.Indexes.Models
{
    /// <summary> Common language model parameters for Chat Completions. If omitted, default values are used. </summary>
    public partial class CommonModelParameters
    {
        /// <summary> Initializes a new instance of <see cref="CommonModelParameters"/>. </summary>
        public CommonModelParameters()
        {
            Stop = new ChangeTrackingList<string>();
        }

        /// <summary> Initializes a new instance of <see cref="CommonModelParameters"/>. </summary>
        /// <param name="model"> The name of the model to use (e.g., 'gpt-4o', etc.). Default is null if not specified. </param>
        /// <param name="frequencyPenalty"> A float in the range [-2,2] that reduces or increases likelihood of repeated tokens. Default is 0. </param>
        /// <param name="presencePenalty"> A float in the range [-2,2] that penalizes new tokens based on their existing presence. Default is 0. </param>
        /// <param name="maxTokens"> Maximum number of tokens to generate. </param>
        /// <param name="temperature"> Sampling temperature. Default is 0.7. </param>
        /// <param name="seed"> Random seed for controlling deterministic outputs. If omitted, randomization is used. </param>
        /// <param name="stop"> List of stop sequences that will cut off text generation. Default is none. </param>
        internal CommonModelParameters(string model, float? frequencyPenalty, float? presencePenalty, int? maxTokens, float? temperature, int? seed, IList<string> stop)
        {
            Model = model;
            FrequencyPenalty = frequencyPenalty;
            PresencePenalty = presencePenalty;
            MaxTokens = maxTokens;
            Temperature = temperature;
            Seed = seed;
            Stop = stop;
        }

        /// <summary> The name of the model to use (e.g., 'gpt-4o', etc.). Default is null if not specified. </summary>
        public string Model { get; set; }
        /// <summary> A float in the range [-2,2] that reduces or increases likelihood of repeated tokens. Default is 0. </summary>
        public float? FrequencyPenalty { get; set; }
        /// <summary> A float in the range [-2,2] that penalizes new tokens based on their existing presence. Default is 0. </summary>
        public float? PresencePenalty { get; set; }
        /// <summary> Maximum number of tokens to generate. </summary>
        public int? MaxTokens { get; set; }
        /// <summary> Sampling temperature. Default is 0.7. </summary>
        public float? Temperature { get; set; }
        /// <summary> Random seed for controlling deterministic outputs. If omitted, randomization is used. </summary>
        public int? Seed { get; set; }
        /// <summary> List of stop sequences that will cut off text generation. Default is none. </summary>
        public IList<string> Stop { get; set; }
    }
}

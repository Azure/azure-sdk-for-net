// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.

// <auto-generated/>

#nullable disable

using System;
using System.Collections.Generic;

namespace Azure.Search.Documents.Indexes.Models
{
    internal partial class KeywordTokenizerV2 : LexicalTokenizer
    {
        /// <summary> Initializes a new instance of <see cref="KeywordTokenizerV2"/>. </summary>
        /// <param name="name"> The name of the tokenizer. It must only contain letters, digits, spaces, dashes or underscores, can only start and end with alphanumeric characters, and is limited to 128 characters. </param>
        public KeywordTokenizerV2(string name) : base("#Microsoft.Azure.Search.KeywordTokenizerV2", name)
        {
        }

        /// <summary> Initializes a new instance of <see cref="KeywordTokenizerV2"/>. </summary>
        /// <param name="odataType"> The discriminator for derived types. </param>
        /// <param name="name"> The name of the tokenizer. It must only contain letters, digits, spaces, dashes or underscores, can only start and end with alphanumeric characters, and is limited to 128 characters. </param>
        /// <param name="additionalBinaryDataProperties"> Keeps track of any properties unknown to the library. </param>
        /// <param name="maxTokenLength"> The maximum token length. Default is 256. Tokens longer than the maximum length are split. The maximum token length that can be used is 300 characters. </param>
        internal KeywordTokenizerV2(string odataType, string name, IDictionary<string, BinaryData> additionalBinaryDataProperties, int? maxTokenLength) : base(odataType, name, additionalBinaryDataProperties)
        {
            MaxTokenLength = maxTokenLength;
        }

        /// <summary> The maximum token length. Default is 256. Tokens longer than the maximum length are split. The maximum token length that can be used is 300 characters. </summary>
        public int? MaxTokenLength { get; set; }
    }
}

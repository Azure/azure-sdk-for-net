// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.

// <auto-generated/>

#nullable disable

using System;
using System.Collections.Generic;
using Azure.Search.Documents;

namespace Azure.Search.Documents.Indexes.Models
{
    /// <summary> Common language model parameters for Chat Completions. If omitted, default values are used. </summary>
    public partial class ChatCompletionCommonModelParameters
    {
        /// <summary> Keeps track of any properties unknown to the library. </summary>
        private protected readonly IDictionary<string, BinaryData> _additionalBinaryDataProperties;

        /// <summary> Initializes a new instance of <see cref="ChatCompletionCommonModelParameters"/>. </summary>
        public ChatCompletionCommonModelParameters()
        {
            Stop = new ChangeTrackingList<string>();
        }

        /// <summary> Initializes a new instance of <see cref="ChatCompletionCommonModelParameters"/>. </summary>
        /// <param name="modelName"> The name of the model to use (e.g., 'gpt-4o', etc.). Default is null if not specified. </param>
        /// <param name="frequencyPenalty"> A float in the range [-2,2] that reduces or increases likelihood of repeated tokens. Default is 0. </param>
        /// <param name="presencePenalty"> A float in the range [-2,2] that penalizes new tokens based on their existing presence. Default is 0. </param>
        /// <param name="maxTokens"> Maximum number of tokens to generate. </param>
        /// <param name="temperature"> Sampling temperature. Default is 0.7. </param>
        /// <param name="seed"> Random seed for controlling deterministic outputs. If omitted, randomization is used. </param>
        /// <param name="stop"> List of stop sequences that will cut off text generation. Default is none. </param>
        /// <param name="additionalBinaryDataProperties"> Keeps track of any properties unknown to the library. </param>
        internal ChatCompletionCommonModelParameters(string modelName, double? frequencyPenalty, double? presencePenalty, int? maxTokens, double? temperature, int? seed, IList<string> stop, IDictionary<string, BinaryData> additionalBinaryDataProperties)
        {
            ModelName = modelName;
            FrequencyPenalty = frequencyPenalty;
            PresencePenalty = presencePenalty;
            MaxTokens = maxTokens;
            Temperature = temperature;
            Seed = seed;
            Stop = stop;
            _additionalBinaryDataProperties = additionalBinaryDataProperties;
        }

        /// <summary> The name of the model to use (e.g., 'gpt-4o', etc.). Default is null if not specified. </summary>
        public string ModelName { get; set; }

        /// <summary> A float in the range [-2,2] that reduces or increases likelihood of repeated tokens. Default is 0. </summary>
        public double? FrequencyPenalty { get; set; }

        /// <summary> A float in the range [-2,2] that penalizes new tokens based on their existing presence. Default is 0. </summary>
        public double? PresencePenalty { get; set; }

        /// <summary> Maximum number of tokens to generate. </summary>
        public int? MaxTokens { get; set; }

        /// <summary> Sampling temperature. Default is 0.7. </summary>
        public double? Temperature { get; set; }

        /// <summary> Random seed for controlling deterministic outputs. If omitted, randomization is used. </summary>
        public int? Seed { get; set; }

        /// <summary> List of stop sequences that will cut off text generation. Default is none. </summary>
        public IList<string> Stop { get; set; }
    }
}

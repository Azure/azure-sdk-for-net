// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.

// <auto-generated/>

#nullable disable

using System;
using System.Collections.Generic;

namespace Azure.Search.Documents.Indexes.Models
{
    /// <summary>
    /// Contains configuration options specific to the compression method used during indexing or querying.
    /// Please note this is the abstract base class. The derived classes available for instantiation are: <see cref="ScalarQuantizationCompression"/> and <see cref="BinaryQuantizationCompression"/>.
    /// </summary>
    public abstract partial class VectorSearchCompression
    {
        /// <summary> Keeps track of any properties unknown to the library. </summary>
        private protected readonly IDictionary<string, BinaryData> _additionalBinaryDataProperties;

        /// <summary> Initializes a new instance of <see cref="VectorSearchCompression"/>. </summary>
        /// <param name="compressionName"> The name to associate with this particular configuration. </param>
        /// <param name="kind"> Type of VectorSearchCompression. </param>
        private protected VectorSearchCompression(string compressionName, VectorSearchCompressionKind kind)
        {
            CompressionName = compressionName;
            Kind = kind;
        }

        /// <summary> Initializes a new instance of <see cref="VectorSearchCompression"/>. </summary>
        /// <param name="compressionName"> The name to associate with this particular configuration. </param>
        /// <param name="rescoringOptions"> Contains the options for rescoring. </param>
        /// <param name="truncationDimension"> The number of dimensions to truncate the vectors to. Truncating the vectors reduces the size of the vectors and the amount of data that needs to be transferred during search. This can save storage cost and improve search performance at the expense of recall. It should be only used for embeddings trained with Matryoshka Representation Learning (MRL) such as OpenAI text-embedding-3-large (small). The default value is null, which means no truncation. </param>
        /// <param name="kind"> Type of VectorSearchCompression. </param>
        /// <param name="additionalBinaryDataProperties"> Keeps track of any properties unknown to the library. </param>
        internal VectorSearchCompression(string compressionName, RescoringOptions rescoringOptions, int? truncationDimension, VectorSearchCompressionKind kind, IDictionary<string, BinaryData> additionalBinaryDataProperties)
        {
            CompressionName = compressionName;
            RescoringOptions = rescoringOptions;
            TruncationDimension = truncationDimension;
            Kind = kind;
            _additionalBinaryDataProperties = additionalBinaryDataProperties;
        }

        /// <summary> Contains the options for rescoring. </summary>
        public RescoringOptions RescoringOptions { get; set; }

        /// <summary> The number of dimensions to truncate the vectors to. Truncating the vectors reduces the size of the vectors and the amount of data that needs to be transferred during search. This can save storage cost and improve search performance at the expense of recall. It should be only used for embeddings trained with Matryoshka Representation Learning (MRL) such as OpenAI text-embedding-3-large (small). The default value is null, which means no truncation. </summary>
        public int? TruncationDimension { get; set; }

        /// <summary> Type of VectorSearchCompression. </summary>
        internal VectorSearchCompressionKind Kind { get; set; }
    }
}

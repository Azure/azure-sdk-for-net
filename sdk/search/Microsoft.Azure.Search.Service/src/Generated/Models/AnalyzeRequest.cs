// <auto-generated>
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License. See License.txt in the project root for
// license information.
//
// Code generated by Microsoft (R) AutoRest Code Generator.
// Changes may cause incorrect behavior and will be lost if the code is
// regenerated.
// </auto-generated>

namespace Microsoft.Azure.Search.Models
{
    using Microsoft.Rest;
    using Newtonsoft.Json;
    using System.Collections;
    using System.Collections.Generic;
    using System.Linq;

    /// <summary>
    /// Specifies some text and analysis components used to break that text
    /// into tokens.
    /// </summary>
    public partial class AnalyzeRequest
    {
        /// <summary>
        /// Initializes a new instance of the AnalyzeRequest class.
        /// </summary>
        public AnalyzeRequest()
        {
            CustomInit();
        }

        /// <summary>
        /// Initializes a new instance of the AnalyzeRequest class.
        /// </summary>
        /// <param name="text">The text to break into tokens.</param>
        /// <param name="analyzer">The name of the analyzer to use to break the
        /// given text. If this parameter is not specified, you must specify a
        /// tokenizer instead. The tokenizer and analyzer parameters are
        /// mutually exclusive. Possible values include: 'ar.microsoft',
        /// 'ar.lucene', 'hy.lucene', 'bn.microsoft', 'eu.lucene',
        /// 'bg.microsoft', 'bg.lucene', 'ca.microsoft', 'ca.lucene',
        /// 'zh-Hans.microsoft', 'zh-Hans.lucene', 'zh-Hant.microsoft',
        /// 'zh-Hant.lucene', 'hr.microsoft', 'cs.microsoft', 'cs.lucene',
        /// 'da.microsoft', 'da.lucene', 'nl.microsoft', 'nl.lucene',
        /// 'en.microsoft', 'en.lucene', 'et.microsoft', 'fi.microsoft',
        /// 'fi.lucene', 'fr.microsoft', 'fr.lucene', 'gl.lucene',
        /// 'de.microsoft', 'de.lucene', 'el.microsoft', 'el.lucene',
        /// 'gu.microsoft', 'he.microsoft', 'hi.microsoft', 'hi.lucene',
        /// 'hu.microsoft', 'hu.lucene', 'is.microsoft', 'id.microsoft',
        /// 'id.lucene', 'ga.lucene', 'it.microsoft', 'it.lucene',
        /// 'ja.microsoft', 'ja.lucene', 'kn.microsoft', 'ko.microsoft',
        /// 'ko.lucene', 'lv.microsoft', 'lv.lucene', 'lt.microsoft',
        /// 'ml.microsoft', 'ms.microsoft', 'mr.microsoft', 'nb.microsoft',
        /// 'no.lucene', 'fa.lucene', 'pl.microsoft', 'pl.lucene',
        /// 'pt-BR.microsoft', 'pt-BR.lucene', 'pt-PT.microsoft',
        /// 'pt-PT.lucene', 'pa.microsoft', 'ro.microsoft', 'ro.lucene',
        /// 'ru.microsoft', 'ru.lucene', 'sr-cyrillic.microsoft',
        /// 'sr-latin.microsoft', 'sk.microsoft', 'sl.microsoft',
        /// 'es.microsoft', 'es.lucene', 'sv.microsoft', 'sv.lucene',
        /// 'ta.microsoft', 'te.microsoft', 'th.microsoft', 'th.lucene',
        /// 'tr.microsoft', 'tr.lucene', 'uk.microsoft', 'ur.microsoft',
        /// 'vi.microsoft', 'standard.lucene', 'standardasciifolding.lucene',
        /// 'keyword', 'pattern', 'simple', 'stop', 'whitespace'</param>
        /// <param name="tokenizer">The name of the tokenizer to use to break
        /// the given text. If this parameter is not specified, you must
        /// specify an analyzer instead. The tokenizer and analyzer parameters
        /// are mutually exclusive. Possible values include: 'classic',
        /// 'edgeNGram', 'keyword_v2', 'letter', 'lowercase',
        /// 'microsoft_language_tokenizer',
        /// 'microsoft_language_stemming_tokenizer', 'nGram',
        /// 'path_hierarchy_v2', 'pattern', 'standard_v2', 'uax_url_email',
        /// 'whitespace'</param>
        /// <param name="tokenFilters">An optional list of token filters to use
        /// when breaking the given text. This parameter can only be set when
        /// using the tokenizer parameter.</param>
        /// <param name="charFilters">An optional list of character filters to
        /// use when breaking the given text. This parameter can only be set
        /// when using the tokenizer parameter.</param>
        public AnalyzeRequest(string text, AnalyzerName? analyzer = default(AnalyzerName?), TokenizerName? tokenizer = default(TokenizerName?), IList<TokenFilterName> tokenFilters = default(IList<TokenFilterName>), IList<CharFilterName> charFilters = default(IList<CharFilterName>))
        {
            Text = text;
            Analyzer = analyzer;
            Tokenizer = tokenizer;
            TokenFilters = tokenFilters;
            CharFilters = charFilters;
            CustomInit();
        }

        /// <summary>
        /// An initialization method that performs custom operations like setting defaults
        /// </summary>
        partial void CustomInit();

        /// <summary>
        /// Gets or sets the text to break into tokens.
        /// </summary>
        [JsonProperty(PropertyName = "text")]
        public string Text { get; set; }

        /// <summary>
        /// Gets or sets the name of the analyzer to use to break the given
        /// text. If this parameter is not specified, you must specify a
        /// tokenizer instead. The tokenizer and analyzer parameters are
        /// mutually exclusive. Possible values include: 'ar.microsoft',
        /// 'ar.lucene', 'hy.lucene', 'bn.microsoft', 'eu.lucene',
        /// 'bg.microsoft', 'bg.lucene', 'ca.microsoft', 'ca.lucene',
        /// 'zh-Hans.microsoft', 'zh-Hans.lucene', 'zh-Hant.microsoft',
        /// 'zh-Hant.lucene', 'hr.microsoft', 'cs.microsoft', 'cs.lucene',
        /// 'da.microsoft', 'da.lucene', 'nl.microsoft', 'nl.lucene',
        /// 'en.microsoft', 'en.lucene', 'et.microsoft', 'fi.microsoft',
        /// 'fi.lucene', 'fr.microsoft', 'fr.lucene', 'gl.lucene',
        /// 'de.microsoft', 'de.lucene', 'el.microsoft', 'el.lucene',
        /// 'gu.microsoft', 'he.microsoft', 'hi.microsoft', 'hi.lucene',
        /// 'hu.microsoft', 'hu.lucene', 'is.microsoft', 'id.microsoft',
        /// 'id.lucene', 'ga.lucene', 'it.microsoft', 'it.lucene',
        /// 'ja.microsoft', 'ja.lucene', 'kn.microsoft', 'ko.microsoft',
        /// 'ko.lucene', 'lv.microsoft', 'lv.lucene', 'lt.microsoft',
        /// 'ml.microsoft', 'ms.microsoft', 'mr.microsoft', 'nb.microsoft',
        /// 'no.lucene', 'fa.lucene', 'pl.microsoft', 'pl.lucene',
        /// 'pt-BR.microsoft', 'pt-BR.lucene', 'pt-PT.microsoft',
        /// 'pt-PT.lucene', 'pa.microsoft', 'ro.microsoft', 'ro.lucene',
        /// 'ru.microsoft', 'ru.lucene', 'sr-cyrillic.microsoft',
        /// 'sr-latin.microsoft', 'sk.microsoft', 'sl.microsoft',
        /// 'es.microsoft', 'es.lucene', 'sv.microsoft', 'sv.lucene',
        /// 'ta.microsoft', 'te.microsoft', 'th.microsoft', 'th.lucene',
        /// 'tr.microsoft', 'tr.lucene', 'uk.microsoft', 'ur.microsoft',
        /// 'vi.microsoft', 'standard.lucene', 'standardasciifolding.lucene',
        /// 'keyword', 'pattern', 'simple', 'stop', 'whitespace'
        /// </summary>
        [JsonProperty(PropertyName = "analyzer")]
        public AnalyzerName? Analyzer { get; set; }

        /// <summary>
        /// Gets or sets the name of the tokenizer to use to break the given
        /// text. If this parameter is not specified, you must specify an
        /// analyzer instead. The tokenizer and analyzer parameters are
        /// mutually exclusive. Possible values include: 'classic',
        /// 'edgeNGram', 'keyword_v2', 'letter', 'lowercase',
        /// 'microsoft_language_tokenizer',
        /// 'microsoft_language_stemming_tokenizer', 'nGram',
        /// 'path_hierarchy_v2', 'pattern', 'standard_v2', 'uax_url_email',
        /// 'whitespace'
        /// </summary>
        [JsonProperty(PropertyName = "tokenizer")]
        public TokenizerName? Tokenizer { get; set; }

        /// <summary>
        /// Gets or sets an optional list of token filters to use when breaking
        /// the given text. This parameter can only be set when using the
        /// tokenizer parameter.
        /// </summary>
        [JsonProperty(PropertyName = "tokenFilters")]
        public IList<TokenFilterName> TokenFilters { get; set; }

        /// <summary>
        /// Gets or sets an optional list of character filters to use when
        /// breaking the given text. This parameter can only be set when using
        /// the tokenizer parameter.
        /// </summary>
        [JsonProperty(PropertyName = "charFilters")]
        public IList<CharFilterName> CharFilters { get; set; }

        /// <summary>
        /// Validate the object.
        /// </summary>
        /// <exception cref="ValidationException">
        /// Thrown if validation fails
        /// </exception>
        public virtual void Validate()
        {
            if (Text == null)
            {
                throw new ValidationException(ValidationRules.CannotBeNull, "Text");
            }
        }
    }
}

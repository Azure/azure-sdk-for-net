// <auto-generated>
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License. See License.txt in the project root for
// license information.
//
// Code generated by Microsoft (R) AutoRest Code Generator.
// Changes may cause incorrect behavior and will be lost if the code is
// regenerated.
// </auto-generated>

namespace Microsoft.Azure.Search.Models
{
    using Newtonsoft.Json;
    using System.Linq;

    /// <summary>
    /// Tokenizer that uses regex pattern matching to construct distinct
    /// tokens. This tokenizer is implemented using Apache Lucene.
    /// <see
    /// href="http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/pattern/PatternTokenizer.html"
    /// />
    /// </summary>
    [Newtonsoft.Json.JsonObject("#Microsoft.Azure.Search.PatternTokenizer")]
    public partial class PatternTokenizer : Tokenizer
    {
        /// <summary>
        /// Initializes a new instance of the PatternTokenizer class.
        /// </summary>
        public PatternTokenizer()
        {
            CustomInit();
        }

        /// <summary>
        /// Initializes a new instance of the PatternTokenizer class.
        /// </summary>
        /// <param name="name">The name of the tokenizer. It must only contain
        /// letters, digits, spaces, dashes or underscores, can only start and
        /// end with alphanumeric characters, and is limited to 128
        /// characters.</param>
        /// <param name="pattern">A regular expression pattern to match token
        /// separators. Default is an expression that matches one or more
        /// whitespace characters.</param>
        /// <param name="flags">Regular expression flags. Possible values
        /// include: 'CANON_EQ', 'CASE_INSENSITIVE', 'COMMENTS', 'DOTALL',
        /// 'LITERAL', 'MULTILINE', 'UNICODE_CASE', 'UNIX_LINES'</param>
        /// <param name="group">The zero-based ordinal of the matching group in
        /// the regular expression pattern to extract into tokens. Use -1 if
        /// you want to use the entire pattern to split the input into tokens,
        /// irrespective of matching groups. Default is -1.</param>
        public PatternTokenizer(string name, string pattern = default(string), RegexFlags? flags = default(RegexFlags?), int? group = default(int?))
            : base(name)
        {
            Pattern = pattern;
            Flags = flags;
            Group = group;
            CustomInit();
        }

        /// <summary>
        /// An initialization method that performs custom operations like setting defaults
        /// </summary>
        partial void CustomInit();

        /// <summary>
        /// Gets or sets a regular expression pattern to match token
        /// separators. Default is an expression that matches one or more
        /// whitespace characters.
        /// </summary>
        [JsonProperty(PropertyName = "pattern")]
        public string Pattern { get; set; }

        /// <summary>
        /// Gets or sets regular expression flags. Possible values include:
        /// 'CANON_EQ', 'CASE_INSENSITIVE', 'COMMENTS', 'DOTALL', 'LITERAL',
        /// 'MULTILINE', 'UNICODE_CASE', 'UNIX_LINES'
        /// </summary>
        [JsonProperty(PropertyName = "flags")]
        public RegexFlags? Flags { get; set; }

        /// <summary>
        /// Gets or sets the zero-based ordinal of the matching group in the
        /// regular expression pattern to extract into tokens. Use -1 if you
        /// want to use the entire pattern to split the input into tokens,
        /// irrespective of matching groups. Default is -1.
        /// </summary>
        [JsonProperty(PropertyName = "group")]
        public int? Group { get; set; }

        /// <summary>
        /// Validate the object.
        /// </summary>
        /// <exception cref="Rest.ValidationException">
        /// Thrown if validation fails
        /// </exception>
        public override void Validate()
        {
            base.Validate();
        }
    }
}

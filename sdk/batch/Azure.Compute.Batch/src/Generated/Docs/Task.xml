<?xml version="1.0" encoding="utf-8"?>
<doc>
  <members>
    <member name="AddAsync(String,RequestContent,Int32,String,Boolean,String,RequestContext)">
<example>
This sample shows how to call AddAsync with required parameters.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetTaskClient(<2022-10-01.16.0>);

var data = new {};

Response response = await client.AddAsync("<jobId>", RequestContent.Create(data));
Console.WriteLine(response.Status);
]]></code>
This sample shows how to call AddAsync with all parameters and request content.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetTaskClient(<2022-10-01.16.0>);

var data = new {
    id = "<id>",
    displayName = "<displayName>",
    exitConditions = new {
        exitCodes = new[] {
            new {
                code = 1234,
                exitOptions = new {
                    jobAction = "none",
                    dependencyAction = "satisfy",
                },
            }
        },
        exitCodeRanges = new[] {
            new {
                start = 1234,
                end = 1234,
                exitOptions = new {
                    jobAction = "none",
                    dependencyAction = "satisfy",
                },
            }
        },
        preProcessingError = new {
            jobAction = "none",
            dependencyAction = "satisfy",
        },
        fileUploadError = new {
            jobAction = "none",
            dependencyAction = "satisfy",
        },
        default = new {
            jobAction = "none",
            dependencyAction = "satisfy",
        },
    },
    commandLine = "<commandLine>",
    containerSettings = new {
        containerRunOptions = "<containerRunOptions>",
        imageName = "<imageName>",
        registry = new {
            username = "<username>",
            password = "<password>",
            registryServer = "<registryServer>",
            identityReference = new {
                resourceId = "<resourceId>",
            },
        },
        workingDirectory = "taskWorkingDirectory",
    },
    resourceFiles = new[] {
        new {
            autoStorageContainerName = "<autoStorageContainerName>",
            storageContainerUrl = "<storageContainerUrl>",
            httpUrl = "<httpUrl>",
            blobPrefix = "<blobPrefix>",
            filePath = "<filePath>",
            fileMode = "<fileMode>",
            identityReference = new {
                resourceId = "<resourceId>",
            },
        }
    },
    outputFiles = new[] {
        new {
            filePattern = "<filePattern>",
            destination = new {
                container = new {
                    path = "<path>",
                    containerUrl = "<containerUrl>",
                    identityReference = new {
                        resourceId = "<resourceId>",
                    },
                    uploadHeaders = new[] {
                        new {
                            name = "<name>",
                            value = "<value>",
                        }
                    },
                },
            },
            uploadOptions = new {
                uploadCondition = "tasksuccess",
            },
        }
    },
    environmentSettings = new[] {
        new {
            name = "<name>",
            value = "<value>",
        }
    },
    affinityInfo = new {
        affinityId = "<affinityId>",
    },
    constraints = new {
        maxWallClockTime = PT1H23M45S,
        retentionTime = PT1H23M45S,
        maxTaskRetryCount = 1234,
    },
    requiredSlots = 1234,
    userIdentity = new {
        username = "<username>",
        autoUser = new {
            scope = "task",
            elevationLevel = "nonadmin",
        },
    },
    multiInstanceSettings = new {
        numberOfInstances = 1234,
        coordinationCommandLine = "<coordinationCommandLine>",
        commonResourceFiles = new[] {
            new {
                autoStorageContainerName = "<autoStorageContainerName>",
                storageContainerUrl = "<storageContainerUrl>",
                httpUrl = "<httpUrl>",
                blobPrefix = "<blobPrefix>",
                filePath = "<filePath>",
                fileMode = "<fileMode>",
                identityReference = new {
                    resourceId = "<resourceId>",
                },
            }
        },
    },
    dependsOn = new {
        taskIds = new[] {
            "<String>"
        },
        taskIdRanges = new[] {
            new {
                start = 1234,
                end = 1234,
            }
        },
    },
    applicationPackageReferences = new[] {
        new {
            applicationId = "<applicationId>",
            version = "<version>",
        }
    },
    authenticationTokenSettings = new {
        access = new[] {
            "job"
        },
    },
};

Response response = await client.AddAsync("<jobId>", RequestContent.Create(data), 1234, "<clientRequestId>", true, "<ocpDate>");
Console.WriteLine(response.Status);
]]></code>
</example>
<remarks>
The maximum lifetime of a Task from addition to completion is 180 days. If a
Task has not completed within 180 days of being added it will be terminated by
the Batch service and left in whatever state it was in at that time.

Below is the JSON schema for the request payload.

Request Body:

Schema for <c>BatchTask</c>:
<code>{
  id: string, # Optional. The ID can contain any combination of alphanumeric characters including hyphens
and underscores, and cannot contain more than 64 characters.
  displayName: string, # Optional. The display name need not be unique and can contain any Unicode characters up
to a maximum length of 1024.
  url: string, # Optional. The URL of the Task.
  eTag: string, # Optional. This is an opaque string. You can use it to detect whether the Task has changed
between requests. In particular, you can be pass the ETag when updating a Task
to specify that your changes should take effect only if nobody else has
modified the Task in the meantime.
  lastModified: string (date &amp; time), # Optional. The last modified time of the Task.
  creationTime: string (date &amp; time), # Optional. The creation time of the Task.
  exitConditions: {
    exitCodes: [ExitCodeMapping], # Optional. A list of individual Task exit codes and how the Batch service should respond
to them.
    exitCodeRanges: [ExitCodeRangeMapping], # Optional. A list of Task exit code ranges and how the Batch service should respond to
them.
    preProcessingError: {
      jobAction: &quot;none&quot; | &quot;disable&quot; | &quot;terminate&quot;, # Optional. The default is none for exit code 0 and terminate for all other exit
conditions. If the Job&apos;s onTaskFailed property is noaction, then specifying
this property returns an error and the add Task request fails with an invalid
property value error; if you are calling the REST API directly, the HTTP status
code is 400 (Bad Request).
      dependencyAction: &quot;satisfy&quot; | &quot;block&quot;, # Optional. Possible values are &apos;satisfy&apos; (allowing dependent tasks to progress) and
&apos;block&apos; (dependent tasks continue to wait). Batch does not yet support
cancellation of dependent tasks.
    }, # Optional. Specifies how the Batch service responds to a particular exit condition.
    fileUploadError: ExitOptions, # Optional. If the Task exited with an exit code that was specified via exitCodes or
exitCodeRanges, and then encountered a file upload error, then the action
specified by the exit code takes precedence.
    default: ExitOptions, # Optional. This value is used if the Task exits with any nonzero exit code not listed in
the exitCodes or exitCodeRanges collection, with a pre-processing error if the
preProcessingError property is not present, or with a file upload error if the
fileUploadError property is not present. If you want non-default behavior on
exit code 0, you must list it explicitly using the exitCodes or exitCodeRanges
collection.
  }, # Optional. How the Batch service should respond when the Task completes.
  state: &quot;active&quot; | &quot;preparing&quot; | &quot;running&quot; | &quot;completed&quot;, # Optional. The state of the Task.
  stateTransitionTime: string (date &amp; time), # Optional. The time at which the Task entered its current state.
  previousState: &quot;active&quot; | &quot;preparing&quot; | &quot;running&quot; | &quot;completed&quot;, # Optional. This property is not set if the Task is in its initial Active state.
  previousStateTransitionTime: string (date &amp; time), # Optional. This property is not set if the Task is in its initial Active state.
  commandLine: string, # Optional. For multi-instance Tasks, the command line is executed as the primary Task,
after the primary Task and all subtasks have finished executing the
coordination command line. The command line does not run under a shell, and
therefore cannot take advantage of shell features such as environment variable
expansion. If you want to take advantage of such features, you should invoke
the shell in the command line, for example using &quot;cmd /c MyCommand&quot; in
Windows or &quot;/bin/sh -c MyCommand&quot; in Linux. If the command line refers to
file paths, it should use a relative path (relative to the Task working
directory), or use the Batch provided environment variable
(https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).
  containerSettings: {
    containerRunOptions: string, # Optional. These additional options are supplied as arguments to the &quot;docker create&quot;
command, in addition to those controlled by the Batch Service.
    imageName: string, # Required. This is the full Image reference, as would be specified to &quot;docker pull&quot;. If
no tag is provided as part of the Image name, the tag &quot;:latest&quot; is used as a
default.
    registry: {
      username: string, # Optional. The user name to log into the registry server.
      password: string, # Optional. The password to log into the registry server.
      registryServer: string, # Optional. If omitted, the default is &quot;docker.io&quot;.
      identityReference: {
        resourceId: string, # Optional. The ARM resource id of the user assigned identity.
      }, # Optional. The reference to a user assigned identity associated with the Batch pool which
a compute node will use.
    }, # Optional. This setting can be omitted if was already provided at Pool creation.
    workingDirectory: &quot;taskWorkingDirectory&quot; | &quot;containerImageDefault&quot;, # Optional. The default is &apos;taskWorkingDirectory&apos;.
  }, # Optional. If the Pool that will run this Task has containerConfiguration set, this must
be set as well. If the Pool that will run this Task doesn&apos;t have
containerConfiguration set, this must not be set. When this is specified, all
directories recursively below the AZ_BATCH_NODE_ROOT_DIR (the root of Azure
Batch directories on the node) are mapped into the container, all Task
environment variables are mapped into the container, and the Task command line
is executed in the container. Files produced in the container outside of
AZ_BATCH_NODE_ROOT_DIR might not be reflected to the host disk, meaning that
Batch file APIs will not be able to access those files.
  resourceFiles: [
    {
      autoStorageContainerName: string, # Optional. The autoStorageContainerName, storageContainerUrl and httpUrl properties are
mutually exclusive and one of them must be specified.
      storageContainerUrl: string, # Optional. The autoStorageContainerName, storageContainerUrl and httpUrl properties are
mutually exclusive and one of them must be specified. This URL must be readable
and listable from compute nodes. There are three ways to get such a URL for a
container in Azure storage: include a Shared Access Signature (SAS) granting
read and list permissions on the container, use a managed identity with read
and list permissions, or set the ACL for the container to allow public access.
      httpUrl: string, # Optional. The autoStorageContainerName, storageContainerUrl and httpUrl properties are
mutually exclusive and one of them must be specified. If the URL points to
Azure Blob Storage, it must be readable from compute nodes. There are three
ways to get such a URL for a blob in Azure storage: include a Shared Access
Signature (SAS) granting read permissions on the blob, use a managed identity
with read permission, or set the ACL for the blob or its container to allow
public access.
      blobPrefix: string, # Optional. The property is valid only when autoStorageContainerName or storageContainerUrl
is used. This prefix can be a partial filename or a subdirectory. If a prefix
is not specified, all the files in the container will be downloaded.
      filePath: string, # Optional. If the httpUrl property is specified, the filePath is required and describes
the path which the file will be downloaded to, including the filename.
Otherwise, if the autoStorageContainerName or storageContainerUrl property is
specified, filePath is optional and is the directory to download the files to.
In the case where filePath is used as a directory, any directory structure
already associated with the input data will be retained in full and appended to
the specified filePath directory. The specified relative path cannot break out
of the Task&apos;s working directory (for example by using &apos;..&apos;).
      fileMode: string, # Optional. This property applies only to files being downloaded to Linux Compute Nodes. It
will be ignored if it is specified for a resourceFile which will be downloaded
to a Windows Compute Node. If this property is not specified for a Linux
Compute Node, then a default value of 0770 is applied to the file.
      identityReference: ComputeNodeIdentityReference, # Optional. The reference to a user assigned identity associated with the Batch pool which
a compute node will use.
    }
  ], # Optional. For multi-instance Tasks, the resource files will only be downloaded to the
Compute Node on which the primary Task is executed. There is a maximum size for
the list of resource files.  When the max size is exceeded, the request will
fail and the response error code will be RequestEntityTooLarge. If this occurs,
the collection of ResourceFiles must be reduced in size. This can be achieved
using .zip files, Application Packages, or Docker Containers.
  outputFiles: [OutputFile], # Optional. For multi-instance Tasks, the files will only be uploaded from the Compute Node
on which the primary Task is executed.
  environmentSettings: [EnvironmentSetting], # Optional. A list of environment variable settings for the Task.
  affinityInfo: {
    affinityId: string, # Required. You can pass the affinityId of a Node to indicate that this Task needs to run
on that Compute Node. Note that this is just a soft affinity. If the target
Compute Node is busy or unavailable at the time the Task is scheduled, then the
Task will be scheduled elsewhere.
  }, # Optional. A locality hint that can be used by the Batch service to select a Compute Node
on which to start a Task.
  constraints: {
    maxWallClockTime: string (duration ISO 8601 Format), # Optional. If this is not specified, there is no time limit on how long the Task may run.
    retentionTime: string (duration ISO 8601 Format), # Optional. The default is 7 days, i.e. the Task directory will be retained for 7 days
unless the Compute Node is removed or the Job is deleted.
    maxTaskRetryCount: number, # Optional. Note that this value specifically controls the number of retries for the Task
executable due to a nonzero exit code. The Batch service will try the Task
once, and may then retry up to this limit. For example, if the maximum retry
count is 3, Batch tries the Task up to 4 times (one initial try and 3 retries).
If the maximum retry count is 0, the Batch service does not retry the Task
after the first attempt. If the maximum retry count is -1, the Batch service
retries the Task without limit, however this is not recommended for a start
task or any task. The default value is 0 (no retries)
  }, # Optional. Execution constraints to apply to a Task.
  requiredSlots: number, # Optional. The default is 1. A Task can only be scheduled to run on a compute node if the
node has enough free scheduling slots available. For multi-instance Tasks, this
must be 1.
  userIdentity: {
    username: string, # Optional. The userName and autoUser properties are mutually exclusive; you must specify
one but not both.
    autoUser: {
      scope: &quot;task&quot; | &quot;pool&quot;, # Optional. The default value is pool. If the pool is running Windows a value of Task
should be specified if stricter isolation between tasks is required. For
example, if the task mutates the registry in a way which could impact other
tasks, or if certificates have been specified on the pool which should not be
accessible by normal tasks but should be accessible by StartTasks.
      elevationLevel: &quot;nonadmin&quot; | &quot;admin&quot;, # Optional. The default value is nonAdmin.
    }, # Optional. The userName and autoUser properties are mutually exclusive; you must specify
one but not both.
  }, # Optional. If omitted, the Task runs as a non-administrative user unique to the Task.
  executionInfo: {
    startTime: string (date &amp; time), # Optional. &apos;Running&apos; corresponds to the running state, so if the Task specifies resource
files or Packages, then the start time reflects the time at which the Task
started downloading or deploying these. If the Task has been restarted or
retried, this is the most recent time at which the Task started running. This
property is present only for Tasks that are in the running or completed state.
    endTime: string (date &amp; time), # Optional. This property is set only if the Task is in the Completed state.
    exitCode: number, # Optional. This property is set only if the Task is in the completed state. In general,
the exit code for a process reflects the specific convention implemented by the
application developer for that process. If you use the exit code value to make
decisions in your code, be sure that you know the exit code convention used by
the application process. However, if the Batch service terminates the Task (due
to timeout, or user termination via the API) you may see an operating
system-defined exit code.
    containerInfo: {
      containerId: string, # Optional. The ID of the container.
      state: string, # Optional. This is the state of the container according to the Docker service. It is
equivalent to the status field returned by &quot;docker inspect&quot;.
      error: string, # Optional. This is the detailed error string from the Docker service, if available. It is
equivalent to the error field returned by &quot;docker inspect&quot;.
    }, # Optional. This property is set only if the Task runs in a container context.
    failureInfo: {
      category: &quot;usererror&quot; | &quot;servererror&quot;, # Required. The category of the error.
      code: string, # Optional. An identifier for the Task error. Codes are invariant and are intended to be
consumed programmatically.
      message: string, # Optional. A message describing the Task error, intended to be suitable for display in a
user interface.
      details: [NameValuePair], # Optional. A list of additional details related to the error.
    }, # Optional. This property is set only if the Task is in the completed state and encountered
a failure.
    retryCount: number, # Required. Task application failures (non-zero exit code) are retried, pre-processing
errors (the Task could not be run) and file upload errors are not retried. The
Batch service will retry the Task up to the limit specified by the constraints.
    lastRetryTime: string (date &amp; time), # Optional. This element is present only if the Task was retried (i.e. retryCount is
nonzero). If present, this is typically the same as startTime, but may be
different if the Task has been restarted for reasons other than retry; for
example, if the Compute Node was rebooted during a retry, then the startTime is
updated but the lastRetryTime is not.
    requeueCount: number, # Required. When the user removes Compute Nodes from a Pool (by resizing/shrinking the
pool) or when the Job is being disabled, the user can specify that running
Tasks on the Compute Nodes be requeued for execution. This count tracks how
many times the Task has been requeued for these reasons.
    lastRequeueTime: string (date &amp; time), # Optional. This property is set only if the requeueCount is nonzero.
    result: &quot;success&quot; | &quot;failure&quot;, # Optional. If the value is &apos;failed&apos;, then the details of the failure can be found in the
failureInfo property.
  }, # Optional. Information about the execution of a Task.
  nodeInfo: {
    affinityId: string, # Optional. An identifier for the Node on which the Task ran, which can be passed when
adding a Task to request that the Task be scheduled on this Compute Node.
    nodeUrl: string, # Optional. The URL of the Compute Node on which the Task ran. 
    poolId: string, # Optional. The ID of the Pool on which the Task ran.
    nodeId: string, # Optional. The ID of the Compute Node on which the Task ran.
    taskRootDirectory: string, # Optional. The root directory of the Task on the Compute Node.
    taskRootDirectoryUrl: string, # Optional. The URL to the root directory of the Task on the Compute Node.
  }, # Optional. Information about the Compute Node on which a Task ran.
  multiInstanceSettings: {
    numberOfInstances: number, # Optional. If omitted, the default is 1.
    coordinationCommandLine: string, # Required. A typical coordination command line launches a background service and verifies
that the service is ready to process inter-node messages.
    commonResourceFiles: [ResourceFile], # Optional. The difference between common resource files and Task resource files is that
common resource files are downloaded for all subtasks including the primary,
whereas Task resource files are downloaded only for the primary. Also note that
these resource files are not downloaded to the Task working directory, but
instead are downloaded to the Task root directory (one directory above the
working directory).  There is a maximum size for the list of resource files. 
When the max size is exceeded, the request will fail and the response error
code will be RequestEntityTooLarge. If this occurs, the collection of
ResourceFiles must be reduced in size. This can be achieved using .zip files,
Application Packages, or Docker Containers.
  }, # Optional. Multi-instance Tasks are commonly used to support MPI Tasks. In the MPI case,
if any of the subtasks fail (for example due to exiting with a non-zero exit
code) the entire multi-instance Task fails. The multi-instance Task is then
terminated and retried, up to its retry limit.
  stats: {
    url: string, # Required. The URL of the statistics.
    startTime: string (date &amp; time), # Required. The start time of the time range covered by the statistics.
    lastUpdateTime: string (date &amp; time), # Required. The time at which the statistics were last updated. All statistics are limited
to the range between startTime and lastUpdateTime.
    userCPUTime: string (duration ISO 8601 Format), # Required. The total user mode CPU time (summed across all cores and all Compute Nodes)
consumed by the Task.
    kernelCPUTime: string (duration ISO 8601 Format), # Required. The total kernel mode CPU time (summed across all cores and all Compute Nodes)
consumed by the Task.
    wallClockTime: string (duration ISO 8601 Format), # Required. The wall clock time is the elapsed time from when the Task started running on a
Compute Node to when it finished (or to the last time the statistics were
updated, if the Task had not finished by then). If the Task was retried, this
includes the wall clock time of all the Task retries.
    readIOps: number, # Required. The total number of disk read operations made by the Task.
    writeIOps: number, # Required. The total number of disk write operations made by the Task.
    readIOGiB: number, # Required. The total gibibytes read from disk by the Task.
    writeIOGiB: number, # Required. The total gibibytes written to disk by the Task.
    waitTime: string (duration ISO 8601 Format), # Required. The total wait time of the Task. The wait time for a Task is defined as the
elapsed time between the creation of the Task and the start of Task execution.
(If the Task is retried due to failures, the wait time is the time to the most
recent Task execution.)
  }, # Optional. Resource usage statistics for a Task.
  dependsOn: {
    taskIds: [string], # Optional. The taskIds collection is limited to 64000 characters total (i.e. the combined
length of all Task IDs). If the taskIds collection exceeds the maximum length,
the Add Task request fails with error code TaskDependencyListTooLong. In this
case consider using Task ID ranges instead.
    taskIdRanges: [TaskIdRange], # Optional. The list of Task ID ranges that this Task depends on. All Tasks in all ranges
must complete successfully before the dependent Task can be scheduled.
  }, # Optional. This Task will not be scheduled until all Tasks that it depends on have
completed successfully. If any of those Tasks fail and exhaust their retry
counts, this Task will never be scheduled.
  applicationPackageReferences: [ApplicationPackageReference], # Optional. Application packages are downloaded and deployed to a shared directory, not the
Task working directory. Therefore, if a referenced package is already on the
Node, and is up to date, then it is not re-downloaded; the existing copy on the
Compute Node is used. If a referenced Package cannot be installed, for example
because the package has been deleted or because download failed, the Task
fails.
  authenticationTokenSettings: {
    access: [&quot;job&quot;], # Optional. The authentication token grants access to a limited set of Batch service
operations. Currently the only supported value for the access property is
&apos;job&apos;, which grants access to all operations related to the Job which contains
the Task.
  }, # Optional. If this property is set, the Batch service provides the Task with an
authentication token which can be used to authenticate Batch service operations
without requiring an Account access key. The token is provided via the
AZ_BATCH_AUTHENTICATION_TOKEN environment variable. The operations that the
Task can carry out using the token depend on the settings. For example, a Task
can request Job permissions in order to add other Tasks to the Job, or check
the status of the Job or of other Tasks under the Job.
}
</code>

</remarks>
    </member>
    <member name="Add(String,RequestContent,Int32,String,Boolean,String,RequestContext)">
<example>
This sample shows how to call Add with required parameters.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetTaskClient(<2022-10-01.16.0>);

var data = new {};

Response response = client.Add("<jobId>", RequestContent.Create(data));
Console.WriteLine(response.Status);
]]></code>
This sample shows how to call Add with all parameters and request content.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetTaskClient(<2022-10-01.16.0>);

var data = new {
    id = "<id>",
    displayName = "<displayName>",
    exitConditions = new {
        exitCodes = new[] {
            new {
                code = 1234,
                exitOptions = new {
                    jobAction = "none",
                    dependencyAction = "satisfy",
                },
            }
        },
        exitCodeRanges = new[] {
            new {
                start = 1234,
                end = 1234,
                exitOptions = new {
                    jobAction = "none",
                    dependencyAction = "satisfy",
                },
            }
        },
        preProcessingError = new {
            jobAction = "none",
            dependencyAction = "satisfy",
        },
        fileUploadError = new {
            jobAction = "none",
            dependencyAction = "satisfy",
        },
        default = new {
            jobAction = "none",
            dependencyAction = "satisfy",
        },
    },
    commandLine = "<commandLine>",
    containerSettings = new {
        containerRunOptions = "<containerRunOptions>",
        imageName = "<imageName>",
        registry = new {
            username = "<username>",
            password = "<password>",
            registryServer = "<registryServer>",
            identityReference = new {
                resourceId = "<resourceId>",
            },
        },
        workingDirectory = "taskWorkingDirectory",
    },
    resourceFiles = new[] {
        new {
            autoStorageContainerName = "<autoStorageContainerName>",
            storageContainerUrl = "<storageContainerUrl>",
            httpUrl = "<httpUrl>",
            blobPrefix = "<blobPrefix>",
            filePath = "<filePath>",
            fileMode = "<fileMode>",
            identityReference = new {
                resourceId = "<resourceId>",
            },
        }
    },
    outputFiles = new[] {
        new {
            filePattern = "<filePattern>",
            destination = new {
                container = new {
                    path = "<path>",
                    containerUrl = "<containerUrl>",
                    identityReference = new {
                        resourceId = "<resourceId>",
                    },
                    uploadHeaders = new[] {
                        new {
                            name = "<name>",
                            value = "<value>",
                        }
                    },
                },
            },
            uploadOptions = new {
                uploadCondition = "tasksuccess",
            },
        }
    },
    environmentSettings = new[] {
        new {
            name = "<name>",
            value = "<value>",
        }
    },
    affinityInfo = new {
        affinityId = "<affinityId>",
    },
    constraints = new {
        maxWallClockTime = PT1H23M45S,
        retentionTime = PT1H23M45S,
        maxTaskRetryCount = 1234,
    },
    requiredSlots = 1234,
    userIdentity = new {
        username = "<username>",
        autoUser = new {
            scope = "task",
            elevationLevel = "nonadmin",
        },
    },
    multiInstanceSettings = new {
        numberOfInstances = 1234,
        coordinationCommandLine = "<coordinationCommandLine>",
        commonResourceFiles = new[] {
            new {
                autoStorageContainerName = "<autoStorageContainerName>",
                storageContainerUrl = "<storageContainerUrl>",
                httpUrl = "<httpUrl>",
                blobPrefix = "<blobPrefix>",
                filePath = "<filePath>",
                fileMode = "<fileMode>",
                identityReference = new {
                    resourceId = "<resourceId>",
                },
            }
        },
    },
    dependsOn = new {
        taskIds = new[] {
            "<String>"
        },
        taskIdRanges = new[] {
            new {
                start = 1234,
                end = 1234,
            }
        },
    },
    applicationPackageReferences = new[] {
        new {
            applicationId = "<applicationId>",
            version = "<version>",
        }
    },
    authenticationTokenSettings = new {
        access = new[] {
            "job"
        },
    },
};

Response response = client.Add("<jobId>", RequestContent.Create(data), 1234, "<clientRequestId>", true, "<ocpDate>");
Console.WriteLine(response.Status);
]]></code>
</example>
<remarks>
The maximum lifetime of a Task from addition to completion is 180 days. If a
Task has not completed within 180 days of being added it will be terminated by
the Batch service and left in whatever state it was in at that time.

Below is the JSON schema for the request payload.

Request Body:

Schema for <c>BatchTask</c>:
<code>{
  id: string, # Optional. The ID can contain any combination of alphanumeric characters including hyphens
and underscores, and cannot contain more than 64 characters.
  displayName: string, # Optional. The display name need not be unique and can contain any Unicode characters up
to a maximum length of 1024.
  url: string, # Optional. The URL of the Task.
  eTag: string, # Optional. This is an opaque string. You can use it to detect whether the Task has changed
between requests. In particular, you can be pass the ETag when updating a Task
to specify that your changes should take effect only if nobody else has
modified the Task in the meantime.
  lastModified: string (date &amp; time), # Optional. The last modified time of the Task.
  creationTime: string (date &amp; time), # Optional. The creation time of the Task.
  exitConditions: {
    exitCodes: [ExitCodeMapping], # Optional. A list of individual Task exit codes and how the Batch service should respond
to them.
    exitCodeRanges: [ExitCodeRangeMapping], # Optional. A list of Task exit code ranges and how the Batch service should respond to
them.
    preProcessingError: {
      jobAction: &quot;none&quot; | &quot;disable&quot; | &quot;terminate&quot;, # Optional. The default is none for exit code 0 and terminate for all other exit
conditions. If the Job&apos;s onTaskFailed property is noaction, then specifying
this property returns an error and the add Task request fails with an invalid
property value error; if you are calling the REST API directly, the HTTP status
code is 400 (Bad Request).
      dependencyAction: &quot;satisfy&quot; | &quot;block&quot;, # Optional. Possible values are &apos;satisfy&apos; (allowing dependent tasks to progress) and
&apos;block&apos; (dependent tasks continue to wait). Batch does not yet support
cancellation of dependent tasks.
    }, # Optional. Specifies how the Batch service responds to a particular exit condition.
    fileUploadError: ExitOptions, # Optional. If the Task exited with an exit code that was specified via exitCodes or
exitCodeRanges, and then encountered a file upload error, then the action
specified by the exit code takes precedence.
    default: ExitOptions, # Optional. This value is used if the Task exits with any nonzero exit code not listed in
the exitCodes or exitCodeRanges collection, with a pre-processing error if the
preProcessingError property is not present, or with a file upload error if the
fileUploadError property is not present. If you want non-default behavior on
exit code 0, you must list it explicitly using the exitCodes or exitCodeRanges
collection.
  }, # Optional. How the Batch service should respond when the Task completes.
  state: &quot;active&quot; | &quot;preparing&quot; | &quot;running&quot; | &quot;completed&quot;, # Optional. The state of the Task.
  stateTransitionTime: string (date &amp; time), # Optional. The time at which the Task entered its current state.
  previousState: &quot;active&quot; | &quot;preparing&quot; | &quot;running&quot; | &quot;completed&quot;, # Optional. This property is not set if the Task is in its initial Active state.
  previousStateTransitionTime: string (date &amp; time), # Optional. This property is not set if the Task is in its initial Active state.
  commandLine: string, # Optional. For multi-instance Tasks, the command line is executed as the primary Task,
after the primary Task and all subtasks have finished executing the
coordination command line. The command line does not run under a shell, and
therefore cannot take advantage of shell features such as environment variable
expansion. If you want to take advantage of such features, you should invoke
the shell in the command line, for example using &quot;cmd /c MyCommand&quot; in
Windows or &quot;/bin/sh -c MyCommand&quot; in Linux. If the command line refers to
file paths, it should use a relative path (relative to the Task working
directory), or use the Batch provided environment variable
(https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).
  containerSettings: {
    containerRunOptions: string, # Optional. These additional options are supplied as arguments to the &quot;docker create&quot;
command, in addition to those controlled by the Batch Service.
    imageName: string, # Required. This is the full Image reference, as would be specified to &quot;docker pull&quot;. If
no tag is provided as part of the Image name, the tag &quot;:latest&quot; is used as a
default.
    registry: {
      username: string, # Optional. The user name to log into the registry server.
      password: string, # Optional. The password to log into the registry server.
      registryServer: string, # Optional. If omitted, the default is &quot;docker.io&quot;.
      identityReference: {
        resourceId: string, # Optional. The ARM resource id of the user assigned identity.
      }, # Optional. The reference to a user assigned identity associated with the Batch pool which
a compute node will use.
    }, # Optional. This setting can be omitted if was already provided at Pool creation.
    workingDirectory: &quot;taskWorkingDirectory&quot; | &quot;containerImageDefault&quot;, # Optional. The default is &apos;taskWorkingDirectory&apos;.
  }, # Optional. If the Pool that will run this Task has containerConfiguration set, this must
be set as well. If the Pool that will run this Task doesn&apos;t have
containerConfiguration set, this must not be set. When this is specified, all
directories recursively below the AZ_BATCH_NODE_ROOT_DIR (the root of Azure
Batch directories on the node) are mapped into the container, all Task
environment variables are mapped into the container, and the Task command line
is executed in the container. Files produced in the container outside of
AZ_BATCH_NODE_ROOT_DIR might not be reflected to the host disk, meaning that
Batch file APIs will not be able to access those files.
  resourceFiles: [
    {
      autoStorageContainerName: string, # Optional. The autoStorageContainerName, storageContainerUrl and httpUrl properties are
mutually exclusive and one of them must be specified.
      storageContainerUrl: string, # Optional. The autoStorageContainerName, storageContainerUrl and httpUrl properties are
mutually exclusive and one of them must be specified. This URL must be readable
and listable from compute nodes. There are three ways to get such a URL for a
container in Azure storage: include a Shared Access Signature (SAS) granting
read and list permissions on the container, use a managed identity with read
and list permissions, or set the ACL for the container to allow public access.
      httpUrl: string, # Optional. The autoStorageContainerName, storageContainerUrl and httpUrl properties are
mutually exclusive and one of them must be specified. If the URL points to
Azure Blob Storage, it must be readable from compute nodes. There are three
ways to get such a URL for a blob in Azure storage: include a Shared Access
Signature (SAS) granting read permissions on the blob, use a managed identity
with read permission, or set the ACL for the blob or its container to allow
public access.
      blobPrefix: string, # Optional. The property is valid only when autoStorageContainerName or storageContainerUrl
is used. This prefix can be a partial filename or a subdirectory. If a prefix
is not specified, all the files in the container will be downloaded.
      filePath: string, # Optional. If the httpUrl property is specified, the filePath is required and describes
the path which the file will be downloaded to, including the filename.
Otherwise, if the autoStorageContainerName or storageContainerUrl property is
specified, filePath is optional and is the directory to download the files to.
In the case where filePath is used as a directory, any directory structure
already associated with the input data will be retained in full and appended to
the specified filePath directory. The specified relative path cannot break out
of the Task&apos;s working directory (for example by using &apos;..&apos;).
      fileMode: string, # Optional. This property applies only to files being downloaded to Linux Compute Nodes. It
will be ignored if it is specified for a resourceFile which will be downloaded
to a Windows Compute Node. If this property is not specified for a Linux
Compute Node, then a default value of 0770 is applied to the file.
      identityReference: ComputeNodeIdentityReference, # Optional. The reference to a user assigned identity associated with the Batch pool which
a compute node will use.
    }
  ], # Optional. For multi-instance Tasks, the resource files will only be downloaded to the
Compute Node on which the primary Task is executed. There is a maximum size for
the list of resource files.  When the max size is exceeded, the request will
fail and the response error code will be RequestEntityTooLarge. If this occurs,
the collection of ResourceFiles must be reduced in size. This can be achieved
using .zip files, Application Packages, or Docker Containers.
  outputFiles: [OutputFile], # Optional. For multi-instance Tasks, the files will only be uploaded from the Compute Node
on which the primary Task is executed.
  environmentSettings: [EnvironmentSetting], # Optional. A list of environment variable settings for the Task.
  affinityInfo: {
    affinityId: string, # Required. You can pass the affinityId of a Node to indicate that this Task needs to run
on that Compute Node. Note that this is just a soft affinity. If the target
Compute Node is busy or unavailable at the time the Task is scheduled, then the
Task will be scheduled elsewhere.
  }, # Optional. A locality hint that can be used by the Batch service to select a Compute Node
on which to start a Task.
  constraints: {
    maxWallClockTime: string (duration ISO 8601 Format), # Optional. If this is not specified, there is no time limit on how long the Task may run.
    retentionTime: string (duration ISO 8601 Format), # Optional. The default is 7 days, i.e. the Task directory will be retained for 7 days
unless the Compute Node is removed or the Job is deleted.
    maxTaskRetryCount: number, # Optional. Note that this value specifically controls the number of retries for the Task
executable due to a nonzero exit code. The Batch service will try the Task
once, and may then retry up to this limit. For example, if the maximum retry
count is 3, Batch tries the Task up to 4 times (one initial try and 3 retries).
If the maximum retry count is 0, the Batch service does not retry the Task
after the first attempt. If the maximum retry count is -1, the Batch service
retries the Task without limit, however this is not recommended for a start
task or any task. The default value is 0 (no retries)
  }, # Optional. Execution constraints to apply to a Task.
  requiredSlots: number, # Optional. The default is 1. A Task can only be scheduled to run on a compute node if the
node has enough free scheduling slots available. For multi-instance Tasks, this
must be 1.
  userIdentity: {
    username: string, # Optional. The userName and autoUser properties are mutually exclusive; you must specify
one but not both.
    autoUser: {
      scope: &quot;task&quot; | &quot;pool&quot;, # Optional. The default value is pool. If the pool is running Windows a value of Task
should be specified if stricter isolation between tasks is required. For
example, if the task mutates the registry in a way which could impact other
tasks, or if certificates have been specified on the pool which should not be
accessible by normal tasks but should be accessible by StartTasks.
      elevationLevel: &quot;nonadmin&quot; | &quot;admin&quot;, # Optional. The default value is nonAdmin.
    }, # Optional. The userName and autoUser properties are mutually exclusive; you must specify
one but not both.
  }, # Optional. If omitted, the Task runs as a non-administrative user unique to the Task.
  executionInfo: {
    startTime: string (date &amp; time), # Optional. &apos;Running&apos; corresponds to the running state, so if the Task specifies resource
files or Packages, then the start time reflects the time at which the Task
started downloading or deploying these. If the Task has been restarted or
retried, this is the most recent time at which the Task started running. This
property is present only for Tasks that are in the running or completed state.
    endTime: string (date &amp; time), # Optional. This property is set only if the Task is in the Completed state.
    exitCode: number, # Optional. This property is set only if the Task is in the completed state. In general,
the exit code for a process reflects the specific convention implemented by the
application developer for that process. If you use the exit code value to make
decisions in your code, be sure that you know the exit code convention used by
the application process. However, if the Batch service terminates the Task (due
to timeout, or user termination via the API) you may see an operating
system-defined exit code.
    containerInfo: {
      containerId: string, # Optional. The ID of the container.
      state: string, # Optional. This is the state of the container according to the Docker service. It is
equivalent to the status field returned by &quot;docker inspect&quot;.
      error: string, # Optional. This is the detailed error string from the Docker service, if available. It is
equivalent to the error field returned by &quot;docker inspect&quot;.
    }, # Optional. This property is set only if the Task runs in a container context.
    failureInfo: {
      category: &quot;usererror&quot; | &quot;servererror&quot;, # Required. The category of the error.
      code: string, # Optional. An identifier for the Task error. Codes are invariant and are intended to be
consumed programmatically.
      message: string, # Optional. A message describing the Task error, intended to be suitable for display in a
user interface.
      details: [NameValuePair], # Optional. A list of additional details related to the error.
    }, # Optional. This property is set only if the Task is in the completed state and encountered
a failure.
    retryCount: number, # Required. Task application failures (non-zero exit code) are retried, pre-processing
errors (the Task could not be run) and file upload errors are not retried. The
Batch service will retry the Task up to the limit specified by the constraints.
    lastRetryTime: string (date &amp; time), # Optional. This element is present only if the Task was retried (i.e. retryCount is
nonzero). If present, this is typically the same as startTime, but may be
different if the Task has been restarted for reasons other than retry; for
example, if the Compute Node was rebooted during a retry, then the startTime is
updated but the lastRetryTime is not.
    requeueCount: number, # Required. When the user removes Compute Nodes from a Pool (by resizing/shrinking the
pool) or when the Job is being disabled, the user can specify that running
Tasks on the Compute Nodes be requeued for execution. This count tracks how
many times the Task has been requeued for these reasons.
    lastRequeueTime: string (date &amp; time), # Optional. This property is set only if the requeueCount is nonzero.
    result: &quot;success&quot; | &quot;failure&quot;, # Optional. If the value is &apos;failed&apos;, then the details of the failure can be found in the
failureInfo property.
  }, # Optional. Information about the execution of a Task.
  nodeInfo: {
    affinityId: string, # Optional. An identifier for the Node on which the Task ran, which can be passed when
adding a Task to request that the Task be scheduled on this Compute Node.
    nodeUrl: string, # Optional. The URL of the Compute Node on which the Task ran. 
    poolId: string, # Optional. The ID of the Pool on which the Task ran.
    nodeId: string, # Optional. The ID of the Compute Node on which the Task ran.
    taskRootDirectory: string, # Optional. The root directory of the Task on the Compute Node.
    taskRootDirectoryUrl: string, # Optional. The URL to the root directory of the Task on the Compute Node.
  }, # Optional. Information about the Compute Node on which a Task ran.
  multiInstanceSettings: {
    numberOfInstances: number, # Optional. If omitted, the default is 1.
    coordinationCommandLine: string, # Required. A typical coordination command line launches a background service and verifies
that the service is ready to process inter-node messages.
    commonResourceFiles: [ResourceFile], # Optional. The difference between common resource files and Task resource files is that
common resource files are downloaded for all subtasks including the primary,
whereas Task resource files are downloaded only for the primary. Also note that
these resource files are not downloaded to the Task working directory, but
instead are downloaded to the Task root directory (one directory above the
working directory).  There is a maximum size for the list of resource files. 
When the max size is exceeded, the request will fail and the response error
code will be RequestEntityTooLarge. If this occurs, the collection of
ResourceFiles must be reduced in size. This can be achieved using .zip files,
Application Packages, or Docker Containers.
  }, # Optional. Multi-instance Tasks are commonly used to support MPI Tasks. In the MPI case,
if any of the subtasks fail (for example due to exiting with a non-zero exit
code) the entire multi-instance Task fails. The multi-instance Task is then
terminated and retried, up to its retry limit.
  stats: {
    url: string, # Required. The URL of the statistics.
    startTime: string (date &amp; time), # Required. The start time of the time range covered by the statistics.
    lastUpdateTime: string (date &amp; time), # Required. The time at which the statistics were last updated. All statistics are limited
to the range between startTime and lastUpdateTime.
    userCPUTime: string (duration ISO 8601 Format), # Required. The total user mode CPU time (summed across all cores and all Compute Nodes)
consumed by the Task.
    kernelCPUTime: string (duration ISO 8601 Format), # Required. The total kernel mode CPU time (summed across all cores and all Compute Nodes)
consumed by the Task.
    wallClockTime: string (duration ISO 8601 Format), # Required. The wall clock time is the elapsed time from when the Task started running on a
Compute Node to when it finished (or to the last time the statistics were
updated, if the Task had not finished by then). If the Task was retried, this
includes the wall clock time of all the Task retries.
    readIOps: number, # Required. The total number of disk read operations made by the Task.
    writeIOps: number, # Required. The total number of disk write operations made by the Task.
    readIOGiB: number, # Required. The total gibibytes read from disk by the Task.
    writeIOGiB: number, # Required. The total gibibytes written to disk by the Task.
    waitTime: string (duration ISO 8601 Format), # Required. The total wait time of the Task. The wait time for a Task is defined as the
elapsed time between the creation of the Task and the start of Task execution.
(If the Task is retried due to failures, the wait time is the time to the most
recent Task execution.)
  }, # Optional. Resource usage statistics for a Task.
  dependsOn: {
    taskIds: [string], # Optional. The taskIds collection is limited to 64000 characters total (i.e. the combined
length of all Task IDs). If the taskIds collection exceeds the maximum length,
the Add Task request fails with error code TaskDependencyListTooLong. In this
case consider using Task ID ranges instead.
    taskIdRanges: [TaskIdRange], # Optional. The list of Task ID ranges that this Task depends on. All Tasks in all ranges
must complete successfully before the dependent Task can be scheduled.
  }, # Optional. This Task will not be scheduled until all Tasks that it depends on have
completed successfully. If any of those Tasks fail and exhaust their retry
counts, this Task will never be scheduled.
  applicationPackageReferences: [ApplicationPackageReference], # Optional. Application packages are downloaded and deployed to a shared directory, not the
Task working directory. Therefore, if a referenced package is already on the
Node, and is up to date, then it is not re-downloaded; the existing copy on the
Compute Node is used. If a referenced Package cannot be installed, for example
because the package has been deleted or because download failed, the Task
fails.
  authenticationTokenSettings: {
    access: [&quot;job&quot;], # Optional. The authentication token grants access to a limited set of Batch service
operations. Currently the only supported value for the access property is
&apos;job&apos;, which grants access to all operations related to the Job which contains
the Task.
  }, # Optional. If this property is set, the Batch service provides the Task with an
authentication token which can be used to authenticate Batch service operations
without requiring an Account access key. The token is provided via the
AZ_BATCH_AUTHENTICATION_TOKEN environment variable. The operations that the
Task can carry out using the token depend on the settings. For example, a Task
can request Job permissions in order to add other Tasks to the Job, or check
the status of the Job or of other Tasks under the Job.
}
</code>

</remarks>
    </member>
    <member name="GetTasksAsync(String,Int32,String,Int32,String,Boolean,String,String,String,RequestContext)">
<example>
This sample shows how to call GetTasksAsync with required parameters and parse the result.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetTaskClient(<2022-10-01.16.0>);

Response response = await client.GetTasksAsync("<jobId>");

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.ToString());
]]></code>
This sample shows how to call GetTasksAsync with all parameters, and how to parse the result.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetTaskClient(<2022-10-01.16.0>);

Response response = await client.GetTasksAsync("<jobId>", 1234, "<ocpDate>", 1234, "<clientRequestId>", true, "<filter>", "<select>", "<expand>");

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.GetProperty("value")[0].GetProperty("id").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("displayName").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("url").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("eTag").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("lastModified").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("creationTime").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("exitConditions").GetProperty("exitCodes")[0].GetProperty("code").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("exitConditions").GetProperty("exitCodes")[0].GetProperty("exitOptions").GetProperty("jobAction").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("exitConditions").GetProperty("exitCodes")[0].GetProperty("exitOptions").GetProperty("dependencyAction").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("exitConditions").GetProperty("exitCodeRanges")[0].GetProperty("start").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("exitConditions").GetProperty("exitCodeRanges")[0].GetProperty("end").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("exitConditions").GetProperty("exitCodeRanges")[0].GetProperty("exitOptions").GetProperty("jobAction").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("exitConditions").GetProperty("exitCodeRanges")[0].GetProperty("exitOptions").GetProperty("dependencyAction").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("exitConditions").GetProperty("preProcessingError").GetProperty("jobAction").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("exitConditions").GetProperty("preProcessingError").GetProperty("dependencyAction").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("exitConditions").GetProperty("fileUploadError").GetProperty("jobAction").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("exitConditions").GetProperty("fileUploadError").GetProperty("dependencyAction").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("exitConditions").GetProperty("default").GetProperty("jobAction").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("exitConditions").GetProperty("default").GetProperty("dependencyAction").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("state").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("stateTransitionTime").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("previousState").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("previousStateTransitionTime").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("commandLine").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("containerSettings").GetProperty("containerRunOptions").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("containerSettings").GetProperty("imageName").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("containerSettings").GetProperty("registry").GetProperty("username").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("containerSettings").GetProperty("registry").GetProperty("password").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("containerSettings").GetProperty("registry").GetProperty("registryServer").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("containerSettings").GetProperty("registry").GetProperty("identityReference").GetProperty("resourceId").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("containerSettings").GetProperty("workingDirectory").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("resourceFiles")[0].GetProperty("autoStorageContainerName").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("resourceFiles")[0].GetProperty("storageContainerUrl").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("resourceFiles")[0].GetProperty("httpUrl").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("resourceFiles")[0].GetProperty("blobPrefix").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("resourceFiles")[0].GetProperty("filePath").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("resourceFiles")[0].GetProperty("fileMode").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("resourceFiles")[0].GetProperty("identityReference").GetProperty("resourceId").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("outputFiles")[0].GetProperty("filePattern").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("outputFiles")[0].GetProperty("destination").GetProperty("container").GetProperty("path").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("outputFiles")[0].GetProperty("destination").GetProperty("container").GetProperty("containerUrl").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("outputFiles")[0].GetProperty("destination").GetProperty("container").GetProperty("identityReference").GetProperty("resourceId").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("outputFiles")[0].GetProperty("destination").GetProperty("container").GetProperty("uploadHeaders")[0].GetProperty("name").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("outputFiles")[0].GetProperty("destination").GetProperty("container").GetProperty("uploadHeaders")[0].GetProperty("value").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("outputFiles")[0].GetProperty("uploadOptions").GetProperty("uploadCondition").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("environmentSettings")[0].GetProperty("name").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("environmentSettings")[0].GetProperty("value").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("affinityInfo").GetProperty("affinityId").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("constraints").GetProperty("maxWallClockTime").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("constraints").GetProperty("retentionTime").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("constraints").GetProperty("maxTaskRetryCount").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("requiredSlots").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("userIdentity").GetProperty("username").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("userIdentity").GetProperty("autoUser").GetProperty("scope").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("userIdentity").GetProperty("autoUser").GetProperty("elevationLevel").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("executionInfo").GetProperty("startTime").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("executionInfo").GetProperty("endTime").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("executionInfo").GetProperty("exitCode").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("executionInfo").GetProperty("containerInfo").GetProperty("containerId").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("executionInfo").GetProperty("containerInfo").GetProperty("state").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("executionInfo").GetProperty("containerInfo").GetProperty("error").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("executionInfo").GetProperty("failureInfo").GetProperty("category").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("executionInfo").GetProperty("failureInfo").GetProperty("code").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("executionInfo").GetProperty("failureInfo").GetProperty("message").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("executionInfo").GetProperty("failureInfo").GetProperty("details")[0].GetProperty("name").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("executionInfo").GetProperty("failureInfo").GetProperty("details")[0].GetProperty("value").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("executionInfo").GetProperty("retryCount").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("executionInfo").GetProperty("lastRetryTime").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("executionInfo").GetProperty("requeueCount").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("executionInfo").GetProperty("lastRequeueTime").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("executionInfo").GetProperty("result").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("nodeInfo").GetProperty("affinityId").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("nodeInfo").GetProperty("nodeUrl").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("nodeInfo").GetProperty("poolId").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("nodeInfo").GetProperty("nodeId").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("nodeInfo").GetProperty("taskRootDirectory").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("nodeInfo").GetProperty("taskRootDirectoryUrl").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("multiInstanceSettings").GetProperty("numberOfInstances").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("multiInstanceSettings").GetProperty("coordinationCommandLine").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("multiInstanceSettings").GetProperty("commonResourceFiles")[0].GetProperty("autoStorageContainerName").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("multiInstanceSettings").GetProperty("commonResourceFiles")[0].GetProperty("storageContainerUrl").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("multiInstanceSettings").GetProperty("commonResourceFiles")[0].GetProperty("httpUrl").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("multiInstanceSettings").GetProperty("commonResourceFiles")[0].GetProperty("blobPrefix").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("multiInstanceSettings").GetProperty("commonResourceFiles")[0].GetProperty("filePath").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("multiInstanceSettings").GetProperty("commonResourceFiles")[0].GetProperty("fileMode").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("multiInstanceSettings").GetProperty("commonResourceFiles")[0].GetProperty("identityReference").GetProperty("resourceId").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("stats").GetProperty("url").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("stats").GetProperty("startTime").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("stats").GetProperty("lastUpdateTime").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("stats").GetProperty("userCPUTime").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("stats").GetProperty("kernelCPUTime").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("stats").GetProperty("wallClockTime").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("stats").GetProperty("readIOps").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("stats").GetProperty("writeIOps").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("stats").GetProperty("readIOGiB").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("stats").GetProperty("writeIOGiB").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("stats").GetProperty("waitTime").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("dependsOn").GetProperty("taskIds")[0].ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("dependsOn").GetProperty("taskIdRanges")[0].GetProperty("start").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("dependsOn").GetProperty("taskIdRanges")[0].GetProperty("end").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("applicationPackageReferences")[0].GetProperty("applicationId").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("applicationPackageReferences")[0].GetProperty("version").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("authenticationTokenSettings").GetProperty("access")[0].ToString());
Console.WriteLine(result.GetProperty("odata.nextLink").ToString());
]]></code>
</example>
<remarks>
For multi-instance Tasks, information such as affinityId, executionInfo and
nodeInfo refer to the primary Task. Use the list subtasks API to retrieve
information about subtasks.

Below is the JSON schema for the response payload.

Response Body:

Schema for <c>BatchTaskListResult</c>:
<code>{
  value: [
    {
      id: string, # Optional. The ID can contain any combination of alphanumeric characters including hyphens
and underscores, and cannot contain more than 64 characters.
      displayName: string, # Optional. The display name need not be unique and can contain any Unicode characters up
to a maximum length of 1024.
      url: string, # Optional. The URL of the Task.
      eTag: string, # Optional. This is an opaque string. You can use it to detect whether the Task has changed
between requests. In particular, you can be pass the ETag when updating a Task
to specify that your changes should take effect only if nobody else has
modified the Task in the meantime.
      lastModified: string (date &amp; time), # Optional. The last modified time of the Task.
      creationTime: string (date &amp; time), # Optional. The creation time of the Task.
      exitConditions: {
        exitCodes: [ExitCodeMapping], # Optional. A list of individual Task exit codes and how the Batch service should respond
to them.
        exitCodeRanges: [ExitCodeRangeMapping], # Optional. A list of Task exit code ranges and how the Batch service should respond to
them.
        preProcessingError: {
          jobAction: &quot;none&quot; | &quot;disable&quot; | &quot;terminate&quot;, # Optional. The default is none for exit code 0 and terminate for all other exit
conditions. If the Job&apos;s onTaskFailed property is noaction, then specifying
this property returns an error and the add Task request fails with an invalid
property value error; if you are calling the REST API directly, the HTTP status
code is 400 (Bad Request).
          dependencyAction: &quot;satisfy&quot; | &quot;block&quot;, # Optional. Possible values are &apos;satisfy&apos; (allowing dependent tasks to progress) and
&apos;block&apos; (dependent tasks continue to wait). Batch does not yet support
cancellation of dependent tasks.
        }, # Optional. Specifies how the Batch service responds to a particular exit condition.
        fileUploadError: ExitOptions, # Optional. If the Task exited with an exit code that was specified via exitCodes or
exitCodeRanges, and then encountered a file upload error, then the action
specified by the exit code takes precedence.
        default: ExitOptions, # Optional. This value is used if the Task exits with any nonzero exit code not listed in
the exitCodes or exitCodeRanges collection, with a pre-processing error if the
preProcessingError property is not present, or with a file upload error if the
fileUploadError property is not present. If you want non-default behavior on
exit code 0, you must list it explicitly using the exitCodes or exitCodeRanges
collection.
      }, # Optional. How the Batch service should respond when the Task completes.
      state: &quot;active&quot; | &quot;preparing&quot; | &quot;running&quot; | &quot;completed&quot;, # Optional. The state of the Task.
      stateTransitionTime: string (date &amp; time), # Optional. The time at which the Task entered its current state.
      previousState: &quot;active&quot; | &quot;preparing&quot; | &quot;running&quot; | &quot;completed&quot;, # Optional. This property is not set if the Task is in its initial Active state.
      previousStateTransitionTime: string (date &amp; time), # Optional. This property is not set if the Task is in its initial Active state.
      commandLine: string, # Optional. For multi-instance Tasks, the command line is executed as the primary Task,
after the primary Task and all subtasks have finished executing the
coordination command line. The command line does not run under a shell, and
therefore cannot take advantage of shell features such as environment variable
expansion. If you want to take advantage of such features, you should invoke
the shell in the command line, for example using &quot;cmd /c MyCommand&quot; in
Windows or &quot;/bin/sh -c MyCommand&quot; in Linux. If the command line refers to
file paths, it should use a relative path (relative to the Task working
directory), or use the Batch provided environment variable
(https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).
      containerSettings: {
        containerRunOptions: string, # Optional. These additional options are supplied as arguments to the &quot;docker create&quot;
command, in addition to those controlled by the Batch Service.
        imageName: string, # Required. This is the full Image reference, as would be specified to &quot;docker pull&quot;. If
no tag is provided as part of the Image name, the tag &quot;:latest&quot; is used as a
default.
        registry: {
          username: string, # Optional. The user name to log into the registry server.
          password: string, # Optional. The password to log into the registry server.
          registryServer: string, # Optional. If omitted, the default is &quot;docker.io&quot;.
          identityReference: {
            resourceId: string, # Optional. The ARM resource id of the user assigned identity.
          }, # Optional. The reference to a user assigned identity associated with the Batch pool which
a compute node will use.
        }, # Optional. This setting can be omitted if was already provided at Pool creation.
        workingDirectory: &quot;taskWorkingDirectory&quot; | &quot;containerImageDefault&quot;, # Optional. The default is &apos;taskWorkingDirectory&apos;.
      }, # Optional. If the Pool that will run this Task has containerConfiguration set, this must
be set as well. If the Pool that will run this Task doesn&apos;t have
containerConfiguration set, this must not be set. When this is specified, all
directories recursively below the AZ_BATCH_NODE_ROOT_DIR (the root of Azure
Batch directories on the node) are mapped into the container, all Task
environment variables are mapped into the container, and the Task command line
is executed in the container. Files produced in the container outside of
AZ_BATCH_NODE_ROOT_DIR might not be reflected to the host disk, meaning that
Batch file APIs will not be able to access those files.
      resourceFiles: [ResourceFile], # Optional. For multi-instance Tasks, the resource files will only be downloaded to the
Compute Node on which the primary Task is executed. There is a maximum size for
the list of resource files.  When the max size is exceeded, the request will
fail and the response error code will be RequestEntityTooLarge. If this occurs,
the collection of ResourceFiles must be reduced in size. This can be achieved
using .zip files, Application Packages, or Docker Containers.
      outputFiles: [OutputFile], # Optional. For multi-instance Tasks, the files will only be uploaded from the Compute Node
on which the primary Task is executed.
      environmentSettings: [EnvironmentSetting], # Optional. A list of environment variable settings for the Task.
      affinityInfo: {
        affinityId: string, # Required. You can pass the affinityId of a Node to indicate that this Task needs to run
on that Compute Node. Note that this is just a soft affinity. If the target
Compute Node is busy or unavailable at the time the Task is scheduled, then the
Task will be scheduled elsewhere.
      }, # Optional. A locality hint that can be used by the Batch service to select a Compute Node
on which to start a Task.
      constraints: {
        maxWallClockTime: string (duration ISO 8601 Format), # Optional. If this is not specified, there is no time limit on how long the Task may run.
        retentionTime: string (duration ISO 8601 Format), # Optional. The default is 7 days, i.e. the Task directory will be retained for 7 days
unless the Compute Node is removed or the Job is deleted.
        maxTaskRetryCount: number, # Optional. Note that this value specifically controls the number of retries for the Task
executable due to a nonzero exit code. The Batch service will try the Task
once, and may then retry up to this limit. For example, if the maximum retry
count is 3, Batch tries the Task up to 4 times (one initial try and 3 retries).
If the maximum retry count is 0, the Batch service does not retry the Task
after the first attempt. If the maximum retry count is -1, the Batch service
retries the Task without limit, however this is not recommended for a start
task or any task. The default value is 0 (no retries)
      }, # Optional. Execution constraints to apply to a Task.
      requiredSlots: number, # Optional. The default is 1. A Task can only be scheduled to run on a compute node if the
node has enough free scheduling slots available. For multi-instance Tasks, this
must be 1.
      userIdentity: {
        username: string, # Optional. The userName and autoUser properties are mutually exclusive; you must specify
one but not both.
        autoUser: {
          scope: &quot;task&quot; | &quot;pool&quot;, # Optional. The default value is pool. If the pool is running Windows a value of Task
should be specified if stricter isolation between tasks is required. For
example, if the task mutates the registry in a way which could impact other
tasks, or if certificates have been specified on the pool which should not be
accessible by normal tasks but should be accessible by StartTasks.
          elevationLevel: &quot;nonadmin&quot; | &quot;admin&quot;, # Optional. The default value is nonAdmin.
        }, # Optional. The userName and autoUser properties are mutually exclusive; you must specify
one but not both.
      }, # Optional. If omitted, the Task runs as a non-administrative user unique to the Task.
      executionInfo: {
        startTime: string (date &amp; time), # Optional. &apos;Running&apos; corresponds to the running state, so if the Task specifies resource
files or Packages, then the start time reflects the time at which the Task
started downloading or deploying these. If the Task has been restarted or
retried, this is the most recent time at which the Task started running. This
property is present only for Tasks that are in the running or completed state.
        endTime: string (date &amp; time), # Optional. This property is set only if the Task is in the Completed state.
        exitCode: number, # Optional. This property is set only if the Task is in the completed state. In general,
the exit code for a process reflects the specific convention implemented by the
application developer for that process. If you use the exit code value to make
decisions in your code, be sure that you know the exit code convention used by
the application process. However, if the Batch service terminates the Task (due
to timeout, or user termination via the API) you may see an operating
system-defined exit code.
        containerInfo: {
          containerId: string, # Optional. The ID of the container.
          state: string, # Optional. This is the state of the container according to the Docker service. It is
equivalent to the status field returned by &quot;docker inspect&quot;.
          error: string, # Optional. This is the detailed error string from the Docker service, if available. It is
equivalent to the error field returned by &quot;docker inspect&quot;.
        }, # Optional. This property is set only if the Task runs in a container context.
        failureInfo: {
          category: &quot;usererror&quot; | &quot;servererror&quot;, # Required. The category of the error.
          code: string, # Optional. An identifier for the Task error. Codes are invariant and are intended to be
consumed programmatically.
          message: string, # Optional. A message describing the Task error, intended to be suitable for display in a
user interface.
          details: [NameValuePair], # Optional. A list of additional details related to the error.
        }, # Optional. This property is set only if the Task is in the completed state and encountered
a failure.
        retryCount: number, # Required. Task application failures (non-zero exit code) are retried, pre-processing
errors (the Task could not be run) and file upload errors are not retried. The
Batch service will retry the Task up to the limit specified by the constraints.
        lastRetryTime: string (date &amp; time), # Optional. This element is present only if the Task was retried (i.e. retryCount is
nonzero). If present, this is typically the same as startTime, but may be
different if the Task has been restarted for reasons other than retry; for
example, if the Compute Node was rebooted during a retry, then the startTime is
updated but the lastRetryTime is not.
        requeueCount: number, # Required. When the user removes Compute Nodes from a Pool (by resizing/shrinking the
pool) or when the Job is being disabled, the user can specify that running
Tasks on the Compute Nodes be requeued for execution. This count tracks how
many times the Task has been requeued for these reasons.
        lastRequeueTime: string (date &amp; time), # Optional. This property is set only if the requeueCount is nonzero.
        result: &quot;success&quot; | &quot;failure&quot;, # Optional. If the value is &apos;failed&apos;, then the details of the failure can be found in the
failureInfo property.
      }, # Optional. Information about the execution of a Task.
      nodeInfo: {
        affinityId: string, # Optional. An identifier for the Node on which the Task ran, which can be passed when
adding a Task to request that the Task be scheduled on this Compute Node.
        nodeUrl: string, # Optional. The URL of the Compute Node on which the Task ran. 
        poolId: string, # Optional. The ID of the Pool on which the Task ran.
        nodeId: string, # Optional. The ID of the Compute Node on which the Task ran.
        taskRootDirectory: string, # Optional. The root directory of the Task on the Compute Node.
        taskRootDirectoryUrl: string, # Optional. The URL to the root directory of the Task on the Compute Node.
      }, # Optional. Information about the Compute Node on which a Task ran.
      multiInstanceSettings: {
        numberOfInstances: number, # Optional. If omitted, the default is 1.
        coordinationCommandLine: string, # Required. A typical coordination command line launches a background service and verifies
that the service is ready to process inter-node messages.
        commonResourceFiles: [ResourceFile], # Optional. The difference between common resource files and Task resource files is that
common resource files are downloaded for all subtasks including the primary,
whereas Task resource files are downloaded only for the primary. Also note that
these resource files are not downloaded to the Task working directory, but
instead are downloaded to the Task root directory (one directory above the
working directory).  There is a maximum size for the list of resource files. 
When the max size is exceeded, the request will fail and the response error
code will be RequestEntityTooLarge. If this occurs, the collection of
ResourceFiles must be reduced in size. This can be achieved using .zip files,
Application Packages, or Docker Containers.
      }, # Optional. Multi-instance Tasks are commonly used to support MPI Tasks. In the MPI case,
if any of the subtasks fail (for example due to exiting with a non-zero exit
code) the entire multi-instance Task fails. The multi-instance Task is then
terminated and retried, up to its retry limit.
      stats: {
        url: string, # Required. The URL of the statistics.
        startTime: string (date &amp; time), # Required. The start time of the time range covered by the statistics.
        lastUpdateTime: string (date &amp; time), # Required. The time at which the statistics were last updated. All statistics are limited
to the range between startTime and lastUpdateTime.
        userCPUTime: string (duration ISO 8601 Format), # Required. The total user mode CPU time (summed across all cores and all Compute Nodes)
consumed by the Task.
        kernelCPUTime: string (duration ISO 8601 Format), # Required. The total kernel mode CPU time (summed across all cores and all Compute Nodes)
consumed by the Task.
        wallClockTime: string (duration ISO 8601 Format), # Required. The wall clock time is the elapsed time from when the Task started running on a
Compute Node to when it finished (or to the last time the statistics were
updated, if the Task had not finished by then). If the Task was retried, this
includes the wall clock time of all the Task retries.
        readIOps: number, # Required. The total number of disk read operations made by the Task.
        writeIOps: number, # Required. The total number of disk write operations made by the Task.
        readIOGiB: number, # Required. The total gibibytes read from disk by the Task.
        writeIOGiB: number, # Required. The total gibibytes written to disk by the Task.
        waitTime: string (duration ISO 8601 Format), # Required. The total wait time of the Task. The wait time for a Task is defined as the
elapsed time between the creation of the Task and the start of Task execution.
(If the Task is retried due to failures, the wait time is the time to the most
recent Task execution.)
      }, # Optional. Resource usage statistics for a Task.
      dependsOn: {
        taskIds: [string], # Optional. The taskIds collection is limited to 64000 characters total (i.e. the combined
length of all Task IDs). If the taskIds collection exceeds the maximum length,
the Add Task request fails with error code TaskDependencyListTooLong. In this
case consider using Task ID ranges instead.
        taskIdRanges: [TaskIdRange], # Optional. The list of Task ID ranges that this Task depends on. All Tasks in all ranges
must complete successfully before the dependent Task can be scheduled.
      }, # Optional. This Task will not be scheduled until all Tasks that it depends on have
completed successfully. If any of those Tasks fail and exhaust their retry
counts, this Task will never be scheduled.
      applicationPackageReferences: [ApplicationPackageReference], # Optional. Application packages are downloaded and deployed to a shared directory, not the
Task working directory. Therefore, if a referenced package is already on the
Node, and is up to date, then it is not re-downloaded; the existing copy on the
Compute Node is used. If a referenced Package cannot be installed, for example
because the package has been deleted or because download failed, the Task
fails.
      authenticationTokenSettings: {
        access: [&quot;job&quot;], # Optional. The authentication token grants access to a limited set of Batch service
operations. Currently the only supported value for the access property is
&apos;job&apos;, which grants access to all operations related to the Job which contains
the Task.
      }, # Optional. If this property is set, the Batch service provides the Task with an
authentication token which can be used to authenticate Batch service operations
without requiring an Account access key. The token is provided via the
AZ_BATCH_AUTHENTICATION_TOKEN environment variable. The operations that the
Task can carry out using the token depend on the settings. For example, a Task
can request Job permissions in order to add other Tasks to the Job, or check
the status of the Job or of other Tasks under the Job.
    }
  ], # Optional. The list of Tasks.
  odata.nextLink: string, # Optional. The URL to get the next set of results.
}
</code>

</remarks>
    </member>
    <member name="GetTasks(String,Int32,String,Int32,String,Boolean,String,String,String,RequestContext)">
<example>
This sample shows how to call GetTasks with required parameters and parse the result.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetTaskClient(<2022-10-01.16.0>);

Response response = client.GetTasks("<jobId>");

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.ToString());
]]></code>
This sample shows how to call GetTasks with all parameters, and how to parse the result.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetTaskClient(<2022-10-01.16.0>);

Response response = client.GetTasks("<jobId>", 1234, "<ocpDate>", 1234, "<clientRequestId>", true, "<filter>", "<select>", "<expand>");

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.GetProperty("value")[0].GetProperty("id").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("displayName").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("url").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("eTag").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("lastModified").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("creationTime").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("exitConditions").GetProperty("exitCodes")[0].GetProperty("code").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("exitConditions").GetProperty("exitCodes")[0].GetProperty("exitOptions").GetProperty("jobAction").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("exitConditions").GetProperty("exitCodes")[0].GetProperty("exitOptions").GetProperty("dependencyAction").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("exitConditions").GetProperty("exitCodeRanges")[0].GetProperty("start").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("exitConditions").GetProperty("exitCodeRanges")[0].GetProperty("end").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("exitConditions").GetProperty("exitCodeRanges")[0].GetProperty("exitOptions").GetProperty("jobAction").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("exitConditions").GetProperty("exitCodeRanges")[0].GetProperty("exitOptions").GetProperty("dependencyAction").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("exitConditions").GetProperty("preProcessingError").GetProperty("jobAction").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("exitConditions").GetProperty("preProcessingError").GetProperty("dependencyAction").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("exitConditions").GetProperty("fileUploadError").GetProperty("jobAction").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("exitConditions").GetProperty("fileUploadError").GetProperty("dependencyAction").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("exitConditions").GetProperty("default").GetProperty("jobAction").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("exitConditions").GetProperty("default").GetProperty("dependencyAction").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("state").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("stateTransitionTime").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("previousState").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("previousStateTransitionTime").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("commandLine").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("containerSettings").GetProperty("containerRunOptions").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("containerSettings").GetProperty("imageName").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("containerSettings").GetProperty("registry").GetProperty("username").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("containerSettings").GetProperty("registry").GetProperty("password").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("containerSettings").GetProperty("registry").GetProperty("registryServer").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("containerSettings").GetProperty("registry").GetProperty("identityReference").GetProperty("resourceId").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("containerSettings").GetProperty("workingDirectory").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("resourceFiles")[0].GetProperty("autoStorageContainerName").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("resourceFiles")[0].GetProperty("storageContainerUrl").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("resourceFiles")[0].GetProperty("httpUrl").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("resourceFiles")[0].GetProperty("blobPrefix").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("resourceFiles")[0].GetProperty("filePath").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("resourceFiles")[0].GetProperty("fileMode").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("resourceFiles")[0].GetProperty("identityReference").GetProperty("resourceId").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("outputFiles")[0].GetProperty("filePattern").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("outputFiles")[0].GetProperty("destination").GetProperty("container").GetProperty("path").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("outputFiles")[0].GetProperty("destination").GetProperty("container").GetProperty("containerUrl").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("outputFiles")[0].GetProperty("destination").GetProperty("container").GetProperty("identityReference").GetProperty("resourceId").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("outputFiles")[0].GetProperty("destination").GetProperty("container").GetProperty("uploadHeaders")[0].GetProperty("name").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("outputFiles")[0].GetProperty("destination").GetProperty("container").GetProperty("uploadHeaders")[0].GetProperty("value").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("outputFiles")[0].GetProperty("uploadOptions").GetProperty("uploadCondition").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("environmentSettings")[0].GetProperty("name").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("environmentSettings")[0].GetProperty("value").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("affinityInfo").GetProperty("affinityId").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("constraints").GetProperty("maxWallClockTime").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("constraints").GetProperty("retentionTime").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("constraints").GetProperty("maxTaskRetryCount").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("requiredSlots").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("userIdentity").GetProperty("username").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("userIdentity").GetProperty("autoUser").GetProperty("scope").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("userIdentity").GetProperty("autoUser").GetProperty("elevationLevel").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("executionInfo").GetProperty("startTime").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("executionInfo").GetProperty("endTime").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("executionInfo").GetProperty("exitCode").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("executionInfo").GetProperty("containerInfo").GetProperty("containerId").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("executionInfo").GetProperty("containerInfo").GetProperty("state").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("executionInfo").GetProperty("containerInfo").GetProperty("error").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("executionInfo").GetProperty("failureInfo").GetProperty("category").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("executionInfo").GetProperty("failureInfo").GetProperty("code").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("executionInfo").GetProperty("failureInfo").GetProperty("message").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("executionInfo").GetProperty("failureInfo").GetProperty("details")[0].GetProperty("name").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("executionInfo").GetProperty("failureInfo").GetProperty("details")[0].GetProperty("value").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("executionInfo").GetProperty("retryCount").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("executionInfo").GetProperty("lastRetryTime").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("executionInfo").GetProperty("requeueCount").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("executionInfo").GetProperty("lastRequeueTime").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("executionInfo").GetProperty("result").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("nodeInfo").GetProperty("affinityId").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("nodeInfo").GetProperty("nodeUrl").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("nodeInfo").GetProperty("poolId").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("nodeInfo").GetProperty("nodeId").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("nodeInfo").GetProperty("taskRootDirectory").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("nodeInfo").GetProperty("taskRootDirectoryUrl").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("multiInstanceSettings").GetProperty("numberOfInstances").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("multiInstanceSettings").GetProperty("coordinationCommandLine").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("multiInstanceSettings").GetProperty("commonResourceFiles")[0].GetProperty("autoStorageContainerName").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("multiInstanceSettings").GetProperty("commonResourceFiles")[0].GetProperty("storageContainerUrl").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("multiInstanceSettings").GetProperty("commonResourceFiles")[0].GetProperty("httpUrl").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("multiInstanceSettings").GetProperty("commonResourceFiles")[0].GetProperty("blobPrefix").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("multiInstanceSettings").GetProperty("commonResourceFiles")[0].GetProperty("filePath").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("multiInstanceSettings").GetProperty("commonResourceFiles")[0].GetProperty("fileMode").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("multiInstanceSettings").GetProperty("commonResourceFiles")[0].GetProperty("identityReference").GetProperty("resourceId").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("stats").GetProperty("url").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("stats").GetProperty("startTime").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("stats").GetProperty("lastUpdateTime").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("stats").GetProperty("userCPUTime").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("stats").GetProperty("kernelCPUTime").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("stats").GetProperty("wallClockTime").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("stats").GetProperty("readIOps").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("stats").GetProperty("writeIOps").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("stats").GetProperty("readIOGiB").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("stats").GetProperty("writeIOGiB").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("stats").GetProperty("waitTime").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("dependsOn").GetProperty("taskIds")[0].ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("dependsOn").GetProperty("taskIdRanges")[0].GetProperty("start").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("dependsOn").GetProperty("taskIdRanges")[0].GetProperty("end").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("applicationPackageReferences")[0].GetProperty("applicationId").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("applicationPackageReferences")[0].GetProperty("version").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("authenticationTokenSettings").GetProperty("access")[0].ToString());
Console.WriteLine(result.GetProperty("odata.nextLink").ToString());
]]></code>
</example>
<remarks>
For multi-instance Tasks, information such as affinityId, executionInfo and
nodeInfo refer to the primary Task. Use the list subtasks API to retrieve
information about subtasks.

Below is the JSON schema for the response payload.

Response Body:

Schema for <c>BatchTaskListResult</c>:
<code>{
  value: [
    {
      id: string, # Optional. The ID can contain any combination of alphanumeric characters including hyphens
and underscores, and cannot contain more than 64 characters.
      displayName: string, # Optional. The display name need not be unique and can contain any Unicode characters up
to a maximum length of 1024.
      url: string, # Optional. The URL of the Task.
      eTag: string, # Optional. This is an opaque string. You can use it to detect whether the Task has changed
between requests. In particular, you can be pass the ETag when updating a Task
to specify that your changes should take effect only if nobody else has
modified the Task in the meantime.
      lastModified: string (date &amp; time), # Optional. The last modified time of the Task.
      creationTime: string (date &amp; time), # Optional. The creation time of the Task.
      exitConditions: {
        exitCodes: [ExitCodeMapping], # Optional. A list of individual Task exit codes and how the Batch service should respond
to them.
        exitCodeRanges: [ExitCodeRangeMapping], # Optional. A list of Task exit code ranges and how the Batch service should respond to
them.
        preProcessingError: {
          jobAction: &quot;none&quot; | &quot;disable&quot; | &quot;terminate&quot;, # Optional. The default is none for exit code 0 and terminate for all other exit
conditions. If the Job&apos;s onTaskFailed property is noaction, then specifying
this property returns an error and the add Task request fails with an invalid
property value error; if you are calling the REST API directly, the HTTP status
code is 400 (Bad Request).
          dependencyAction: &quot;satisfy&quot; | &quot;block&quot;, # Optional. Possible values are &apos;satisfy&apos; (allowing dependent tasks to progress) and
&apos;block&apos; (dependent tasks continue to wait). Batch does not yet support
cancellation of dependent tasks.
        }, # Optional. Specifies how the Batch service responds to a particular exit condition.
        fileUploadError: ExitOptions, # Optional. If the Task exited with an exit code that was specified via exitCodes or
exitCodeRanges, and then encountered a file upload error, then the action
specified by the exit code takes precedence.
        default: ExitOptions, # Optional. This value is used if the Task exits with any nonzero exit code not listed in
the exitCodes or exitCodeRanges collection, with a pre-processing error if the
preProcessingError property is not present, or with a file upload error if the
fileUploadError property is not present. If you want non-default behavior on
exit code 0, you must list it explicitly using the exitCodes or exitCodeRanges
collection.
      }, # Optional. How the Batch service should respond when the Task completes.
      state: &quot;active&quot; | &quot;preparing&quot; | &quot;running&quot; | &quot;completed&quot;, # Optional. The state of the Task.
      stateTransitionTime: string (date &amp; time), # Optional. The time at which the Task entered its current state.
      previousState: &quot;active&quot; | &quot;preparing&quot; | &quot;running&quot; | &quot;completed&quot;, # Optional. This property is not set if the Task is in its initial Active state.
      previousStateTransitionTime: string (date &amp; time), # Optional. This property is not set if the Task is in its initial Active state.
      commandLine: string, # Optional. For multi-instance Tasks, the command line is executed as the primary Task,
after the primary Task and all subtasks have finished executing the
coordination command line. The command line does not run under a shell, and
therefore cannot take advantage of shell features such as environment variable
expansion. If you want to take advantage of such features, you should invoke
the shell in the command line, for example using &quot;cmd /c MyCommand&quot; in
Windows or &quot;/bin/sh -c MyCommand&quot; in Linux. If the command line refers to
file paths, it should use a relative path (relative to the Task working
directory), or use the Batch provided environment variable
(https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).
      containerSettings: {
        containerRunOptions: string, # Optional. These additional options are supplied as arguments to the &quot;docker create&quot;
command, in addition to those controlled by the Batch Service.
        imageName: string, # Required. This is the full Image reference, as would be specified to &quot;docker pull&quot;. If
no tag is provided as part of the Image name, the tag &quot;:latest&quot; is used as a
default.
        registry: {
          username: string, # Optional. The user name to log into the registry server.
          password: string, # Optional. The password to log into the registry server.
          registryServer: string, # Optional. If omitted, the default is &quot;docker.io&quot;.
          identityReference: {
            resourceId: string, # Optional. The ARM resource id of the user assigned identity.
          }, # Optional. The reference to a user assigned identity associated with the Batch pool which
a compute node will use.
        }, # Optional. This setting can be omitted if was already provided at Pool creation.
        workingDirectory: &quot;taskWorkingDirectory&quot; | &quot;containerImageDefault&quot;, # Optional. The default is &apos;taskWorkingDirectory&apos;.
      }, # Optional. If the Pool that will run this Task has containerConfiguration set, this must
be set as well. If the Pool that will run this Task doesn&apos;t have
containerConfiguration set, this must not be set. When this is specified, all
directories recursively below the AZ_BATCH_NODE_ROOT_DIR (the root of Azure
Batch directories on the node) are mapped into the container, all Task
environment variables are mapped into the container, and the Task command line
is executed in the container. Files produced in the container outside of
AZ_BATCH_NODE_ROOT_DIR might not be reflected to the host disk, meaning that
Batch file APIs will not be able to access those files.
      resourceFiles: [ResourceFile], # Optional. For multi-instance Tasks, the resource files will only be downloaded to the
Compute Node on which the primary Task is executed. There is a maximum size for
the list of resource files.  When the max size is exceeded, the request will
fail and the response error code will be RequestEntityTooLarge. If this occurs,
the collection of ResourceFiles must be reduced in size. This can be achieved
using .zip files, Application Packages, or Docker Containers.
      outputFiles: [OutputFile], # Optional. For multi-instance Tasks, the files will only be uploaded from the Compute Node
on which the primary Task is executed.
      environmentSettings: [EnvironmentSetting], # Optional. A list of environment variable settings for the Task.
      affinityInfo: {
        affinityId: string, # Required. You can pass the affinityId of a Node to indicate that this Task needs to run
on that Compute Node. Note that this is just a soft affinity. If the target
Compute Node is busy or unavailable at the time the Task is scheduled, then the
Task will be scheduled elsewhere.
      }, # Optional. A locality hint that can be used by the Batch service to select a Compute Node
on which to start a Task.
      constraints: {
        maxWallClockTime: string (duration ISO 8601 Format), # Optional. If this is not specified, there is no time limit on how long the Task may run.
        retentionTime: string (duration ISO 8601 Format), # Optional. The default is 7 days, i.e. the Task directory will be retained for 7 days
unless the Compute Node is removed or the Job is deleted.
        maxTaskRetryCount: number, # Optional. Note that this value specifically controls the number of retries for the Task
executable due to a nonzero exit code. The Batch service will try the Task
once, and may then retry up to this limit. For example, if the maximum retry
count is 3, Batch tries the Task up to 4 times (one initial try and 3 retries).
If the maximum retry count is 0, the Batch service does not retry the Task
after the first attempt. If the maximum retry count is -1, the Batch service
retries the Task without limit, however this is not recommended for a start
task or any task. The default value is 0 (no retries)
      }, # Optional. Execution constraints to apply to a Task.
      requiredSlots: number, # Optional. The default is 1. A Task can only be scheduled to run on a compute node if the
node has enough free scheduling slots available. For multi-instance Tasks, this
must be 1.
      userIdentity: {
        username: string, # Optional. The userName and autoUser properties are mutually exclusive; you must specify
one but not both.
        autoUser: {
          scope: &quot;task&quot; | &quot;pool&quot;, # Optional. The default value is pool. If the pool is running Windows a value of Task
should be specified if stricter isolation between tasks is required. For
example, if the task mutates the registry in a way which could impact other
tasks, or if certificates have been specified on the pool which should not be
accessible by normal tasks but should be accessible by StartTasks.
          elevationLevel: &quot;nonadmin&quot; | &quot;admin&quot;, # Optional. The default value is nonAdmin.
        }, # Optional. The userName and autoUser properties are mutually exclusive; you must specify
one but not both.
      }, # Optional. If omitted, the Task runs as a non-administrative user unique to the Task.
      executionInfo: {
        startTime: string (date &amp; time), # Optional. &apos;Running&apos; corresponds to the running state, so if the Task specifies resource
files or Packages, then the start time reflects the time at which the Task
started downloading or deploying these. If the Task has been restarted or
retried, this is the most recent time at which the Task started running. This
property is present only for Tasks that are in the running or completed state.
        endTime: string (date &amp; time), # Optional. This property is set only if the Task is in the Completed state.
        exitCode: number, # Optional. This property is set only if the Task is in the completed state. In general,
the exit code for a process reflects the specific convention implemented by the
application developer for that process. If you use the exit code value to make
decisions in your code, be sure that you know the exit code convention used by
the application process. However, if the Batch service terminates the Task (due
to timeout, or user termination via the API) you may see an operating
system-defined exit code.
        containerInfo: {
          containerId: string, # Optional. The ID of the container.
          state: string, # Optional. This is the state of the container according to the Docker service. It is
equivalent to the status field returned by &quot;docker inspect&quot;.
          error: string, # Optional. This is the detailed error string from the Docker service, if available. It is
equivalent to the error field returned by &quot;docker inspect&quot;.
        }, # Optional. This property is set only if the Task runs in a container context.
        failureInfo: {
          category: &quot;usererror&quot; | &quot;servererror&quot;, # Required. The category of the error.
          code: string, # Optional. An identifier for the Task error. Codes are invariant and are intended to be
consumed programmatically.
          message: string, # Optional. A message describing the Task error, intended to be suitable for display in a
user interface.
          details: [NameValuePair], # Optional. A list of additional details related to the error.
        }, # Optional. This property is set only if the Task is in the completed state and encountered
a failure.
        retryCount: number, # Required. Task application failures (non-zero exit code) are retried, pre-processing
errors (the Task could not be run) and file upload errors are not retried. The
Batch service will retry the Task up to the limit specified by the constraints.
        lastRetryTime: string (date &amp; time), # Optional. This element is present only if the Task was retried (i.e. retryCount is
nonzero). If present, this is typically the same as startTime, but may be
different if the Task has been restarted for reasons other than retry; for
example, if the Compute Node was rebooted during a retry, then the startTime is
updated but the lastRetryTime is not.
        requeueCount: number, # Required. When the user removes Compute Nodes from a Pool (by resizing/shrinking the
pool) or when the Job is being disabled, the user can specify that running
Tasks on the Compute Nodes be requeued for execution. This count tracks how
many times the Task has been requeued for these reasons.
        lastRequeueTime: string (date &amp; time), # Optional. This property is set only if the requeueCount is nonzero.
        result: &quot;success&quot; | &quot;failure&quot;, # Optional. If the value is &apos;failed&apos;, then the details of the failure can be found in the
failureInfo property.
      }, # Optional. Information about the execution of a Task.
      nodeInfo: {
        affinityId: string, # Optional. An identifier for the Node on which the Task ran, which can be passed when
adding a Task to request that the Task be scheduled on this Compute Node.
        nodeUrl: string, # Optional. The URL of the Compute Node on which the Task ran. 
        poolId: string, # Optional. The ID of the Pool on which the Task ran.
        nodeId: string, # Optional. The ID of the Compute Node on which the Task ran.
        taskRootDirectory: string, # Optional. The root directory of the Task on the Compute Node.
        taskRootDirectoryUrl: string, # Optional. The URL to the root directory of the Task on the Compute Node.
      }, # Optional. Information about the Compute Node on which a Task ran.
      multiInstanceSettings: {
        numberOfInstances: number, # Optional. If omitted, the default is 1.
        coordinationCommandLine: string, # Required. A typical coordination command line launches a background service and verifies
that the service is ready to process inter-node messages.
        commonResourceFiles: [ResourceFile], # Optional. The difference between common resource files and Task resource files is that
common resource files are downloaded for all subtasks including the primary,
whereas Task resource files are downloaded only for the primary. Also note that
these resource files are not downloaded to the Task working directory, but
instead are downloaded to the Task root directory (one directory above the
working directory).  There is a maximum size for the list of resource files. 
When the max size is exceeded, the request will fail and the response error
code will be RequestEntityTooLarge. If this occurs, the collection of
ResourceFiles must be reduced in size. This can be achieved using .zip files,
Application Packages, or Docker Containers.
      }, # Optional. Multi-instance Tasks are commonly used to support MPI Tasks. In the MPI case,
if any of the subtasks fail (for example due to exiting with a non-zero exit
code) the entire multi-instance Task fails. The multi-instance Task is then
terminated and retried, up to its retry limit.
      stats: {
        url: string, # Required. The URL of the statistics.
        startTime: string (date &amp; time), # Required. The start time of the time range covered by the statistics.
        lastUpdateTime: string (date &amp; time), # Required. The time at which the statistics were last updated. All statistics are limited
to the range between startTime and lastUpdateTime.
        userCPUTime: string (duration ISO 8601 Format), # Required. The total user mode CPU time (summed across all cores and all Compute Nodes)
consumed by the Task.
        kernelCPUTime: string (duration ISO 8601 Format), # Required. The total kernel mode CPU time (summed across all cores and all Compute Nodes)
consumed by the Task.
        wallClockTime: string (duration ISO 8601 Format), # Required. The wall clock time is the elapsed time from when the Task started running on a
Compute Node to when it finished (or to the last time the statistics were
updated, if the Task had not finished by then). If the Task was retried, this
includes the wall clock time of all the Task retries.
        readIOps: number, # Required. The total number of disk read operations made by the Task.
        writeIOps: number, # Required. The total number of disk write operations made by the Task.
        readIOGiB: number, # Required. The total gibibytes read from disk by the Task.
        writeIOGiB: number, # Required. The total gibibytes written to disk by the Task.
        waitTime: string (duration ISO 8601 Format), # Required. The total wait time of the Task. The wait time for a Task is defined as the
elapsed time between the creation of the Task and the start of Task execution.
(If the Task is retried due to failures, the wait time is the time to the most
recent Task execution.)
      }, # Optional. Resource usage statistics for a Task.
      dependsOn: {
        taskIds: [string], # Optional. The taskIds collection is limited to 64000 characters total (i.e. the combined
length of all Task IDs). If the taskIds collection exceeds the maximum length,
the Add Task request fails with error code TaskDependencyListTooLong. In this
case consider using Task ID ranges instead.
        taskIdRanges: [TaskIdRange], # Optional. The list of Task ID ranges that this Task depends on. All Tasks in all ranges
must complete successfully before the dependent Task can be scheduled.
      }, # Optional. This Task will not be scheduled until all Tasks that it depends on have
completed successfully. If any of those Tasks fail and exhaust their retry
counts, this Task will never be scheduled.
      applicationPackageReferences: [ApplicationPackageReference], # Optional. Application packages are downloaded and deployed to a shared directory, not the
Task working directory. Therefore, if a referenced package is already on the
Node, and is up to date, then it is not re-downloaded; the existing copy on the
Compute Node is used. If a referenced Package cannot be installed, for example
because the package has been deleted or because download failed, the Task
fails.
      authenticationTokenSettings: {
        access: [&quot;job&quot;], # Optional. The authentication token grants access to a limited set of Batch service
operations. Currently the only supported value for the access property is
&apos;job&apos;, which grants access to all operations related to the Job which contains
the Task.
      }, # Optional. If this property is set, the Batch service provides the Task with an
authentication token which can be used to authenticate Batch service operations
without requiring an Account access key. The token is provided via the
AZ_BATCH_AUTHENTICATION_TOKEN environment variable. The operations that the
Task can carry out using the token depend on the settings. For example, a Task
can request Job permissions in order to add other Tasks to the Job, or check
the status of the Job or of other Tasks under the Job.
    }
  ], # Optional. The list of Tasks.
  odata.nextLink: string, # Optional. The URL to get the next set of results.
}
</code>

</remarks>
    </member>
    <member name="AddCollectionAsync(String,RequestContent,Int32,String,Boolean,String,RequestContext)">
<example>
This sample shows how to call AddCollectionAsync with required parameters and request content, and how to parse the result.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetTaskClient(<2022-10-01.16.0>);

var data = new {
    value = new[] {
        new {}
    },
};

Response response = await client.AddCollectionAsync("<jobId>", RequestContent.Create(data));

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.ToString());
]]></code>
This sample shows how to call AddCollectionAsync with all parameters and request content, and how to parse the result.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetTaskClient(<2022-10-01.16.0>);

var data = new {
    value = new[] {
        new {
            id = "<id>",
            displayName = "<displayName>",
            exitConditions = new {
                exitCodes = new[] {
                    new {
                        code = 1234,
                        exitOptions = new {
                            jobAction = "none",
                            dependencyAction = "satisfy",
                        },
                    }
                },
                exitCodeRanges = new[] {
                    new {
                        start = 1234,
                        end = 1234,
                        exitOptions = new {
                            jobAction = "none",
                            dependencyAction = "satisfy",
                        },
                    }
                },
                preProcessingError = new {
                    jobAction = "none",
                    dependencyAction = "satisfy",
                },
                fileUploadError = new {
                    jobAction = "none",
                    dependencyAction = "satisfy",
                },
                default = new {
                    jobAction = "none",
                    dependencyAction = "satisfy",
                },
            },
            commandLine = "<commandLine>",
            containerSettings = new {
                containerRunOptions = "<containerRunOptions>",
                imageName = "<imageName>",
                registry = new {
                    username = "<username>",
                    password = "<password>",
                    registryServer = "<registryServer>",
                    identityReference = new {
                        resourceId = "<resourceId>",
                    },
                },
                workingDirectory = "taskWorkingDirectory",
            },
            resourceFiles = new[] {
                new {
                    autoStorageContainerName = "<autoStorageContainerName>",
                    storageContainerUrl = "<storageContainerUrl>",
                    httpUrl = "<httpUrl>",
                    blobPrefix = "<blobPrefix>",
                    filePath = "<filePath>",
                    fileMode = "<fileMode>",
                    identityReference = new {
                        resourceId = "<resourceId>",
                    },
                }
            },
            outputFiles = new[] {
                new {
                    filePattern = "<filePattern>",
                    destination = new {
                        container = new {
                            path = "<path>",
                            containerUrl = "<containerUrl>",
                            identityReference = new {
                                resourceId = "<resourceId>",
                            },
                            uploadHeaders = new[] {
                                new {
                                    name = "<name>",
                                    value = "<value>",
                                }
                            },
                        },
                    },
                    uploadOptions = new {
                        uploadCondition = "tasksuccess",
                    },
                }
            },
            environmentSettings = new[] {
                new {
                    name = "<name>",
                    value = "<value>",
                }
            },
            affinityInfo = new {
                affinityId = "<affinityId>",
            },
            constraints = new {
                maxWallClockTime = PT1H23M45S,
                retentionTime = PT1H23M45S,
                maxTaskRetryCount = 1234,
            },
            requiredSlots = 1234,
            userIdentity = new {
                username = "<username>",
                autoUser = new {
                    scope = "task",
                    elevationLevel = "nonadmin",
                },
            },
            multiInstanceSettings = new {
                numberOfInstances = 1234,
                coordinationCommandLine = "<coordinationCommandLine>",
                commonResourceFiles = new[] {
                    new {
                        autoStorageContainerName = "<autoStorageContainerName>",
                        storageContainerUrl = "<storageContainerUrl>",
                        httpUrl = "<httpUrl>",
                        blobPrefix = "<blobPrefix>",
                        filePath = "<filePath>",
                        fileMode = "<fileMode>",
                        identityReference = new {
                            resourceId = "<resourceId>",
                        },
                    }
                },
            },
            dependsOn = new {
                taskIds = new[] {
                    "<String>"
                },
                taskIdRanges = new[] {
                    new {
                        start = 1234,
                        end = 1234,
                    }
                },
            },
            applicationPackageReferences = new[] {
                new {
                    applicationId = "<applicationId>",
                    version = "<version>",
                }
            },
            authenticationTokenSettings = new {
                access = new[] {
                    "job"
                },
            },
        }
    },
};

Response response = await client.AddCollectionAsync("<jobId>", RequestContent.Create(data), 1234, "<clientRequestId>", true, "<ocpDate>");

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.GetProperty("value")[0].GetProperty("status").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("taskId").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("eTag").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("lastModified").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("location").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("error").GetProperty("code").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("error").GetProperty("message").GetProperty("lang").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("error").GetProperty("message").GetProperty("value").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("error").GetProperty("values")[0].GetProperty("key").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("error").GetProperty("values")[0].GetProperty("value").ToString());
]]></code>
</example>
<remarks>
Note that each Task must have a unique ID. The Batch service may not return the
results for each Task in the same order the Tasks were submitted in this
request. If the server times out or the connection is closed during the
request, the request may have been partially or fully processed, or not at all.
In such cases, the user should re-issue the request. Note that it is up to the
user to correctly handle failures when re-issuing a request. For example, you
should use the same Task IDs during a retry so that if the prior operation
succeeded, the retry will not create extra Tasks unexpectedly. If the response
contains any Tasks which failed to add, a client can retry the request. In a
retry, it is most efficient to resubmit only Tasks that failed to add, and to
omit Tasks that were successfully added on the first attempt. The maximum
lifetime of a Task from addition to completion is 180 days. If a Task has not
completed within 180 days of being added it will be terminated by the Batch
service and left in whatever state it was in at that time.

Below is the JSON schema for the request and response payloads.

Request Body:

Schema for <c>BatchTaskCollection</c>:
<code>{
  value: [
    {
      id: string, # Optional. The ID can contain any combination of alphanumeric characters including hyphens
and underscores, and cannot contain more than 64 characters.
      displayName: string, # Optional. The display name need not be unique and can contain any Unicode characters up
to a maximum length of 1024.
      url: string, # Optional. The URL of the Task.
      eTag: string, # Optional. This is an opaque string. You can use it to detect whether the Task has changed
between requests. In particular, you can be pass the ETag when updating a Task
to specify that your changes should take effect only if nobody else has
modified the Task in the meantime.
      lastModified: string (date &amp; time), # Optional. The last modified time of the Task.
      creationTime: string (date &amp; time), # Optional. The creation time of the Task.
      exitConditions: {
        exitCodes: [ExitCodeMapping], # Optional. A list of individual Task exit codes and how the Batch service should respond
to them.
        exitCodeRanges: [ExitCodeRangeMapping], # Optional. A list of Task exit code ranges and how the Batch service should respond to
them.
        preProcessingError: {
          jobAction: &quot;none&quot; | &quot;disable&quot; | &quot;terminate&quot;, # Optional. The default is none for exit code 0 and terminate for all other exit
conditions. If the Job&apos;s onTaskFailed property is noaction, then specifying
this property returns an error and the add Task request fails with an invalid
property value error; if you are calling the REST API directly, the HTTP status
code is 400 (Bad Request).
          dependencyAction: &quot;satisfy&quot; | &quot;block&quot;, # Optional. Possible values are &apos;satisfy&apos; (allowing dependent tasks to progress) and
&apos;block&apos; (dependent tasks continue to wait). Batch does not yet support
cancellation of dependent tasks.
        }, # Optional. Specifies how the Batch service responds to a particular exit condition.
        fileUploadError: ExitOptions, # Optional. If the Task exited with an exit code that was specified via exitCodes or
exitCodeRanges, and then encountered a file upload error, then the action
specified by the exit code takes precedence.
        default: ExitOptions, # Optional. This value is used if the Task exits with any nonzero exit code not listed in
the exitCodes or exitCodeRanges collection, with a pre-processing error if the
preProcessingError property is not present, or with a file upload error if the
fileUploadError property is not present. If you want non-default behavior on
exit code 0, you must list it explicitly using the exitCodes or exitCodeRanges
collection.
      }, # Optional. How the Batch service should respond when the Task completes.
      state: &quot;active&quot; | &quot;preparing&quot; | &quot;running&quot; | &quot;completed&quot;, # Optional. The state of the Task.
      stateTransitionTime: string (date &amp; time), # Optional. The time at which the Task entered its current state.
      previousState: &quot;active&quot; | &quot;preparing&quot; | &quot;running&quot; | &quot;completed&quot;, # Optional. This property is not set if the Task is in its initial Active state.
      previousStateTransitionTime: string (date &amp; time), # Optional. This property is not set if the Task is in its initial Active state.
      commandLine: string, # Optional. For multi-instance Tasks, the command line is executed as the primary Task,
after the primary Task and all subtasks have finished executing the
coordination command line. The command line does not run under a shell, and
therefore cannot take advantage of shell features such as environment variable
expansion. If you want to take advantage of such features, you should invoke
the shell in the command line, for example using &quot;cmd /c MyCommand&quot; in
Windows or &quot;/bin/sh -c MyCommand&quot; in Linux. If the command line refers to
file paths, it should use a relative path (relative to the Task working
directory), or use the Batch provided environment variable
(https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).
      containerSettings: {
        containerRunOptions: string, # Optional. These additional options are supplied as arguments to the &quot;docker create&quot;
command, in addition to those controlled by the Batch Service.
        imageName: string, # Required. This is the full Image reference, as would be specified to &quot;docker pull&quot;. If
no tag is provided as part of the Image name, the tag &quot;:latest&quot; is used as a
default.
        registry: {
          username: string, # Optional. The user name to log into the registry server.
          password: string, # Optional. The password to log into the registry server.
          registryServer: string, # Optional. If omitted, the default is &quot;docker.io&quot;.
          identityReference: {
            resourceId: string, # Optional. The ARM resource id of the user assigned identity.
          }, # Optional. The reference to a user assigned identity associated with the Batch pool which
a compute node will use.
        }, # Optional. This setting can be omitted if was already provided at Pool creation.
        workingDirectory: &quot;taskWorkingDirectory&quot; | &quot;containerImageDefault&quot;, # Optional. The default is &apos;taskWorkingDirectory&apos;.
      }, # Optional. If the Pool that will run this Task has containerConfiguration set, this must
be set as well. If the Pool that will run this Task doesn&apos;t have
containerConfiguration set, this must not be set. When this is specified, all
directories recursively below the AZ_BATCH_NODE_ROOT_DIR (the root of Azure
Batch directories on the node) are mapped into the container, all Task
environment variables are mapped into the container, and the Task command line
is executed in the container. Files produced in the container outside of
AZ_BATCH_NODE_ROOT_DIR might not be reflected to the host disk, meaning that
Batch file APIs will not be able to access those files.
      resourceFiles: [ResourceFile], # Optional. For multi-instance Tasks, the resource files will only be downloaded to the
Compute Node on which the primary Task is executed. There is a maximum size for
the list of resource files.  When the max size is exceeded, the request will
fail and the response error code will be RequestEntityTooLarge. If this occurs,
the collection of ResourceFiles must be reduced in size. This can be achieved
using .zip files, Application Packages, or Docker Containers.
      outputFiles: [OutputFile], # Optional. For multi-instance Tasks, the files will only be uploaded from the Compute Node
on which the primary Task is executed.
      environmentSettings: [EnvironmentSetting], # Optional. A list of environment variable settings for the Task.
      affinityInfo: {
        affinityId: string, # Required. You can pass the affinityId of a Node to indicate that this Task needs to run
on that Compute Node. Note that this is just a soft affinity. If the target
Compute Node is busy or unavailable at the time the Task is scheduled, then the
Task will be scheduled elsewhere.
      }, # Optional. A locality hint that can be used by the Batch service to select a Compute Node
on which to start a Task.
      constraints: {
        maxWallClockTime: string (duration ISO 8601 Format), # Optional. If this is not specified, there is no time limit on how long the Task may run.
        retentionTime: string (duration ISO 8601 Format), # Optional. The default is 7 days, i.e. the Task directory will be retained for 7 days
unless the Compute Node is removed or the Job is deleted.
        maxTaskRetryCount: number, # Optional. Note that this value specifically controls the number of retries for the Task
executable due to a nonzero exit code. The Batch service will try the Task
once, and may then retry up to this limit. For example, if the maximum retry
count is 3, Batch tries the Task up to 4 times (one initial try and 3 retries).
If the maximum retry count is 0, the Batch service does not retry the Task
after the first attempt. If the maximum retry count is -1, the Batch service
retries the Task without limit, however this is not recommended for a start
task or any task. The default value is 0 (no retries)
      }, # Optional. Execution constraints to apply to a Task.
      requiredSlots: number, # Optional. The default is 1. A Task can only be scheduled to run on a compute node if the
node has enough free scheduling slots available. For multi-instance Tasks, this
must be 1.
      userIdentity: {
        username: string, # Optional. The userName and autoUser properties are mutually exclusive; you must specify
one but not both.
        autoUser: {
          scope: &quot;task&quot; | &quot;pool&quot;, # Optional. The default value is pool. If the pool is running Windows a value of Task
should be specified if stricter isolation between tasks is required. For
example, if the task mutates the registry in a way which could impact other
tasks, or if certificates have been specified on the pool which should not be
accessible by normal tasks but should be accessible by StartTasks.
          elevationLevel: &quot;nonadmin&quot; | &quot;admin&quot;, # Optional. The default value is nonAdmin.
        }, # Optional. The userName and autoUser properties are mutually exclusive; you must specify
one but not both.
      }, # Optional. If omitted, the Task runs as a non-administrative user unique to the Task.
      executionInfo: {
        startTime: string (date &amp; time), # Optional. &apos;Running&apos; corresponds to the running state, so if the Task specifies resource
files or Packages, then the start time reflects the time at which the Task
started downloading or deploying these. If the Task has been restarted or
retried, this is the most recent time at which the Task started running. This
property is present only for Tasks that are in the running or completed state.
        endTime: string (date &amp; time), # Optional. This property is set only if the Task is in the Completed state.
        exitCode: number, # Optional. This property is set only if the Task is in the completed state. In general,
the exit code for a process reflects the specific convention implemented by the
application developer for that process. If you use the exit code value to make
decisions in your code, be sure that you know the exit code convention used by
the application process. However, if the Batch service terminates the Task (due
to timeout, or user termination via the API) you may see an operating
system-defined exit code.
        containerInfo: {
          containerId: string, # Optional. The ID of the container.
          state: string, # Optional. This is the state of the container according to the Docker service. It is
equivalent to the status field returned by &quot;docker inspect&quot;.
          error: string, # Optional. This is the detailed error string from the Docker service, if available. It is
equivalent to the error field returned by &quot;docker inspect&quot;.
        }, # Optional. This property is set only if the Task runs in a container context.
        failureInfo: {
          category: &quot;usererror&quot; | &quot;servererror&quot;, # Required. The category of the error.
          code: string, # Optional. An identifier for the Task error. Codes are invariant and are intended to be
consumed programmatically.
          message: string, # Optional. A message describing the Task error, intended to be suitable for display in a
user interface.
          details: [NameValuePair], # Optional. A list of additional details related to the error.
        }, # Optional. This property is set only if the Task is in the completed state and encountered
a failure.
        retryCount: number, # Required. Task application failures (non-zero exit code) are retried, pre-processing
errors (the Task could not be run) and file upload errors are not retried. The
Batch service will retry the Task up to the limit specified by the constraints.
        lastRetryTime: string (date &amp; time), # Optional. This element is present only if the Task was retried (i.e. retryCount is
nonzero). If present, this is typically the same as startTime, but may be
different if the Task has been restarted for reasons other than retry; for
example, if the Compute Node was rebooted during a retry, then the startTime is
updated but the lastRetryTime is not.
        requeueCount: number, # Required. When the user removes Compute Nodes from a Pool (by resizing/shrinking the
pool) or when the Job is being disabled, the user can specify that running
Tasks on the Compute Nodes be requeued for execution. This count tracks how
many times the Task has been requeued for these reasons.
        lastRequeueTime: string (date &amp; time), # Optional. This property is set only if the requeueCount is nonzero.
        result: &quot;success&quot; | &quot;failure&quot;, # Optional. If the value is &apos;failed&apos;, then the details of the failure can be found in the
failureInfo property.
      }, # Optional. Information about the execution of a Task.
      nodeInfo: {
        affinityId: string, # Optional. An identifier for the Node on which the Task ran, which can be passed when
adding a Task to request that the Task be scheduled on this Compute Node.
        nodeUrl: string, # Optional. The URL of the Compute Node on which the Task ran. 
        poolId: string, # Optional. The ID of the Pool on which the Task ran.
        nodeId: string, # Optional. The ID of the Compute Node on which the Task ran.
        taskRootDirectory: string, # Optional. The root directory of the Task on the Compute Node.
        taskRootDirectoryUrl: string, # Optional. The URL to the root directory of the Task on the Compute Node.
      }, # Optional. Information about the Compute Node on which a Task ran.
      multiInstanceSettings: {
        numberOfInstances: number, # Optional. If omitted, the default is 1.
        coordinationCommandLine: string, # Required. A typical coordination command line launches a background service and verifies
that the service is ready to process inter-node messages.
        commonResourceFiles: [ResourceFile], # Optional. The difference between common resource files and Task resource files is that
common resource files are downloaded for all subtasks including the primary,
whereas Task resource files are downloaded only for the primary. Also note that
these resource files are not downloaded to the Task working directory, but
instead are downloaded to the Task root directory (one directory above the
working directory).  There is a maximum size for the list of resource files. 
When the max size is exceeded, the request will fail and the response error
code will be RequestEntityTooLarge. If this occurs, the collection of
ResourceFiles must be reduced in size. This can be achieved using .zip files,
Application Packages, or Docker Containers.
      }, # Optional. Multi-instance Tasks are commonly used to support MPI Tasks. In the MPI case,
if any of the subtasks fail (for example due to exiting with a non-zero exit
code) the entire multi-instance Task fails. The multi-instance Task is then
terminated and retried, up to its retry limit.
      stats: {
        url: string, # Required. The URL of the statistics.
        startTime: string (date &amp; time), # Required. The start time of the time range covered by the statistics.
        lastUpdateTime: string (date &amp; time), # Required. The time at which the statistics were last updated. All statistics are limited
to the range between startTime and lastUpdateTime.
        userCPUTime: string (duration ISO 8601 Format), # Required. The total user mode CPU time (summed across all cores and all Compute Nodes)
consumed by the Task.
        kernelCPUTime: string (duration ISO 8601 Format), # Required. The total kernel mode CPU time (summed across all cores and all Compute Nodes)
consumed by the Task.
        wallClockTime: string (duration ISO 8601 Format), # Required. The wall clock time is the elapsed time from when the Task started running on a
Compute Node to when it finished (or to the last time the statistics were
updated, if the Task had not finished by then). If the Task was retried, this
includes the wall clock time of all the Task retries.
        readIOps: number, # Required. The total number of disk read operations made by the Task.
        writeIOps: number, # Required. The total number of disk write operations made by the Task.
        readIOGiB: number, # Required. The total gibibytes read from disk by the Task.
        writeIOGiB: number, # Required. The total gibibytes written to disk by the Task.
        waitTime: string (duration ISO 8601 Format), # Required. The total wait time of the Task. The wait time for a Task is defined as the
elapsed time between the creation of the Task and the start of Task execution.
(If the Task is retried due to failures, the wait time is the time to the most
recent Task execution.)
      }, # Optional. Resource usage statistics for a Task.
      dependsOn: {
        taskIds: [string], # Optional. The taskIds collection is limited to 64000 characters total (i.e. the combined
length of all Task IDs). If the taskIds collection exceeds the maximum length,
the Add Task request fails with error code TaskDependencyListTooLong. In this
case consider using Task ID ranges instead.
        taskIdRanges: [TaskIdRange], # Optional. The list of Task ID ranges that this Task depends on. All Tasks in all ranges
must complete successfully before the dependent Task can be scheduled.
      }, # Optional. This Task will not be scheduled until all Tasks that it depends on have
completed successfully. If any of those Tasks fail and exhaust their retry
counts, this Task will never be scheduled.
      applicationPackageReferences: [ApplicationPackageReference], # Optional. Application packages are downloaded and deployed to a shared directory, not the
Task working directory. Therefore, if a referenced package is already on the
Node, and is up to date, then it is not re-downloaded; the existing copy on the
Compute Node is used. If a referenced Package cannot be installed, for example
because the package has been deleted or because download failed, the Task
fails.
      authenticationTokenSettings: {
        access: [&quot;job&quot;], # Optional. The authentication token grants access to a limited set of Batch service
operations. Currently the only supported value for the access property is
&apos;job&apos;, which grants access to all operations related to the Job which contains
the Task.
      }, # Optional. If this property is set, the Batch service provides the Task with an
authentication token which can be used to authenticate Batch service operations
without requiring an Account access key. The token is provided via the
AZ_BATCH_AUTHENTICATION_TOKEN environment variable. The operations that the
Task can carry out using the token depend on the settings. For example, a Task
can request Job permissions in order to add other Tasks to the Job, or check
the status of the Job or of other Tasks under the Job.
    }
  ], # Required. The total serialized size of this collection must be less than 1MB. If it is
greater than 1MB (for example if each Task has 100&apos;s of resource files or
environment variables), the request will fail with code &apos;RequestBodyTooLarge&apos;
and should be retried again with fewer Tasks.
}
</code>

Response Body:

Schema for <c>TaskAddCollectionResult</c>:
<code>{
  value: [
    {
      status: &quot;success&quot; | &quot;clienterror&quot; | &quot;servererror&quot;, # Required. The status of the add Task request.
      taskId: string, # Required. The ID of the Task for which this is the result.
      eTag: string, # Optional. You can use this to detect whether the Task has changed between requests. In
particular, you can be pass the ETag with an Update Task request to specify
that your changes should take effect only if nobody else has modified the Job
in the meantime.
      lastModified: string (date &amp; time), # Optional. The last modified time of the Task.
      location: string, # Optional. The URL of the Task, if the Task was successfully added.
      error: {
        code: string, # Optional. An identifier for the error. Codes are invariant and are intended to be
consumed programmatically.
        message: {
          lang: string, # Optional. The language code of the error message
          value: string, # Optional. The text of the message.
        }, # Optional. An error message received in an Azure Batch error response.
        values: [BatchErrorDetail], # Optional. A collection of key-value pairs containing additional details about the error.
      }, # Optional. An error response received from the Azure Batch service.
    }
  ], # Optional. The results of the add Task collection operation.
}
</code>

</remarks>
    </member>
    <member name="AddCollection(String,RequestContent,Int32,String,Boolean,String,RequestContext)">
<example>
This sample shows how to call AddCollection with required parameters and request content, and how to parse the result.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetTaskClient(<2022-10-01.16.0>);

var data = new {
    value = new[] {
        new {}
    },
};

Response response = client.AddCollection("<jobId>", RequestContent.Create(data));

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.ToString());
]]></code>
This sample shows how to call AddCollection with all parameters and request content, and how to parse the result.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetTaskClient(<2022-10-01.16.0>);

var data = new {
    value = new[] {
        new {
            id = "<id>",
            displayName = "<displayName>",
            exitConditions = new {
                exitCodes = new[] {
                    new {
                        code = 1234,
                        exitOptions = new {
                            jobAction = "none",
                            dependencyAction = "satisfy",
                        },
                    }
                },
                exitCodeRanges = new[] {
                    new {
                        start = 1234,
                        end = 1234,
                        exitOptions = new {
                            jobAction = "none",
                            dependencyAction = "satisfy",
                        },
                    }
                },
                preProcessingError = new {
                    jobAction = "none",
                    dependencyAction = "satisfy",
                },
                fileUploadError = new {
                    jobAction = "none",
                    dependencyAction = "satisfy",
                },
                default = new {
                    jobAction = "none",
                    dependencyAction = "satisfy",
                },
            },
            commandLine = "<commandLine>",
            containerSettings = new {
                containerRunOptions = "<containerRunOptions>",
                imageName = "<imageName>",
                registry = new {
                    username = "<username>",
                    password = "<password>",
                    registryServer = "<registryServer>",
                    identityReference = new {
                        resourceId = "<resourceId>",
                    },
                },
                workingDirectory = "taskWorkingDirectory",
            },
            resourceFiles = new[] {
                new {
                    autoStorageContainerName = "<autoStorageContainerName>",
                    storageContainerUrl = "<storageContainerUrl>",
                    httpUrl = "<httpUrl>",
                    blobPrefix = "<blobPrefix>",
                    filePath = "<filePath>",
                    fileMode = "<fileMode>",
                    identityReference = new {
                        resourceId = "<resourceId>",
                    },
                }
            },
            outputFiles = new[] {
                new {
                    filePattern = "<filePattern>",
                    destination = new {
                        container = new {
                            path = "<path>",
                            containerUrl = "<containerUrl>",
                            identityReference = new {
                                resourceId = "<resourceId>",
                            },
                            uploadHeaders = new[] {
                                new {
                                    name = "<name>",
                                    value = "<value>",
                                }
                            },
                        },
                    },
                    uploadOptions = new {
                        uploadCondition = "tasksuccess",
                    },
                }
            },
            environmentSettings = new[] {
                new {
                    name = "<name>",
                    value = "<value>",
                }
            },
            affinityInfo = new {
                affinityId = "<affinityId>",
            },
            constraints = new {
                maxWallClockTime = PT1H23M45S,
                retentionTime = PT1H23M45S,
                maxTaskRetryCount = 1234,
            },
            requiredSlots = 1234,
            userIdentity = new {
                username = "<username>",
                autoUser = new {
                    scope = "task",
                    elevationLevel = "nonadmin",
                },
            },
            multiInstanceSettings = new {
                numberOfInstances = 1234,
                coordinationCommandLine = "<coordinationCommandLine>",
                commonResourceFiles = new[] {
                    new {
                        autoStorageContainerName = "<autoStorageContainerName>",
                        storageContainerUrl = "<storageContainerUrl>",
                        httpUrl = "<httpUrl>",
                        blobPrefix = "<blobPrefix>",
                        filePath = "<filePath>",
                        fileMode = "<fileMode>",
                        identityReference = new {
                            resourceId = "<resourceId>",
                        },
                    }
                },
            },
            dependsOn = new {
                taskIds = new[] {
                    "<String>"
                },
                taskIdRanges = new[] {
                    new {
                        start = 1234,
                        end = 1234,
                    }
                },
            },
            applicationPackageReferences = new[] {
                new {
                    applicationId = "<applicationId>",
                    version = "<version>",
                }
            },
            authenticationTokenSettings = new {
                access = new[] {
                    "job"
                },
            },
        }
    },
};

Response response = client.AddCollection("<jobId>", RequestContent.Create(data), 1234, "<clientRequestId>", true, "<ocpDate>");

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.GetProperty("value")[0].GetProperty("status").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("taskId").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("eTag").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("lastModified").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("location").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("error").GetProperty("code").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("error").GetProperty("message").GetProperty("lang").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("error").GetProperty("message").GetProperty("value").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("error").GetProperty("values")[0].GetProperty("key").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("error").GetProperty("values")[0].GetProperty("value").ToString());
]]></code>
</example>
<remarks>
Note that each Task must have a unique ID. The Batch service may not return the
results for each Task in the same order the Tasks were submitted in this
request. If the server times out or the connection is closed during the
request, the request may have been partially or fully processed, or not at all.
In such cases, the user should re-issue the request. Note that it is up to the
user to correctly handle failures when re-issuing a request. For example, you
should use the same Task IDs during a retry so that if the prior operation
succeeded, the retry will not create extra Tasks unexpectedly. If the response
contains any Tasks which failed to add, a client can retry the request. In a
retry, it is most efficient to resubmit only Tasks that failed to add, and to
omit Tasks that were successfully added on the first attempt. The maximum
lifetime of a Task from addition to completion is 180 days. If a Task has not
completed within 180 days of being added it will be terminated by the Batch
service and left in whatever state it was in at that time.

Below is the JSON schema for the request and response payloads.

Request Body:

Schema for <c>BatchTaskCollection</c>:
<code>{
  value: [
    {
      id: string, # Optional. The ID can contain any combination of alphanumeric characters including hyphens
and underscores, and cannot contain more than 64 characters.
      displayName: string, # Optional. The display name need not be unique and can contain any Unicode characters up
to a maximum length of 1024.
      url: string, # Optional. The URL of the Task.
      eTag: string, # Optional. This is an opaque string. You can use it to detect whether the Task has changed
between requests. In particular, you can be pass the ETag when updating a Task
to specify that your changes should take effect only if nobody else has
modified the Task in the meantime.
      lastModified: string (date &amp; time), # Optional. The last modified time of the Task.
      creationTime: string (date &amp; time), # Optional. The creation time of the Task.
      exitConditions: {
        exitCodes: [ExitCodeMapping], # Optional. A list of individual Task exit codes and how the Batch service should respond
to them.
        exitCodeRanges: [ExitCodeRangeMapping], # Optional. A list of Task exit code ranges and how the Batch service should respond to
them.
        preProcessingError: {
          jobAction: &quot;none&quot; | &quot;disable&quot; | &quot;terminate&quot;, # Optional. The default is none for exit code 0 and terminate for all other exit
conditions. If the Job&apos;s onTaskFailed property is noaction, then specifying
this property returns an error and the add Task request fails with an invalid
property value error; if you are calling the REST API directly, the HTTP status
code is 400 (Bad Request).
          dependencyAction: &quot;satisfy&quot; | &quot;block&quot;, # Optional. Possible values are &apos;satisfy&apos; (allowing dependent tasks to progress) and
&apos;block&apos; (dependent tasks continue to wait). Batch does not yet support
cancellation of dependent tasks.
        }, # Optional. Specifies how the Batch service responds to a particular exit condition.
        fileUploadError: ExitOptions, # Optional. If the Task exited with an exit code that was specified via exitCodes or
exitCodeRanges, and then encountered a file upload error, then the action
specified by the exit code takes precedence.
        default: ExitOptions, # Optional. This value is used if the Task exits with any nonzero exit code not listed in
the exitCodes or exitCodeRanges collection, with a pre-processing error if the
preProcessingError property is not present, or with a file upload error if the
fileUploadError property is not present. If you want non-default behavior on
exit code 0, you must list it explicitly using the exitCodes or exitCodeRanges
collection.
      }, # Optional. How the Batch service should respond when the Task completes.
      state: &quot;active&quot; | &quot;preparing&quot; | &quot;running&quot; | &quot;completed&quot;, # Optional. The state of the Task.
      stateTransitionTime: string (date &amp; time), # Optional. The time at which the Task entered its current state.
      previousState: &quot;active&quot; | &quot;preparing&quot; | &quot;running&quot; | &quot;completed&quot;, # Optional. This property is not set if the Task is in its initial Active state.
      previousStateTransitionTime: string (date &amp; time), # Optional. This property is not set if the Task is in its initial Active state.
      commandLine: string, # Optional. For multi-instance Tasks, the command line is executed as the primary Task,
after the primary Task and all subtasks have finished executing the
coordination command line. The command line does not run under a shell, and
therefore cannot take advantage of shell features such as environment variable
expansion. If you want to take advantage of such features, you should invoke
the shell in the command line, for example using &quot;cmd /c MyCommand&quot; in
Windows or &quot;/bin/sh -c MyCommand&quot; in Linux. If the command line refers to
file paths, it should use a relative path (relative to the Task working
directory), or use the Batch provided environment variable
(https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).
      containerSettings: {
        containerRunOptions: string, # Optional. These additional options are supplied as arguments to the &quot;docker create&quot;
command, in addition to those controlled by the Batch Service.
        imageName: string, # Required. This is the full Image reference, as would be specified to &quot;docker pull&quot;. If
no tag is provided as part of the Image name, the tag &quot;:latest&quot; is used as a
default.
        registry: {
          username: string, # Optional. The user name to log into the registry server.
          password: string, # Optional. The password to log into the registry server.
          registryServer: string, # Optional. If omitted, the default is &quot;docker.io&quot;.
          identityReference: {
            resourceId: string, # Optional. The ARM resource id of the user assigned identity.
          }, # Optional. The reference to a user assigned identity associated with the Batch pool which
a compute node will use.
        }, # Optional. This setting can be omitted if was already provided at Pool creation.
        workingDirectory: &quot;taskWorkingDirectory&quot; | &quot;containerImageDefault&quot;, # Optional. The default is &apos;taskWorkingDirectory&apos;.
      }, # Optional. If the Pool that will run this Task has containerConfiguration set, this must
be set as well. If the Pool that will run this Task doesn&apos;t have
containerConfiguration set, this must not be set. When this is specified, all
directories recursively below the AZ_BATCH_NODE_ROOT_DIR (the root of Azure
Batch directories on the node) are mapped into the container, all Task
environment variables are mapped into the container, and the Task command line
is executed in the container. Files produced in the container outside of
AZ_BATCH_NODE_ROOT_DIR might not be reflected to the host disk, meaning that
Batch file APIs will not be able to access those files.
      resourceFiles: [ResourceFile], # Optional. For multi-instance Tasks, the resource files will only be downloaded to the
Compute Node on which the primary Task is executed. There is a maximum size for
the list of resource files.  When the max size is exceeded, the request will
fail and the response error code will be RequestEntityTooLarge. If this occurs,
the collection of ResourceFiles must be reduced in size. This can be achieved
using .zip files, Application Packages, or Docker Containers.
      outputFiles: [OutputFile], # Optional. For multi-instance Tasks, the files will only be uploaded from the Compute Node
on which the primary Task is executed.
      environmentSettings: [EnvironmentSetting], # Optional. A list of environment variable settings for the Task.
      affinityInfo: {
        affinityId: string, # Required. You can pass the affinityId of a Node to indicate that this Task needs to run
on that Compute Node. Note that this is just a soft affinity. If the target
Compute Node is busy or unavailable at the time the Task is scheduled, then the
Task will be scheduled elsewhere.
      }, # Optional. A locality hint that can be used by the Batch service to select a Compute Node
on which to start a Task.
      constraints: {
        maxWallClockTime: string (duration ISO 8601 Format), # Optional. If this is not specified, there is no time limit on how long the Task may run.
        retentionTime: string (duration ISO 8601 Format), # Optional. The default is 7 days, i.e. the Task directory will be retained for 7 days
unless the Compute Node is removed or the Job is deleted.
        maxTaskRetryCount: number, # Optional. Note that this value specifically controls the number of retries for the Task
executable due to a nonzero exit code. The Batch service will try the Task
once, and may then retry up to this limit. For example, if the maximum retry
count is 3, Batch tries the Task up to 4 times (one initial try and 3 retries).
If the maximum retry count is 0, the Batch service does not retry the Task
after the first attempt. If the maximum retry count is -1, the Batch service
retries the Task without limit, however this is not recommended for a start
task or any task. The default value is 0 (no retries)
      }, # Optional. Execution constraints to apply to a Task.
      requiredSlots: number, # Optional. The default is 1. A Task can only be scheduled to run on a compute node if the
node has enough free scheduling slots available. For multi-instance Tasks, this
must be 1.
      userIdentity: {
        username: string, # Optional. The userName and autoUser properties are mutually exclusive; you must specify
one but not both.
        autoUser: {
          scope: &quot;task&quot; | &quot;pool&quot;, # Optional. The default value is pool. If the pool is running Windows a value of Task
should be specified if stricter isolation between tasks is required. For
example, if the task mutates the registry in a way which could impact other
tasks, or if certificates have been specified on the pool which should not be
accessible by normal tasks but should be accessible by StartTasks.
          elevationLevel: &quot;nonadmin&quot; | &quot;admin&quot;, # Optional. The default value is nonAdmin.
        }, # Optional. The userName and autoUser properties are mutually exclusive; you must specify
one but not both.
      }, # Optional. If omitted, the Task runs as a non-administrative user unique to the Task.
      executionInfo: {
        startTime: string (date &amp; time), # Optional. &apos;Running&apos; corresponds to the running state, so if the Task specifies resource
files or Packages, then the start time reflects the time at which the Task
started downloading or deploying these. If the Task has been restarted or
retried, this is the most recent time at which the Task started running. This
property is present only for Tasks that are in the running or completed state.
        endTime: string (date &amp; time), # Optional. This property is set only if the Task is in the Completed state.
        exitCode: number, # Optional. This property is set only if the Task is in the completed state. In general,
the exit code for a process reflects the specific convention implemented by the
application developer for that process. If you use the exit code value to make
decisions in your code, be sure that you know the exit code convention used by
the application process. However, if the Batch service terminates the Task (due
to timeout, or user termination via the API) you may see an operating
system-defined exit code.
        containerInfo: {
          containerId: string, # Optional. The ID of the container.
          state: string, # Optional. This is the state of the container according to the Docker service. It is
equivalent to the status field returned by &quot;docker inspect&quot;.
          error: string, # Optional. This is the detailed error string from the Docker service, if available. It is
equivalent to the error field returned by &quot;docker inspect&quot;.
        }, # Optional. This property is set only if the Task runs in a container context.
        failureInfo: {
          category: &quot;usererror&quot; | &quot;servererror&quot;, # Required. The category of the error.
          code: string, # Optional. An identifier for the Task error. Codes are invariant and are intended to be
consumed programmatically.
          message: string, # Optional. A message describing the Task error, intended to be suitable for display in a
user interface.
          details: [NameValuePair], # Optional. A list of additional details related to the error.
        }, # Optional. This property is set only if the Task is in the completed state and encountered
a failure.
        retryCount: number, # Required. Task application failures (non-zero exit code) are retried, pre-processing
errors (the Task could not be run) and file upload errors are not retried. The
Batch service will retry the Task up to the limit specified by the constraints.
        lastRetryTime: string (date &amp; time), # Optional. This element is present only if the Task was retried (i.e. retryCount is
nonzero). If present, this is typically the same as startTime, but may be
different if the Task has been restarted for reasons other than retry; for
example, if the Compute Node was rebooted during a retry, then the startTime is
updated but the lastRetryTime is not.
        requeueCount: number, # Required. When the user removes Compute Nodes from a Pool (by resizing/shrinking the
pool) or when the Job is being disabled, the user can specify that running
Tasks on the Compute Nodes be requeued for execution. This count tracks how
many times the Task has been requeued for these reasons.
        lastRequeueTime: string (date &amp; time), # Optional. This property is set only if the requeueCount is nonzero.
        result: &quot;success&quot; | &quot;failure&quot;, # Optional. If the value is &apos;failed&apos;, then the details of the failure can be found in the
failureInfo property.
      }, # Optional. Information about the execution of a Task.
      nodeInfo: {
        affinityId: string, # Optional. An identifier for the Node on which the Task ran, which can be passed when
adding a Task to request that the Task be scheduled on this Compute Node.
        nodeUrl: string, # Optional. The URL of the Compute Node on which the Task ran. 
        poolId: string, # Optional. The ID of the Pool on which the Task ran.
        nodeId: string, # Optional. The ID of the Compute Node on which the Task ran.
        taskRootDirectory: string, # Optional. The root directory of the Task on the Compute Node.
        taskRootDirectoryUrl: string, # Optional. The URL to the root directory of the Task on the Compute Node.
      }, # Optional. Information about the Compute Node on which a Task ran.
      multiInstanceSettings: {
        numberOfInstances: number, # Optional. If omitted, the default is 1.
        coordinationCommandLine: string, # Required. A typical coordination command line launches a background service and verifies
that the service is ready to process inter-node messages.
        commonResourceFiles: [ResourceFile], # Optional. The difference between common resource files and Task resource files is that
common resource files are downloaded for all subtasks including the primary,
whereas Task resource files are downloaded only for the primary. Also note that
these resource files are not downloaded to the Task working directory, but
instead are downloaded to the Task root directory (one directory above the
working directory).  There is a maximum size for the list of resource files. 
When the max size is exceeded, the request will fail and the response error
code will be RequestEntityTooLarge. If this occurs, the collection of
ResourceFiles must be reduced in size. This can be achieved using .zip files,
Application Packages, or Docker Containers.
      }, # Optional. Multi-instance Tasks are commonly used to support MPI Tasks. In the MPI case,
if any of the subtasks fail (for example due to exiting with a non-zero exit
code) the entire multi-instance Task fails. The multi-instance Task is then
terminated and retried, up to its retry limit.
      stats: {
        url: string, # Required. The URL of the statistics.
        startTime: string (date &amp; time), # Required. The start time of the time range covered by the statistics.
        lastUpdateTime: string (date &amp; time), # Required. The time at which the statistics were last updated. All statistics are limited
to the range between startTime and lastUpdateTime.
        userCPUTime: string (duration ISO 8601 Format), # Required. The total user mode CPU time (summed across all cores and all Compute Nodes)
consumed by the Task.
        kernelCPUTime: string (duration ISO 8601 Format), # Required. The total kernel mode CPU time (summed across all cores and all Compute Nodes)
consumed by the Task.
        wallClockTime: string (duration ISO 8601 Format), # Required. The wall clock time is the elapsed time from when the Task started running on a
Compute Node to when it finished (or to the last time the statistics were
updated, if the Task had not finished by then). If the Task was retried, this
includes the wall clock time of all the Task retries.
        readIOps: number, # Required. The total number of disk read operations made by the Task.
        writeIOps: number, # Required. The total number of disk write operations made by the Task.
        readIOGiB: number, # Required. The total gibibytes read from disk by the Task.
        writeIOGiB: number, # Required. The total gibibytes written to disk by the Task.
        waitTime: string (duration ISO 8601 Format), # Required. The total wait time of the Task. The wait time for a Task is defined as the
elapsed time between the creation of the Task and the start of Task execution.
(If the Task is retried due to failures, the wait time is the time to the most
recent Task execution.)
      }, # Optional. Resource usage statistics for a Task.
      dependsOn: {
        taskIds: [string], # Optional. The taskIds collection is limited to 64000 characters total (i.e. the combined
length of all Task IDs). If the taskIds collection exceeds the maximum length,
the Add Task request fails with error code TaskDependencyListTooLong. In this
case consider using Task ID ranges instead.
        taskIdRanges: [TaskIdRange], # Optional. The list of Task ID ranges that this Task depends on. All Tasks in all ranges
must complete successfully before the dependent Task can be scheduled.
      }, # Optional. This Task will not be scheduled until all Tasks that it depends on have
completed successfully. If any of those Tasks fail and exhaust their retry
counts, this Task will never be scheduled.
      applicationPackageReferences: [ApplicationPackageReference], # Optional. Application packages are downloaded and deployed to a shared directory, not the
Task working directory. Therefore, if a referenced package is already on the
Node, and is up to date, then it is not re-downloaded; the existing copy on the
Compute Node is used. If a referenced Package cannot be installed, for example
because the package has been deleted or because download failed, the Task
fails.
      authenticationTokenSettings: {
        access: [&quot;job&quot;], # Optional. The authentication token grants access to a limited set of Batch service
operations. Currently the only supported value for the access property is
&apos;job&apos;, which grants access to all operations related to the Job which contains
the Task.
      }, # Optional. If this property is set, the Batch service provides the Task with an
authentication token which can be used to authenticate Batch service operations
without requiring an Account access key. The token is provided via the
AZ_BATCH_AUTHENTICATION_TOKEN environment variable. The operations that the
Task can carry out using the token depend on the settings. For example, a Task
can request Job permissions in order to add other Tasks to the Job, or check
the status of the Job or of other Tasks under the Job.
    }
  ], # Required. The total serialized size of this collection must be less than 1MB. If it is
greater than 1MB (for example if each Task has 100&apos;s of resource files or
environment variables), the request will fail with code &apos;RequestBodyTooLarge&apos;
and should be retried again with fewer Tasks.
}
</code>

Response Body:

Schema for <c>TaskAddCollectionResult</c>:
<code>{
  value: [
    {
      status: &quot;success&quot; | &quot;clienterror&quot; | &quot;servererror&quot;, # Required. The status of the add Task request.
      taskId: string, # Required. The ID of the Task for which this is the result.
      eTag: string, # Optional. You can use this to detect whether the Task has changed between requests. In
particular, you can be pass the ETag with an Update Task request to specify
that your changes should take effect only if nobody else has modified the Job
in the meantime.
      lastModified: string (date &amp; time), # Optional. The last modified time of the Task.
      location: string, # Optional. The URL of the Task, if the Task was successfully added.
      error: {
        code: string, # Optional. An identifier for the error. Codes are invariant and are intended to be
consumed programmatically.
        message: {
          lang: string, # Optional. The language code of the error message
          value: string, # Optional. The text of the message.
        }, # Optional. An error message received in an Azure Batch error response.
        values: [BatchErrorDetail], # Optional. A collection of key-value pairs containing additional details about the error.
      }, # Optional. An error response received from the Azure Batch service.
    }
  ], # Optional. The results of the add Task collection operation.
}
</code>

</remarks>
    </member>
    <member name="DeleteAsync(String,String,Int32,String,Boolean,String,RequestConditions,RequestContext)">
<example>
This sample shows how to call DeleteAsync with required parameters.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetTaskClient(<2022-10-01.16.0>);

Response response = await client.DeleteAsync("<jobId>", "<taskId>");
Console.WriteLine(response.Status);
]]></code>
This sample shows how to call DeleteAsync with all parameters.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetTaskClient(<2022-10-01.16.0>);

Response response = await client.DeleteAsync("<jobId>", "<taskId>", 1234, "<clientRequestId>", true, "<ocpDate>", null);
Console.WriteLine(response.Status);
]]></code>
</example>
<remarks>
When a Task is deleted, all of the files in its directory on the Compute Node
where it ran are also deleted (regardless of the retention time). For
multi-instance Tasks, the delete Task operation applies synchronously to the
primary task; subtasks and their files are then deleted asynchronously in the
background.
</remarks>
    </member>
    <member name="Delete(String,String,Int32,String,Boolean,String,RequestConditions,RequestContext)">
<example>
This sample shows how to call Delete with required parameters.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetTaskClient(<2022-10-01.16.0>);

Response response = client.Delete("<jobId>", "<taskId>");
Console.WriteLine(response.Status);
]]></code>
This sample shows how to call Delete with all parameters.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetTaskClient(<2022-10-01.16.0>);

Response response = client.Delete("<jobId>", "<taskId>", 1234, "<clientRequestId>", true, "<ocpDate>", null);
Console.WriteLine(response.Status);
]]></code>
</example>
<remarks>
When a Task is deleted, all of the files in its directory on the Compute Node
where it ran are also deleted (regardless of the retention time). For
multi-instance Tasks, the delete Task operation applies synchronously to the
primary task; subtasks and their files are then deleted asynchronously in the
background.
</remarks>
    </member>
    <member name="GetTaskAsync(String,String,Int32,String,Boolean,String,String,String,RequestConditions,RequestContext)">
<example>
This sample shows how to call GetTaskAsync with required parameters and parse the result.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetTaskClient(<2022-10-01.16.0>);

Response response = await client.GetTaskAsync("<jobId>", "<taskId>");

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.ToString());
]]></code>
This sample shows how to call GetTaskAsync with all parameters, and how to parse the result.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetTaskClient(<2022-10-01.16.0>);

Response response = await client.GetTaskAsync("<jobId>", "<taskId>", 1234, "<clientRequestId>", true, "<ocpDate>", "<select>", "<expand>", null);

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.GetProperty("id").ToString());
Console.WriteLine(result.GetProperty("displayName").ToString());
Console.WriteLine(result.GetProperty("url").ToString());
Console.WriteLine(result.GetProperty("eTag").ToString());
Console.WriteLine(result.GetProperty("lastModified").ToString());
Console.WriteLine(result.GetProperty("creationTime").ToString());
Console.WriteLine(result.GetProperty("exitConditions").GetProperty("exitCodes")[0].GetProperty("code").ToString());
Console.WriteLine(result.GetProperty("exitConditions").GetProperty("exitCodes")[0].GetProperty("exitOptions").GetProperty("jobAction").ToString());
Console.WriteLine(result.GetProperty("exitConditions").GetProperty("exitCodes")[0].GetProperty("exitOptions").GetProperty("dependencyAction").ToString());
Console.WriteLine(result.GetProperty("exitConditions").GetProperty("exitCodeRanges")[0].GetProperty("start").ToString());
Console.WriteLine(result.GetProperty("exitConditions").GetProperty("exitCodeRanges")[0].GetProperty("end").ToString());
Console.WriteLine(result.GetProperty("exitConditions").GetProperty("exitCodeRanges")[0].GetProperty("exitOptions").GetProperty("jobAction").ToString());
Console.WriteLine(result.GetProperty("exitConditions").GetProperty("exitCodeRanges")[0].GetProperty("exitOptions").GetProperty("dependencyAction").ToString());
Console.WriteLine(result.GetProperty("exitConditions").GetProperty("preProcessingError").GetProperty("jobAction").ToString());
Console.WriteLine(result.GetProperty("exitConditions").GetProperty("preProcessingError").GetProperty("dependencyAction").ToString());
Console.WriteLine(result.GetProperty("exitConditions").GetProperty("fileUploadError").GetProperty("jobAction").ToString());
Console.WriteLine(result.GetProperty("exitConditions").GetProperty("fileUploadError").GetProperty("dependencyAction").ToString());
Console.WriteLine(result.GetProperty("exitConditions").GetProperty("default").GetProperty("jobAction").ToString());
Console.WriteLine(result.GetProperty("exitConditions").GetProperty("default").GetProperty("dependencyAction").ToString());
Console.WriteLine(result.GetProperty("state").ToString());
Console.WriteLine(result.GetProperty("stateTransitionTime").ToString());
Console.WriteLine(result.GetProperty("previousState").ToString());
Console.WriteLine(result.GetProperty("previousStateTransitionTime").ToString());
Console.WriteLine(result.GetProperty("commandLine").ToString());
Console.WriteLine(result.GetProperty("containerSettings").GetProperty("containerRunOptions").ToString());
Console.WriteLine(result.GetProperty("containerSettings").GetProperty("imageName").ToString());
Console.WriteLine(result.GetProperty("containerSettings").GetProperty("registry").GetProperty("username").ToString());
Console.WriteLine(result.GetProperty("containerSettings").GetProperty("registry").GetProperty("password").ToString());
Console.WriteLine(result.GetProperty("containerSettings").GetProperty("registry").GetProperty("registryServer").ToString());
Console.WriteLine(result.GetProperty("containerSettings").GetProperty("registry").GetProperty("identityReference").GetProperty("resourceId").ToString());
Console.WriteLine(result.GetProperty("containerSettings").GetProperty("workingDirectory").ToString());
Console.WriteLine(result.GetProperty("resourceFiles")[0].GetProperty("autoStorageContainerName").ToString());
Console.WriteLine(result.GetProperty("resourceFiles")[0].GetProperty("storageContainerUrl").ToString());
Console.WriteLine(result.GetProperty("resourceFiles")[0].GetProperty("httpUrl").ToString());
Console.WriteLine(result.GetProperty("resourceFiles")[0].GetProperty("blobPrefix").ToString());
Console.WriteLine(result.GetProperty("resourceFiles")[0].GetProperty("filePath").ToString());
Console.WriteLine(result.GetProperty("resourceFiles")[0].GetProperty("fileMode").ToString());
Console.WriteLine(result.GetProperty("resourceFiles")[0].GetProperty("identityReference").GetProperty("resourceId").ToString());
Console.WriteLine(result.GetProperty("outputFiles")[0].GetProperty("filePattern").ToString());
Console.WriteLine(result.GetProperty("outputFiles")[0].GetProperty("destination").GetProperty("container").GetProperty("path").ToString());
Console.WriteLine(result.GetProperty("outputFiles")[0].GetProperty("destination").GetProperty("container").GetProperty("containerUrl").ToString());
Console.WriteLine(result.GetProperty("outputFiles")[0].GetProperty("destination").GetProperty("container").GetProperty("identityReference").GetProperty("resourceId").ToString());
Console.WriteLine(result.GetProperty("outputFiles")[0].GetProperty("destination").GetProperty("container").GetProperty("uploadHeaders")[0].GetProperty("name").ToString());
Console.WriteLine(result.GetProperty("outputFiles")[0].GetProperty("destination").GetProperty("container").GetProperty("uploadHeaders")[0].GetProperty("value").ToString());
Console.WriteLine(result.GetProperty("outputFiles")[0].GetProperty("uploadOptions").GetProperty("uploadCondition").ToString());
Console.WriteLine(result.GetProperty("environmentSettings")[0].GetProperty("name").ToString());
Console.WriteLine(result.GetProperty("environmentSettings")[0].GetProperty("value").ToString());
Console.WriteLine(result.GetProperty("affinityInfo").GetProperty("affinityId").ToString());
Console.WriteLine(result.GetProperty("constraints").GetProperty("maxWallClockTime").ToString());
Console.WriteLine(result.GetProperty("constraints").GetProperty("retentionTime").ToString());
Console.WriteLine(result.GetProperty("constraints").GetProperty("maxTaskRetryCount").ToString());
Console.WriteLine(result.GetProperty("requiredSlots").ToString());
Console.WriteLine(result.GetProperty("userIdentity").GetProperty("username").ToString());
Console.WriteLine(result.GetProperty("userIdentity").GetProperty("autoUser").GetProperty("scope").ToString());
Console.WriteLine(result.GetProperty("userIdentity").GetProperty("autoUser").GetProperty("elevationLevel").ToString());
Console.WriteLine(result.GetProperty("executionInfo").GetProperty("startTime").ToString());
Console.WriteLine(result.GetProperty("executionInfo").GetProperty("endTime").ToString());
Console.WriteLine(result.GetProperty("executionInfo").GetProperty("exitCode").ToString());
Console.WriteLine(result.GetProperty("executionInfo").GetProperty("containerInfo").GetProperty("containerId").ToString());
Console.WriteLine(result.GetProperty("executionInfo").GetProperty("containerInfo").GetProperty("state").ToString());
Console.WriteLine(result.GetProperty("executionInfo").GetProperty("containerInfo").GetProperty("error").ToString());
Console.WriteLine(result.GetProperty("executionInfo").GetProperty("failureInfo").GetProperty("category").ToString());
Console.WriteLine(result.GetProperty("executionInfo").GetProperty("failureInfo").GetProperty("code").ToString());
Console.WriteLine(result.GetProperty("executionInfo").GetProperty("failureInfo").GetProperty("message").ToString());
Console.WriteLine(result.GetProperty("executionInfo").GetProperty("failureInfo").GetProperty("details")[0].GetProperty("name").ToString());
Console.WriteLine(result.GetProperty("executionInfo").GetProperty("failureInfo").GetProperty("details")[0].GetProperty("value").ToString());
Console.WriteLine(result.GetProperty("executionInfo").GetProperty("retryCount").ToString());
Console.WriteLine(result.GetProperty("executionInfo").GetProperty("lastRetryTime").ToString());
Console.WriteLine(result.GetProperty("executionInfo").GetProperty("requeueCount").ToString());
Console.WriteLine(result.GetProperty("executionInfo").GetProperty("lastRequeueTime").ToString());
Console.WriteLine(result.GetProperty("executionInfo").GetProperty("result").ToString());
Console.WriteLine(result.GetProperty("nodeInfo").GetProperty("affinityId").ToString());
Console.WriteLine(result.GetProperty("nodeInfo").GetProperty("nodeUrl").ToString());
Console.WriteLine(result.GetProperty("nodeInfo").GetProperty("poolId").ToString());
Console.WriteLine(result.GetProperty("nodeInfo").GetProperty("nodeId").ToString());
Console.WriteLine(result.GetProperty("nodeInfo").GetProperty("taskRootDirectory").ToString());
Console.WriteLine(result.GetProperty("nodeInfo").GetProperty("taskRootDirectoryUrl").ToString());
Console.WriteLine(result.GetProperty("multiInstanceSettings").GetProperty("numberOfInstances").ToString());
Console.WriteLine(result.GetProperty("multiInstanceSettings").GetProperty("coordinationCommandLine").ToString());
Console.WriteLine(result.GetProperty("multiInstanceSettings").GetProperty("commonResourceFiles")[0].GetProperty("autoStorageContainerName").ToString());
Console.WriteLine(result.GetProperty("multiInstanceSettings").GetProperty("commonResourceFiles")[0].GetProperty("storageContainerUrl").ToString());
Console.WriteLine(result.GetProperty("multiInstanceSettings").GetProperty("commonResourceFiles")[0].GetProperty("httpUrl").ToString());
Console.WriteLine(result.GetProperty("multiInstanceSettings").GetProperty("commonResourceFiles")[0].GetProperty("blobPrefix").ToString());
Console.WriteLine(result.GetProperty("multiInstanceSettings").GetProperty("commonResourceFiles")[0].GetProperty("filePath").ToString());
Console.WriteLine(result.GetProperty("multiInstanceSettings").GetProperty("commonResourceFiles")[0].GetProperty("fileMode").ToString());
Console.WriteLine(result.GetProperty("multiInstanceSettings").GetProperty("commonResourceFiles")[0].GetProperty("identityReference").GetProperty("resourceId").ToString());
Console.WriteLine(result.GetProperty("stats").GetProperty("url").ToString());
Console.WriteLine(result.GetProperty("stats").GetProperty("startTime").ToString());
Console.WriteLine(result.GetProperty("stats").GetProperty("lastUpdateTime").ToString());
Console.WriteLine(result.GetProperty("stats").GetProperty("userCPUTime").ToString());
Console.WriteLine(result.GetProperty("stats").GetProperty("kernelCPUTime").ToString());
Console.WriteLine(result.GetProperty("stats").GetProperty("wallClockTime").ToString());
Console.WriteLine(result.GetProperty("stats").GetProperty("readIOps").ToString());
Console.WriteLine(result.GetProperty("stats").GetProperty("writeIOps").ToString());
Console.WriteLine(result.GetProperty("stats").GetProperty("readIOGiB").ToString());
Console.WriteLine(result.GetProperty("stats").GetProperty("writeIOGiB").ToString());
Console.WriteLine(result.GetProperty("stats").GetProperty("waitTime").ToString());
Console.WriteLine(result.GetProperty("dependsOn").GetProperty("taskIds")[0].ToString());
Console.WriteLine(result.GetProperty("dependsOn").GetProperty("taskIdRanges")[0].GetProperty("start").ToString());
Console.WriteLine(result.GetProperty("dependsOn").GetProperty("taskIdRanges")[0].GetProperty("end").ToString());
Console.WriteLine(result.GetProperty("applicationPackageReferences")[0].GetProperty("applicationId").ToString());
Console.WriteLine(result.GetProperty("applicationPackageReferences")[0].GetProperty("version").ToString());
Console.WriteLine(result.GetProperty("authenticationTokenSettings").GetProperty("access")[0].ToString());
]]></code>
</example>
<remarks>
For multi-instance Tasks, information such as affinityId, executionInfo and
nodeInfo refer to the primary Task. Use the list subtasks API to retrieve
information about subtasks.

Below is the JSON schema for the response payload.

Response Body:

Schema for <c>BatchTask</c>:
<code>{
  id: string, # Optional. The ID can contain any combination of alphanumeric characters including hyphens
and underscores, and cannot contain more than 64 characters.
  displayName: string, # Optional. The display name need not be unique and can contain any Unicode characters up
to a maximum length of 1024.
  url: string, # Optional. The URL of the Task.
  eTag: string, # Optional. This is an opaque string. You can use it to detect whether the Task has changed
between requests. In particular, you can be pass the ETag when updating a Task
to specify that your changes should take effect only if nobody else has
modified the Task in the meantime.
  lastModified: string (date &amp; time), # Optional. The last modified time of the Task.
  creationTime: string (date &amp; time), # Optional. The creation time of the Task.
  exitConditions: {
    exitCodes: [ExitCodeMapping], # Optional. A list of individual Task exit codes and how the Batch service should respond
to them.
    exitCodeRanges: [ExitCodeRangeMapping], # Optional. A list of Task exit code ranges and how the Batch service should respond to
them.
    preProcessingError: {
      jobAction: &quot;none&quot; | &quot;disable&quot; | &quot;terminate&quot;, # Optional. The default is none for exit code 0 and terminate for all other exit
conditions. If the Job&apos;s onTaskFailed property is noaction, then specifying
this property returns an error and the add Task request fails with an invalid
property value error; if you are calling the REST API directly, the HTTP status
code is 400 (Bad Request).
      dependencyAction: &quot;satisfy&quot; | &quot;block&quot;, # Optional. Possible values are &apos;satisfy&apos; (allowing dependent tasks to progress) and
&apos;block&apos; (dependent tasks continue to wait). Batch does not yet support
cancellation of dependent tasks.
    }, # Optional. Specifies how the Batch service responds to a particular exit condition.
    fileUploadError: ExitOptions, # Optional. If the Task exited with an exit code that was specified via exitCodes or
exitCodeRanges, and then encountered a file upload error, then the action
specified by the exit code takes precedence.
    default: ExitOptions, # Optional. This value is used if the Task exits with any nonzero exit code not listed in
the exitCodes or exitCodeRanges collection, with a pre-processing error if the
preProcessingError property is not present, or with a file upload error if the
fileUploadError property is not present. If you want non-default behavior on
exit code 0, you must list it explicitly using the exitCodes or exitCodeRanges
collection.
  }, # Optional. How the Batch service should respond when the Task completes.
  state: &quot;active&quot; | &quot;preparing&quot; | &quot;running&quot; | &quot;completed&quot;, # Optional. The state of the Task.
  stateTransitionTime: string (date &amp; time), # Optional. The time at which the Task entered its current state.
  previousState: &quot;active&quot; | &quot;preparing&quot; | &quot;running&quot; | &quot;completed&quot;, # Optional. This property is not set if the Task is in its initial Active state.
  previousStateTransitionTime: string (date &amp; time), # Optional. This property is not set if the Task is in its initial Active state.
  commandLine: string, # Optional. For multi-instance Tasks, the command line is executed as the primary Task,
after the primary Task and all subtasks have finished executing the
coordination command line. The command line does not run under a shell, and
therefore cannot take advantage of shell features such as environment variable
expansion. If you want to take advantage of such features, you should invoke
the shell in the command line, for example using &quot;cmd /c MyCommand&quot; in
Windows or &quot;/bin/sh -c MyCommand&quot; in Linux. If the command line refers to
file paths, it should use a relative path (relative to the Task working
directory), or use the Batch provided environment variable
(https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).
  containerSettings: {
    containerRunOptions: string, # Optional. These additional options are supplied as arguments to the &quot;docker create&quot;
command, in addition to those controlled by the Batch Service.
    imageName: string, # Required. This is the full Image reference, as would be specified to &quot;docker pull&quot;. If
no tag is provided as part of the Image name, the tag &quot;:latest&quot; is used as a
default.
    registry: {
      username: string, # Optional. The user name to log into the registry server.
      password: string, # Optional. The password to log into the registry server.
      registryServer: string, # Optional. If omitted, the default is &quot;docker.io&quot;.
      identityReference: {
        resourceId: string, # Optional. The ARM resource id of the user assigned identity.
      }, # Optional. The reference to a user assigned identity associated with the Batch pool which
a compute node will use.
    }, # Optional. This setting can be omitted if was already provided at Pool creation.
    workingDirectory: &quot;taskWorkingDirectory&quot; | &quot;containerImageDefault&quot;, # Optional. The default is &apos;taskWorkingDirectory&apos;.
  }, # Optional. If the Pool that will run this Task has containerConfiguration set, this must
be set as well. If the Pool that will run this Task doesn&apos;t have
containerConfiguration set, this must not be set. When this is specified, all
directories recursively below the AZ_BATCH_NODE_ROOT_DIR (the root of Azure
Batch directories on the node) are mapped into the container, all Task
environment variables are mapped into the container, and the Task command line
is executed in the container. Files produced in the container outside of
AZ_BATCH_NODE_ROOT_DIR might not be reflected to the host disk, meaning that
Batch file APIs will not be able to access those files.
  resourceFiles: [
    {
      autoStorageContainerName: string, # Optional. The autoStorageContainerName, storageContainerUrl and httpUrl properties are
mutually exclusive and one of them must be specified.
      storageContainerUrl: string, # Optional. The autoStorageContainerName, storageContainerUrl and httpUrl properties are
mutually exclusive and one of them must be specified. This URL must be readable
and listable from compute nodes. There are three ways to get such a URL for a
container in Azure storage: include a Shared Access Signature (SAS) granting
read and list permissions on the container, use a managed identity with read
and list permissions, or set the ACL for the container to allow public access.
      httpUrl: string, # Optional. The autoStorageContainerName, storageContainerUrl and httpUrl properties are
mutually exclusive and one of them must be specified. If the URL points to
Azure Blob Storage, it must be readable from compute nodes. There are three
ways to get such a URL for a blob in Azure storage: include a Shared Access
Signature (SAS) granting read permissions on the blob, use a managed identity
with read permission, or set the ACL for the blob or its container to allow
public access.
      blobPrefix: string, # Optional. The property is valid only when autoStorageContainerName or storageContainerUrl
is used. This prefix can be a partial filename or a subdirectory. If a prefix
is not specified, all the files in the container will be downloaded.
      filePath: string, # Optional. If the httpUrl property is specified, the filePath is required and describes
the path which the file will be downloaded to, including the filename.
Otherwise, if the autoStorageContainerName or storageContainerUrl property is
specified, filePath is optional and is the directory to download the files to.
In the case where filePath is used as a directory, any directory structure
already associated with the input data will be retained in full and appended to
the specified filePath directory. The specified relative path cannot break out
of the Task&apos;s working directory (for example by using &apos;..&apos;).
      fileMode: string, # Optional. This property applies only to files being downloaded to Linux Compute Nodes. It
will be ignored if it is specified for a resourceFile which will be downloaded
to a Windows Compute Node. If this property is not specified for a Linux
Compute Node, then a default value of 0770 is applied to the file.
      identityReference: ComputeNodeIdentityReference, # Optional. The reference to a user assigned identity associated with the Batch pool which
a compute node will use.
    }
  ], # Optional. For multi-instance Tasks, the resource files will only be downloaded to the
Compute Node on which the primary Task is executed. There is a maximum size for
the list of resource files.  When the max size is exceeded, the request will
fail and the response error code will be RequestEntityTooLarge. If this occurs,
the collection of ResourceFiles must be reduced in size. This can be achieved
using .zip files, Application Packages, or Docker Containers.
  outputFiles: [OutputFile], # Optional. For multi-instance Tasks, the files will only be uploaded from the Compute Node
on which the primary Task is executed.
  environmentSettings: [EnvironmentSetting], # Optional. A list of environment variable settings for the Task.
  affinityInfo: {
    affinityId: string, # Required. You can pass the affinityId of a Node to indicate that this Task needs to run
on that Compute Node. Note that this is just a soft affinity. If the target
Compute Node is busy or unavailable at the time the Task is scheduled, then the
Task will be scheduled elsewhere.
  }, # Optional. A locality hint that can be used by the Batch service to select a Compute Node
on which to start a Task.
  constraints: {
    maxWallClockTime: string (duration ISO 8601 Format), # Optional. If this is not specified, there is no time limit on how long the Task may run.
    retentionTime: string (duration ISO 8601 Format), # Optional. The default is 7 days, i.e. the Task directory will be retained for 7 days
unless the Compute Node is removed or the Job is deleted.
    maxTaskRetryCount: number, # Optional. Note that this value specifically controls the number of retries for the Task
executable due to a nonzero exit code. The Batch service will try the Task
once, and may then retry up to this limit. For example, if the maximum retry
count is 3, Batch tries the Task up to 4 times (one initial try and 3 retries).
If the maximum retry count is 0, the Batch service does not retry the Task
after the first attempt. If the maximum retry count is -1, the Batch service
retries the Task without limit, however this is not recommended for a start
task or any task. The default value is 0 (no retries)
  }, # Optional. Execution constraints to apply to a Task.
  requiredSlots: number, # Optional. The default is 1. A Task can only be scheduled to run on a compute node if the
node has enough free scheduling slots available. For multi-instance Tasks, this
must be 1.
  userIdentity: {
    username: string, # Optional. The userName and autoUser properties are mutually exclusive; you must specify
one but not both.
    autoUser: {
      scope: &quot;task&quot; | &quot;pool&quot;, # Optional. The default value is pool. If the pool is running Windows a value of Task
should be specified if stricter isolation between tasks is required. For
example, if the task mutates the registry in a way which could impact other
tasks, or if certificates have been specified on the pool which should not be
accessible by normal tasks but should be accessible by StartTasks.
      elevationLevel: &quot;nonadmin&quot; | &quot;admin&quot;, # Optional. The default value is nonAdmin.
    }, # Optional. The userName and autoUser properties are mutually exclusive; you must specify
one but not both.
  }, # Optional. If omitted, the Task runs as a non-administrative user unique to the Task.
  executionInfo: {
    startTime: string (date &amp; time), # Optional. &apos;Running&apos; corresponds to the running state, so if the Task specifies resource
files or Packages, then the start time reflects the time at which the Task
started downloading or deploying these. If the Task has been restarted or
retried, this is the most recent time at which the Task started running. This
property is present only for Tasks that are in the running or completed state.
    endTime: string (date &amp; time), # Optional. This property is set only if the Task is in the Completed state.
    exitCode: number, # Optional. This property is set only if the Task is in the completed state. In general,
the exit code for a process reflects the specific convention implemented by the
application developer for that process. If you use the exit code value to make
decisions in your code, be sure that you know the exit code convention used by
the application process. However, if the Batch service terminates the Task (due
to timeout, or user termination via the API) you may see an operating
system-defined exit code.
    containerInfo: {
      containerId: string, # Optional. The ID of the container.
      state: string, # Optional. This is the state of the container according to the Docker service. It is
equivalent to the status field returned by &quot;docker inspect&quot;.
      error: string, # Optional. This is the detailed error string from the Docker service, if available. It is
equivalent to the error field returned by &quot;docker inspect&quot;.
    }, # Optional. This property is set only if the Task runs in a container context.
    failureInfo: {
      category: &quot;usererror&quot; | &quot;servererror&quot;, # Required. The category of the error.
      code: string, # Optional. An identifier for the Task error. Codes are invariant and are intended to be
consumed programmatically.
      message: string, # Optional. A message describing the Task error, intended to be suitable for display in a
user interface.
      details: [NameValuePair], # Optional. A list of additional details related to the error.
    }, # Optional. This property is set only if the Task is in the completed state and encountered
a failure.
    retryCount: number, # Required. Task application failures (non-zero exit code) are retried, pre-processing
errors (the Task could not be run) and file upload errors are not retried. The
Batch service will retry the Task up to the limit specified by the constraints.
    lastRetryTime: string (date &amp; time), # Optional. This element is present only if the Task was retried (i.e. retryCount is
nonzero). If present, this is typically the same as startTime, but may be
different if the Task has been restarted for reasons other than retry; for
example, if the Compute Node was rebooted during a retry, then the startTime is
updated but the lastRetryTime is not.
    requeueCount: number, # Required. When the user removes Compute Nodes from a Pool (by resizing/shrinking the
pool) or when the Job is being disabled, the user can specify that running
Tasks on the Compute Nodes be requeued for execution. This count tracks how
many times the Task has been requeued for these reasons.
    lastRequeueTime: string (date &amp; time), # Optional. This property is set only if the requeueCount is nonzero.
    result: &quot;success&quot; | &quot;failure&quot;, # Optional. If the value is &apos;failed&apos;, then the details of the failure can be found in the
failureInfo property.
  }, # Optional. Information about the execution of a Task.
  nodeInfo: {
    affinityId: string, # Optional. An identifier for the Node on which the Task ran, which can be passed when
adding a Task to request that the Task be scheduled on this Compute Node.
    nodeUrl: string, # Optional. The URL of the Compute Node on which the Task ran. 
    poolId: string, # Optional. The ID of the Pool on which the Task ran.
    nodeId: string, # Optional. The ID of the Compute Node on which the Task ran.
    taskRootDirectory: string, # Optional. The root directory of the Task on the Compute Node.
    taskRootDirectoryUrl: string, # Optional. The URL to the root directory of the Task on the Compute Node.
  }, # Optional. Information about the Compute Node on which a Task ran.
  multiInstanceSettings: {
    numberOfInstances: number, # Optional. If omitted, the default is 1.
    coordinationCommandLine: string, # Required. A typical coordination command line launches a background service and verifies
that the service is ready to process inter-node messages.
    commonResourceFiles: [ResourceFile], # Optional. The difference between common resource files and Task resource files is that
common resource files are downloaded for all subtasks including the primary,
whereas Task resource files are downloaded only for the primary. Also note that
these resource files are not downloaded to the Task working directory, but
instead are downloaded to the Task root directory (one directory above the
working directory).  There is a maximum size for the list of resource files. 
When the max size is exceeded, the request will fail and the response error
code will be RequestEntityTooLarge. If this occurs, the collection of
ResourceFiles must be reduced in size. This can be achieved using .zip files,
Application Packages, or Docker Containers.
  }, # Optional. Multi-instance Tasks are commonly used to support MPI Tasks. In the MPI case,
if any of the subtasks fail (for example due to exiting with a non-zero exit
code) the entire multi-instance Task fails. The multi-instance Task is then
terminated and retried, up to its retry limit.
  stats: {
    url: string, # Required. The URL of the statistics.
    startTime: string (date &amp; time), # Required. The start time of the time range covered by the statistics.
    lastUpdateTime: string (date &amp; time), # Required. The time at which the statistics were last updated. All statistics are limited
to the range between startTime and lastUpdateTime.
    userCPUTime: string (duration ISO 8601 Format), # Required. The total user mode CPU time (summed across all cores and all Compute Nodes)
consumed by the Task.
    kernelCPUTime: string (duration ISO 8601 Format), # Required. The total kernel mode CPU time (summed across all cores and all Compute Nodes)
consumed by the Task.
    wallClockTime: string (duration ISO 8601 Format), # Required. The wall clock time is the elapsed time from when the Task started running on a
Compute Node to when it finished (or to the last time the statistics were
updated, if the Task had not finished by then). If the Task was retried, this
includes the wall clock time of all the Task retries.
    readIOps: number, # Required. The total number of disk read operations made by the Task.
    writeIOps: number, # Required. The total number of disk write operations made by the Task.
    readIOGiB: number, # Required. The total gibibytes read from disk by the Task.
    writeIOGiB: number, # Required. The total gibibytes written to disk by the Task.
    waitTime: string (duration ISO 8601 Format), # Required. The total wait time of the Task. The wait time for a Task is defined as the
elapsed time between the creation of the Task and the start of Task execution.
(If the Task is retried due to failures, the wait time is the time to the most
recent Task execution.)
  }, # Optional. Resource usage statistics for a Task.
  dependsOn: {
    taskIds: [string], # Optional. The taskIds collection is limited to 64000 characters total (i.e. the combined
length of all Task IDs). If the taskIds collection exceeds the maximum length,
the Add Task request fails with error code TaskDependencyListTooLong. In this
case consider using Task ID ranges instead.
    taskIdRanges: [TaskIdRange], # Optional. The list of Task ID ranges that this Task depends on. All Tasks in all ranges
must complete successfully before the dependent Task can be scheduled.
  }, # Optional. This Task will not be scheduled until all Tasks that it depends on have
completed successfully. If any of those Tasks fail and exhaust their retry
counts, this Task will never be scheduled.
  applicationPackageReferences: [ApplicationPackageReference], # Optional. Application packages are downloaded and deployed to a shared directory, not the
Task working directory. Therefore, if a referenced package is already on the
Node, and is up to date, then it is not re-downloaded; the existing copy on the
Compute Node is used. If a referenced Package cannot be installed, for example
because the package has been deleted or because download failed, the Task
fails.
  authenticationTokenSettings: {
    access: [&quot;job&quot;], # Optional. The authentication token grants access to a limited set of Batch service
operations. Currently the only supported value for the access property is
&apos;job&apos;, which grants access to all operations related to the Job which contains
the Task.
  }, # Optional. If this property is set, the Batch service provides the Task with an
authentication token which can be used to authenticate Batch service operations
without requiring an Account access key. The token is provided via the
AZ_BATCH_AUTHENTICATION_TOKEN environment variable. The operations that the
Task can carry out using the token depend on the settings. For example, a Task
can request Job permissions in order to add other Tasks to the Job, or check
the status of the Job or of other Tasks under the Job.
}
</code>

</remarks>
    </member>
    <member name="GetTask(String,String,Int32,String,Boolean,String,String,String,RequestConditions,RequestContext)">
<example>
This sample shows how to call GetTask with required parameters and parse the result.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetTaskClient(<2022-10-01.16.0>);

Response response = client.GetTask("<jobId>", "<taskId>");

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.ToString());
]]></code>
This sample shows how to call GetTask with all parameters, and how to parse the result.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetTaskClient(<2022-10-01.16.0>);

Response response = client.GetTask("<jobId>", "<taskId>", 1234, "<clientRequestId>", true, "<ocpDate>", "<select>", "<expand>", null);

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.GetProperty("id").ToString());
Console.WriteLine(result.GetProperty("displayName").ToString());
Console.WriteLine(result.GetProperty("url").ToString());
Console.WriteLine(result.GetProperty("eTag").ToString());
Console.WriteLine(result.GetProperty("lastModified").ToString());
Console.WriteLine(result.GetProperty("creationTime").ToString());
Console.WriteLine(result.GetProperty("exitConditions").GetProperty("exitCodes")[0].GetProperty("code").ToString());
Console.WriteLine(result.GetProperty("exitConditions").GetProperty("exitCodes")[0].GetProperty("exitOptions").GetProperty("jobAction").ToString());
Console.WriteLine(result.GetProperty("exitConditions").GetProperty("exitCodes")[0].GetProperty("exitOptions").GetProperty("dependencyAction").ToString());
Console.WriteLine(result.GetProperty("exitConditions").GetProperty("exitCodeRanges")[0].GetProperty("start").ToString());
Console.WriteLine(result.GetProperty("exitConditions").GetProperty("exitCodeRanges")[0].GetProperty("end").ToString());
Console.WriteLine(result.GetProperty("exitConditions").GetProperty("exitCodeRanges")[0].GetProperty("exitOptions").GetProperty("jobAction").ToString());
Console.WriteLine(result.GetProperty("exitConditions").GetProperty("exitCodeRanges")[0].GetProperty("exitOptions").GetProperty("dependencyAction").ToString());
Console.WriteLine(result.GetProperty("exitConditions").GetProperty("preProcessingError").GetProperty("jobAction").ToString());
Console.WriteLine(result.GetProperty("exitConditions").GetProperty("preProcessingError").GetProperty("dependencyAction").ToString());
Console.WriteLine(result.GetProperty("exitConditions").GetProperty("fileUploadError").GetProperty("jobAction").ToString());
Console.WriteLine(result.GetProperty("exitConditions").GetProperty("fileUploadError").GetProperty("dependencyAction").ToString());
Console.WriteLine(result.GetProperty("exitConditions").GetProperty("default").GetProperty("jobAction").ToString());
Console.WriteLine(result.GetProperty("exitConditions").GetProperty("default").GetProperty("dependencyAction").ToString());
Console.WriteLine(result.GetProperty("state").ToString());
Console.WriteLine(result.GetProperty("stateTransitionTime").ToString());
Console.WriteLine(result.GetProperty("previousState").ToString());
Console.WriteLine(result.GetProperty("previousStateTransitionTime").ToString());
Console.WriteLine(result.GetProperty("commandLine").ToString());
Console.WriteLine(result.GetProperty("containerSettings").GetProperty("containerRunOptions").ToString());
Console.WriteLine(result.GetProperty("containerSettings").GetProperty("imageName").ToString());
Console.WriteLine(result.GetProperty("containerSettings").GetProperty("registry").GetProperty("username").ToString());
Console.WriteLine(result.GetProperty("containerSettings").GetProperty("registry").GetProperty("password").ToString());
Console.WriteLine(result.GetProperty("containerSettings").GetProperty("registry").GetProperty("registryServer").ToString());
Console.WriteLine(result.GetProperty("containerSettings").GetProperty("registry").GetProperty("identityReference").GetProperty("resourceId").ToString());
Console.WriteLine(result.GetProperty("containerSettings").GetProperty("workingDirectory").ToString());
Console.WriteLine(result.GetProperty("resourceFiles")[0].GetProperty("autoStorageContainerName").ToString());
Console.WriteLine(result.GetProperty("resourceFiles")[0].GetProperty("storageContainerUrl").ToString());
Console.WriteLine(result.GetProperty("resourceFiles")[0].GetProperty("httpUrl").ToString());
Console.WriteLine(result.GetProperty("resourceFiles")[0].GetProperty("blobPrefix").ToString());
Console.WriteLine(result.GetProperty("resourceFiles")[0].GetProperty("filePath").ToString());
Console.WriteLine(result.GetProperty("resourceFiles")[0].GetProperty("fileMode").ToString());
Console.WriteLine(result.GetProperty("resourceFiles")[0].GetProperty("identityReference").GetProperty("resourceId").ToString());
Console.WriteLine(result.GetProperty("outputFiles")[0].GetProperty("filePattern").ToString());
Console.WriteLine(result.GetProperty("outputFiles")[0].GetProperty("destination").GetProperty("container").GetProperty("path").ToString());
Console.WriteLine(result.GetProperty("outputFiles")[0].GetProperty("destination").GetProperty("container").GetProperty("containerUrl").ToString());
Console.WriteLine(result.GetProperty("outputFiles")[0].GetProperty("destination").GetProperty("container").GetProperty("identityReference").GetProperty("resourceId").ToString());
Console.WriteLine(result.GetProperty("outputFiles")[0].GetProperty("destination").GetProperty("container").GetProperty("uploadHeaders")[0].GetProperty("name").ToString());
Console.WriteLine(result.GetProperty("outputFiles")[0].GetProperty("destination").GetProperty("container").GetProperty("uploadHeaders")[0].GetProperty("value").ToString());
Console.WriteLine(result.GetProperty("outputFiles")[0].GetProperty("uploadOptions").GetProperty("uploadCondition").ToString());
Console.WriteLine(result.GetProperty("environmentSettings")[0].GetProperty("name").ToString());
Console.WriteLine(result.GetProperty("environmentSettings")[0].GetProperty("value").ToString());
Console.WriteLine(result.GetProperty("affinityInfo").GetProperty("affinityId").ToString());
Console.WriteLine(result.GetProperty("constraints").GetProperty("maxWallClockTime").ToString());
Console.WriteLine(result.GetProperty("constraints").GetProperty("retentionTime").ToString());
Console.WriteLine(result.GetProperty("constraints").GetProperty("maxTaskRetryCount").ToString());
Console.WriteLine(result.GetProperty("requiredSlots").ToString());
Console.WriteLine(result.GetProperty("userIdentity").GetProperty("username").ToString());
Console.WriteLine(result.GetProperty("userIdentity").GetProperty("autoUser").GetProperty("scope").ToString());
Console.WriteLine(result.GetProperty("userIdentity").GetProperty("autoUser").GetProperty("elevationLevel").ToString());
Console.WriteLine(result.GetProperty("executionInfo").GetProperty("startTime").ToString());
Console.WriteLine(result.GetProperty("executionInfo").GetProperty("endTime").ToString());
Console.WriteLine(result.GetProperty("executionInfo").GetProperty("exitCode").ToString());
Console.WriteLine(result.GetProperty("executionInfo").GetProperty("containerInfo").GetProperty("containerId").ToString());
Console.WriteLine(result.GetProperty("executionInfo").GetProperty("containerInfo").GetProperty("state").ToString());
Console.WriteLine(result.GetProperty("executionInfo").GetProperty("containerInfo").GetProperty("error").ToString());
Console.WriteLine(result.GetProperty("executionInfo").GetProperty("failureInfo").GetProperty("category").ToString());
Console.WriteLine(result.GetProperty("executionInfo").GetProperty("failureInfo").GetProperty("code").ToString());
Console.WriteLine(result.GetProperty("executionInfo").GetProperty("failureInfo").GetProperty("message").ToString());
Console.WriteLine(result.GetProperty("executionInfo").GetProperty("failureInfo").GetProperty("details")[0].GetProperty("name").ToString());
Console.WriteLine(result.GetProperty("executionInfo").GetProperty("failureInfo").GetProperty("details")[0].GetProperty("value").ToString());
Console.WriteLine(result.GetProperty("executionInfo").GetProperty("retryCount").ToString());
Console.WriteLine(result.GetProperty("executionInfo").GetProperty("lastRetryTime").ToString());
Console.WriteLine(result.GetProperty("executionInfo").GetProperty("requeueCount").ToString());
Console.WriteLine(result.GetProperty("executionInfo").GetProperty("lastRequeueTime").ToString());
Console.WriteLine(result.GetProperty("executionInfo").GetProperty("result").ToString());
Console.WriteLine(result.GetProperty("nodeInfo").GetProperty("affinityId").ToString());
Console.WriteLine(result.GetProperty("nodeInfo").GetProperty("nodeUrl").ToString());
Console.WriteLine(result.GetProperty("nodeInfo").GetProperty("poolId").ToString());
Console.WriteLine(result.GetProperty("nodeInfo").GetProperty("nodeId").ToString());
Console.WriteLine(result.GetProperty("nodeInfo").GetProperty("taskRootDirectory").ToString());
Console.WriteLine(result.GetProperty("nodeInfo").GetProperty("taskRootDirectoryUrl").ToString());
Console.WriteLine(result.GetProperty("multiInstanceSettings").GetProperty("numberOfInstances").ToString());
Console.WriteLine(result.GetProperty("multiInstanceSettings").GetProperty("coordinationCommandLine").ToString());
Console.WriteLine(result.GetProperty("multiInstanceSettings").GetProperty("commonResourceFiles")[0].GetProperty("autoStorageContainerName").ToString());
Console.WriteLine(result.GetProperty("multiInstanceSettings").GetProperty("commonResourceFiles")[0].GetProperty("storageContainerUrl").ToString());
Console.WriteLine(result.GetProperty("multiInstanceSettings").GetProperty("commonResourceFiles")[0].GetProperty("httpUrl").ToString());
Console.WriteLine(result.GetProperty("multiInstanceSettings").GetProperty("commonResourceFiles")[0].GetProperty("blobPrefix").ToString());
Console.WriteLine(result.GetProperty("multiInstanceSettings").GetProperty("commonResourceFiles")[0].GetProperty("filePath").ToString());
Console.WriteLine(result.GetProperty("multiInstanceSettings").GetProperty("commonResourceFiles")[0].GetProperty("fileMode").ToString());
Console.WriteLine(result.GetProperty("multiInstanceSettings").GetProperty("commonResourceFiles")[0].GetProperty("identityReference").GetProperty("resourceId").ToString());
Console.WriteLine(result.GetProperty("stats").GetProperty("url").ToString());
Console.WriteLine(result.GetProperty("stats").GetProperty("startTime").ToString());
Console.WriteLine(result.GetProperty("stats").GetProperty("lastUpdateTime").ToString());
Console.WriteLine(result.GetProperty("stats").GetProperty("userCPUTime").ToString());
Console.WriteLine(result.GetProperty("stats").GetProperty("kernelCPUTime").ToString());
Console.WriteLine(result.GetProperty("stats").GetProperty("wallClockTime").ToString());
Console.WriteLine(result.GetProperty("stats").GetProperty("readIOps").ToString());
Console.WriteLine(result.GetProperty("stats").GetProperty("writeIOps").ToString());
Console.WriteLine(result.GetProperty("stats").GetProperty("readIOGiB").ToString());
Console.WriteLine(result.GetProperty("stats").GetProperty("writeIOGiB").ToString());
Console.WriteLine(result.GetProperty("stats").GetProperty("waitTime").ToString());
Console.WriteLine(result.GetProperty("dependsOn").GetProperty("taskIds")[0].ToString());
Console.WriteLine(result.GetProperty("dependsOn").GetProperty("taskIdRanges")[0].GetProperty("start").ToString());
Console.WriteLine(result.GetProperty("dependsOn").GetProperty("taskIdRanges")[0].GetProperty("end").ToString());
Console.WriteLine(result.GetProperty("applicationPackageReferences")[0].GetProperty("applicationId").ToString());
Console.WriteLine(result.GetProperty("applicationPackageReferences")[0].GetProperty("version").ToString());
Console.WriteLine(result.GetProperty("authenticationTokenSettings").GetProperty("access")[0].ToString());
]]></code>
</example>
<remarks>
For multi-instance Tasks, information such as affinityId, executionInfo and
nodeInfo refer to the primary Task. Use the list subtasks API to retrieve
information about subtasks.

Below is the JSON schema for the response payload.

Response Body:

Schema for <c>BatchTask</c>:
<code>{
  id: string, # Optional. The ID can contain any combination of alphanumeric characters including hyphens
and underscores, and cannot contain more than 64 characters.
  displayName: string, # Optional. The display name need not be unique and can contain any Unicode characters up
to a maximum length of 1024.
  url: string, # Optional. The URL of the Task.
  eTag: string, # Optional. This is an opaque string. You can use it to detect whether the Task has changed
between requests. In particular, you can be pass the ETag when updating a Task
to specify that your changes should take effect only if nobody else has
modified the Task in the meantime.
  lastModified: string (date &amp; time), # Optional. The last modified time of the Task.
  creationTime: string (date &amp; time), # Optional. The creation time of the Task.
  exitConditions: {
    exitCodes: [ExitCodeMapping], # Optional. A list of individual Task exit codes and how the Batch service should respond
to them.
    exitCodeRanges: [ExitCodeRangeMapping], # Optional. A list of Task exit code ranges and how the Batch service should respond to
them.
    preProcessingError: {
      jobAction: &quot;none&quot; | &quot;disable&quot; | &quot;terminate&quot;, # Optional. The default is none for exit code 0 and terminate for all other exit
conditions. If the Job&apos;s onTaskFailed property is noaction, then specifying
this property returns an error and the add Task request fails with an invalid
property value error; if you are calling the REST API directly, the HTTP status
code is 400 (Bad Request).
      dependencyAction: &quot;satisfy&quot; | &quot;block&quot;, # Optional. Possible values are &apos;satisfy&apos; (allowing dependent tasks to progress) and
&apos;block&apos; (dependent tasks continue to wait). Batch does not yet support
cancellation of dependent tasks.
    }, # Optional. Specifies how the Batch service responds to a particular exit condition.
    fileUploadError: ExitOptions, # Optional. If the Task exited with an exit code that was specified via exitCodes or
exitCodeRanges, and then encountered a file upload error, then the action
specified by the exit code takes precedence.
    default: ExitOptions, # Optional. This value is used if the Task exits with any nonzero exit code not listed in
the exitCodes or exitCodeRanges collection, with a pre-processing error if the
preProcessingError property is not present, or with a file upload error if the
fileUploadError property is not present. If you want non-default behavior on
exit code 0, you must list it explicitly using the exitCodes or exitCodeRanges
collection.
  }, # Optional. How the Batch service should respond when the Task completes.
  state: &quot;active&quot; | &quot;preparing&quot; | &quot;running&quot; | &quot;completed&quot;, # Optional. The state of the Task.
  stateTransitionTime: string (date &amp; time), # Optional. The time at which the Task entered its current state.
  previousState: &quot;active&quot; | &quot;preparing&quot; | &quot;running&quot; | &quot;completed&quot;, # Optional. This property is not set if the Task is in its initial Active state.
  previousStateTransitionTime: string (date &amp; time), # Optional. This property is not set if the Task is in its initial Active state.
  commandLine: string, # Optional. For multi-instance Tasks, the command line is executed as the primary Task,
after the primary Task and all subtasks have finished executing the
coordination command line. The command line does not run under a shell, and
therefore cannot take advantage of shell features such as environment variable
expansion. If you want to take advantage of such features, you should invoke
the shell in the command line, for example using &quot;cmd /c MyCommand&quot; in
Windows or &quot;/bin/sh -c MyCommand&quot; in Linux. If the command line refers to
file paths, it should use a relative path (relative to the Task working
directory), or use the Batch provided environment variable
(https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).
  containerSettings: {
    containerRunOptions: string, # Optional. These additional options are supplied as arguments to the &quot;docker create&quot;
command, in addition to those controlled by the Batch Service.
    imageName: string, # Required. This is the full Image reference, as would be specified to &quot;docker pull&quot;. If
no tag is provided as part of the Image name, the tag &quot;:latest&quot; is used as a
default.
    registry: {
      username: string, # Optional. The user name to log into the registry server.
      password: string, # Optional. The password to log into the registry server.
      registryServer: string, # Optional. If omitted, the default is &quot;docker.io&quot;.
      identityReference: {
        resourceId: string, # Optional. The ARM resource id of the user assigned identity.
      }, # Optional. The reference to a user assigned identity associated with the Batch pool which
a compute node will use.
    }, # Optional. This setting can be omitted if was already provided at Pool creation.
    workingDirectory: &quot;taskWorkingDirectory&quot; | &quot;containerImageDefault&quot;, # Optional. The default is &apos;taskWorkingDirectory&apos;.
  }, # Optional. If the Pool that will run this Task has containerConfiguration set, this must
be set as well. If the Pool that will run this Task doesn&apos;t have
containerConfiguration set, this must not be set. When this is specified, all
directories recursively below the AZ_BATCH_NODE_ROOT_DIR (the root of Azure
Batch directories on the node) are mapped into the container, all Task
environment variables are mapped into the container, and the Task command line
is executed in the container. Files produced in the container outside of
AZ_BATCH_NODE_ROOT_DIR might not be reflected to the host disk, meaning that
Batch file APIs will not be able to access those files.
  resourceFiles: [
    {
      autoStorageContainerName: string, # Optional. The autoStorageContainerName, storageContainerUrl and httpUrl properties are
mutually exclusive and one of them must be specified.
      storageContainerUrl: string, # Optional. The autoStorageContainerName, storageContainerUrl and httpUrl properties are
mutually exclusive and one of them must be specified. This URL must be readable
and listable from compute nodes. There are three ways to get such a URL for a
container in Azure storage: include a Shared Access Signature (SAS) granting
read and list permissions on the container, use a managed identity with read
and list permissions, or set the ACL for the container to allow public access.
      httpUrl: string, # Optional. The autoStorageContainerName, storageContainerUrl and httpUrl properties are
mutually exclusive and one of them must be specified. If the URL points to
Azure Blob Storage, it must be readable from compute nodes. There are three
ways to get such a URL for a blob in Azure storage: include a Shared Access
Signature (SAS) granting read permissions on the blob, use a managed identity
with read permission, or set the ACL for the blob or its container to allow
public access.
      blobPrefix: string, # Optional. The property is valid only when autoStorageContainerName or storageContainerUrl
is used. This prefix can be a partial filename or a subdirectory. If a prefix
is not specified, all the files in the container will be downloaded.
      filePath: string, # Optional. If the httpUrl property is specified, the filePath is required and describes
the path which the file will be downloaded to, including the filename.
Otherwise, if the autoStorageContainerName or storageContainerUrl property is
specified, filePath is optional and is the directory to download the files to.
In the case where filePath is used as a directory, any directory structure
already associated with the input data will be retained in full and appended to
the specified filePath directory. The specified relative path cannot break out
of the Task&apos;s working directory (for example by using &apos;..&apos;).
      fileMode: string, # Optional. This property applies only to files being downloaded to Linux Compute Nodes. It
will be ignored if it is specified for a resourceFile which will be downloaded
to a Windows Compute Node. If this property is not specified for a Linux
Compute Node, then a default value of 0770 is applied to the file.
      identityReference: ComputeNodeIdentityReference, # Optional. The reference to a user assigned identity associated with the Batch pool which
a compute node will use.
    }
  ], # Optional. For multi-instance Tasks, the resource files will only be downloaded to the
Compute Node on which the primary Task is executed. There is a maximum size for
the list of resource files.  When the max size is exceeded, the request will
fail and the response error code will be RequestEntityTooLarge. If this occurs,
the collection of ResourceFiles must be reduced in size. This can be achieved
using .zip files, Application Packages, or Docker Containers.
  outputFiles: [OutputFile], # Optional. For multi-instance Tasks, the files will only be uploaded from the Compute Node
on which the primary Task is executed.
  environmentSettings: [EnvironmentSetting], # Optional. A list of environment variable settings for the Task.
  affinityInfo: {
    affinityId: string, # Required. You can pass the affinityId of a Node to indicate that this Task needs to run
on that Compute Node. Note that this is just a soft affinity. If the target
Compute Node is busy or unavailable at the time the Task is scheduled, then the
Task will be scheduled elsewhere.
  }, # Optional. A locality hint that can be used by the Batch service to select a Compute Node
on which to start a Task.
  constraints: {
    maxWallClockTime: string (duration ISO 8601 Format), # Optional. If this is not specified, there is no time limit on how long the Task may run.
    retentionTime: string (duration ISO 8601 Format), # Optional. The default is 7 days, i.e. the Task directory will be retained for 7 days
unless the Compute Node is removed or the Job is deleted.
    maxTaskRetryCount: number, # Optional. Note that this value specifically controls the number of retries for the Task
executable due to a nonzero exit code. The Batch service will try the Task
once, and may then retry up to this limit. For example, if the maximum retry
count is 3, Batch tries the Task up to 4 times (one initial try and 3 retries).
If the maximum retry count is 0, the Batch service does not retry the Task
after the first attempt. If the maximum retry count is -1, the Batch service
retries the Task without limit, however this is not recommended for a start
task or any task. The default value is 0 (no retries)
  }, # Optional. Execution constraints to apply to a Task.
  requiredSlots: number, # Optional. The default is 1. A Task can only be scheduled to run on a compute node if the
node has enough free scheduling slots available. For multi-instance Tasks, this
must be 1.
  userIdentity: {
    username: string, # Optional. The userName and autoUser properties are mutually exclusive; you must specify
one but not both.
    autoUser: {
      scope: &quot;task&quot; | &quot;pool&quot;, # Optional. The default value is pool. If the pool is running Windows a value of Task
should be specified if stricter isolation between tasks is required. For
example, if the task mutates the registry in a way which could impact other
tasks, or if certificates have been specified on the pool which should not be
accessible by normal tasks but should be accessible by StartTasks.
      elevationLevel: &quot;nonadmin&quot; | &quot;admin&quot;, # Optional. The default value is nonAdmin.
    }, # Optional. The userName and autoUser properties are mutually exclusive; you must specify
one but not both.
  }, # Optional. If omitted, the Task runs as a non-administrative user unique to the Task.
  executionInfo: {
    startTime: string (date &amp; time), # Optional. &apos;Running&apos; corresponds to the running state, so if the Task specifies resource
files or Packages, then the start time reflects the time at which the Task
started downloading or deploying these. If the Task has been restarted or
retried, this is the most recent time at which the Task started running. This
property is present only for Tasks that are in the running or completed state.
    endTime: string (date &amp; time), # Optional. This property is set only if the Task is in the Completed state.
    exitCode: number, # Optional. This property is set only if the Task is in the completed state. In general,
the exit code for a process reflects the specific convention implemented by the
application developer for that process. If you use the exit code value to make
decisions in your code, be sure that you know the exit code convention used by
the application process. However, if the Batch service terminates the Task (due
to timeout, or user termination via the API) you may see an operating
system-defined exit code.
    containerInfo: {
      containerId: string, # Optional. The ID of the container.
      state: string, # Optional. This is the state of the container according to the Docker service. It is
equivalent to the status field returned by &quot;docker inspect&quot;.
      error: string, # Optional. This is the detailed error string from the Docker service, if available. It is
equivalent to the error field returned by &quot;docker inspect&quot;.
    }, # Optional. This property is set only if the Task runs in a container context.
    failureInfo: {
      category: &quot;usererror&quot; | &quot;servererror&quot;, # Required. The category of the error.
      code: string, # Optional. An identifier for the Task error. Codes are invariant and are intended to be
consumed programmatically.
      message: string, # Optional. A message describing the Task error, intended to be suitable for display in a
user interface.
      details: [NameValuePair], # Optional. A list of additional details related to the error.
    }, # Optional. This property is set only if the Task is in the completed state and encountered
a failure.
    retryCount: number, # Required. Task application failures (non-zero exit code) are retried, pre-processing
errors (the Task could not be run) and file upload errors are not retried. The
Batch service will retry the Task up to the limit specified by the constraints.
    lastRetryTime: string (date &amp; time), # Optional. This element is present only if the Task was retried (i.e. retryCount is
nonzero). If present, this is typically the same as startTime, but may be
different if the Task has been restarted for reasons other than retry; for
example, if the Compute Node was rebooted during a retry, then the startTime is
updated but the lastRetryTime is not.
    requeueCount: number, # Required. When the user removes Compute Nodes from a Pool (by resizing/shrinking the
pool) or when the Job is being disabled, the user can specify that running
Tasks on the Compute Nodes be requeued for execution. This count tracks how
many times the Task has been requeued for these reasons.
    lastRequeueTime: string (date &amp; time), # Optional. This property is set only if the requeueCount is nonzero.
    result: &quot;success&quot; | &quot;failure&quot;, # Optional. If the value is &apos;failed&apos;, then the details of the failure can be found in the
failureInfo property.
  }, # Optional. Information about the execution of a Task.
  nodeInfo: {
    affinityId: string, # Optional. An identifier for the Node on which the Task ran, which can be passed when
adding a Task to request that the Task be scheduled on this Compute Node.
    nodeUrl: string, # Optional. The URL of the Compute Node on which the Task ran. 
    poolId: string, # Optional. The ID of the Pool on which the Task ran.
    nodeId: string, # Optional. The ID of the Compute Node on which the Task ran.
    taskRootDirectory: string, # Optional. The root directory of the Task on the Compute Node.
    taskRootDirectoryUrl: string, # Optional. The URL to the root directory of the Task on the Compute Node.
  }, # Optional. Information about the Compute Node on which a Task ran.
  multiInstanceSettings: {
    numberOfInstances: number, # Optional. If omitted, the default is 1.
    coordinationCommandLine: string, # Required. A typical coordination command line launches a background service and verifies
that the service is ready to process inter-node messages.
    commonResourceFiles: [ResourceFile], # Optional. The difference between common resource files and Task resource files is that
common resource files are downloaded for all subtasks including the primary,
whereas Task resource files are downloaded only for the primary. Also note that
these resource files are not downloaded to the Task working directory, but
instead are downloaded to the Task root directory (one directory above the
working directory).  There is a maximum size for the list of resource files. 
When the max size is exceeded, the request will fail and the response error
code will be RequestEntityTooLarge. If this occurs, the collection of
ResourceFiles must be reduced in size. This can be achieved using .zip files,
Application Packages, or Docker Containers.
  }, # Optional. Multi-instance Tasks are commonly used to support MPI Tasks. In the MPI case,
if any of the subtasks fail (for example due to exiting with a non-zero exit
code) the entire multi-instance Task fails. The multi-instance Task is then
terminated and retried, up to its retry limit.
  stats: {
    url: string, # Required. The URL of the statistics.
    startTime: string (date &amp; time), # Required. The start time of the time range covered by the statistics.
    lastUpdateTime: string (date &amp; time), # Required. The time at which the statistics were last updated. All statistics are limited
to the range between startTime and lastUpdateTime.
    userCPUTime: string (duration ISO 8601 Format), # Required. The total user mode CPU time (summed across all cores and all Compute Nodes)
consumed by the Task.
    kernelCPUTime: string (duration ISO 8601 Format), # Required. The total kernel mode CPU time (summed across all cores and all Compute Nodes)
consumed by the Task.
    wallClockTime: string (duration ISO 8601 Format), # Required. The wall clock time is the elapsed time from when the Task started running on a
Compute Node to when it finished (or to the last time the statistics were
updated, if the Task had not finished by then). If the Task was retried, this
includes the wall clock time of all the Task retries.
    readIOps: number, # Required. The total number of disk read operations made by the Task.
    writeIOps: number, # Required. The total number of disk write operations made by the Task.
    readIOGiB: number, # Required. The total gibibytes read from disk by the Task.
    writeIOGiB: number, # Required. The total gibibytes written to disk by the Task.
    waitTime: string (duration ISO 8601 Format), # Required. The total wait time of the Task. The wait time for a Task is defined as the
elapsed time between the creation of the Task and the start of Task execution.
(If the Task is retried due to failures, the wait time is the time to the most
recent Task execution.)
  }, # Optional. Resource usage statistics for a Task.
  dependsOn: {
    taskIds: [string], # Optional. The taskIds collection is limited to 64000 characters total (i.e. the combined
length of all Task IDs). If the taskIds collection exceeds the maximum length,
the Add Task request fails with error code TaskDependencyListTooLong. In this
case consider using Task ID ranges instead.
    taskIdRanges: [TaskIdRange], # Optional. The list of Task ID ranges that this Task depends on. All Tasks in all ranges
must complete successfully before the dependent Task can be scheduled.
  }, # Optional. This Task will not be scheduled until all Tasks that it depends on have
completed successfully. If any of those Tasks fail and exhaust their retry
counts, this Task will never be scheduled.
  applicationPackageReferences: [ApplicationPackageReference], # Optional. Application packages are downloaded and deployed to a shared directory, not the
Task working directory. Therefore, if a referenced package is already on the
Node, and is up to date, then it is not re-downloaded; the existing copy on the
Compute Node is used. If a referenced Package cannot be installed, for example
because the package has been deleted or because download failed, the Task
fails.
  authenticationTokenSettings: {
    access: [&quot;job&quot;], # Optional. The authentication token grants access to a limited set of Batch service
operations. Currently the only supported value for the access property is
&apos;job&apos;, which grants access to all operations related to the Job which contains
the Task.
  }, # Optional. If this property is set, the Batch service provides the Task with an
authentication token which can be used to authenticate Batch service operations
without requiring an Account access key. The token is provided via the
AZ_BATCH_AUTHENTICATION_TOKEN environment variable. The operations that the
Task can carry out using the token depend on the settings. For example, a Task
can request Job permissions in order to add other Tasks to the Job, or check
the status of the Job or of other Tasks under the Job.
}
</code>

</remarks>
    </member>
    <member name="UpdateAsync(String,String,RequestContent,Int32,String,Boolean,String,RequestConditions,RequestContext)">
<example>
This sample shows how to call UpdateAsync with required parameters.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetTaskClient(<2022-10-01.16.0>);

var data = new {};

Response response = await client.UpdateAsync("<jobId>", "<taskId>", RequestContent.Create(data));
Console.WriteLine(response.Status);
]]></code>
This sample shows how to call UpdateAsync with all parameters and request content.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetTaskClient(<2022-10-01.16.0>);

var data = new {
    id = "<id>",
    displayName = "<displayName>",
    exitConditions = new {
        exitCodes = new[] {
            new {
                code = 1234,
                exitOptions = new {
                    jobAction = "none",
                    dependencyAction = "satisfy",
                },
            }
        },
        exitCodeRanges = new[] {
            new {
                start = 1234,
                end = 1234,
                exitOptions = new {
                    jobAction = "none",
                    dependencyAction = "satisfy",
                },
            }
        },
        preProcessingError = new {
            jobAction = "none",
            dependencyAction = "satisfy",
        },
        fileUploadError = new {
            jobAction = "none",
            dependencyAction = "satisfy",
        },
        default = new {
            jobAction = "none",
            dependencyAction = "satisfy",
        },
    },
    commandLine = "<commandLine>",
    containerSettings = new {
        containerRunOptions = "<containerRunOptions>",
        imageName = "<imageName>",
        registry = new {
            username = "<username>",
            password = "<password>",
            registryServer = "<registryServer>",
            identityReference = new {
                resourceId = "<resourceId>",
            },
        },
        workingDirectory = "taskWorkingDirectory",
    },
    resourceFiles = new[] {
        new {
            autoStorageContainerName = "<autoStorageContainerName>",
            storageContainerUrl = "<storageContainerUrl>",
            httpUrl = "<httpUrl>",
            blobPrefix = "<blobPrefix>",
            filePath = "<filePath>",
            fileMode = "<fileMode>",
            identityReference = new {
                resourceId = "<resourceId>",
            },
        }
    },
    outputFiles = new[] {
        new {
            filePattern = "<filePattern>",
            destination = new {
                container = new {
                    path = "<path>",
                    containerUrl = "<containerUrl>",
                    identityReference = new {
                        resourceId = "<resourceId>",
                    },
                    uploadHeaders = new[] {
                        new {
                            name = "<name>",
                            value = "<value>",
                        }
                    },
                },
            },
            uploadOptions = new {
                uploadCondition = "tasksuccess",
            },
        }
    },
    environmentSettings = new[] {
        new {
            name = "<name>",
            value = "<value>",
        }
    },
    affinityInfo = new {
        affinityId = "<affinityId>",
    },
    constraints = new {
        maxWallClockTime = PT1H23M45S,
        retentionTime = PT1H23M45S,
        maxTaskRetryCount = 1234,
    },
    requiredSlots = 1234,
    userIdentity = new {
        username = "<username>",
        autoUser = new {
            scope = "task",
            elevationLevel = "nonadmin",
        },
    },
    multiInstanceSettings = new {
        numberOfInstances = 1234,
        coordinationCommandLine = "<coordinationCommandLine>",
        commonResourceFiles = new[] {
            new {
                autoStorageContainerName = "<autoStorageContainerName>",
                storageContainerUrl = "<storageContainerUrl>",
                httpUrl = "<httpUrl>",
                blobPrefix = "<blobPrefix>",
                filePath = "<filePath>",
                fileMode = "<fileMode>",
                identityReference = new {
                    resourceId = "<resourceId>",
                },
            }
        },
    },
    dependsOn = new {
        taskIds = new[] {
            "<String>"
        },
        taskIdRanges = new[] {
            new {
                start = 1234,
                end = 1234,
            }
        },
    },
    applicationPackageReferences = new[] {
        new {
            applicationId = "<applicationId>",
            version = "<version>",
        }
    },
    authenticationTokenSettings = new {
        access = new[] {
            "job"
        },
    },
};

Response response = await client.UpdateAsync("<jobId>", "<taskId>", RequestContent.Create(data), 1234, "<clientRequestId>", true, "<ocpDate>", null);
Console.WriteLine(response.Status);
]]></code>
</example>
<remarks>
Below is the JSON schema for the request payload.

Request Body:

Schema for <c>BatchTask</c>:
<code>{
  id: string, # Optional. The ID can contain any combination of alphanumeric characters including hyphens
and underscores, and cannot contain more than 64 characters.
  displayName: string, # Optional. The display name need not be unique and can contain any Unicode characters up
to a maximum length of 1024.
  url: string, # Optional. The URL of the Task.
  eTag: string, # Optional. This is an opaque string. You can use it to detect whether the Task has changed
between requests. In particular, you can be pass the ETag when updating a Task
to specify that your changes should take effect only if nobody else has
modified the Task in the meantime.
  lastModified: string (date &amp; time), # Optional. The last modified time of the Task.
  creationTime: string (date &amp; time), # Optional. The creation time of the Task.
  exitConditions: {
    exitCodes: [ExitCodeMapping], # Optional. A list of individual Task exit codes and how the Batch service should respond
to them.
    exitCodeRanges: [ExitCodeRangeMapping], # Optional. A list of Task exit code ranges and how the Batch service should respond to
them.
    preProcessingError: {
      jobAction: &quot;none&quot; | &quot;disable&quot; | &quot;terminate&quot;, # Optional. The default is none for exit code 0 and terminate for all other exit
conditions. If the Job&apos;s onTaskFailed property is noaction, then specifying
this property returns an error and the add Task request fails with an invalid
property value error; if you are calling the REST API directly, the HTTP status
code is 400 (Bad Request).
      dependencyAction: &quot;satisfy&quot; | &quot;block&quot;, # Optional. Possible values are &apos;satisfy&apos; (allowing dependent tasks to progress) and
&apos;block&apos; (dependent tasks continue to wait). Batch does not yet support
cancellation of dependent tasks.
    }, # Optional. Specifies how the Batch service responds to a particular exit condition.
    fileUploadError: ExitOptions, # Optional. If the Task exited with an exit code that was specified via exitCodes or
exitCodeRanges, and then encountered a file upload error, then the action
specified by the exit code takes precedence.
    default: ExitOptions, # Optional. This value is used if the Task exits with any nonzero exit code not listed in
the exitCodes or exitCodeRanges collection, with a pre-processing error if the
preProcessingError property is not present, or with a file upload error if the
fileUploadError property is not present. If you want non-default behavior on
exit code 0, you must list it explicitly using the exitCodes or exitCodeRanges
collection.
  }, # Optional. How the Batch service should respond when the Task completes.
  state: &quot;active&quot; | &quot;preparing&quot; | &quot;running&quot; | &quot;completed&quot;, # Optional. The state of the Task.
  stateTransitionTime: string (date &amp; time), # Optional. The time at which the Task entered its current state.
  previousState: &quot;active&quot; | &quot;preparing&quot; | &quot;running&quot; | &quot;completed&quot;, # Optional. This property is not set if the Task is in its initial Active state.
  previousStateTransitionTime: string (date &amp; time), # Optional. This property is not set if the Task is in its initial Active state.
  commandLine: string, # Optional. For multi-instance Tasks, the command line is executed as the primary Task,
after the primary Task and all subtasks have finished executing the
coordination command line. The command line does not run under a shell, and
therefore cannot take advantage of shell features such as environment variable
expansion. If you want to take advantage of such features, you should invoke
the shell in the command line, for example using &quot;cmd /c MyCommand&quot; in
Windows or &quot;/bin/sh -c MyCommand&quot; in Linux. If the command line refers to
file paths, it should use a relative path (relative to the Task working
directory), or use the Batch provided environment variable
(https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).
  containerSettings: {
    containerRunOptions: string, # Optional. These additional options are supplied as arguments to the &quot;docker create&quot;
command, in addition to those controlled by the Batch Service.
    imageName: string, # Required. This is the full Image reference, as would be specified to &quot;docker pull&quot;. If
no tag is provided as part of the Image name, the tag &quot;:latest&quot; is used as a
default.
    registry: {
      username: string, # Optional. The user name to log into the registry server.
      password: string, # Optional. The password to log into the registry server.
      registryServer: string, # Optional. If omitted, the default is &quot;docker.io&quot;.
      identityReference: {
        resourceId: string, # Optional. The ARM resource id of the user assigned identity.
      }, # Optional. The reference to a user assigned identity associated with the Batch pool which
a compute node will use.
    }, # Optional. This setting can be omitted if was already provided at Pool creation.
    workingDirectory: &quot;taskWorkingDirectory&quot; | &quot;containerImageDefault&quot;, # Optional. The default is &apos;taskWorkingDirectory&apos;.
  }, # Optional. If the Pool that will run this Task has containerConfiguration set, this must
be set as well. If the Pool that will run this Task doesn&apos;t have
containerConfiguration set, this must not be set. When this is specified, all
directories recursively below the AZ_BATCH_NODE_ROOT_DIR (the root of Azure
Batch directories on the node) are mapped into the container, all Task
environment variables are mapped into the container, and the Task command line
is executed in the container. Files produced in the container outside of
AZ_BATCH_NODE_ROOT_DIR might not be reflected to the host disk, meaning that
Batch file APIs will not be able to access those files.
  resourceFiles: [
    {
      autoStorageContainerName: string, # Optional. The autoStorageContainerName, storageContainerUrl and httpUrl properties are
mutually exclusive and one of them must be specified.
      storageContainerUrl: string, # Optional. The autoStorageContainerName, storageContainerUrl and httpUrl properties are
mutually exclusive and one of them must be specified. This URL must be readable
and listable from compute nodes. There are three ways to get such a URL for a
container in Azure storage: include a Shared Access Signature (SAS) granting
read and list permissions on the container, use a managed identity with read
and list permissions, or set the ACL for the container to allow public access.
      httpUrl: string, # Optional. The autoStorageContainerName, storageContainerUrl and httpUrl properties are
mutually exclusive and one of them must be specified. If the URL points to
Azure Blob Storage, it must be readable from compute nodes. There are three
ways to get such a URL for a blob in Azure storage: include a Shared Access
Signature (SAS) granting read permissions on the blob, use a managed identity
with read permission, or set the ACL for the blob or its container to allow
public access.
      blobPrefix: string, # Optional. The property is valid only when autoStorageContainerName or storageContainerUrl
is used. This prefix can be a partial filename or a subdirectory. If a prefix
is not specified, all the files in the container will be downloaded.
      filePath: string, # Optional. If the httpUrl property is specified, the filePath is required and describes
the path which the file will be downloaded to, including the filename.
Otherwise, if the autoStorageContainerName or storageContainerUrl property is
specified, filePath is optional and is the directory to download the files to.
In the case where filePath is used as a directory, any directory structure
already associated with the input data will be retained in full and appended to
the specified filePath directory. The specified relative path cannot break out
of the Task&apos;s working directory (for example by using &apos;..&apos;).
      fileMode: string, # Optional. This property applies only to files being downloaded to Linux Compute Nodes. It
will be ignored if it is specified for a resourceFile which will be downloaded
to a Windows Compute Node. If this property is not specified for a Linux
Compute Node, then a default value of 0770 is applied to the file.
      identityReference: ComputeNodeIdentityReference, # Optional. The reference to a user assigned identity associated with the Batch pool which
a compute node will use.
    }
  ], # Optional. For multi-instance Tasks, the resource files will only be downloaded to the
Compute Node on which the primary Task is executed. There is a maximum size for
the list of resource files.  When the max size is exceeded, the request will
fail and the response error code will be RequestEntityTooLarge. If this occurs,
the collection of ResourceFiles must be reduced in size. This can be achieved
using .zip files, Application Packages, or Docker Containers.
  outputFiles: [OutputFile], # Optional. For multi-instance Tasks, the files will only be uploaded from the Compute Node
on which the primary Task is executed.
  environmentSettings: [EnvironmentSetting], # Optional. A list of environment variable settings for the Task.
  affinityInfo: {
    affinityId: string, # Required. You can pass the affinityId of a Node to indicate that this Task needs to run
on that Compute Node. Note that this is just a soft affinity. If the target
Compute Node is busy or unavailable at the time the Task is scheduled, then the
Task will be scheduled elsewhere.
  }, # Optional. A locality hint that can be used by the Batch service to select a Compute Node
on which to start a Task.
  constraints: {
    maxWallClockTime: string (duration ISO 8601 Format), # Optional. If this is not specified, there is no time limit on how long the Task may run.
    retentionTime: string (duration ISO 8601 Format), # Optional. The default is 7 days, i.e. the Task directory will be retained for 7 days
unless the Compute Node is removed or the Job is deleted.
    maxTaskRetryCount: number, # Optional. Note that this value specifically controls the number of retries for the Task
executable due to a nonzero exit code. The Batch service will try the Task
once, and may then retry up to this limit. For example, if the maximum retry
count is 3, Batch tries the Task up to 4 times (one initial try and 3 retries).
If the maximum retry count is 0, the Batch service does not retry the Task
after the first attempt. If the maximum retry count is -1, the Batch service
retries the Task without limit, however this is not recommended for a start
task or any task. The default value is 0 (no retries)
  }, # Optional. Execution constraints to apply to a Task.
  requiredSlots: number, # Optional. The default is 1. A Task can only be scheduled to run on a compute node if the
node has enough free scheduling slots available. For multi-instance Tasks, this
must be 1.
  userIdentity: {
    username: string, # Optional. The userName and autoUser properties are mutually exclusive; you must specify
one but not both.
    autoUser: {
      scope: &quot;task&quot; | &quot;pool&quot;, # Optional. The default value is pool. If the pool is running Windows a value of Task
should be specified if stricter isolation between tasks is required. For
example, if the task mutates the registry in a way which could impact other
tasks, or if certificates have been specified on the pool which should not be
accessible by normal tasks but should be accessible by StartTasks.
      elevationLevel: &quot;nonadmin&quot; | &quot;admin&quot;, # Optional. The default value is nonAdmin.
    }, # Optional. The userName and autoUser properties are mutually exclusive; you must specify
one but not both.
  }, # Optional. If omitted, the Task runs as a non-administrative user unique to the Task.
  executionInfo: {
    startTime: string (date &amp; time), # Optional. &apos;Running&apos; corresponds to the running state, so if the Task specifies resource
files or Packages, then the start time reflects the time at which the Task
started downloading or deploying these. If the Task has been restarted or
retried, this is the most recent time at which the Task started running. This
property is present only for Tasks that are in the running or completed state.
    endTime: string (date &amp; time), # Optional. This property is set only if the Task is in the Completed state.
    exitCode: number, # Optional. This property is set only if the Task is in the completed state. In general,
the exit code for a process reflects the specific convention implemented by the
application developer for that process. If you use the exit code value to make
decisions in your code, be sure that you know the exit code convention used by
the application process. However, if the Batch service terminates the Task (due
to timeout, or user termination via the API) you may see an operating
system-defined exit code.
    containerInfo: {
      containerId: string, # Optional. The ID of the container.
      state: string, # Optional. This is the state of the container according to the Docker service. It is
equivalent to the status field returned by &quot;docker inspect&quot;.
      error: string, # Optional. This is the detailed error string from the Docker service, if available. It is
equivalent to the error field returned by &quot;docker inspect&quot;.
    }, # Optional. This property is set only if the Task runs in a container context.
    failureInfo: {
      category: &quot;usererror&quot; | &quot;servererror&quot;, # Required. The category of the error.
      code: string, # Optional. An identifier for the Task error. Codes are invariant and are intended to be
consumed programmatically.
      message: string, # Optional. A message describing the Task error, intended to be suitable for display in a
user interface.
      details: [NameValuePair], # Optional. A list of additional details related to the error.
    }, # Optional. This property is set only if the Task is in the completed state and encountered
a failure.
    retryCount: number, # Required. Task application failures (non-zero exit code) are retried, pre-processing
errors (the Task could not be run) and file upload errors are not retried. The
Batch service will retry the Task up to the limit specified by the constraints.
    lastRetryTime: string (date &amp; time), # Optional. This element is present only if the Task was retried (i.e. retryCount is
nonzero). If present, this is typically the same as startTime, but may be
different if the Task has been restarted for reasons other than retry; for
example, if the Compute Node was rebooted during a retry, then the startTime is
updated but the lastRetryTime is not.
    requeueCount: number, # Required. When the user removes Compute Nodes from a Pool (by resizing/shrinking the
pool) or when the Job is being disabled, the user can specify that running
Tasks on the Compute Nodes be requeued for execution. This count tracks how
many times the Task has been requeued for these reasons.
    lastRequeueTime: string (date &amp; time), # Optional. This property is set only if the requeueCount is nonzero.
    result: &quot;success&quot; | &quot;failure&quot;, # Optional. If the value is &apos;failed&apos;, then the details of the failure can be found in the
failureInfo property.
  }, # Optional. Information about the execution of a Task.
  nodeInfo: {
    affinityId: string, # Optional. An identifier for the Node on which the Task ran, which can be passed when
adding a Task to request that the Task be scheduled on this Compute Node.
    nodeUrl: string, # Optional. The URL of the Compute Node on which the Task ran. 
    poolId: string, # Optional. The ID of the Pool on which the Task ran.
    nodeId: string, # Optional. The ID of the Compute Node on which the Task ran.
    taskRootDirectory: string, # Optional. The root directory of the Task on the Compute Node.
    taskRootDirectoryUrl: string, # Optional. The URL to the root directory of the Task on the Compute Node.
  }, # Optional. Information about the Compute Node on which a Task ran.
  multiInstanceSettings: {
    numberOfInstances: number, # Optional. If omitted, the default is 1.
    coordinationCommandLine: string, # Required. A typical coordination command line launches a background service and verifies
that the service is ready to process inter-node messages.
    commonResourceFiles: [ResourceFile], # Optional. The difference between common resource files and Task resource files is that
common resource files are downloaded for all subtasks including the primary,
whereas Task resource files are downloaded only for the primary. Also note that
these resource files are not downloaded to the Task working directory, but
instead are downloaded to the Task root directory (one directory above the
working directory).  There is a maximum size for the list of resource files. 
When the max size is exceeded, the request will fail and the response error
code will be RequestEntityTooLarge. If this occurs, the collection of
ResourceFiles must be reduced in size. This can be achieved using .zip files,
Application Packages, or Docker Containers.
  }, # Optional. Multi-instance Tasks are commonly used to support MPI Tasks. In the MPI case,
if any of the subtasks fail (for example due to exiting with a non-zero exit
code) the entire multi-instance Task fails. The multi-instance Task is then
terminated and retried, up to its retry limit.
  stats: {
    url: string, # Required. The URL of the statistics.
    startTime: string (date &amp; time), # Required. The start time of the time range covered by the statistics.
    lastUpdateTime: string (date &amp; time), # Required. The time at which the statistics were last updated. All statistics are limited
to the range between startTime and lastUpdateTime.
    userCPUTime: string (duration ISO 8601 Format), # Required. The total user mode CPU time (summed across all cores and all Compute Nodes)
consumed by the Task.
    kernelCPUTime: string (duration ISO 8601 Format), # Required. The total kernel mode CPU time (summed across all cores and all Compute Nodes)
consumed by the Task.
    wallClockTime: string (duration ISO 8601 Format), # Required. The wall clock time is the elapsed time from when the Task started running on a
Compute Node to when it finished (or to the last time the statistics were
updated, if the Task had not finished by then). If the Task was retried, this
includes the wall clock time of all the Task retries.
    readIOps: number, # Required. The total number of disk read operations made by the Task.
    writeIOps: number, # Required. The total number of disk write operations made by the Task.
    readIOGiB: number, # Required. The total gibibytes read from disk by the Task.
    writeIOGiB: number, # Required. The total gibibytes written to disk by the Task.
    waitTime: string (duration ISO 8601 Format), # Required. The total wait time of the Task. The wait time for a Task is defined as the
elapsed time between the creation of the Task and the start of Task execution.
(If the Task is retried due to failures, the wait time is the time to the most
recent Task execution.)
  }, # Optional. Resource usage statistics for a Task.
  dependsOn: {
    taskIds: [string], # Optional. The taskIds collection is limited to 64000 characters total (i.e. the combined
length of all Task IDs). If the taskIds collection exceeds the maximum length,
the Add Task request fails with error code TaskDependencyListTooLong. In this
case consider using Task ID ranges instead.
    taskIdRanges: [TaskIdRange], # Optional. The list of Task ID ranges that this Task depends on. All Tasks in all ranges
must complete successfully before the dependent Task can be scheduled.
  }, # Optional. This Task will not be scheduled until all Tasks that it depends on have
completed successfully. If any of those Tasks fail and exhaust their retry
counts, this Task will never be scheduled.
  applicationPackageReferences: [ApplicationPackageReference], # Optional. Application packages are downloaded and deployed to a shared directory, not the
Task working directory. Therefore, if a referenced package is already on the
Node, and is up to date, then it is not re-downloaded; the existing copy on the
Compute Node is used. If a referenced Package cannot be installed, for example
because the package has been deleted or because download failed, the Task
fails.
  authenticationTokenSettings: {
    access: [&quot;job&quot;], # Optional. The authentication token grants access to a limited set of Batch service
operations. Currently the only supported value for the access property is
&apos;job&apos;, which grants access to all operations related to the Job which contains
the Task.
  }, # Optional. If this property is set, the Batch service provides the Task with an
authentication token which can be used to authenticate Batch service operations
without requiring an Account access key. The token is provided via the
AZ_BATCH_AUTHENTICATION_TOKEN environment variable. The operations that the
Task can carry out using the token depend on the settings. For example, a Task
can request Job permissions in order to add other Tasks to the Job, or check
the status of the Job or of other Tasks under the Job.
}
</code>

</remarks>
    </member>
    <member name="Update(String,String,RequestContent,Int32,String,Boolean,String,RequestConditions,RequestContext)">
<example>
This sample shows how to call Update with required parameters.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetTaskClient(<2022-10-01.16.0>);

var data = new {};

Response response = client.Update("<jobId>", "<taskId>", RequestContent.Create(data));
Console.WriteLine(response.Status);
]]></code>
This sample shows how to call Update with all parameters and request content.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetTaskClient(<2022-10-01.16.0>);

var data = new {
    id = "<id>",
    displayName = "<displayName>",
    exitConditions = new {
        exitCodes = new[] {
            new {
                code = 1234,
                exitOptions = new {
                    jobAction = "none",
                    dependencyAction = "satisfy",
                },
            }
        },
        exitCodeRanges = new[] {
            new {
                start = 1234,
                end = 1234,
                exitOptions = new {
                    jobAction = "none",
                    dependencyAction = "satisfy",
                },
            }
        },
        preProcessingError = new {
            jobAction = "none",
            dependencyAction = "satisfy",
        },
        fileUploadError = new {
            jobAction = "none",
            dependencyAction = "satisfy",
        },
        default = new {
            jobAction = "none",
            dependencyAction = "satisfy",
        },
    },
    commandLine = "<commandLine>",
    containerSettings = new {
        containerRunOptions = "<containerRunOptions>",
        imageName = "<imageName>",
        registry = new {
            username = "<username>",
            password = "<password>",
            registryServer = "<registryServer>",
            identityReference = new {
                resourceId = "<resourceId>",
            },
        },
        workingDirectory = "taskWorkingDirectory",
    },
    resourceFiles = new[] {
        new {
            autoStorageContainerName = "<autoStorageContainerName>",
            storageContainerUrl = "<storageContainerUrl>",
            httpUrl = "<httpUrl>",
            blobPrefix = "<blobPrefix>",
            filePath = "<filePath>",
            fileMode = "<fileMode>",
            identityReference = new {
                resourceId = "<resourceId>",
            },
        }
    },
    outputFiles = new[] {
        new {
            filePattern = "<filePattern>",
            destination = new {
                container = new {
                    path = "<path>",
                    containerUrl = "<containerUrl>",
                    identityReference = new {
                        resourceId = "<resourceId>",
                    },
                    uploadHeaders = new[] {
                        new {
                            name = "<name>",
                            value = "<value>",
                        }
                    },
                },
            },
            uploadOptions = new {
                uploadCondition = "tasksuccess",
            },
        }
    },
    environmentSettings = new[] {
        new {
            name = "<name>",
            value = "<value>",
        }
    },
    affinityInfo = new {
        affinityId = "<affinityId>",
    },
    constraints = new {
        maxWallClockTime = PT1H23M45S,
        retentionTime = PT1H23M45S,
        maxTaskRetryCount = 1234,
    },
    requiredSlots = 1234,
    userIdentity = new {
        username = "<username>",
        autoUser = new {
            scope = "task",
            elevationLevel = "nonadmin",
        },
    },
    multiInstanceSettings = new {
        numberOfInstances = 1234,
        coordinationCommandLine = "<coordinationCommandLine>",
        commonResourceFiles = new[] {
            new {
                autoStorageContainerName = "<autoStorageContainerName>",
                storageContainerUrl = "<storageContainerUrl>",
                httpUrl = "<httpUrl>",
                blobPrefix = "<blobPrefix>",
                filePath = "<filePath>",
                fileMode = "<fileMode>",
                identityReference = new {
                    resourceId = "<resourceId>",
                },
            }
        },
    },
    dependsOn = new {
        taskIds = new[] {
            "<String>"
        },
        taskIdRanges = new[] {
            new {
                start = 1234,
                end = 1234,
            }
        },
    },
    applicationPackageReferences = new[] {
        new {
            applicationId = "<applicationId>",
            version = "<version>",
        }
    },
    authenticationTokenSettings = new {
        access = new[] {
            "job"
        },
    },
};

Response response = client.Update("<jobId>", "<taskId>", RequestContent.Create(data), 1234, "<clientRequestId>", true, "<ocpDate>", null);
Console.WriteLine(response.Status);
]]></code>
</example>
<remarks>
Below is the JSON schema for the request payload.

Request Body:

Schema for <c>BatchTask</c>:
<code>{
  id: string, # Optional. The ID can contain any combination of alphanumeric characters including hyphens
and underscores, and cannot contain more than 64 characters.
  displayName: string, # Optional. The display name need not be unique and can contain any Unicode characters up
to a maximum length of 1024.
  url: string, # Optional. The URL of the Task.
  eTag: string, # Optional. This is an opaque string. You can use it to detect whether the Task has changed
between requests. In particular, you can be pass the ETag when updating a Task
to specify that your changes should take effect only if nobody else has
modified the Task in the meantime.
  lastModified: string (date &amp; time), # Optional. The last modified time of the Task.
  creationTime: string (date &amp; time), # Optional. The creation time of the Task.
  exitConditions: {
    exitCodes: [ExitCodeMapping], # Optional. A list of individual Task exit codes and how the Batch service should respond
to them.
    exitCodeRanges: [ExitCodeRangeMapping], # Optional. A list of Task exit code ranges and how the Batch service should respond to
them.
    preProcessingError: {
      jobAction: &quot;none&quot; | &quot;disable&quot; | &quot;terminate&quot;, # Optional. The default is none for exit code 0 and terminate for all other exit
conditions. If the Job&apos;s onTaskFailed property is noaction, then specifying
this property returns an error and the add Task request fails with an invalid
property value error; if you are calling the REST API directly, the HTTP status
code is 400 (Bad Request).
      dependencyAction: &quot;satisfy&quot; | &quot;block&quot;, # Optional. Possible values are &apos;satisfy&apos; (allowing dependent tasks to progress) and
&apos;block&apos; (dependent tasks continue to wait). Batch does not yet support
cancellation of dependent tasks.
    }, # Optional. Specifies how the Batch service responds to a particular exit condition.
    fileUploadError: ExitOptions, # Optional. If the Task exited with an exit code that was specified via exitCodes or
exitCodeRanges, and then encountered a file upload error, then the action
specified by the exit code takes precedence.
    default: ExitOptions, # Optional. This value is used if the Task exits with any nonzero exit code not listed in
the exitCodes or exitCodeRanges collection, with a pre-processing error if the
preProcessingError property is not present, or with a file upload error if the
fileUploadError property is not present. If you want non-default behavior on
exit code 0, you must list it explicitly using the exitCodes or exitCodeRanges
collection.
  }, # Optional. How the Batch service should respond when the Task completes.
  state: &quot;active&quot; | &quot;preparing&quot; | &quot;running&quot; | &quot;completed&quot;, # Optional. The state of the Task.
  stateTransitionTime: string (date &amp; time), # Optional. The time at which the Task entered its current state.
  previousState: &quot;active&quot; | &quot;preparing&quot; | &quot;running&quot; | &quot;completed&quot;, # Optional. This property is not set if the Task is in its initial Active state.
  previousStateTransitionTime: string (date &amp; time), # Optional. This property is not set if the Task is in its initial Active state.
  commandLine: string, # Optional. For multi-instance Tasks, the command line is executed as the primary Task,
after the primary Task and all subtasks have finished executing the
coordination command line. The command line does not run under a shell, and
therefore cannot take advantage of shell features such as environment variable
expansion. If you want to take advantage of such features, you should invoke
the shell in the command line, for example using &quot;cmd /c MyCommand&quot; in
Windows or &quot;/bin/sh -c MyCommand&quot; in Linux. If the command line refers to
file paths, it should use a relative path (relative to the Task working
directory), or use the Batch provided environment variable
(https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).
  containerSettings: {
    containerRunOptions: string, # Optional. These additional options are supplied as arguments to the &quot;docker create&quot;
command, in addition to those controlled by the Batch Service.
    imageName: string, # Required. This is the full Image reference, as would be specified to &quot;docker pull&quot;. If
no tag is provided as part of the Image name, the tag &quot;:latest&quot; is used as a
default.
    registry: {
      username: string, # Optional. The user name to log into the registry server.
      password: string, # Optional. The password to log into the registry server.
      registryServer: string, # Optional. If omitted, the default is &quot;docker.io&quot;.
      identityReference: {
        resourceId: string, # Optional. The ARM resource id of the user assigned identity.
      }, # Optional. The reference to a user assigned identity associated with the Batch pool which
a compute node will use.
    }, # Optional. This setting can be omitted if was already provided at Pool creation.
    workingDirectory: &quot;taskWorkingDirectory&quot; | &quot;containerImageDefault&quot;, # Optional. The default is &apos;taskWorkingDirectory&apos;.
  }, # Optional. If the Pool that will run this Task has containerConfiguration set, this must
be set as well. If the Pool that will run this Task doesn&apos;t have
containerConfiguration set, this must not be set. When this is specified, all
directories recursively below the AZ_BATCH_NODE_ROOT_DIR (the root of Azure
Batch directories on the node) are mapped into the container, all Task
environment variables are mapped into the container, and the Task command line
is executed in the container. Files produced in the container outside of
AZ_BATCH_NODE_ROOT_DIR might not be reflected to the host disk, meaning that
Batch file APIs will not be able to access those files.
  resourceFiles: [
    {
      autoStorageContainerName: string, # Optional. The autoStorageContainerName, storageContainerUrl and httpUrl properties are
mutually exclusive and one of them must be specified.
      storageContainerUrl: string, # Optional. The autoStorageContainerName, storageContainerUrl and httpUrl properties are
mutually exclusive and one of them must be specified. This URL must be readable
and listable from compute nodes. There are three ways to get such a URL for a
container in Azure storage: include a Shared Access Signature (SAS) granting
read and list permissions on the container, use a managed identity with read
and list permissions, or set the ACL for the container to allow public access.
      httpUrl: string, # Optional. The autoStorageContainerName, storageContainerUrl and httpUrl properties are
mutually exclusive and one of them must be specified. If the URL points to
Azure Blob Storage, it must be readable from compute nodes. There are three
ways to get such a URL for a blob in Azure storage: include a Shared Access
Signature (SAS) granting read permissions on the blob, use a managed identity
with read permission, or set the ACL for the blob or its container to allow
public access.
      blobPrefix: string, # Optional. The property is valid only when autoStorageContainerName or storageContainerUrl
is used. This prefix can be a partial filename or a subdirectory. If a prefix
is not specified, all the files in the container will be downloaded.
      filePath: string, # Optional. If the httpUrl property is specified, the filePath is required and describes
the path which the file will be downloaded to, including the filename.
Otherwise, if the autoStorageContainerName or storageContainerUrl property is
specified, filePath is optional and is the directory to download the files to.
In the case where filePath is used as a directory, any directory structure
already associated with the input data will be retained in full and appended to
the specified filePath directory. The specified relative path cannot break out
of the Task&apos;s working directory (for example by using &apos;..&apos;).
      fileMode: string, # Optional. This property applies only to files being downloaded to Linux Compute Nodes. It
will be ignored if it is specified for a resourceFile which will be downloaded
to a Windows Compute Node. If this property is not specified for a Linux
Compute Node, then a default value of 0770 is applied to the file.
      identityReference: ComputeNodeIdentityReference, # Optional. The reference to a user assigned identity associated with the Batch pool which
a compute node will use.
    }
  ], # Optional. For multi-instance Tasks, the resource files will only be downloaded to the
Compute Node on which the primary Task is executed. There is a maximum size for
the list of resource files.  When the max size is exceeded, the request will
fail and the response error code will be RequestEntityTooLarge. If this occurs,
the collection of ResourceFiles must be reduced in size. This can be achieved
using .zip files, Application Packages, or Docker Containers.
  outputFiles: [OutputFile], # Optional. For multi-instance Tasks, the files will only be uploaded from the Compute Node
on which the primary Task is executed.
  environmentSettings: [EnvironmentSetting], # Optional. A list of environment variable settings for the Task.
  affinityInfo: {
    affinityId: string, # Required. You can pass the affinityId of a Node to indicate that this Task needs to run
on that Compute Node. Note that this is just a soft affinity. If the target
Compute Node is busy or unavailable at the time the Task is scheduled, then the
Task will be scheduled elsewhere.
  }, # Optional. A locality hint that can be used by the Batch service to select a Compute Node
on which to start a Task.
  constraints: {
    maxWallClockTime: string (duration ISO 8601 Format), # Optional. If this is not specified, there is no time limit on how long the Task may run.
    retentionTime: string (duration ISO 8601 Format), # Optional. The default is 7 days, i.e. the Task directory will be retained for 7 days
unless the Compute Node is removed or the Job is deleted.
    maxTaskRetryCount: number, # Optional. Note that this value specifically controls the number of retries for the Task
executable due to a nonzero exit code. The Batch service will try the Task
once, and may then retry up to this limit. For example, if the maximum retry
count is 3, Batch tries the Task up to 4 times (one initial try and 3 retries).
If the maximum retry count is 0, the Batch service does not retry the Task
after the first attempt. If the maximum retry count is -1, the Batch service
retries the Task without limit, however this is not recommended for a start
task or any task. The default value is 0 (no retries)
  }, # Optional. Execution constraints to apply to a Task.
  requiredSlots: number, # Optional. The default is 1. A Task can only be scheduled to run on a compute node if the
node has enough free scheduling slots available. For multi-instance Tasks, this
must be 1.
  userIdentity: {
    username: string, # Optional. The userName and autoUser properties are mutually exclusive; you must specify
one but not both.
    autoUser: {
      scope: &quot;task&quot; | &quot;pool&quot;, # Optional. The default value is pool. If the pool is running Windows a value of Task
should be specified if stricter isolation between tasks is required. For
example, if the task mutates the registry in a way which could impact other
tasks, or if certificates have been specified on the pool which should not be
accessible by normal tasks but should be accessible by StartTasks.
      elevationLevel: &quot;nonadmin&quot; | &quot;admin&quot;, # Optional. The default value is nonAdmin.
    }, # Optional. The userName and autoUser properties are mutually exclusive; you must specify
one but not both.
  }, # Optional. If omitted, the Task runs as a non-administrative user unique to the Task.
  executionInfo: {
    startTime: string (date &amp; time), # Optional. &apos;Running&apos; corresponds to the running state, so if the Task specifies resource
files or Packages, then the start time reflects the time at which the Task
started downloading or deploying these. If the Task has been restarted or
retried, this is the most recent time at which the Task started running. This
property is present only for Tasks that are in the running or completed state.
    endTime: string (date &amp; time), # Optional. This property is set only if the Task is in the Completed state.
    exitCode: number, # Optional. This property is set only if the Task is in the completed state. In general,
the exit code for a process reflects the specific convention implemented by the
application developer for that process. If you use the exit code value to make
decisions in your code, be sure that you know the exit code convention used by
the application process. However, if the Batch service terminates the Task (due
to timeout, or user termination via the API) you may see an operating
system-defined exit code.
    containerInfo: {
      containerId: string, # Optional. The ID of the container.
      state: string, # Optional. This is the state of the container according to the Docker service. It is
equivalent to the status field returned by &quot;docker inspect&quot;.
      error: string, # Optional. This is the detailed error string from the Docker service, if available. It is
equivalent to the error field returned by &quot;docker inspect&quot;.
    }, # Optional. This property is set only if the Task runs in a container context.
    failureInfo: {
      category: &quot;usererror&quot; | &quot;servererror&quot;, # Required. The category of the error.
      code: string, # Optional. An identifier for the Task error. Codes are invariant and are intended to be
consumed programmatically.
      message: string, # Optional. A message describing the Task error, intended to be suitable for display in a
user interface.
      details: [NameValuePair], # Optional. A list of additional details related to the error.
    }, # Optional. This property is set only if the Task is in the completed state and encountered
a failure.
    retryCount: number, # Required. Task application failures (non-zero exit code) are retried, pre-processing
errors (the Task could not be run) and file upload errors are not retried. The
Batch service will retry the Task up to the limit specified by the constraints.
    lastRetryTime: string (date &amp; time), # Optional. This element is present only if the Task was retried (i.e. retryCount is
nonzero). If present, this is typically the same as startTime, but may be
different if the Task has been restarted for reasons other than retry; for
example, if the Compute Node was rebooted during a retry, then the startTime is
updated but the lastRetryTime is not.
    requeueCount: number, # Required. When the user removes Compute Nodes from a Pool (by resizing/shrinking the
pool) or when the Job is being disabled, the user can specify that running
Tasks on the Compute Nodes be requeued for execution. This count tracks how
many times the Task has been requeued for these reasons.
    lastRequeueTime: string (date &amp; time), # Optional. This property is set only if the requeueCount is nonzero.
    result: &quot;success&quot; | &quot;failure&quot;, # Optional. If the value is &apos;failed&apos;, then the details of the failure can be found in the
failureInfo property.
  }, # Optional. Information about the execution of a Task.
  nodeInfo: {
    affinityId: string, # Optional. An identifier for the Node on which the Task ran, which can be passed when
adding a Task to request that the Task be scheduled on this Compute Node.
    nodeUrl: string, # Optional. The URL of the Compute Node on which the Task ran. 
    poolId: string, # Optional. The ID of the Pool on which the Task ran.
    nodeId: string, # Optional. The ID of the Compute Node on which the Task ran.
    taskRootDirectory: string, # Optional. The root directory of the Task on the Compute Node.
    taskRootDirectoryUrl: string, # Optional. The URL to the root directory of the Task on the Compute Node.
  }, # Optional. Information about the Compute Node on which a Task ran.
  multiInstanceSettings: {
    numberOfInstances: number, # Optional. If omitted, the default is 1.
    coordinationCommandLine: string, # Required. A typical coordination command line launches a background service and verifies
that the service is ready to process inter-node messages.
    commonResourceFiles: [ResourceFile], # Optional. The difference between common resource files and Task resource files is that
common resource files are downloaded for all subtasks including the primary,
whereas Task resource files are downloaded only for the primary. Also note that
these resource files are not downloaded to the Task working directory, but
instead are downloaded to the Task root directory (one directory above the
working directory).  There is a maximum size for the list of resource files. 
When the max size is exceeded, the request will fail and the response error
code will be RequestEntityTooLarge. If this occurs, the collection of
ResourceFiles must be reduced in size. This can be achieved using .zip files,
Application Packages, or Docker Containers.
  }, # Optional. Multi-instance Tasks are commonly used to support MPI Tasks. In the MPI case,
if any of the subtasks fail (for example due to exiting with a non-zero exit
code) the entire multi-instance Task fails. The multi-instance Task is then
terminated and retried, up to its retry limit.
  stats: {
    url: string, # Required. The URL of the statistics.
    startTime: string (date &amp; time), # Required. The start time of the time range covered by the statistics.
    lastUpdateTime: string (date &amp; time), # Required. The time at which the statistics were last updated. All statistics are limited
to the range between startTime and lastUpdateTime.
    userCPUTime: string (duration ISO 8601 Format), # Required. The total user mode CPU time (summed across all cores and all Compute Nodes)
consumed by the Task.
    kernelCPUTime: string (duration ISO 8601 Format), # Required. The total kernel mode CPU time (summed across all cores and all Compute Nodes)
consumed by the Task.
    wallClockTime: string (duration ISO 8601 Format), # Required. The wall clock time is the elapsed time from when the Task started running on a
Compute Node to when it finished (or to the last time the statistics were
updated, if the Task had not finished by then). If the Task was retried, this
includes the wall clock time of all the Task retries.
    readIOps: number, # Required. The total number of disk read operations made by the Task.
    writeIOps: number, # Required. The total number of disk write operations made by the Task.
    readIOGiB: number, # Required. The total gibibytes read from disk by the Task.
    writeIOGiB: number, # Required. The total gibibytes written to disk by the Task.
    waitTime: string (duration ISO 8601 Format), # Required. The total wait time of the Task. The wait time for a Task is defined as the
elapsed time between the creation of the Task and the start of Task execution.
(If the Task is retried due to failures, the wait time is the time to the most
recent Task execution.)
  }, # Optional. Resource usage statistics for a Task.
  dependsOn: {
    taskIds: [string], # Optional. The taskIds collection is limited to 64000 characters total (i.e. the combined
length of all Task IDs). If the taskIds collection exceeds the maximum length,
the Add Task request fails with error code TaskDependencyListTooLong. In this
case consider using Task ID ranges instead.
    taskIdRanges: [TaskIdRange], # Optional. The list of Task ID ranges that this Task depends on. All Tasks in all ranges
must complete successfully before the dependent Task can be scheduled.
  }, # Optional. This Task will not be scheduled until all Tasks that it depends on have
completed successfully. If any of those Tasks fail and exhaust their retry
counts, this Task will never be scheduled.
  applicationPackageReferences: [ApplicationPackageReference], # Optional. Application packages are downloaded and deployed to a shared directory, not the
Task working directory. Therefore, if a referenced package is already on the
Node, and is up to date, then it is not re-downloaded; the existing copy on the
Compute Node is used. If a referenced Package cannot be installed, for example
because the package has been deleted or because download failed, the Task
fails.
  authenticationTokenSettings: {
    access: [&quot;job&quot;], # Optional. The authentication token grants access to a limited set of Batch service
operations. Currently the only supported value for the access property is
&apos;job&apos;, which grants access to all operations related to the Job which contains
the Task.
  }, # Optional. If this property is set, the Batch service provides the Task with an
authentication token which can be used to authenticate Batch service operations
without requiring an Account access key. The token is provided via the
AZ_BATCH_AUTHENTICATION_TOKEN environment variable. The operations that the
Task can carry out using the token depend on the settings. For example, a Task
can request Job permissions in order to add other Tasks to the Job, or check
the status of the Job or of other Tasks under the Job.
}
</code>

</remarks>
    </member>
    <member name="GetSubtasksAsync(String,String,Int32,String,Boolean,String,String,RequestContext)">
<example>
This sample shows how to call GetSubtasksAsync with required parameters and parse the result.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetTaskClient(<2022-10-01.16.0>);

Response response = await client.GetSubtasksAsync("<jobId>", "<taskId>");

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.ToString());
]]></code>
This sample shows how to call GetSubtasksAsync with all parameters, and how to parse the result.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetTaskClient(<2022-10-01.16.0>);

Response response = await client.GetSubtasksAsync("<jobId>", "<taskId>", 1234, "<clientRequestId>", true, "<ocpDate>", "<select>");

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.GetProperty("value")[0].GetProperty("id").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("nodeInfo").GetProperty("affinityId").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("nodeInfo").GetProperty("nodeUrl").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("nodeInfo").GetProperty("poolId").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("nodeInfo").GetProperty("nodeId").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("nodeInfo").GetProperty("taskRootDirectory").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("nodeInfo").GetProperty("taskRootDirectoryUrl").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("startTime").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("endTime").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("exitCode").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("containerInfo").GetProperty("containerId").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("containerInfo").GetProperty("state").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("containerInfo").GetProperty("error").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("failureInfo").GetProperty("category").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("failureInfo").GetProperty("code").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("failureInfo").GetProperty("message").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("failureInfo").GetProperty("details")[0].GetProperty("name").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("failureInfo").GetProperty("details")[0].GetProperty("value").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("state").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("stateTransitionTime").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("previousState").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("previousStateTransitionTime").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("result").ToString());
]]></code>
</example>
<remarks>
If the Task is not a multi-instance Task then this returns an empty collection.

Below is the JSON schema for the response payload.

Response Body:

Schema for <c>BatchTaskListSubtasksResult</c>:
<code>{
  value: [
    {
      id: number, # Optional. The ID of the subtask.
      nodeInfo: {
        affinityId: string, # Optional. An identifier for the Node on which the Task ran, which can be passed when
adding a Task to request that the Task be scheduled on this Compute Node.
        nodeUrl: string, # Optional. The URL of the Compute Node on which the Task ran. 
        poolId: string, # Optional. The ID of the Pool on which the Task ran.
        nodeId: string, # Optional. The ID of the Compute Node on which the Task ran.
        taskRootDirectory: string, # Optional. The root directory of the Task on the Compute Node.
        taskRootDirectoryUrl: string, # Optional. The URL to the root directory of the Task on the Compute Node.
      }, # Optional. Information about the Compute Node on which a Task ran.
      startTime: string (date &amp; time), # Optional. The time at which the subtask started running. If the subtask has been
restarted or retried, this is the most recent time at which the subtask started
running.
      endTime: string (date &amp; time), # Optional. This property is set only if the subtask is in the Completed state.
      exitCode: number, # Optional. This property is set only if the subtask is in the completed state. In general,
the exit code for a process reflects the specific convention implemented by the
application developer for that process. If you use the exit code value to make
decisions in your code, be sure that you know the exit code convention used by
the application process. However, if the Batch service terminates the subtask
(due to timeout, or user termination via the API) you may see an operating
system-defined exit code.
      containerInfo: {
        containerId: string, # Optional. The ID of the container.
        state: string, # Optional. This is the state of the container according to the Docker service. It is
equivalent to the status field returned by &quot;docker inspect&quot;.
        error: string, # Optional. This is the detailed error string from the Docker service, if available. It is
equivalent to the error field returned by &quot;docker inspect&quot;.
      }, # Optional. This property is set only if the Task runs in a container context.
      failureInfo: {
        category: &quot;usererror&quot; | &quot;servererror&quot;, # Required. The category of the error.
        code: string, # Optional. An identifier for the Task error. Codes are invariant and are intended to be
consumed programmatically.
        message: string, # Optional. A message describing the Task error, intended to be suitable for display in a
user interface.
        details: [NameValuePair], # Optional. A list of additional details related to the error.
      }, # Optional. This property is set only if the Task is in the completed state and encountered
a failure.
      state: &quot;preparing&quot; | &quot;running&quot; | &quot;completed&quot;, # Optional. The state of the subtask.
      stateTransitionTime: string (date &amp; time), # Optional. The time at which the subtask entered its current state.
      previousState: &quot;preparing&quot; | &quot;running&quot; | &quot;completed&quot;, # Optional. This property is not set if the subtask is in its initial running state.
      previousStateTransitionTime: string (date &amp; time), # Optional. This property is not set if the subtask is in its initial running state.
      result: &quot;success&quot; | &quot;failure&quot;, # Optional. If the value is &apos;failed&apos;, then the details of the failure can be found in the
failureInfo property.
    }
  ], # Optional. The list of subtasks.
}
</code>

</remarks>
    </member>
    <member name="GetSubtasks(String,String,Int32,String,Boolean,String,String,RequestContext)">
<example>
This sample shows how to call GetSubtasks with required parameters and parse the result.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetTaskClient(<2022-10-01.16.0>);

Response response = client.GetSubtasks("<jobId>", "<taskId>");

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.ToString());
]]></code>
This sample shows how to call GetSubtasks with all parameters, and how to parse the result.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetTaskClient(<2022-10-01.16.0>);

Response response = client.GetSubtasks("<jobId>", "<taskId>", 1234, "<clientRequestId>", true, "<ocpDate>", "<select>");

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.GetProperty("value")[0].GetProperty("id").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("nodeInfo").GetProperty("affinityId").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("nodeInfo").GetProperty("nodeUrl").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("nodeInfo").GetProperty("poolId").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("nodeInfo").GetProperty("nodeId").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("nodeInfo").GetProperty("taskRootDirectory").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("nodeInfo").GetProperty("taskRootDirectoryUrl").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("startTime").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("endTime").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("exitCode").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("containerInfo").GetProperty("containerId").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("containerInfo").GetProperty("state").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("containerInfo").GetProperty("error").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("failureInfo").GetProperty("category").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("failureInfo").GetProperty("code").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("failureInfo").GetProperty("message").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("failureInfo").GetProperty("details")[0].GetProperty("name").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("failureInfo").GetProperty("details")[0].GetProperty("value").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("state").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("stateTransitionTime").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("previousState").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("previousStateTransitionTime").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("result").ToString());
]]></code>
</example>
<remarks>
If the Task is not a multi-instance Task then this returns an empty collection.

Below is the JSON schema for the response payload.

Response Body:

Schema for <c>BatchTaskListSubtasksResult</c>:
<code>{
  value: [
    {
      id: number, # Optional. The ID of the subtask.
      nodeInfo: {
        affinityId: string, # Optional. An identifier for the Node on which the Task ran, which can be passed when
adding a Task to request that the Task be scheduled on this Compute Node.
        nodeUrl: string, # Optional. The URL of the Compute Node on which the Task ran. 
        poolId: string, # Optional. The ID of the Pool on which the Task ran.
        nodeId: string, # Optional. The ID of the Compute Node on which the Task ran.
        taskRootDirectory: string, # Optional. The root directory of the Task on the Compute Node.
        taskRootDirectoryUrl: string, # Optional. The URL to the root directory of the Task on the Compute Node.
      }, # Optional. Information about the Compute Node on which a Task ran.
      startTime: string (date &amp; time), # Optional. The time at which the subtask started running. If the subtask has been
restarted or retried, this is the most recent time at which the subtask started
running.
      endTime: string (date &amp; time), # Optional. This property is set only if the subtask is in the Completed state.
      exitCode: number, # Optional. This property is set only if the subtask is in the completed state. In general,
the exit code for a process reflects the specific convention implemented by the
application developer for that process. If you use the exit code value to make
decisions in your code, be sure that you know the exit code convention used by
the application process. However, if the Batch service terminates the subtask
(due to timeout, or user termination via the API) you may see an operating
system-defined exit code.
      containerInfo: {
        containerId: string, # Optional. The ID of the container.
        state: string, # Optional. This is the state of the container according to the Docker service. It is
equivalent to the status field returned by &quot;docker inspect&quot;.
        error: string, # Optional. This is the detailed error string from the Docker service, if available. It is
equivalent to the error field returned by &quot;docker inspect&quot;.
      }, # Optional. This property is set only if the Task runs in a container context.
      failureInfo: {
        category: &quot;usererror&quot; | &quot;servererror&quot;, # Required. The category of the error.
        code: string, # Optional. An identifier for the Task error. Codes are invariant and are intended to be
consumed programmatically.
        message: string, # Optional. A message describing the Task error, intended to be suitable for display in a
user interface.
        details: [NameValuePair], # Optional. A list of additional details related to the error.
      }, # Optional. This property is set only if the Task is in the completed state and encountered
a failure.
      state: &quot;preparing&quot; | &quot;running&quot; | &quot;completed&quot;, # Optional. The state of the subtask.
      stateTransitionTime: string (date &amp; time), # Optional. The time at which the subtask entered its current state.
      previousState: &quot;preparing&quot; | &quot;running&quot; | &quot;completed&quot;, # Optional. This property is not set if the subtask is in its initial running state.
      previousStateTransitionTime: string (date &amp; time), # Optional. This property is not set if the subtask is in its initial running state.
      result: &quot;success&quot; | &quot;failure&quot;, # Optional. If the value is &apos;failed&apos;, then the details of the failure can be found in the
failureInfo property.
    }
  ], # Optional. The list of subtasks.
}
</code>

</remarks>
    </member>
    <member name="TerminateAsync(String,String,Int32,String,Boolean,String,RequestConditions,RequestContext)">
<example>
This sample shows how to call TerminateAsync with required parameters.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetTaskClient(<2022-10-01.16.0>);

Response response = await client.TerminateAsync("<jobId>", "<taskId>");
Console.WriteLine(response.Status);
]]></code>
This sample shows how to call TerminateAsync with all parameters.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetTaskClient(<2022-10-01.16.0>);

Response response = await client.TerminateAsync("<jobId>", "<taskId>", 1234, "<clientRequestId>", true, "<ocpDate>", null);
Console.WriteLine(response.Status);
]]></code>
</example>
<remarks>
When the Task has been terminated, it moves to the completed state. For
multi-instance Tasks, the terminate Task operation applies synchronously to the
primary task; subtasks are then terminated asynchronously in the background.
</remarks>
    </member>
    <member name="Terminate(String,String,Int32,String,Boolean,String,RequestConditions,RequestContext)">
<example>
This sample shows how to call Terminate with required parameters.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetTaskClient(<2022-10-01.16.0>);

Response response = client.Terminate("<jobId>", "<taskId>");
Console.WriteLine(response.Status);
]]></code>
This sample shows how to call Terminate with all parameters.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetTaskClient(<2022-10-01.16.0>);

Response response = client.Terminate("<jobId>", "<taskId>", 1234, "<clientRequestId>", true, "<ocpDate>", null);
Console.WriteLine(response.Status);
]]></code>
</example>
<remarks>
When the Task has been terminated, it moves to the completed state. For
multi-instance Tasks, the terminate Task operation applies synchronously to the
primary task; subtasks are then terminated asynchronously in the background.
</remarks>
    </member>
    <member name="ReactivateAsync(String,String,Int32,String,Boolean,String,RequestConditions,RequestContext)">
<example>
This sample shows how to call ReactivateAsync with required parameters.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetTaskClient(<2022-10-01.16.0>);

Response response = await client.ReactivateAsync("<jobId>", "<taskId>");
Console.WriteLine(response.Status);
]]></code>
This sample shows how to call ReactivateAsync with all parameters.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetTaskClient(<2022-10-01.16.0>);

Response response = await client.ReactivateAsync("<jobId>", "<taskId>", 1234, "<clientRequestId>", true, "<ocpDate>", null);
Console.WriteLine(response.Status);
]]></code>
</example>
<remarks>
Reactivation makes a Task eligible to be retried again up to its maximum retry
count. The Task&apos;s state is changed to active. As the Task is no longer in the
completed state, any previous exit code or failure information is no longer
available after reactivation. Each time a Task is reactivated, its retry count
is reset to 0. Reactivation will fail for Tasks that are not completed or that
previously completed successfully (with an exit code of 0). Additionally, it
will fail if the Job has completed (or is terminating or deleting).
</remarks>
    </member>
    <member name="Reactivate(String,String,Int32,String,Boolean,String,RequestConditions,RequestContext)">
<example>
This sample shows how to call Reactivate with required parameters.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetTaskClient(<2022-10-01.16.0>);

Response response = client.Reactivate("<jobId>", "<taskId>");
Console.WriteLine(response.Status);
]]></code>
This sample shows how to call Reactivate with all parameters.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetTaskClient(<2022-10-01.16.0>);

Response response = client.Reactivate("<jobId>", "<taskId>", 1234, "<clientRequestId>", true, "<ocpDate>", null);
Console.WriteLine(response.Status);
]]></code>
</example>
<remarks>
Reactivation makes a Task eligible to be retried again up to its maximum retry
count. The Task&apos;s state is changed to active. As the Task is no longer in the
completed state, any previous exit code or failure information is no longer
available after reactivation. Each time a Task is reactivated, its retry count
is reset to 0. Reactivation will fail for Tasks that are not completed or that
previously completed successfully (with an exit code of 0). Additionally, it
will fail if the Job has completed (or is terminating or deleting).
</remarks>
    </member>
  </members>
</doc>
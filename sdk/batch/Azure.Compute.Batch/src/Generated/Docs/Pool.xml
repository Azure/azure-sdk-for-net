<?xml version="1.0" encoding="utf-8"?>
<doc>
  <members>
    <member name="GetAllLifetimeStatisticsAsync(Int32,String,Boolean,String,RequestContext)">
<example>
This sample shows how to call GetAllLifetimeStatisticsAsync and parse the result.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetPoolClient(<2022-10-01.16.0>);

Response response = await client.GetAllLifetimeStatisticsAsync();

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.GetProperty("url").ToString());
Console.WriteLine(result.GetProperty("startTime").ToString());
Console.WriteLine(result.GetProperty("lastUpdateTime").ToString());
]]></code>
This sample shows how to call GetAllLifetimeStatisticsAsync with all parameters, and how to parse the result.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetPoolClient(<2022-10-01.16.0>);

Response response = await client.GetAllLifetimeStatisticsAsync(1234, "<clientRequestId>", true, "<ocpDate>");

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.GetProperty("url").ToString());
Console.WriteLine(result.GetProperty("startTime").ToString());
Console.WriteLine(result.GetProperty("lastUpdateTime").ToString());
Console.WriteLine(result.GetProperty("usageStats").GetProperty("startTime").ToString());
Console.WriteLine(result.GetProperty("usageStats").GetProperty("lastUpdateTime").ToString());
Console.WriteLine(result.GetProperty("usageStats").GetProperty("dedicatedCoreTime").ToString());
Console.WriteLine(result.GetProperty("resourceStats").GetProperty("startTime").ToString());
Console.WriteLine(result.GetProperty("resourceStats").GetProperty("lastUpdateTime").ToString());
Console.WriteLine(result.GetProperty("resourceStats").GetProperty("avgCPUPercentage").ToString());
Console.WriteLine(result.GetProperty("resourceStats").GetProperty("avgMemoryGiB").ToString());
Console.WriteLine(result.GetProperty("resourceStats").GetProperty("peakMemoryGiB").ToString());
Console.WriteLine(result.GetProperty("resourceStats").GetProperty("avgDiskGiB").ToString());
Console.WriteLine(result.GetProperty("resourceStats").GetProperty("peakDiskGiB").ToString());
Console.WriteLine(result.GetProperty("resourceStats").GetProperty("diskReadIOps").ToString());
Console.WriteLine(result.GetProperty("resourceStats").GetProperty("diskWriteIOps").ToString());
Console.WriteLine(result.GetProperty("resourceStats").GetProperty("diskReadGiB").ToString());
Console.WriteLine(result.GetProperty("resourceStats").GetProperty("diskWriteGiB").ToString());
Console.WriteLine(result.GetProperty("resourceStats").GetProperty("networkReadGiB").ToString());
Console.WriteLine(result.GetProperty("resourceStats").GetProperty("networkWriteGiB").ToString());
]]></code>
</example>
<remarks>
Statistics are aggregated across all Pools that have ever existed in the
Account, from Account creation to the last update time of the statistics. The
statistics may not be immediately available. The Batch service performs
periodic roll-up of statistics. The typical delay is about 30 minutes.

Below is the JSON schema for the response payload.

Response Body:

Schema for <c>PoolStatistics</c>:
<code>{
  url: string, # Required. The URL for the statistics.
  startTime: string (date &amp; time), # Required. The start time of the time range covered by the statistics.
  lastUpdateTime: string (date &amp; time), # Required. The time at which the statistics were last updated. All statistics are limited
to the range between startTime and lastUpdateTime.
  usageStats: {
    startTime: string (date &amp; time), # Required. The start time of the time range covered by the statistics.
    lastUpdateTime: string (date &amp; time), # Required. The time at which the statistics were last updated. All statistics are limited
to the range between startTime and lastUpdateTime.
    dedicatedCoreTime: string (duration ISO 8601 Format), # Required. The aggregated wall-clock time of the dedicated Compute Node cores being part
of the Pool.
  }, # Optional. Statistics related to Pool usage information.
  resourceStats: {
    startTime: string (date &amp; time), # Required. The start time of the time range covered by the statistics.
    lastUpdateTime: string (date &amp; time), # Required. The time at which the statistics were last updated. All statistics are limited
to the range between startTime and lastUpdateTime.
    avgCPUPercentage: number, # Required. The average CPU usage across all Compute Nodes in the Pool (percentage per
node).
    avgMemoryGiB: number, # Required. The average memory usage in GiB across all Compute Nodes in the Pool.
    peakMemoryGiB: number, # Required. The peak memory usage in GiB across all Compute Nodes in the Pool.
    avgDiskGiB: number, # Required. The average used disk space in GiB across all Compute Nodes in the Pool.
    peakDiskGiB: number, # Required. The peak used disk space in GiB across all Compute Nodes in the Pool.
    diskReadIOps: number, # Required. The total number of disk read operations across all Compute Nodes in the Pool.
    diskWriteIOps: number, # Required. The total number of disk write operations across all Compute Nodes in the Pool.
    diskReadGiB: number, # Required. The total amount of data in GiB of disk reads across all Compute Nodes in the
Pool.
    diskWriteGiB: number, # Required. The total amount of data in GiB of disk writes across all Compute Nodes in the
Pool.
    networkReadGiB: number, # Required. The total amount of data in GiB of network reads across all Compute Nodes in
the Pool.
    networkWriteGiB: number, # Required. The total amount of data in GiB of network writes across all Compute Nodes in
the Pool.
  }, # Optional. Statistics related to resource consumption by Compute Nodes in a Pool.
}
</code>

</remarks>
    </member>
    <member name="GetAllLifetimeStatistics(Int32,String,Boolean,String,RequestContext)">
<example>
This sample shows how to call GetAllLifetimeStatistics and parse the result.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetPoolClient(<2022-10-01.16.0>);

Response response = client.GetAllLifetimeStatistics();

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.GetProperty("url").ToString());
Console.WriteLine(result.GetProperty("startTime").ToString());
Console.WriteLine(result.GetProperty("lastUpdateTime").ToString());
]]></code>
This sample shows how to call GetAllLifetimeStatistics with all parameters, and how to parse the result.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetPoolClient(<2022-10-01.16.0>);

Response response = client.GetAllLifetimeStatistics(1234, "<clientRequestId>", true, "<ocpDate>");

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.GetProperty("url").ToString());
Console.WriteLine(result.GetProperty("startTime").ToString());
Console.WriteLine(result.GetProperty("lastUpdateTime").ToString());
Console.WriteLine(result.GetProperty("usageStats").GetProperty("startTime").ToString());
Console.WriteLine(result.GetProperty("usageStats").GetProperty("lastUpdateTime").ToString());
Console.WriteLine(result.GetProperty("usageStats").GetProperty("dedicatedCoreTime").ToString());
Console.WriteLine(result.GetProperty("resourceStats").GetProperty("startTime").ToString());
Console.WriteLine(result.GetProperty("resourceStats").GetProperty("lastUpdateTime").ToString());
Console.WriteLine(result.GetProperty("resourceStats").GetProperty("avgCPUPercentage").ToString());
Console.WriteLine(result.GetProperty("resourceStats").GetProperty("avgMemoryGiB").ToString());
Console.WriteLine(result.GetProperty("resourceStats").GetProperty("peakMemoryGiB").ToString());
Console.WriteLine(result.GetProperty("resourceStats").GetProperty("avgDiskGiB").ToString());
Console.WriteLine(result.GetProperty("resourceStats").GetProperty("peakDiskGiB").ToString());
Console.WriteLine(result.GetProperty("resourceStats").GetProperty("diskReadIOps").ToString());
Console.WriteLine(result.GetProperty("resourceStats").GetProperty("diskWriteIOps").ToString());
Console.WriteLine(result.GetProperty("resourceStats").GetProperty("diskReadGiB").ToString());
Console.WriteLine(result.GetProperty("resourceStats").GetProperty("diskWriteGiB").ToString());
Console.WriteLine(result.GetProperty("resourceStats").GetProperty("networkReadGiB").ToString());
Console.WriteLine(result.GetProperty("resourceStats").GetProperty("networkWriteGiB").ToString());
]]></code>
</example>
<remarks>
Statistics are aggregated across all Pools that have ever existed in the
Account, from Account creation to the last update time of the statistics. The
statistics may not be immediately available. The Batch service performs
periodic roll-up of statistics. The typical delay is about 30 minutes.

Below is the JSON schema for the response payload.

Response Body:

Schema for <c>PoolStatistics</c>:
<code>{
  url: string, # Required. The URL for the statistics.
  startTime: string (date &amp; time), # Required. The start time of the time range covered by the statistics.
  lastUpdateTime: string (date &amp; time), # Required. The time at which the statistics were last updated. All statistics are limited
to the range between startTime and lastUpdateTime.
  usageStats: {
    startTime: string (date &amp; time), # Required. The start time of the time range covered by the statistics.
    lastUpdateTime: string (date &amp; time), # Required. The time at which the statistics were last updated. All statistics are limited
to the range between startTime and lastUpdateTime.
    dedicatedCoreTime: string (duration ISO 8601 Format), # Required. The aggregated wall-clock time of the dedicated Compute Node cores being part
of the Pool.
  }, # Optional. Statistics related to Pool usage information.
  resourceStats: {
    startTime: string (date &amp; time), # Required. The start time of the time range covered by the statistics.
    lastUpdateTime: string (date &amp; time), # Required. The time at which the statistics were last updated. All statistics are limited
to the range between startTime and lastUpdateTime.
    avgCPUPercentage: number, # Required. The average CPU usage across all Compute Nodes in the Pool (percentage per
node).
    avgMemoryGiB: number, # Required. The average memory usage in GiB across all Compute Nodes in the Pool.
    peakMemoryGiB: number, # Required. The peak memory usage in GiB across all Compute Nodes in the Pool.
    avgDiskGiB: number, # Required. The average used disk space in GiB across all Compute Nodes in the Pool.
    peakDiskGiB: number, # Required. The peak used disk space in GiB across all Compute Nodes in the Pool.
    diskReadIOps: number, # Required. The total number of disk read operations across all Compute Nodes in the Pool.
    diskWriteIOps: number, # Required. The total number of disk write operations across all Compute Nodes in the Pool.
    diskReadGiB: number, # Required. The total amount of data in GiB of disk reads across all Compute Nodes in the
Pool.
    diskWriteGiB: number, # Required. The total amount of data in GiB of disk writes across all Compute Nodes in the
Pool.
    networkReadGiB: number, # Required. The total amount of data in GiB of network reads across all Compute Nodes in
the Pool.
    networkWriteGiB: number, # Required. The total amount of data in GiB of network writes across all Compute Nodes in
the Pool.
  }, # Optional. Statistics related to resource consumption by Compute Nodes in a Pool.
}
</code>

</remarks>
    </member>
    <member name="AddAsync(RequestContent,Int32,String,Boolean,String,RequestContext)">
<example>
This sample shows how to call AddAsync with required parameters.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetPoolClient(<2022-10-01.16.0>);

var data = new {};

Response response = await client.AddAsync(RequestContent.Create(data));
Console.WriteLine(response.Status);
]]></code>
This sample shows how to call AddAsync with all parameters and request content.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetPoolClient(<2022-10-01.16.0>);

var data = new {
    id = "<id>",
    displayName = "<displayName>",
    vmSize = "<vmSize>",
    cloudServiceConfiguration = new {
        osFamily = "<osFamily>",
        osVersion = "<osVersion>",
    },
    virtualMachineConfiguration = new {
        imageReference = new {
            publisher = "<publisher>",
            offer = "<offer>",
            sku = "<sku>",
            version = "<version>",
            virtualMachineImageId = "<virtualMachineImageId>",
        },
        nodeAgentSKUId = "<nodeAgentSKUId>",
        windowsConfiguration = new {
            enableAutomaticUpdates = true,
        },
        dataDisks = new[] {
            new {
                lun = 1234,
                caching = "none",
                diskSizeGB = 1234,
                storageAccountType = "standard_lrs",
            }
        },
        licenseType = "<licenseType>",
        containerConfiguration = new {
            type = "dockerCompatible",
            containerImageNames = new[] {
                "<String>"
            },
            containerRegistries = new[] {
                new {
                    username = "<username>",
                    password = "<password>",
                    registryServer = "<registryServer>",
                    identityReference = new {
                        resourceId = "<resourceId>",
                    },
                }
            },
        },
        diskEncryptionConfiguration = new {
            targets = new[] {
                "osdisk"
            },
        },
        nodePlacementConfiguration = new {
            policy = "regional",
        },
        extensions = new[] {
            new {
                name = "<name>",
                publisher = "<publisher>",
                type = "<type>",
                typeHandlerVersion = "<typeHandlerVersion>",
                autoUpgradeMinorVersion = true,
                settings = new {},
                protectedSettings = new {},
                provisionAfterExtensions = new[] {
                    "<String>"
                },
            }
        },
        osDisk = new {
            ephemeralOSDiskSettings = new {
                placement = "cachedisk",
            },
        },
    },
    resizeTimeout = PT1H23M45S,
    targetDedicatedNodes = 1234,
    targetLowPriorityNodes = 1234,
    enableAutoScale = true,
    autoScaleFormula = "<autoScaleFormula>",
    autoScaleEvaluationInterval = PT1H23M45S,
    enableInterNodeCommunication = true,
    networkConfiguration = new {
        subnetId = "<subnetId>",
        dynamicVNetAssignmentScope = "none",
        endpointConfiguration = new {
            inboundNATPools = new[] {
                new {
                    name = "<name>",
                    protocol = "tcp",
                    backendPort = 1234,
                    frontendPortRangeStart = 1234,
                    frontendPortRangeEnd = 1234,
                    networkSecurityGroupRules = new[] {
                        new {
                            priority = 1234,
                            access = "allow",
                            sourceAddressPrefix = "<sourceAddressPrefix>",
                            sourcePortRanges = new[] {
                                "<String>"
                            },
                        }
                    },
                }
            },
        },
        publicIPAddressConfiguration = new {
            provision = "batchmanaged",
            ipAddressIds = new[] {
                "<String>"
            },
        },
    },
    startTask = new {
        commandLine = "<commandLine>",
        containerSettings = new {
            containerRunOptions = "<containerRunOptions>",
            imageName = "<imageName>",
            registry = new {
                username = "<username>",
                password = "<password>",
                registryServer = "<registryServer>",
                identityReference = new {
                    resourceId = "<resourceId>",
                },
            },
            workingDirectory = "taskWorkingDirectory",
        },
        resourceFiles = new[] {
            new {
                autoStorageContainerName = "<autoStorageContainerName>",
                storageContainerUrl = "<storageContainerUrl>",
                httpUrl = "<httpUrl>",
                blobPrefix = "<blobPrefix>",
                filePath = "<filePath>",
                fileMode = "<fileMode>",
                identityReference = new {
                    resourceId = "<resourceId>",
                },
            }
        },
        environmentSettings = new[] {
            new {
                name = "<name>",
                value = "<value>",
            }
        },
        userIdentity = new {
            username = "<username>",
            autoUser = new {
                scope = "task",
                elevationLevel = "nonadmin",
            },
        },
        maxTaskRetryCount = 1234,
        waitForSuccess = true,
    },
    certificateReferences = new[] {
        new {
            thumbprint = "<thumbprint>",
            thumbprintAlgorithm = "<thumbprintAlgorithm>",
            storeLocation = "currentuser",
            storeName = "<storeName>",
            visibility = new[] {
                "starttask"
            },
        }
    },
    applicationPackageReferences = new[] {
        new {
            applicationId = "<applicationId>",
            version = "<version>",
        }
    },
    applicationLicenses = new[] {
        "<String>"
    },
    taskSlotsPerNode = 1234,
    taskSchedulingPolicy = new {
        nodeFillType = "spread",
    },
    userAccounts = new[] {
        new {
            name = "<name>",
            password = "<password>",
            elevationLevel = "nonadmin",
            linuxUserConfiguration = new {
                uid = 1234,
                gid = 1234,
                sshPrivateKey = "<sshPrivateKey>",
            },
            windowsUserConfiguration = new {
                loginMode = "batch",
            },
        }
    },
    metadata = new[] {
        new {
            name = "<name>",
            value = "<value>",
        }
    },
    mountConfiguration = new[] {
        new {
            azureBlobFileSystemConfiguration = new {
                accountName = "<accountName>",
                containerName = "<containerName>",
                accountKey = "<accountKey>",
                sasKey = "<sasKey>",
                blobfuseOptions = "<blobfuseOptions>",
                relativeMountPath = "<relativeMountPath>",
                identityReference = new {
                    resourceId = "<resourceId>",
                },
            },
            nfsMountConfiguration = new {
                source = "<source>",
                relativeMountPath = "<relativeMountPath>",
                mountOptions = "<mountOptions>",
            },
            cifsMountConfiguration = new {
                username = "<username>",
                source = "<source>",
                relativeMountPath = "<relativeMountPath>",
                mountOptions = "<mountOptions>",
                password = "<password>",
            },
            azureFileShareConfiguration = new {
                accountName = "<accountName>",
                azureFileUrl = "<azureFileUrl>",
                accountKey = "<accountKey>",
                relativeMountPath = "<relativeMountPath>",
                mountOptions = "<mountOptions>",
            },
        }
    },
    targetNodeCommunicationMode = "default",
};

Response response = await client.AddAsync(RequestContent.Create(data), 1234, "<clientRequestId>", true, "<ocpDate>");
Console.WriteLine(response.Status);
]]></code>
</example>
<remarks>
When naming Pools, avoid including sensitive information such as user names or
secret project names. This information may appear in telemetry logs accessible
to Microsoft Support engineers.

Below is the JSON schema for the request payload.

Request Body:

Schema for <c>BatchPool</c>:
<code>{
  id: string, # Optional. The ID can contain any combination of alphanumeric characters including hyphens
and underscores, and cannot contain more than 64 characters. The ID is
case-preserving and case-insensitive (that is, you may not have two IDs within
an Account that differ only by case).
  displayName: string, # Optional. The display name need not be unique and can contain any Unicode characters up
to a maximum length of 1024.
  url: string, # Optional. The URL of the Pool.
  eTag: string, # Optional. This is an opaque string. You can use it to detect whether the Pool has changed
between requests. In particular, you can be pass the ETag when updating a Pool
to specify that your changes should take effect only if nobody else has
modified the Pool in the meantime.
  lastModified: string (date &amp; time), # Optional. This is the last time at which the Pool level data, such as the
targetDedicatedNodes or enableAutoscale settings, changed. It does not factor
in node-level changes such as a Compute Node changing state.
  creationTime: string (date &amp; time), # Optional. The creation time of the Pool.
  state: &quot;active&quot; | &quot;deleting&quot;, # Optional. The current state of the Pool.
  stateTransitionTime: string (date &amp; time), # Optional. The time at which the Pool entered its current state.
  allocationState: &quot;steady&quot; | &quot;resizing&quot; | &quot;stopping&quot;, # Optional. Whether the Pool is resizing.
  allocationStateTransitionTime: string (date &amp; time), # Optional. The time at which the Pool entered its current allocation state.
  vmSize: string, # Optional. For information about available sizes of virtual machines in Pools, see Choose
a VM size for Compute Nodes in an Azure Batch Pool
(https://docs.microsoft.com/azure/batch/batch-pool-vm-sizes).
  cloudServiceConfiguration: {
    osFamily: string, # Required. Possible values are:
2 - OS Family 2, equivalent to Windows Server 2008 R2
SP1.
3 - OS Family 3, equivalent to Windows Server 2012.
4 - OS Family 4,
equivalent to Windows Server 2012 R2.
5 - OS Family 5, equivalent to Windows
Server 2016.
6 - OS Family 6, equivalent to Windows Server 2019. For more
information, see Azure Guest OS Releases
(https://azure.microsoft.com/documentation/articles/cloud-services-guestos-update-matrix/#releases).
    osVersion: string, # Optional. The default value is * which specifies the latest operating system version for
the specified OS family.
  }, # Optional. This property and virtualMachineConfiguration are mutually exclusive and one of
the properties must be specified. This property cannot be specified if the
Batch Account was created with its poolAllocationMode property set to
&apos;UserSubscription&apos;.
  virtualMachineConfiguration: {
    imageReference: {
      publisher: string, # Optional. For example, Canonical or MicrosoftWindowsServer.
      offer: string, # Optional. For example, UbuntuServer or WindowsServer.
      sku: string, # Optional. For example, 18.04-LTS or 2019-Datacenter.
      version: string, # Optional. A value of &apos;latest&apos; can be specified to select the latest version of an Image.
If omitted, the default is &apos;latest&apos;.
      virtualMachineImageId: string, # Optional. This property is mutually exclusive with other ImageReference properties. The
Shared Image Gallery Image must have replicas in the same region and must be in
the same subscription as the Azure Batch account. If the image version is not
specified in the imageId, the latest version will be used. For information
about the firewall settings for the Batch Compute Node agent to communicate
with the Batch service see
https://docs.microsoft.com/en-us/azure/batch/batch-api-basics#virtual-network-vnet-and-firewall-configuration.
      exactVersion: string, # Optional. The specific version of the platform image or marketplace image used to create
the node. This read-only field differs from &apos;version&apos; only if the value
specified for &apos;version&apos; when the pool was created was &apos;latest&apos;.
    }, # Required. A reference to an Azure Virtual Machines Marketplace Image or a Shared Image
Gallery Image. To get the list of all Azure Marketplace Image references
verified by Azure Batch, see the &apos;List Supported Images&apos; operation.
    nodeAgentSKUId: string, # Required. The Batch Compute Node agent is a program that runs on each Compute Node in the
Pool, and provides the command-and-control interface between the Compute Node
and the Batch service. There are different implementations of the Compute Node
agent, known as SKUs, for different operating systems. You must specify a
Compute Node agent SKU which matches the selected Image reference. To get the
list of supported Compute Node agent SKUs along with their list of verified
Image references, see the &apos;List supported Compute Node agent SKUs&apos; operation.
    windowsConfiguration: {
      enableAutomaticUpdates: boolean, # Optional. If omitted, the default value is true.
    }, # Optional. This property must not be specified if the imageReference property specifies a
Linux OS Image.
    dataDisks: [DataDisk], # Optional. This property must be specified if the Compute Nodes in the Pool need to have
empty data disks attached to them. This cannot be updated. Each Compute Node
gets its own disk (the disk is not a file share). Existing disks cannot be
attached, each attached disk is empty. When the Compute Node is removed from
the Pool, the disk and all data associated with it is also deleted. The disk is
not formatted after being attached, it must be formatted before use - for more
information see
https://docs.microsoft.com/en-us/azure/virtual-machines/linux/classic/attach-disk#initialize-a-new-data-disk-in-linux
and
https://docs.microsoft.com/en-us/azure/virtual-machines/windows/attach-disk-ps#add-an-empty-data-disk-to-a-virtual-machine.
    licenseType: string, # Optional. This only applies to Images that contain the Windows operating system, and
should only be used when you hold valid on-premises licenses for the Compute
Nodes which will be deployed. If omitted, no on-premises licensing discount is
applied. Values are:

 Windows_Server - The on-premises license is for Windows
Server.
 Windows_Client - The on-premises license is for Windows Client.

    containerConfiguration: {
      type: &quot;dockerCompatible&quot;, # Required. The container technology to be used.
      containerImageNames: [string], # Optional. This is the full Image reference, as would be specified to &quot;docker pull&quot;. An
Image will be sourced from the default Docker registry unless the Image is
fully qualified with an alternative registry.
      containerRegistries: [
        {
          username: string, # Optional. The user name to log into the registry server.
          password: string, # Optional. The password to log into the registry server.
          registryServer: string, # Optional. If omitted, the default is &quot;docker.io&quot;.
          identityReference: {
            resourceId: string, # Optional. The ARM resource id of the user assigned identity.
          }, # Optional. The reference to a user assigned identity associated with the Batch pool which
a compute node will use.
        }
      ], # Optional. If any Images must be downloaded from a private registry which requires
credentials, then those credentials must be provided here.
    }, # Optional. If specified, setup is performed on each Compute Node in the Pool to allow
Tasks to run in containers. All regular Tasks and Job manager Tasks run on this
Pool must specify the containerSettings property, and all other Tasks may
specify it.
    diskEncryptionConfiguration: {
      targets: [&quot;osdisk&quot; | &quot;temporarydisk&quot;], # Optional. If omitted, no disks on the compute nodes in the pool will be encrypted. On
Linux pool, only &quot;TemporaryDisk&quot; is supported; on Windows pool, &quot;OsDisk&quot;
and &quot;TemporaryDisk&quot; must be specified.
    }, # Optional. If specified, encryption is performed on each node in the pool during node
provisioning.
    nodePlacementConfiguration: {
      policy: &quot;regional&quot; | &quot;zonal&quot;, # Optional. Allocation policy used by Batch Service to provision the nodes. If not
specified, Batch will use the regional policy.
    }, # Optional. This configuration will specify rules on how nodes in the pool will be
physically allocated.
    extensions: [VMExtension], # Optional. If specified, the extensions mentioned in this configuration will be installed
on each node.
    osDisk: {
      ephemeralOSDiskSettings: {
        placement: &quot;cachedisk&quot;, # Optional. This property can be used by user in the request to choose the location e.g.,
cache disk space for Ephemeral OS disk provisioning. For more information on
Ephemeral OS disk size requirements, please refer to Ephemeral OS disk size
requirements for Windows VMs at
https://docs.microsoft.com/en-us/azure/virtual-machines/windows/ephemeral-os-disks#size-requirements
and Linux VMs at
https://docs.microsoft.com/en-us/azure/virtual-machines/linux/ephemeral-os-disks#size-requirements.
      }, # Optional. Specifies the ephemeral Disk Settings for the operating system disk used by the
compute node (VM).
    }, # Optional. Settings for the operating system disk of the compute node (VM).
  }, # Optional. This property and cloudServiceConfiguration are mutually exclusive and one of
the properties must be specified.
  resizeTimeout: string (duration ISO 8601 Format), # Optional. This is the timeout for the most recent resize operation. (The initial sizing
when the Pool is created counts as a resize.) The default value is 15 minutes.
  resizeErrors: [
    {
      code: string, # Optional. An identifier for the Pool resize error. Codes are invariant and are intended
to be consumed programmatically.
      message: string, # Optional. A message describing the Pool resize error, intended to be suitable for display
in a user interface.
      values: [NameValuePair], # Optional. A list of additional error details related to the Pool resize error.
    }
  ], # Optional. This property is set only if one or more errors occurred during the last Pool
resize, and only when the Pool allocationState is Steady.
  currentDedicatedNodes: number, # Optional. The number of dedicated Compute Nodes currently in the Pool.
  currentLowPriorityNodes: number, # Optional. Spot/Low-priority Compute Nodes which have been preempted are included in this
count.
  targetDedicatedNodes: number, # Optional. The desired number of dedicated Compute Nodes in the Pool.
  targetLowPriorityNodes: number, # Optional. The desired number of Spot/Low-priority Compute Nodes in the Pool.
  enableAutoScale: boolean, # Optional. If false, at least one of targetDedicatedNodes and targetLowPriorityNodes must
be specified. If true, the autoScaleFormula property is required and the Pool
automatically resizes according to the formula. The default value is false.
  autoScaleFormula: string, # Optional. This property is set only if the Pool automatically scales, i.e.
enableAutoScale is true.
  autoScaleEvaluationInterval: string (duration ISO 8601 Format), # Optional. This property is set only if the Pool automatically scales, i.e.
enableAutoScale is true.
  autoScaleRun: {
    timestamp: string (date &amp; time), # Required. The time at which the autoscale formula was last evaluated.
    results: string, # Optional. Each variable value is returned in the form $variable=value, and variables are
separated by semicolons.
    error: {
      code: string, # Optional. An identifier for the autoscale error. Codes are invariant and are intended to
be consumed programmatically.
      message: string, # Optional. A message describing the autoscale error, intended to be suitable for display
in a user interface.
      values: [NameValuePair], # Optional. A list of additional error details related to the autoscale error.
    }, # Optional. An error that occurred when executing or evaluating a Pool autoscale formula.
  }, # Optional. This property is set only if the Pool automatically scales, i.e.
enableAutoScale is true.
  enableInterNodeCommunication: boolean, # Optional. This imposes restrictions on which Compute Nodes can be assigned to the Pool.
Specifying this value can reduce the chance of the requested number of Compute
Nodes to be allocated in the Pool.
  networkConfiguration: {
    subnetId: string, # Optional. The virtual network must be in the same region and subscription as the Azure
Batch Account. The specified subnet should have enough free IP addresses to
accommodate the number of Compute Nodes in the Pool. If the subnet doesn&apos;t have
enough free IP addresses, the Pool will partially allocate Nodes and a resize
error will occur. The &apos;MicrosoftAzureBatch&apos; service principal must have the
&apos;Classic Virtual Machine Contributor&apos; Role-Based Access Control (RBAC) role for
the specified VNet. The specified subnet must allow communication from the
Azure Batch service to be able to schedule Tasks on the Nodes. This can be
verified by checking if the specified VNet has any associated Network Security
Groups (NSG). If communication to the Nodes in the specified subnet is denied
by an NSG, then the Batch service will set the state of the Compute Nodes to
unusable. For Pools created with virtualMachineConfiguration only ARM virtual
networks (&apos;Microsoft.Network/virtualNetworks&apos;) are supported, but for Pools
created with cloudServiceConfiguration both ARM and classic virtual networks
are supported. If the specified VNet has any associated Network Security Groups
(NSG), then a few reserved system ports must be enabled for inbound
communication. For Pools created with a virtual machine configuration, enable
ports 29876 and 29877, as well as port 22 for Linux and port 3389 for Windows.
For Pools created with a cloud service configuration, enable ports 10100,
20100, and 30100. Also enable outbound connections to Azure Storage on port
443. For more details see:
https://docs.microsoft.com/en-us/azure/batch/batch-api-basics#virtual-network-vnet-and-firewall-configuration
    dynamicVNetAssignmentScope: &quot;none&quot; | &quot;job&quot;, # Optional. The scope of dynamic vnet assignment.
    endpointConfiguration: {
      inboundNATPools: [InboundNATPool], # Required. The maximum number of inbound NAT Pools per Batch Pool is 5. If the maximum
number of inbound NAT Pools is exceeded the request fails with HTTP status code
400. This cannot be specified if the IPAddressProvisioningType is
NoPublicIPAddresses.
    }, # Optional. Pool endpoint configuration is only supported on Pools with the
virtualMachineConfiguration property.
    publicIPAddressConfiguration: {
      provision: &quot;batchmanaged&quot; | &quot;usermanaged&quot; | &quot;nopublicipaddresses&quot;, # Optional. The default value is BatchManaged.
      ipAddressIds: [string], # Optional. The number of IPs specified here limits the maximum size of the Pool - 100
dedicated nodes or 100 Spot/Low-priority nodes can be allocated for each public
IP. For example, a pool needing 250 dedicated VMs would need at least 3 public
IPs specified. Each element of this collection is of the form:
/subscriptions/{subscription}/resourceGroups/{group}/providers/Microsoft.Network/publicIPAddresses/{ip}.
    }, # Optional. Public IP configuration property is only supported on Pools with the
virtualMachineConfiguration property.
  }, # Optional. The network configuration for a Pool.
  startTask: {
    commandLine: string, # Required. The command line does not run under a shell, and therefore cannot take
advantage of shell features such as environment variable expansion. If you want
to take advantage of such features, you should invoke the shell in the command
line, for example using &quot;cmd /c MyCommand&quot; in Windows or &quot;/bin/sh -c
MyCommand&quot; in Linux. If the command line refers to file paths, it should use a
relative path (relative to the Task working directory), or use the Batch
provided environment variable
(https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).
    containerSettings: {
      containerRunOptions: string, # Optional. These additional options are supplied as arguments to the &quot;docker create&quot;
command, in addition to those controlled by the Batch Service.
      imageName: string, # Required. This is the full Image reference, as would be specified to &quot;docker pull&quot;. If
no tag is provided as part of the Image name, the tag &quot;:latest&quot; is used as a
default.
      registry: ContainerRegistry, # Optional. This setting can be omitted if was already provided at Pool creation.
      workingDirectory: &quot;taskWorkingDirectory&quot; | &quot;containerImageDefault&quot;, # Optional. The default is &apos;taskWorkingDirectory&apos;.
    }, # Optional. When this is specified, all directories recursively below the
AZ_BATCH_NODE_ROOT_DIR (the root of Azure Batch directories on the node) are
mapped into the container, all Task environment variables are mapped into the
container, and the Task command line is executed in the container. Files
produced in the container outside of AZ_BATCH_NODE_ROOT_DIR might not be
reflected to the host disk, meaning that Batch file APIs will not be able to
access those files.
    resourceFiles: [ResourceFile], # Optional. Files listed under this element are located in the Task&apos;s working directory.
    environmentSettings: [EnvironmentSetting], # Optional. A list of environment variable settings for the StartTask.
    userIdentity: {
      username: string, # Optional. The userName and autoUser properties are mutually exclusive; you must specify
one but not both.
      autoUser: {
        scope: &quot;task&quot; | &quot;pool&quot;, # Optional. The default value is pool. If the pool is running Windows a value of Task
should be specified if stricter isolation between tasks is required. For
example, if the task mutates the registry in a way which could impact other
tasks, or if certificates have been specified on the pool which should not be
accessible by normal tasks but should be accessible by StartTasks.
        elevationLevel: &quot;nonadmin&quot; | &quot;admin&quot;, # Optional. The default value is nonAdmin.
      }, # Optional. The userName and autoUser properties are mutually exclusive; you must specify
one but not both.
    }, # Optional. If omitted, the Task runs as a non-administrative user unique to the Task.
    maxTaskRetryCount: number, # Optional. The Batch service retries a Task if its exit code is nonzero. Note that this
value specifically controls the number of retries. The Batch service will try
the Task once, and may then retry up to this limit. For example, if the maximum
retry count is 3, Batch tries the Task up to 4 times (one initial try and 3
retries). If the maximum retry count is 0, the Batch service does not retry the
Task. If the maximum retry count is -1, the Batch service retries the Task
without limit, however this is not recommended for a start task or any task.
The default value is 0 (no retries)
    waitForSuccess: boolean, # Optional. If true and the StartTask fails on a Node, the Batch service retries the
StartTask up to its maximum retry count (maxTaskRetryCount). If the Task has
still not completed successfully after all retries, then the Batch service
marks the Node unusable, and will not schedule Tasks to it. This condition can
be detected via the Compute Node state and failure info details. If false, the
Batch service will not wait for the StartTask to complete. In this case, other
Tasks can start executing on the Compute Node while the StartTask is still
running; and even if the StartTask fails, new Tasks will continue to be
scheduled on the Compute Node. The default is true.
  }, # Optional. Batch will retry Tasks when a recovery operation is triggered on a Node.
Examples of recovery operations include (but are not limited to) when an
unhealthy Node is rebooted or a Compute Node disappeared due to host failure.
Retries due to recovery operations are independent of and are not counted
against the maxTaskRetryCount. Even if the maxTaskRetryCount is 0, an internal
retry due to a recovery operation may occur. Because of this, all Tasks should
be idempotent. This means Tasks need to tolerate being interrupted and
restarted without causing any corruption or duplicate data. The best practice
for long running Tasks is to use some form of checkpointing. In some cases the
StartTask may be re-run even though the Compute Node was not rebooted. Special
care should be taken to avoid StartTasks which create breakaway process or
install/launch services from the StartTask working directory, as this will
block Batch from being able to re-run the StartTask.
  certificateReferences: [CertificateReference], # Optional. For Windows Nodes, the Batch service installs the Certificates to the specified
Certificate store and location. For Linux Compute Nodes, the Certificates are
stored in a directory inside the Task working directory and an environment
variable AZ_BATCH_CERTIFICATES_DIR is supplied to the Task to query for this
location. For Certificates with visibility of &apos;remoteUser&apos;, a &apos;certs&apos; directory
is created in the user&apos;s home directory (e.g., /home/{user-name}/certs) and
Certificates are placed in that directory.
  applicationPackageReferences: [ApplicationPackageReference], # Optional. Changes to Package references affect all new Nodes joining the Pool, but do not
affect Compute Nodes that are already in the Pool until they are rebooted or
reimaged. There is a maximum of 10 Package references on any given Pool.
  applicationLicenses: [string], # Optional. The list of application licenses must be a subset of available Batch service
application licenses. If a license is requested which is not supported, Pool
creation will fail.
  taskSlotsPerNode: number, # Optional. The default value is 1. The maximum value is the smaller of 4 times the number
of cores of the vmSize of the pool or 256.
  taskSchedulingPolicy: {
    nodeFillType: &quot;spread&quot; | &quot;pack&quot;, # Required. If not specified, the default is spread.
  }, # Optional. If not specified, the default is spread.
  userAccounts: [UserAccount], # Optional. The list of user Accounts to be created on each Compute Node in the Pool.
  metadata: [MetadataItem], # Optional. A list of name-value pairs associated with the Pool as metadata.
  stats: {
    url: string, # Required. The URL for the statistics.
    startTime: string (date &amp; time), # Required. The start time of the time range covered by the statistics.
    lastUpdateTime: string (date &amp; time), # Required. The time at which the statistics were last updated. All statistics are limited
to the range between startTime and lastUpdateTime.
    usageStats: {
      startTime: string (date &amp; time), # Required. The start time of the time range covered by the statistics.
      lastUpdateTime: string (date &amp; time), # Required. The time at which the statistics were last updated. All statistics are limited
to the range between startTime and lastUpdateTime.
      dedicatedCoreTime: string (duration ISO 8601 Format), # Required. The aggregated wall-clock time of the dedicated Compute Node cores being part
of the Pool.
    }, # Optional. Statistics related to Pool usage information.
    resourceStats: {
      startTime: string (date &amp; time), # Required. The start time of the time range covered by the statistics.
      lastUpdateTime: string (date &amp; time), # Required. The time at which the statistics were last updated. All statistics are limited
to the range between startTime and lastUpdateTime.
      avgCPUPercentage: number, # Required. The average CPU usage across all Compute Nodes in the Pool (percentage per
node).
      avgMemoryGiB: number, # Required. The average memory usage in GiB across all Compute Nodes in the Pool.
      peakMemoryGiB: number, # Required. The peak memory usage in GiB across all Compute Nodes in the Pool.
      avgDiskGiB: number, # Required. The average used disk space in GiB across all Compute Nodes in the Pool.
      peakDiskGiB: number, # Required. The peak used disk space in GiB across all Compute Nodes in the Pool.
      diskReadIOps: number, # Required. The total number of disk read operations across all Compute Nodes in the Pool.
      diskWriteIOps: number, # Required. The total number of disk write operations across all Compute Nodes in the Pool.
      diskReadGiB: number, # Required. The total amount of data in GiB of disk reads across all Compute Nodes in the
Pool.
      diskWriteGiB: number, # Required. The total amount of data in GiB of disk writes across all Compute Nodes in the
Pool.
      networkReadGiB: number, # Required. The total amount of data in GiB of network reads across all Compute Nodes in
the Pool.
      networkWriteGiB: number, # Required. The total amount of data in GiB of network writes across all Compute Nodes in
the Pool.
    }, # Optional. Statistics related to resource consumption by Compute Nodes in a Pool.
  }, # Optional. This property is populated only if the CloudPool was retrieved with an expand
clause including the &apos;stats&apos; attribute; otherwise it is null. The statistics
may not be immediately available. The Batch service performs periodic roll-up
of statistics. The typical delay is about 30 minutes.
  mountConfiguration: [MountConfiguration], # Optional. This supports Azure Files, NFS, CIFS/SMB, and Blobfuse.
  identity: {
    type: &quot;UserAssigned&quot; | &quot;None&quot;, # Required. The list of user identities associated with the Batch pool. The user identity
dictionary key references will be ARM resource ids in the form:
&apos;/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.ManagedIdentity/userAssignedIdentities/{identityName}&apos;.
    userAssignedIdentities: [UserAssignedIdentity], # Optional. The user identity dictionary key references will be ARM resource ids in the
form:
&apos;/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.ManagedIdentity/userAssignedIdentities/{identityName}&apos;.
  }, # Optional. The list of user identities associated with the Batch pool. The user identity
dictionary key references will be ARM resource ids in the form:
&apos;/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.ManagedIdentity/userAssignedIdentities/{identityName}&apos;.
  targetNodeCommunicationMode: &quot;default&quot; | &quot;classic&quot; | &quot;simplified&quot;, # Optional. If omitted, the default value is Default.
  currentNodeCommunicationMode: &quot;default&quot; | &quot;classic&quot; | &quot;simplified&quot;, # Optional. Determines how a pool communicates with the Batch service.
}
</code>

</remarks>
    </member>
    <member name="Add(RequestContent,Int32,String,Boolean,String,RequestContext)">
<example>
This sample shows how to call Add with required parameters.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetPoolClient(<2022-10-01.16.0>);

var data = new {};

Response response = client.Add(RequestContent.Create(data));
Console.WriteLine(response.Status);
]]></code>
This sample shows how to call Add with all parameters and request content.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetPoolClient(<2022-10-01.16.0>);

var data = new {
    id = "<id>",
    displayName = "<displayName>",
    vmSize = "<vmSize>",
    cloudServiceConfiguration = new {
        osFamily = "<osFamily>",
        osVersion = "<osVersion>",
    },
    virtualMachineConfiguration = new {
        imageReference = new {
            publisher = "<publisher>",
            offer = "<offer>",
            sku = "<sku>",
            version = "<version>",
            virtualMachineImageId = "<virtualMachineImageId>",
        },
        nodeAgentSKUId = "<nodeAgentSKUId>",
        windowsConfiguration = new {
            enableAutomaticUpdates = true,
        },
        dataDisks = new[] {
            new {
                lun = 1234,
                caching = "none",
                diskSizeGB = 1234,
                storageAccountType = "standard_lrs",
            }
        },
        licenseType = "<licenseType>",
        containerConfiguration = new {
            type = "dockerCompatible",
            containerImageNames = new[] {
                "<String>"
            },
            containerRegistries = new[] {
                new {
                    username = "<username>",
                    password = "<password>",
                    registryServer = "<registryServer>",
                    identityReference = new {
                        resourceId = "<resourceId>",
                    },
                }
            },
        },
        diskEncryptionConfiguration = new {
            targets = new[] {
                "osdisk"
            },
        },
        nodePlacementConfiguration = new {
            policy = "regional",
        },
        extensions = new[] {
            new {
                name = "<name>",
                publisher = "<publisher>",
                type = "<type>",
                typeHandlerVersion = "<typeHandlerVersion>",
                autoUpgradeMinorVersion = true,
                settings = new {},
                protectedSettings = new {},
                provisionAfterExtensions = new[] {
                    "<String>"
                },
            }
        },
        osDisk = new {
            ephemeralOSDiskSettings = new {
                placement = "cachedisk",
            },
        },
    },
    resizeTimeout = PT1H23M45S,
    targetDedicatedNodes = 1234,
    targetLowPriorityNodes = 1234,
    enableAutoScale = true,
    autoScaleFormula = "<autoScaleFormula>",
    autoScaleEvaluationInterval = PT1H23M45S,
    enableInterNodeCommunication = true,
    networkConfiguration = new {
        subnetId = "<subnetId>",
        dynamicVNetAssignmentScope = "none",
        endpointConfiguration = new {
            inboundNATPools = new[] {
                new {
                    name = "<name>",
                    protocol = "tcp",
                    backendPort = 1234,
                    frontendPortRangeStart = 1234,
                    frontendPortRangeEnd = 1234,
                    networkSecurityGroupRules = new[] {
                        new {
                            priority = 1234,
                            access = "allow",
                            sourceAddressPrefix = "<sourceAddressPrefix>",
                            sourcePortRanges = new[] {
                                "<String>"
                            },
                        }
                    },
                }
            },
        },
        publicIPAddressConfiguration = new {
            provision = "batchmanaged",
            ipAddressIds = new[] {
                "<String>"
            },
        },
    },
    startTask = new {
        commandLine = "<commandLine>",
        containerSettings = new {
            containerRunOptions = "<containerRunOptions>",
            imageName = "<imageName>",
            registry = new {
                username = "<username>",
                password = "<password>",
                registryServer = "<registryServer>",
                identityReference = new {
                    resourceId = "<resourceId>",
                },
            },
            workingDirectory = "taskWorkingDirectory",
        },
        resourceFiles = new[] {
            new {
                autoStorageContainerName = "<autoStorageContainerName>",
                storageContainerUrl = "<storageContainerUrl>",
                httpUrl = "<httpUrl>",
                blobPrefix = "<blobPrefix>",
                filePath = "<filePath>",
                fileMode = "<fileMode>",
                identityReference = new {
                    resourceId = "<resourceId>",
                },
            }
        },
        environmentSettings = new[] {
            new {
                name = "<name>",
                value = "<value>",
            }
        },
        userIdentity = new {
            username = "<username>",
            autoUser = new {
                scope = "task",
                elevationLevel = "nonadmin",
            },
        },
        maxTaskRetryCount = 1234,
        waitForSuccess = true,
    },
    certificateReferences = new[] {
        new {
            thumbprint = "<thumbprint>",
            thumbprintAlgorithm = "<thumbprintAlgorithm>",
            storeLocation = "currentuser",
            storeName = "<storeName>",
            visibility = new[] {
                "starttask"
            },
        }
    },
    applicationPackageReferences = new[] {
        new {
            applicationId = "<applicationId>",
            version = "<version>",
        }
    },
    applicationLicenses = new[] {
        "<String>"
    },
    taskSlotsPerNode = 1234,
    taskSchedulingPolicy = new {
        nodeFillType = "spread",
    },
    userAccounts = new[] {
        new {
            name = "<name>",
            password = "<password>",
            elevationLevel = "nonadmin",
            linuxUserConfiguration = new {
                uid = 1234,
                gid = 1234,
                sshPrivateKey = "<sshPrivateKey>",
            },
            windowsUserConfiguration = new {
                loginMode = "batch",
            },
        }
    },
    metadata = new[] {
        new {
            name = "<name>",
            value = "<value>",
        }
    },
    mountConfiguration = new[] {
        new {
            azureBlobFileSystemConfiguration = new {
                accountName = "<accountName>",
                containerName = "<containerName>",
                accountKey = "<accountKey>",
                sasKey = "<sasKey>",
                blobfuseOptions = "<blobfuseOptions>",
                relativeMountPath = "<relativeMountPath>",
                identityReference = new {
                    resourceId = "<resourceId>",
                },
            },
            nfsMountConfiguration = new {
                source = "<source>",
                relativeMountPath = "<relativeMountPath>",
                mountOptions = "<mountOptions>",
            },
            cifsMountConfiguration = new {
                username = "<username>",
                source = "<source>",
                relativeMountPath = "<relativeMountPath>",
                mountOptions = "<mountOptions>",
                password = "<password>",
            },
            azureFileShareConfiguration = new {
                accountName = "<accountName>",
                azureFileUrl = "<azureFileUrl>",
                accountKey = "<accountKey>",
                relativeMountPath = "<relativeMountPath>",
                mountOptions = "<mountOptions>",
            },
        }
    },
    targetNodeCommunicationMode = "default",
};

Response response = client.Add(RequestContent.Create(data), 1234, "<clientRequestId>", true, "<ocpDate>");
Console.WriteLine(response.Status);
]]></code>
</example>
<remarks>
When naming Pools, avoid including sensitive information such as user names or
secret project names. This information may appear in telemetry logs accessible
to Microsoft Support engineers.

Below is the JSON schema for the request payload.

Request Body:

Schema for <c>BatchPool</c>:
<code>{
  id: string, # Optional. The ID can contain any combination of alphanumeric characters including hyphens
and underscores, and cannot contain more than 64 characters. The ID is
case-preserving and case-insensitive (that is, you may not have two IDs within
an Account that differ only by case).
  displayName: string, # Optional. The display name need not be unique and can contain any Unicode characters up
to a maximum length of 1024.
  url: string, # Optional. The URL of the Pool.
  eTag: string, # Optional. This is an opaque string. You can use it to detect whether the Pool has changed
between requests. In particular, you can be pass the ETag when updating a Pool
to specify that your changes should take effect only if nobody else has
modified the Pool in the meantime.
  lastModified: string (date &amp; time), # Optional. This is the last time at which the Pool level data, such as the
targetDedicatedNodes or enableAutoscale settings, changed. It does not factor
in node-level changes such as a Compute Node changing state.
  creationTime: string (date &amp; time), # Optional. The creation time of the Pool.
  state: &quot;active&quot; | &quot;deleting&quot;, # Optional. The current state of the Pool.
  stateTransitionTime: string (date &amp; time), # Optional. The time at which the Pool entered its current state.
  allocationState: &quot;steady&quot; | &quot;resizing&quot; | &quot;stopping&quot;, # Optional. Whether the Pool is resizing.
  allocationStateTransitionTime: string (date &amp; time), # Optional. The time at which the Pool entered its current allocation state.
  vmSize: string, # Optional. For information about available sizes of virtual machines in Pools, see Choose
a VM size for Compute Nodes in an Azure Batch Pool
(https://docs.microsoft.com/azure/batch/batch-pool-vm-sizes).
  cloudServiceConfiguration: {
    osFamily: string, # Required. Possible values are:
2 - OS Family 2, equivalent to Windows Server 2008 R2
SP1.
3 - OS Family 3, equivalent to Windows Server 2012.
4 - OS Family 4,
equivalent to Windows Server 2012 R2.
5 - OS Family 5, equivalent to Windows
Server 2016.
6 - OS Family 6, equivalent to Windows Server 2019. For more
information, see Azure Guest OS Releases
(https://azure.microsoft.com/documentation/articles/cloud-services-guestos-update-matrix/#releases).
    osVersion: string, # Optional. The default value is * which specifies the latest operating system version for
the specified OS family.
  }, # Optional. This property and virtualMachineConfiguration are mutually exclusive and one of
the properties must be specified. This property cannot be specified if the
Batch Account was created with its poolAllocationMode property set to
&apos;UserSubscription&apos;.
  virtualMachineConfiguration: {
    imageReference: {
      publisher: string, # Optional. For example, Canonical or MicrosoftWindowsServer.
      offer: string, # Optional. For example, UbuntuServer or WindowsServer.
      sku: string, # Optional. For example, 18.04-LTS or 2019-Datacenter.
      version: string, # Optional. A value of &apos;latest&apos; can be specified to select the latest version of an Image.
If omitted, the default is &apos;latest&apos;.
      virtualMachineImageId: string, # Optional. This property is mutually exclusive with other ImageReference properties. The
Shared Image Gallery Image must have replicas in the same region and must be in
the same subscription as the Azure Batch account. If the image version is not
specified in the imageId, the latest version will be used. For information
about the firewall settings for the Batch Compute Node agent to communicate
with the Batch service see
https://docs.microsoft.com/en-us/azure/batch/batch-api-basics#virtual-network-vnet-and-firewall-configuration.
      exactVersion: string, # Optional. The specific version of the platform image or marketplace image used to create
the node. This read-only field differs from &apos;version&apos; only if the value
specified for &apos;version&apos; when the pool was created was &apos;latest&apos;.
    }, # Required. A reference to an Azure Virtual Machines Marketplace Image or a Shared Image
Gallery Image. To get the list of all Azure Marketplace Image references
verified by Azure Batch, see the &apos;List Supported Images&apos; operation.
    nodeAgentSKUId: string, # Required. The Batch Compute Node agent is a program that runs on each Compute Node in the
Pool, and provides the command-and-control interface between the Compute Node
and the Batch service. There are different implementations of the Compute Node
agent, known as SKUs, for different operating systems. You must specify a
Compute Node agent SKU which matches the selected Image reference. To get the
list of supported Compute Node agent SKUs along with their list of verified
Image references, see the &apos;List supported Compute Node agent SKUs&apos; operation.
    windowsConfiguration: {
      enableAutomaticUpdates: boolean, # Optional. If omitted, the default value is true.
    }, # Optional. This property must not be specified if the imageReference property specifies a
Linux OS Image.
    dataDisks: [DataDisk], # Optional. This property must be specified if the Compute Nodes in the Pool need to have
empty data disks attached to them. This cannot be updated. Each Compute Node
gets its own disk (the disk is not a file share). Existing disks cannot be
attached, each attached disk is empty. When the Compute Node is removed from
the Pool, the disk and all data associated with it is also deleted. The disk is
not formatted after being attached, it must be formatted before use - for more
information see
https://docs.microsoft.com/en-us/azure/virtual-machines/linux/classic/attach-disk#initialize-a-new-data-disk-in-linux
and
https://docs.microsoft.com/en-us/azure/virtual-machines/windows/attach-disk-ps#add-an-empty-data-disk-to-a-virtual-machine.
    licenseType: string, # Optional. This only applies to Images that contain the Windows operating system, and
should only be used when you hold valid on-premises licenses for the Compute
Nodes which will be deployed. If omitted, no on-premises licensing discount is
applied. Values are:

 Windows_Server - The on-premises license is for Windows
Server.
 Windows_Client - The on-premises license is for Windows Client.

    containerConfiguration: {
      type: &quot;dockerCompatible&quot;, # Required. The container technology to be used.
      containerImageNames: [string], # Optional. This is the full Image reference, as would be specified to &quot;docker pull&quot;. An
Image will be sourced from the default Docker registry unless the Image is
fully qualified with an alternative registry.
      containerRegistries: [
        {
          username: string, # Optional. The user name to log into the registry server.
          password: string, # Optional. The password to log into the registry server.
          registryServer: string, # Optional. If omitted, the default is &quot;docker.io&quot;.
          identityReference: {
            resourceId: string, # Optional. The ARM resource id of the user assigned identity.
          }, # Optional. The reference to a user assigned identity associated with the Batch pool which
a compute node will use.
        }
      ], # Optional. If any Images must be downloaded from a private registry which requires
credentials, then those credentials must be provided here.
    }, # Optional. If specified, setup is performed on each Compute Node in the Pool to allow
Tasks to run in containers. All regular Tasks and Job manager Tasks run on this
Pool must specify the containerSettings property, and all other Tasks may
specify it.
    diskEncryptionConfiguration: {
      targets: [&quot;osdisk&quot; | &quot;temporarydisk&quot;], # Optional. If omitted, no disks on the compute nodes in the pool will be encrypted. On
Linux pool, only &quot;TemporaryDisk&quot; is supported; on Windows pool, &quot;OsDisk&quot;
and &quot;TemporaryDisk&quot; must be specified.
    }, # Optional. If specified, encryption is performed on each node in the pool during node
provisioning.
    nodePlacementConfiguration: {
      policy: &quot;regional&quot; | &quot;zonal&quot;, # Optional. Allocation policy used by Batch Service to provision the nodes. If not
specified, Batch will use the regional policy.
    }, # Optional. This configuration will specify rules on how nodes in the pool will be
physically allocated.
    extensions: [VMExtension], # Optional. If specified, the extensions mentioned in this configuration will be installed
on each node.
    osDisk: {
      ephemeralOSDiskSettings: {
        placement: &quot;cachedisk&quot;, # Optional. This property can be used by user in the request to choose the location e.g.,
cache disk space for Ephemeral OS disk provisioning. For more information on
Ephemeral OS disk size requirements, please refer to Ephemeral OS disk size
requirements for Windows VMs at
https://docs.microsoft.com/en-us/azure/virtual-machines/windows/ephemeral-os-disks#size-requirements
and Linux VMs at
https://docs.microsoft.com/en-us/azure/virtual-machines/linux/ephemeral-os-disks#size-requirements.
      }, # Optional. Specifies the ephemeral Disk Settings for the operating system disk used by the
compute node (VM).
    }, # Optional. Settings for the operating system disk of the compute node (VM).
  }, # Optional. This property and cloudServiceConfiguration are mutually exclusive and one of
the properties must be specified.
  resizeTimeout: string (duration ISO 8601 Format), # Optional. This is the timeout for the most recent resize operation. (The initial sizing
when the Pool is created counts as a resize.) The default value is 15 minutes.
  resizeErrors: [
    {
      code: string, # Optional. An identifier for the Pool resize error. Codes are invariant and are intended
to be consumed programmatically.
      message: string, # Optional. A message describing the Pool resize error, intended to be suitable for display
in a user interface.
      values: [NameValuePair], # Optional. A list of additional error details related to the Pool resize error.
    }
  ], # Optional. This property is set only if one or more errors occurred during the last Pool
resize, and only when the Pool allocationState is Steady.
  currentDedicatedNodes: number, # Optional. The number of dedicated Compute Nodes currently in the Pool.
  currentLowPriorityNodes: number, # Optional. Spot/Low-priority Compute Nodes which have been preempted are included in this
count.
  targetDedicatedNodes: number, # Optional. The desired number of dedicated Compute Nodes in the Pool.
  targetLowPriorityNodes: number, # Optional. The desired number of Spot/Low-priority Compute Nodes in the Pool.
  enableAutoScale: boolean, # Optional. If false, at least one of targetDedicatedNodes and targetLowPriorityNodes must
be specified. If true, the autoScaleFormula property is required and the Pool
automatically resizes according to the formula. The default value is false.
  autoScaleFormula: string, # Optional. This property is set only if the Pool automatically scales, i.e.
enableAutoScale is true.
  autoScaleEvaluationInterval: string (duration ISO 8601 Format), # Optional. This property is set only if the Pool automatically scales, i.e.
enableAutoScale is true.
  autoScaleRun: {
    timestamp: string (date &amp; time), # Required. The time at which the autoscale formula was last evaluated.
    results: string, # Optional. Each variable value is returned in the form $variable=value, and variables are
separated by semicolons.
    error: {
      code: string, # Optional. An identifier for the autoscale error. Codes are invariant and are intended to
be consumed programmatically.
      message: string, # Optional. A message describing the autoscale error, intended to be suitable for display
in a user interface.
      values: [NameValuePair], # Optional. A list of additional error details related to the autoscale error.
    }, # Optional. An error that occurred when executing or evaluating a Pool autoscale formula.
  }, # Optional. This property is set only if the Pool automatically scales, i.e.
enableAutoScale is true.
  enableInterNodeCommunication: boolean, # Optional. This imposes restrictions on which Compute Nodes can be assigned to the Pool.
Specifying this value can reduce the chance of the requested number of Compute
Nodes to be allocated in the Pool.
  networkConfiguration: {
    subnetId: string, # Optional. The virtual network must be in the same region and subscription as the Azure
Batch Account. The specified subnet should have enough free IP addresses to
accommodate the number of Compute Nodes in the Pool. If the subnet doesn&apos;t have
enough free IP addresses, the Pool will partially allocate Nodes and a resize
error will occur. The &apos;MicrosoftAzureBatch&apos; service principal must have the
&apos;Classic Virtual Machine Contributor&apos; Role-Based Access Control (RBAC) role for
the specified VNet. The specified subnet must allow communication from the
Azure Batch service to be able to schedule Tasks on the Nodes. This can be
verified by checking if the specified VNet has any associated Network Security
Groups (NSG). If communication to the Nodes in the specified subnet is denied
by an NSG, then the Batch service will set the state of the Compute Nodes to
unusable. For Pools created with virtualMachineConfiguration only ARM virtual
networks (&apos;Microsoft.Network/virtualNetworks&apos;) are supported, but for Pools
created with cloudServiceConfiguration both ARM and classic virtual networks
are supported. If the specified VNet has any associated Network Security Groups
(NSG), then a few reserved system ports must be enabled for inbound
communication. For Pools created with a virtual machine configuration, enable
ports 29876 and 29877, as well as port 22 for Linux and port 3389 for Windows.
For Pools created with a cloud service configuration, enable ports 10100,
20100, and 30100. Also enable outbound connections to Azure Storage on port
443. For more details see:
https://docs.microsoft.com/en-us/azure/batch/batch-api-basics#virtual-network-vnet-and-firewall-configuration
    dynamicVNetAssignmentScope: &quot;none&quot; | &quot;job&quot;, # Optional. The scope of dynamic vnet assignment.
    endpointConfiguration: {
      inboundNATPools: [InboundNATPool], # Required. The maximum number of inbound NAT Pools per Batch Pool is 5. If the maximum
number of inbound NAT Pools is exceeded the request fails with HTTP status code
400. This cannot be specified if the IPAddressProvisioningType is
NoPublicIPAddresses.
    }, # Optional. Pool endpoint configuration is only supported on Pools with the
virtualMachineConfiguration property.
    publicIPAddressConfiguration: {
      provision: &quot;batchmanaged&quot; | &quot;usermanaged&quot; | &quot;nopublicipaddresses&quot;, # Optional. The default value is BatchManaged.
      ipAddressIds: [string], # Optional. The number of IPs specified here limits the maximum size of the Pool - 100
dedicated nodes or 100 Spot/Low-priority nodes can be allocated for each public
IP. For example, a pool needing 250 dedicated VMs would need at least 3 public
IPs specified. Each element of this collection is of the form:
/subscriptions/{subscription}/resourceGroups/{group}/providers/Microsoft.Network/publicIPAddresses/{ip}.
    }, # Optional. Public IP configuration property is only supported on Pools with the
virtualMachineConfiguration property.
  }, # Optional. The network configuration for a Pool.
  startTask: {
    commandLine: string, # Required. The command line does not run under a shell, and therefore cannot take
advantage of shell features such as environment variable expansion. If you want
to take advantage of such features, you should invoke the shell in the command
line, for example using &quot;cmd /c MyCommand&quot; in Windows or &quot;/bin/sh -c
MyCommand&quot; in Linux. If the command line refers to file paths, it should use a
relative path (relative to the Task working directory), or use the Batch
provided environment variable
(https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).
    containerSettings: {
      containerRunOptions: string, # Optional. These additional options are supplied as arguments to the &quot;docker create&quot;
command, in addition to those controlled by the Batch Service.
      imageName: string, # Required. This is the full Image reference, as would be specified to &quot;docker pull&quot;. If
no tag is provided as part of the Image name, the tag &quot;:latest&quot; is used as a
default.
      registry: ContainerRegistry, # Optional. This setting can be omitted if was already provided at Pool creation.
      workingDirectory: &quot;taskWorkingDirectory&quot; | &quot;containerImageDefault&quot;, # Optional. The default is &apos;taskWorkingDirectory&apos;.
    }, # Optional. When this is specified, all directories recursively below the
AZ_BATCH_NODE_ROOT_DIR (the root of Azure Batch directories on the node) are
mapped into the container, all Task environment variables are mapped into the
container, and the Task command line is executed in the container. Files
produced in the container outside of AZ_BATCH_NODE_ROOT_DIR might not be
reflected to the host disk, meaning that Batch file APIs will not be able to
access those files.
    resourceFiles: [ResourceFile], # Optional. Files listed under this element are located in the Task&apos;s working directory.
    environmentSettings: [EnvironmentSetting], # Optional. A list of environment variable settings for the StartTask.
    userIdentity: {
      username: string, # Optional. The userName and autoUser properties are mutually exclusive; you must specify
one but not both.
      autoUser: {
        scope: &quot;task&quot; | &quot;pool&quot;, # Optional. The default value is pool. If the pool is running Windows a value of Task
should be specified if stricter isolation between tasks is required. For
example, if the task mutates the registry in a way which could impact other
tasks, or if certificates have been specified on the pool which should not be
accessible by normal tasks but should be accessible by StartTasks.
        elevationLevel: &quot;nonadmin&quot; | &quot;admin&quot;, # Optional. The default value is nonAdmin.
      }, # Optional. The userName and autoUser properties are mutually exclusive; you must specify
one but not both.
    }, # Optional. If omitted, the Task runs as a non-administrative user unique to the Task.
    maxTaskRetryCount: number, # Optional. The Batch service retries a Task if its exit code is nonzero. Note that this
value specifically controls the number of retries. The Batch service will try
the Task once, and may then retry up to this limit. For example, if the maximum
retry count is 3, Batch tries the Task up to 4 times (one initial try and 3
retries). If the maximum retry count is 0, the Batch service does not retry the
Task. If the maximum retry count is -1, the Batch service retries the Task
without limit, however this is not recommended for a start task or any task.
The default value is 0 (no retries)
    waitForSuccess: boolean, # Optional. If true and the StartTask fails on a Node, the Batch service retries the
StartTask up to its maximum retry count (maxTaskRetryCount). If the Task has
still not completed successfully after all retries, then the Batch service
marks the Node unusable, and will not schedule Tasks to it. This condition can
be detected via the Compute Node state and failure info details. If false, the
Batch service will not wait for the StartTask to complete. In this case, other
Tasks can start executing on the Compute Node while the StartTask is still
running; and even if the StartTask fails, new Tasks will continue to be
scheduled on the Compute Node. The default is true.
  }, # Optional. Batch will retry Tasks when a recovery operation is triggered on a Node.
Examples of recovery operations include (but are not limited to) when an
unhealthy Node is rebooted or a Compute Node disappeared due to host failure.
Retries due to recovery operations are independent of and are not counted
against the maxTaskRetryCount. Even if the maxTaskRetryCount is 0, an internal
retry due to a recovery operation may occur. Because of this, all Tasks should
be idempotent. This means Tasks need to tolerate being interrupted and
restarted without causing any corruption or duplicate data. The best practice
for long running Tasks is to use some form of checkpointing. In some cases the
StartTask may be re-run even though the Compute Node was not rebooted. Special
care should be taken to avoid StartTasks which create breakaway process or
install/launch services from the StartTask working directory, as this will
block Batch from being able to re-run the StartTask.
  certificateReferences: [CertificateReference], # Optional. For Windows Nodes, the Batch service installs the Certificates to the specified
Certificate store and location. For Linux Compute Nodes, the Certificates are
stored in a directory inside the Task working directory and an environment
variable AZ_BATCH_CERTIFICATES_DIR is supplied to the Task to query for this
location. For Certificates with visibility of &apos;remoteUser&apos;, a &apos;certs&apos; directory
is created in the user&apos;s home directory (e.g., /home/{user-name}/certs) and
Certificates are placed in that directory.
  applicationPackageReferences: [ApplicationPackageReference], # Optional. Changes to Package references affect all new Nodes joining the Pool, but do not
affect Compute Nodes that are already in the Pool until they are rebooted or
reimaged. There is a maximum of 10 Package references on any given Pool.
  applicationLicenses: [string], # Optional. The list of application licenses must be a subset of available Batch service
application licenses. If a license is requested which is not supported, Pool
creation will fail.
  taskSlotsPerNode: number, # Optional. The default value is 1. The maximum value is the smaller of 4 times the number
of cores of the vmSize of the pool or 256.
  taskSchedulingPolicy: {
    nodeFillType: &quot;spread&quot; | &quot;pack&quot;, # Required. If not specified, the default is spread.
  }, # Optional. If not specified, the default is spread.
  userAccounts: [UserAccount], # Optional. The list of user Accounts to be created on each Compute Node in the Pool.
  metadata: [MetadataItem], # Optional. A list of name-value pairs associated with the Pool as metadata.
  stats: {
    url: string, # Required. The URL for the statistics.
    startTime: string (date &amp; time), # Required. The start time of the time range covered by the statistics.
    lastUpdateTime: string (date &amp; time), # Required. The time at which the statistics were last updated. All statistics are limited
to the range between startTime and lastUpdateTime.
    usageStats: {
      startTime: string (date &amp; time), # Required. The start time of the time range covered by the statistics.
      lastUpdateTime: string (date &amp; time), # Required. The time at which the statistics were last updated. All statistics are limited
to the range between startTime and lastUpdateTime.
      dedicatedCoreTime: string (duration ISO 8601 Format), # Required. The aggregated wall-clock time of the dedicated Compute Node cores being part
of the Pool.
    }, # Optional. Statistics related to Pool usage information.
    resourceStats: {
      startTime: string (date &amp; time), # Required. The start time of the time range covered by the statistics.
      lastUpdateTime: string (date &amp; time), # Required. The time at which the statistics were last updated. All statistics are limited
to the range between startTime and lastUpdateTime.
      avgCPUPercentage: number, # Required. The average CPU usage across all Compute Nodes in the Pool (percentage per
node).
      avgMemoryGiB: number, # Required. The average memory usage in GiB across all Compute Nodes in the Pool.
      peakMemoryGiB: number, # Required. The peak memory usage in GiB across all Compute Nodes in the Pool.
      avgDiskGiB: number, # Required. The average used disk space in GiB across all Compute Nodes in the Pool.
      peakDiskGiB: number, # Required. The peak used disk space in GiB across all Compute Nodes in the Pool.
      diskReadIOps: number, # Required. The total number of disk read operations across all Compute Nodes in the Pool.
      diskWriteIOps: number, # Required. The total number of disk write operations across all Compute Nodes in the Pool.
      diskReadGiB: number, # Required. The total amount of data in GiB of disk reads across all Compute Nodes in the
Pool.
      diskWriteGiB: number, # Required. The total amount of data in GiB of disk writes across all Compute Nodes in the
Pool.
      networkReadGiB: number, # Required. The total amount of data in GiB of network reads across all Compute Nodes in
the Pool.
      networkWriteGiB: number, # Required. The total amount of data in GiB of network writes across all Compute Nodes in
the Pool.
    }, # Optional. Statistics related to resource consumption by Compute Nodes in a Pool.
  }, # Optional. This property is populated only if the CloudPool was retrieved with an expand
clause including the &apos;stats&apos; attribute; otherwise it is null. The statistics
may not be immediately available. The Batch service performs periodic roll-up
of statistics. The typical delay is about 30 minutes.
  mountConfiguration: [MountConfiguration], # Optional. This supports Azure Files, NFS, CIFS/SMB, and Blobfuse.
  identity: {
    type: &quot;UserAssigned&quot; | &quot;None&quot;, # Required. The list of user identities associated with the Batch pool. The user identity
dictionary key references will be ARM resource ids in the form:
&apos;/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.ManagedIdentity/userAssignedIdentities/{identityName}&apos;.
    userAssignedIdentities: [UserAssignedIdentity], # Optional. The user identity dictionary key references will be ARM resource ids in the
form:
&apos;/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.ManagedIdentity/userAssignedIdentities/{identityName}&apos;.
  }, # Optional. The list of user identities associated with the Batch pool. The user identity
dictionary key references will be ARM resource ids in the form:
&apos;/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.ManagedIdentity/userAssignedIdentities/{identityName}&apos;.
  targetNodeCommunicationMode: &quot;default&quot; | &quot;classic&quot; | &quot;simplified&quot;, # Optional. If omitted, the default value is Default.
  currentNodeCommunicationMode: &quot;default&quot; | &quot;classic&quot; | &quot;simplified&quot;, # Optional. Determines how a pool communicates with the Batch service.
}
</code>

</remarks>
    </member>
    <member name="GetPoolsAsync(Int32,String,Int32,String,Boolean,String,String,String,RequestContext)">
<example>
This sample shows how to call GetPoolsAsync and parse the result.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetPoolClient(<2022-10-01.16.0>);

Response response = await client.GetPoolsAsync();

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.ToString());
]]></code>
This sample shows how to call GetPoolsAsync with all parameters, and how to parse the result.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetPoolClient(<2022-10-01.16.0>);

Response response = await client.GetPoolsAsync(1234, "<ocpDate>", 1234, "<clientRequestId>", true, "<filter>", "<select>", "<expand>");

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.GetProperty("value")[0].GetProperty("id").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("displayName").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("url").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("eTag").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("lastModified").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("creationTime").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("state").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("stateTransitionTime").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("allocationState").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("allocationStateTransitionTime").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("vmSize").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("cloudServiceConfiguration").GetProperty("osFamily").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("cloudServiceConfiguration").GetProperty("osVersion").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("virtualMachineConfiguration").GetProperty("imageReference").GetProperty("publisher").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("virtualMachineConfiguration").GetProperty("imageReference").GetProperty("offer").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("virtualMachineConfiguration").GetProperty("imageReference").GetProperty("sku").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("virtualMachineConfiguration").GetProperty("imageReference").GetProperty("version").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("virtualMachineConfiguration").GetProperty("imageReference").GetProperty("virtualMachineImageId").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("virtualMachineConfiguration").GetProperty("imageReference").GetProperty("exactVersion").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("virtualMachineConfiguration").GetProperty("nodeAgentSKUId").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("virtualMachineConfiguration").GetProperty("windowsConfiguration").GetProperty("enableAutomaticUpdates").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("virtualMachineConfiguration").GetProperty("dataDisks")[0].GetProperty("lun").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("virtualMachineConfiguration").GetProperty("dataDisks")[0].GetProperty("caching").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("virtualMachineConfiguration").GetProperty("dataDisks")[0].GetProperty("diskSizeGB").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("virtualMachineConfiguration").GetProperty("dataDisks")[0].GetProperty("storageAccountType").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("virtualMachineConfiguration").GetProperty("licenseType").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("virtualMachineConfiguration").GetProperty("containerConfiguration").GetProperty("type").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("virtualMachineConfiguration").GetProperty("containerConfiguration").GetProperty("containerImageNames")[0].ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("virtualMachineConfiguration").GetProperty("containerConfiguration").GetProperty("containerRegistries")[0].GetProperty("username").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("virtualMachineConfiguration").GetProperty("containerConfiguration").GetProperty("containerRegistries")[0].GetProperty("password").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("virtualMachineConfiguration").GetProperty("containerConfiguration").GetProperty("containerRegistries")[0].GetProperty("registryServer").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("virtualMachineConfiguration").GetProperty("containerConfiguration").GetProperty("containerRegistries")[0].GetProperty("identityReference").GetProperty("resourceId").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("virtualMachineConfiguration").GetProperty("diskEncryptionConfiguration").GetProperty("targets")[0].ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("virtualMachineConfiguration").GetProperty("nodePlacementConfiguration").GetProperty("policy").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("virtualMachineConfiguration").GetProperty("extensions")[0].GetProperty("name").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("virtualMachineConfiguration").GetProperty("extensions")[0].GetProperty("publisher").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("virtualMachineConfiguration").GetProperty("extensions")[0].GetProperty("type").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("virtualMachineConfiguration").GetProperty("extensions")[0].GetProperty("typeHandlerVersion").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("virtualMachineConfiguration").GetProperty("extensions")[0].GetProperty("autoUpgradeMinorVersion").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("virtualMachineConfiguration").GetProperty("extensions")[0].GetProperty("provisionAfterExtensions")[0].ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("virtualMachineConfiguration").GetProperty("osDisk").GetProperty("ephemeralOSDiskSettings").GetProperty("placement").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("resizeTimeout").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("resizeErrors")[0].GetProperty("code").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("resizeErrors")[0].GetProperty("message").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("resizeErrors")[0].GetProperty("values")[0].GetProperty("name").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("resizeErrors")[0].GetProperty("values")[0].GetProperty("value").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("currentDedicatedNodes").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("currentLowPriorityNodes").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("targetDedicatedNodes").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("targetLowPriorityNodes").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("enableAutoScale").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("autoScaleFormula").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("autoScaleEvaluationInterval").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("autoScaleRun").GetProperty("timestamp").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("autoScaleRun").GetProperty("results").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("autoScaleRun").GetProperty("error").GetProperty("code").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("autoScaleRun").GetProperty("error").GetProperty("message").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("autoScaleRun").GetProperty("error").GetProperty("values")[0].GetProperty("name").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("autoScaleRun").GetProperty("error").GetProperty("values")[0].GetProperty("value").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("enableInterNodeCommunication").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("networkConfiguration").GetProperty("subnetId").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("networkConfiguration").GetProperty("dynamicVNetAssignmentScope").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("networkConfiguration").GetProperty("endpointConfiguration").GetProperty("inboundNATPools")[0].GetProperty("name").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("networkConfiguration").GetProperty("endpointConfiguration").GetProperty("inboundNATPools")[0].GetProperty("protocol").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("networkConfiguration").GetProperty("endpointConfiguration").GetProperty("inboundNATPools")[0].GetProperty("backendPort").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("networkConfiguration").GetProperty("endpointConfiguration").GetProperty("inboundNATPools")[0].GetProperty("frontendPortRangeStart").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("networkConfiguration").GetProperty("endpointConfiguration").GetProperty("inboundNATPools")[0].GetProperty("frontendPortRangeEnd").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("networkConfiguration").GetProperty("endpointConfiguration").GetProperty("inboundNATPools")[0].GetProperty("networkSecurityGroupRules")[0].GetProperty("priority").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("networkConfiguration").GetProperty("endpointConfiguration").GetProperty("inboundNATPools")[0].GetProperty("networkSecurityGroupRules")[0].GetProperty("access").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("networkConfiguration").GetProperty("endpointConfiguration").GetProperty("inboundNATPools")[0].GetProperty("networkSecurityGroupRules")[0].GetProperty("sourceAddressPrefix").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("networkConfiguration").GetProperty("endpointConfiguration").GetProperty("inboundNATPools")[0].GetProperty("networkSecurityGroupRules")[0].GetProperty("sourcePortRanges")[0].ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("networkConfiguration").GetProperty("publicIPAddressConfiguration").GetProperty("provision").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("networkConfiguration").GetProperty("publicIPAddressConfiguration").GetProperty("ipAddressIds")[0].ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("startTask").GetProperty("commandLine").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("startTask").GetProperty("containerSettings").GetProperty("containerRunOptions").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("startTask").GetProperty("containerSettings").GetProperty("imageName").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("startTask").GetProperty("containerSettings").GetProperty("registry").GetProperty("username").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("startTask").GetProperty("containerSettings").GetProperty("registry").GetProperty("password").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("startTask").GetProperty("containerSettings").GetProperty("registry").GetProperty("registryServer").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("startTask").GetProperty("containerSettings").GetProperty("registry").GetProperty("identityReference").GetProperty("resourceId").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("startTask").GetProperty("containerSettings").GetProperty("workingDirectory").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("startTask").GetProperty("resourceFiles")[0].GetProperty("autoStorageContainerName").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("startTask").GetProperty("resourceFiles")[0].GetProperty("storageContainerUrl").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("startTask").GetProperty("resourceFiles")[0].GetProperty("httpUrl").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("startTask").GetProperty("resourceFiles")[0].GetProperty("blobPrefix").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("startTask").GetProperty("resourceFiles")[0].GetProperty("filePath").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("startTask").GetProperty("resourceFiles")[0].GetProperty("fileMode").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("startTask").GetProperty("resourceFiles")[0].GetProperty("identityReference").GetProperty("resourceId").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("startTask").GetProperty("environmentSettings")[0].GetProperty("name").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("startTask").GetProperty("environmentSettings")[0].GetProperty("value").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("startTask").GetProperty("userIdentity").GetProperty("username").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("startTask").GetProperty("userIdentity").GetProperty("autoUser").GetProperty("scope").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("startTask").GetProperty("userIdentity").GetProperty("autoUser").GetProperty("elevationLevel").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("startTask").GetProperty("maxTaskRetryCount").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("startTask").GetProperty("waitForSuccess").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("certificateReferences")[0].GetProperty("thumbprint").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("certificateReferences")[0].GetProperty("thumbprintAlgorithm").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("certificateReferences")[0].GetProperty("storeLocation").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("certificateReferences")[0].GetProperty("storeName").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("certificateReferences")[0].GetProperty("visibility")[0].ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("applicationPackageReferences")[0].GetProperty("applicationId").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("applicationPackageReferences")[0].GetProperty("version").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("applicationLicenses")[0].ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("taskSlotsPerNode").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("taskSchedulingPolicy").GetProperty("nodeFillType").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("userAccounts")[0].GetProperty("name").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("userAccounts")[0].GetProperty("password").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("userAccounts")[0].GetProperty("elevationLevel").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("userAccounts")[0].GetProperty("linuxUserConfiguration").GetProperty("uid").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("userAccounts")[0].GetProperty("linuxUserConfiguration").GetProperty("gid").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("userAccounts")[0].GetProperty("linuxUserConfiguration").GetProperty("sshPrivateKey").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("userAccounts")[0].GetProperty("windowsUserConfiguration").GetProperty("loginMode").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("metadata")[0].GetProperty("name").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("metadata")[0].GetProperty("value").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("stats").GetProperty("url").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("stats").GetProperty("startTime").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("stats").GetProperty("lastUpdateTime").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("stats").GetProperty("usageStats").GetProperty("startTime").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("stats").GetProperty("usageStats").GetProperty("lastUpdateTime").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("stats").GetProperty("usageStats").GetProperty("dedicatedCoreTime").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("stats").GetProperty("resourceStats").GetProperty("startTime").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("stats").GetProperty("resourceStats").GetProperty("lastUpdateTime").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("stats").GetProperty("resourceStats").GetProperty("avgCPUPercentage").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("stats").GetProperty("resourceStats").GetProperty("avgMemoryGiB").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("stats").GetProperty("resourceStats").GetProperty("peakMemoryGiB").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("stats").GetProperty("resourceStats").GetProperty("avgDiskGiB").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("stats").GetProperty("resourceStats").GetProperty("peakDiskGiB").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("stats").GetProperty("resourceStats").GetProperty("diskReadIOps").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("stats").GetProperty("resourceStats").GetProperty("diskWriteIOps").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("stats").GetProperty("resourceStats").GetProperty("diskReadGiB").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("stats").GetProperty("resourceStats").GetProperty("diskWriteGiB").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("stats").GetProperty("resourceStats").GetProperty("networkReadGiB").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("stats").GetProperty("resourceStats").GetProperty("networkWriteGiB").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("mountConfiguration")[0].GetProperty("azureBlobFileSystemConfiguration").GetProperty("accountName").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("mountConfiguration")[0].GetProperty("azureBlobFileSystemConfiguration").GetProperty("containerName").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("mountConfiguration")[0].GetProperty("azureBlobFileSystemConfiguration").GetProperty("accountKey").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("mountConfiguration")[0].GetProperty("azureBlobFileSystemConfiguration").GetProperty("sasKey").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("mountConfiguration")[0].GetProperty("azureBlobFileSystemConfiguration").GetProperty("blobfuseOptions").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("mountConfiguration")[0].GetProperty("azureBlobFileSystemConfiguration").GetProperty("relativeMountPath").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("mountConfiguration")[0].GetProperty("azureBlobFileSystemConfiguration").GetProperty("identityReference").GetProperty("resourceId").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("mountConfiguration")[0].GetProperty("nfsMountConfiguration").GetProperty("source").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("mountConfiguration")[0].GetProperty("nfsMountConfiguration").GetProperty("relativeMountPath").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("mountConfiguration")[0].GetProperty("nfsMountConfiguration").GetProperty("mountOptions").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("mountConfiguration")[0].GetProperty("cifsMountConfiguration").GetProperty("username").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("mountConfiguration")[0].GetProperty("cifsMountConfiguration").GetProperty("source").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("mountConfiguration")[0].GetProperty("cifsMountConfiguration").GetProperty("relativeMountPath").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("mountConfiguration")[0].GetProperty("cifsMountConfiguration").GetProperty("mountOptions").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("mountConfiguration")[0].GetProperty("cifsMountConfiguration").GetProperty("password").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("mountConfiguration")[0].GetProperty("azureFileShareConfiguration").GetProperty("accountName").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("mountConfiguration")[0].GetProperty("azureFileShareConfiguration").GetProperty("azureFileUrl").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("mountConfiguration")[0].GetProperty("azureFileShareConfiguration").GetProperty("accountKey").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("mountConfiguration")[0].GetProperty("azureFileShareConfiguration").GetProperty("relativeMountPath").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("mountConfiguration")[0].GetProperty("azureFileShareConfiguration").GetProperty("mountOptions").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("identity").GetProperty("type").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("identity").GetProperty("userAssignedIdentities")[0].GetProperty("resourceId").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("identity").GetProperty("userAssignedIdentities")[0].GetProperty("clientId").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("identity").GetProperty("userAssignedIdentities")[0].GetProperty("principalId").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("targetNodeCommunicationMode").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("currentNodeCommunicationMode").ToString());
Console.WriteLine(result.GetProperty("odata.nextLink").ToString());
]]></code>
</example>
<remarks>
Below is the JSON schema for the response payload.

Response Body:

Schema for <c>BatchPoolListResult</c>:
<code>{
  value: [
    {
      id: string, # Optional. The ID can contain any combination of alphanumeric characters including hyphens
and underscores, and cannot contain more than 64 characters. The ID is
case-preserving and case-insensitive (that is, you may not have two IDs within
an Account that differ only by case).
      displayName: string, # Optional. The display name need not be unique and can contain any Unicode characters up
to a maximum length of 1024.
      url: string, # Optional. The URL of the Pool.
      eTag: string, # Optional. This is an opaque string. You can use it to detect whether the Pool has changed
between requests. In particular, you can be pass the ETag when updating a Pool
to specify that your changes should take effect only if nobody else has
modified the Pool in the meantime.
      lastModified: string (date &amp; time), # Optional. This is the last time at which the Pool level data, such as the
targetDedicatedNodes or enableAutoscale settings, changed. It does not factor
in node-level changes such as a Compute Node changing state.
      creationTime: string (date &amp; time), # Optional. The creation time of the Pool.
      state: &quot;active&quot; | &quot;deleting&quot;, # Optional. The current state of the Pool.
      stateTransitionTime: string (date &amp; time), # Optional. The time at which the Pool entered its current state.
      allocationState: &quot;steady&quot; | &quot;resizing&quot; | &quot;stopping&quot;, # Optional. Whether the Pool is resizing.
      allocationStateTransitionTime: string (date &amp; time), # Optional. The time at which the Pool entered its current allocation state.
      vmSize: string, # Optional. For information about available sizes of virtual machines in Pools, see Choose
a VM size for Compute Nodes in an Azure Batch Pool
(https://docs.microsoft.com/azure/batch/batch-pool-vm-sizes).
      cloudServiceConfiguration: {
        osFamily: string, # Required. Possible values are:
2 - OS Family 2, equivalent to Windows Server 2008 R2
SP1.
3 - OS Family 3, equivalent to Windows Server 2012.
4 - OS Family 4,
equivalent to Windows Server 2012 R2.
5 - OS Family 5, equivalent to Windows
Server 2016.
6 - OS Family 6, equivalent to Windows Server 2019. For more
information, see Azure Guest OS Releases
(https://azure.microsoft.com/documentation/articles/cloud-services-guestos-update-matrix/#releases).
        osVersion: string, # Optional. The default value is * which specifies the latest operating system version for
the specified OS family.
      }, # Optional. This property and virtualMachineConfiguration are mutually exclusive and one of
the properties must be specified. This property cannot be specified if the
Batch Account was created with its poolAllocationMode property set to
&apos;UserSubscription&apos;.
      virtualMachineConfiguration: {
        imageReference: {
          publisher: string, # Optional. For example, Canonical or MicrosoftWindowsServer.
          offer: string, # Optional. For example, UbuntuServer or WindowsServer.
          sku: string, # Optional. For example, 18.04-LTS or 2019-Datacenter.
          version: string, # Optional. A value of &apos;latest&apos; can be specified to select the latest version of an Image.
If omitted, the default is &apos;latest&apos;.
          virtualMachineImageId: string, # Optional. This property is mutually exclusive with other ImageReference properties. The
Shared Image Gallery Image must have replicas in the same region and must be in
the same subscription as the Azure Batch account. If the image version is not
specified in the imageId, the latest version will be used. For information
about the firewall settings for the Batch Compute Node agent to communicate
with the Batch service see
https://docs.microsoft.com/en-us/azure/batch/batch-api-basics#virtual-network-vnet-and-firewall-configuration.
          exactVersion: string, # Optional. The specific version of the platform image or marketplace image used to create
the node. This read-only field differs from &apos;version&apos; only if the value
specified for &apos;version&apos; when the pool was created was &apos;latest&apos;.
        }, # Required. A reference to an Azure Virtual Machines Marketplace Image or a Shared Image
Gallery Image. To get the list of all Azure Marketplace Image references
verified by Azure Batch, see the &apos;List Supported Images&apos; operation.
        nodeAgentSKUId: string, # Required. The Batch Compute Node agent is a program that runs on each Compute Node in the
Pool, and provides the command-and-control interface between the Compute Node
and the Batch service. There are different implementations of the Compute Node
agent, known as SKUs, for different operating systems. You must specify a
Compute Node agent SKU which matches the selected Image reference. To get the
list of supported Compute Node agent SKUs along with their list of verified
Image references, see the &apos;List supported Compute Node agent SKUs&apos; operation.
        windowsConfiguration: {
          enableAutomaticUpdates: boolean, # Optional. If omitted, the default value is true.
        }, # Optional. This property must not be specified if the imageReference property specifies a
Linux OS Image.
        dataDisks: [DataDisk], # Optional. This property must be specified if the Compute Nodes in the Pool need to have
empty data disks attached to them. This cannot be updated. Each Compute Node
gets its own disk (the disk is not a file share). Existing disks cannot be
attached, each attached disk is empty. When the Compute Node is removed from
the Pool, the disk and all data associated with it is also deleted. The disk is
not formatted after being attached, it must be formatted before use - for more
information see
https://docs.microsoft.com/en-us/azure/virtual-machines/linux/classic/attach-disk#initialize-a-new-data-disk-in-linux
and
https://docs.microsoft.com/en-us/azure/virtual-machines/windows/attach-disk-ps#add-an-empty-data-disk-to-a-virtual-machine.
        licenseType: string, # Optional. This only applies to Images that contain the Windows operating system, and
should only be used when you hold valid on-premises licenses for the Compute
Nodes which will be deployed. If omitted, no on-premises licensing discount is
applied. Values are:

 Windows_Server - The on-premises license is for Windows
Server.
 Windows_Client - The on-premises license is for Windows Client.

        containerConfiguration: {
          type: &quot;dockerCompatible&quot;, # Required. The container technology to be used.
          containerImageNames: [string], # Optional. This is the full Image reference, as would be specified to &quot;docker pull&quot;. An
Image will be sourced from the default Docker registry unless the Image is
fully qualified with an alternative registry.
          containerRegistries: [
            {
              username: string, # Optional. The user name to log into the registry server.
              password: string, # Optional. The password to log into the registry server.
              registryServer: string, # Optional. If omitted, the default is &quot;docker.io&quot;.
              identityReference: {
                resourceId: string, # Optional. The ARM resource id of the user assigned identity.
              }, # Optional. The reference to a user assigned identity associated with the Batch pool which
a compute node will use.
            }
          ], # Optional. If any Images must be downloaded from a private registry which requires
credentials, then those credentials must be provided here.
        }, # Optional. If specified, setup is performed on each Compute Node in the Pool to allow
Tasks to run in containers. All regular Tasks and Job manager Tasks run on this
Pool must specify the containerSettings property, and all other Tasks may
specify it.
        diskEncryptionConfiguration: {
          targets: [&quot;osdisk&quot; | &quot;temporarydisk&quot;], # Optional. If omitted, no disks on the compute nodes in the pool will be encrypted. On
Linux pool, only &quot;TemporaryDisk&quot; is supported; on Windows pool, &quot;OsDisk&quot;
and &quot;TemporaryDisk&quot; must be specified.
        }, # Optional. If specified, encryption is performed on each node in the pool during node
provisioning.
        nodePlacementConfiguration: {
          policy: &quot;regional&quot; | &quot;zonal&quot;, # Optional. Allocation policy used by Batch Service to provision the nodes. If not
specified, Batch will use the regional policy.
        }, # Optional. This configuration will specify rules on how nodes in the pool will be
physically allocated.
        extensions: [VMExtension], # Optional. If specified, the extensions mentioned in this configuration will be installed
on each node.
        osDisk: {
          ephemeralOSDiskSettings: {
            placement: &quot;cachedisk&quot;, # Optional. This property can be used by user in the request to choose the location e.g.,
cache disk space for Ephemeral OS disk provisioning. For more information on
Ephemeral OS disk size requirements, please refer to Ephemeral OS disk size
requirements for Windows VMs at
https://docs.microsoft.com/en-us/azure/virtual-machines/windows/ephemeral-os-disks#size-requirements
and Linux VMs at
https://docs.microsoft.com/en-us/azure/virtual-machines/linux/ephemeral-os-disks#size-requirements.
          }, # Optional. Specifies the ephemeral Disk Settings for the operating system disk used by the
compute node (VM).
        }, # Optional. Settings for the operating system disk of the compute node (VM).
      }, # Optional. This property and cloudServiceConfiguration are mutually exclusive and one of
the properties must be specified.
      resizeTimeout: string (duration ISO 8601 Format), # Optional. This is the timeout for the most recent resize operation. (The initial sizing
when the Pool is created counts as a resize.) The default value is 15 minutes.
      resizeErrors: [ResizeError], # Optional. This property is set only if one or more errors occurred during the last Pool
resize, and only when the Pool allocationState is Steady.
      currentDedicatedNodes: number, # Optional. The number of dedicated Compute Nodes currently in the Pool.
      currentLowPriorityNodes: number, # Optional. Spot/Low-priority Compute Nodes which have been preempted are included in this
count.
      targetDedicatedNodes: number, # Optional. The desired number of dedicated Compute Nodes in the Pool.
      targetLowPriorityNodes: number, # Optional. The desired number of Spot/Low-priority Compute Nodes in the Pool.
      enableAutoScale: boolean, # Optional. If false, at least one of targetDedicatedNodes and targetLowPriorityNodes must
be specified. If true, the autoScaleFormula property is required and the Pool
automatically resizes according to the formula. The default value is false.
      autoScaleFormula: string, # Optional. This property is set only if the Pool automatically scales, i.e.
enableAutoScale is true.
      autoScaleEvaluationInterval: string (duration ISO 8601 Format), # Optional. This property is set only if the Pool automatically scales, i.e.
enableAutoScale is true.
      autoScaleRun: {
        timestamp: string (date &amp; time), # Required. The time at which the autoscale formula was last evaluated.
        results: string, # Optional. Each variable value is returned in the form $variable=value, and variables are
separated by semicolons.
        error: {
          code: string, # Optional. An identifier for the autoscale error. Codes are invariant and are intended to
be consumed programmatically.
          message: string, # Optional. A message describing the autoscale error, intended to be suitable for display
in a user interface.
          values: [NameValuePair], # Optional. A list of additional error details related to the autoscale error.
        }, # Optional. An error that occurred when executing or evaluating a Pool autoscale formula.
      }, # Optional. This property is set only if the Pool automatically scales, i.e.
enableAutoScale is true.
      enableInterNodeCommunication: boolean, # Optional. This imposes restrictions on which Compute Nodes can be assigned to the Pool.
Specifying this value can reduce the chance of the requested number of Compute
Nodes to be allocated in the Pool.
      networkConfiguration: {
        subnetId: string, # Optional. The virtual network must be in the same region and subscription as the Azure
Batch Account. The specified subnet should have enough free IP addresses to
accommodate the number of Compute Nodes in the Pool. If the subnet doesn&apos;t have
enough free IP addresses, the Pool will partially allocate Nodes and a resize
error will occur. The &apos;MicrosoftAzureBatch&apos; service principal must have the
&apos;Classic Virtual Machine Contributor&apos; Role-Based Access Control (RBAC) role for
the specified VNet. The specified subnet must allow communication from the
Azure Batch service to be able to schedule Tasks on the Nodes. This can be
verified by checking if the specified VNet has any associated Network Security
Groups (NSG). If communication to the Nodes in the specified subnet is denied
by an NSG, then the Batch service will set the state of the Compute Nodes to
unusable. For Pools created with virtualMachineConfiguration only ARM virtual
networks (&apos;Microsoft.Network/virtualNetworks&apos;) are supported, but for Pools
created with cloudServiceConfiguration both ARM and classic virtual networks
are supported. If the specified VNet has any associated Network Security Groups
(NSG), then a few reserved system ports must be enabled for inbound
communication. For Pools created with a virtual machine configuration, enable
ports 29876 and 29877, as well as port 22 for Linux and port 3389 for Windows.
For Pools created with a cloud service configuration, enable ports 10100,
20100, and 30100. Also enable outbound connections to Azure Storage on port
443. For more details see:
https://docs.microsoft.com/en-us/azure/batch/batch-api-basics#virtual-network-vnet-and-firewall-configuration
        dynamicVNetAssignmentScope: &quot;none&quot; | &quot;job&quot;, # Optional. The scope of dynamic vnet assignment.
        endpointConfiguration: {
          inboundNATPools: [InboundNATPool], # Required. The maximum number of inbound NAT Pools per Batch Pool is 5. If the maximum
number of inbound NAT Pools is exceeded the request fails with HTTP status code
400. This cannot be specified if the IPAddressProvisioningType is
NoPublicIPAddresses.
        }, # Optional. Pool endpoint configuration is only supported on Pools with the
virtualMachineConfiguration property.
        publicIPAddressConfiguration: {
          provision: &quot;batchmanaged&quot; | &quot;usermanaged&quot; | &quot;nopublicipaddresses&quot;, # Optional. The default value is BatchManaged.
          ipAddressIds: [string], # Optional. The number of IPs specified here limits the maximum size of the Pool - 100
dedicated nodes or 100 Spot/Low-priority nodes can be allocated for each public
IP. For example, a pool needing 250 dedicated VMs would need at least 3 public
IPs specified. Each element of this collection is of the form:
/subscriptions/{subscription}/resourceGroups/{group}/providers/Microsoft.Network/publicIPAddresses/{ip}.
        }, # Optional. Public IP configuration property is only supported on Pools with the
virtualMachineConfiguration property.
      }, # Optional. The network configuration for a Pool.
      startTask: {
        commandLine: string, # Required. The command line does not run under a shell, and therefore cannot take
advantage of shell features such as environment variable expansion. If you want
to take advantage of such features, you should invoke the shell in the command
line, for example using &quot;cmd /c MyCommand&quot; in Windows or &quot;/bin/sh -c
MyCommand&quot; in Linux. If the command line refers to file paths, it should use a
relative path (relative to the Task working directory), or use the Batch
provided environment variable
(https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).
        containerSettings: {
          containerRunOptions: string, # Optional. These additional options are supplied as arguments to the &quot;docker create&quot;
command, in addition to those controlled by the Batch Service.
          imageName: string, # Required. This is the full Image reference, as would be specified to &quot;docker pull&quot;. If
no tag is provided as part of the Image name, the tag &quot;:latest&quot; is used as a
default.
          registry: ContainerRegistry, # Optional. This setting can be omitted if was already provided at Pool creation.
          workingDirectory: &quot;taskWorkingDirectory&quot; | &quot;containerImageDefault&quot;, # Optional. The default is &apos;taskWorkingDirectory&apos;.
        }, # Optional. When this is specified, all directories recursively below the
AZ_BATCH_NODE_ROOT_DIR (the root of Azure Batch directories on the node) are
mapped into the container, all Task environment variables are mapped into the
container, and the Task command line is executed in the container. Files
produced in the container outside of AZ_BATCH_NODE_ROOT_DIR might not be
reflected to the host disk, meaning that Batch file APIs will not be able to
access those files.
        resourceFiles: [ResourceFile], # Optional. Files listed under this element are located in the Task&apos;s working directory.
        environmentSettings: [EnvironmentSetting], # Optional. A list of environment variable settings for the StartTask.
        userIdentity: {
          username: string, # Optional. The userName and autoUser properties are mutually exclusive; you must specify
one but not both.
          autoUser: {
            scope: &quot;task&quot; | &quot;pool&quot;, # Optional. The default value is pool. If the pool is running Windows a value of Task
should be specified if stricter isolation between tasks is required. For
example, if the task mutates the registry in a way which could impact other
tasks, or if certificates have been specified on the pool which should not be
accessible by normal tasks but should be accessible by StartTasks.
            elevationLevel: &quot;nonadmin&quot; | &quot;admin&quot;, # Optional. The default value is nonAdmin.
          }, # Optional. The userName and autoUser properties are mutually exclusive; you must specify
one but not both.
        }, # Optional. If omitted, the Task runs as a non-administrative user unique to the Task.
        maxTaskRetryCount: number, # Optional. The Batch service retries a Task if its exit code is nonzero. Note that this
value specifically controls the number of retries. The Batch service will try
the Task once, and may then retry up to this limit. For example, if the maximum
retry count is 3, Batch tries the Task up to 4 times (one initial try and 3
retries). If the maximum retry count is 0, the Batch service does not retry the
Task. If the maximum retry count is -1, the Batch service retries the Task
without limit, however this is not recommended for a start task or any task.
The default value is 0 (no retries)
        waitForSuccess: boolean, # Optional. If true and the StartTask fails on a Node, the Batch service retries the
StartTask up to its maximum retry count (maxTaskRetryCount). If the Task has
still not completed successfully after all retries, then the Batch service
marks the Node unusable, and will not schedule Tasks to it. This condition can
be detected via the Compute Node state and failure info details. If false, the
Batch service will not wait for the StartTask to complete. In this case, other
Tasks can start executing on the Compute Node while the StartTask is still
running; and even if the StartTask fails, new Tasks will continue to be
scheduled on the Compute Node. The default is true.
      }, # Optional. Batch will retry Tasks when a recovery operation is triggered on a Node.
Examples of recovery operations include (but are not limited to) when an
unhealthy Node is rebooted or a Compute Node disappeared due to host failure.
Retries due to recovery operations are independent of and are not counted
against the maxTaskRetryCount. Even if the maxTaskRetryCount is 0, an internal
retry due to a recovery operation may occur. Because of this, all Tasks should
be idempotent. This means Tasks need to tolerate being interrupted and
restarted without causing any corruption or duplicate data. The best practice
for long running Tasks is to use some form of checkpointing. In some cases the
StartTask may be re-run even though the Compute Node was not rebooted. Special
care should be taken to avoid StartTasks which create breakaway process or
install/launch services from the StartTask working directory, as this will
block Batch from being able to re-run the StartTask.
      certificateReferences: [CertificateReference], # Optional. For Windows Nodes, the Batch service installs the Certificates to the specified
Certificate store and location. For Linux Compute Nodes, the Certificates are
stored in a directory inside the Task working directory and an environment
variable AZ_BATCH_CERTIFICATES_DIR is supplied to the Task to query for this
location. For Certificates with visibility of &apos;remoteUser&apos;, a &apos;certs&apos; directory
is created in the user&apos;s home directory (e.g., /home/{user-name}/certs) and
Certificates are placed in that directory.
      applicationPackageReferences: [ApplicationPackageReference], # Optional. Changes to Package references affect all new Nodes joining the Pool, but do not
affect Compute Nodes that are already in the Pool until they are rebooted or
reimaged. There is a maximum of 10 Package references on any given Pool.
      applicationLicenses: [string], # Optional. The list of application licenses must be a subset of available Batch service
application licenses. If a license is requested which is not supported, Pool
creation will fail.
      taskSlotsPerNode: number, # Optional. The default value is 1. The maximum value is the smaller of 4 times the number
of cores of the vmSize of the pool or 256.
      taskSchedulingPolicy: {
        nodeFillType: &quot;spread&quot; | &quot;pack&quot;, # Required. If not specified, the default is spread.
      }, # Optional. If not specified, the default is spread.
      userAccounts: [UserAccount], # Optional. The list of user Accounts to be created on each Compute Node in the Pool.
      metadata: [MetadataItem], # Optional. A list of name-value pairs associated with the Pool as metadata.
      stats: {
        url: string, # Required. The URL for the statistics.
        startTime: string (date &amp; time), # Required. The start time of the time range covered by the statistics.
        lastUpdateTime: string (date &amp; time), # Required. The time at which the statistics were last updated. All statistics are limited
to the range between startTime and lastUpdateTime.
        usageStats: {
          startTime: string (date &amp; time), # Required. The start time of the time range covered by the statistics.
          lastUpdateTime: string (date &amp; time), # Required. The time at which the statistics were last updated. All statistics are limited
to the range between startTime and lastUpdateTime.
          dedicatedCoreTime: string (duration ISO 8601 Format), # Required. The aggregated wall-clock time of the dedicated Compute Node cores being part
of the Pool.
        }, # Optional. Statistics related to Pool usage information.
        resourceStats: {
          startTime: string (date &amp; time), # Required. The start time of the time range covered by the statistics.
          lastUpdateTime: string (date &amp; time), # Required. The time at which the statistics were last updated. All statistics are limited
to the range between startTime and lastUpdateTime.
          avgCPUPercentage: number, # Required. The average CPU usage across all Compute Nodes in the Pool (percentage per
node).
          avgMemoryGiB: number, # Required. The average memory usage in GiB across all Compute Nodes in the Pool.
          peakMemoryGiB: number, # Required. The peak memory usage in GiB across all Compute Nodes in the Pool.
          avgDiskGiB: number, # Required. The average used disk space in GiB across all Compute Nodes in the Pool.
          peakDiskGiB: number, # Required. The peak used disk space in GiB across all Compute Nodes in the Pool.
          diskReadIOps: number, # Required. The total number of disk read operations across all Compute Nodes in the Pool.
          diskWriteIOps: number, # Required. The total number of disk write operations across all Compute Nodes in the Pool.
          diskReadGiB: number, # Required. The total amount of data in GiB of disk reads across all Compute Nodes in the
Pool.
          diskWriteGiB: number, # Required. The total amount of data in GiB of disk writes across all Compute Nodes in the
Pool.
          networkReadGiB: number, # Required. The total amount of data in GiB of network reads across all Compute Nodes in
the Pool.
          networkWriteGiB: number, # Required. The total amount of data in GiB of network writes across all Compute Nodes in
the Pool.
        }, # Optional. Statistics related to resource consumption by Compute Nodes in a Pool.
      }, # Optional. This property is populated only if the CloudPool was retrieved with an expand
clause including the &apos;stats&apos; attribute; otherwise it is null. The statistics
may not be immediately available. The Batch service performs periodic roll-up
of statistics. The typical delay is about 30 minutes.
      mountConfiguration: [MountConfiguration], # Optional. This supports Azure Files, NFS, CIFS/SMB, and Blobfuse.
      identity: {
        type: &quot;UserAssigned&quot; | &quot;None&quot;, # Required. The list of user identities associated with the Batch pool. The user identity
dictionary key references will be ARM resource ids in the form:
&apos;/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.ManagedIdentity/userAssignedIdentities/{identityName}&apos;.
        userAssignedIdentities: [UserAssignedIdentity], # Optional. The user identity dictionary key references will be ARM resource ids in the
form:
&apos;/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.ManagedIdentity/userAssignedIdentities/{identityName}&apos;.
      }, # Optional. The list of user identities associated with the Batch pool. The user identity
dictionary key references will be ARM resource ids in the form:
&apos;/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.ManagedIdentity/userAssignedIdentities/{identityName}&apos;.
      targetNodeCommunicationMode: &quot;default&quot; | &quot;classic&quot; | &quot;simplified&quot;, # Optional. If omitted, the default value is Default.
      currentNodeCommunicationMode: &quot;default&quot; | &quot;classic&quot; | &quot;simplified&quot;, # Optional. Determines how a pool communicates with the Batch service.
    }
  ], # Optional. The list of Pools.
  odata.nextLink: string, # Optional. The URL to get the next set of results.
}
</code>

</remarks>
    </member>
    <member name="GetPools(Int32,String,Int32,String,Boolean,String,String,String,RequestContext)">
<example>
This sample shows how to call GetPools and parse the result.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetPoolClient(<2022-10-01.16.0>);

Response response = client.GetPools();

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.ToString());
]]></code>
This sample shows how to call GetPools with all parameters, and how to parse the result.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetPoolClient(<2022-10-01.16.0>);

Response response = client.GetPools(1234, "<ocpDate>", 1234, "<clientRequestId>", true, "<filter>", "<select>", "<expand>");

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.GetProperty("value")[0].GetProperty("id").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("displayName").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("url").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("eTag").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("lastModified").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("creationTime").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("state").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("stateTransitionTime").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("allocationState").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("allocationStateTransitionTime").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("vmSize").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("cloudServiceConfiguration").GetProperty("osFamily").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("cloudServiceConfiguration").GetProperty("osVersion").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("virtualMachineConfiguration").GetProperty("imageReference").GetProperty("publisher").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("virtualMachineConfiguration").GetProperty("imageReference").GetProperty("offer").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("virtualMachineConfiguration").GetProperty("imageReference").GetProperty("sku").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("virtualMachineConfiguration").GetProperty("imageReference").GetProperty("version").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("virtualMachineConfiguration").GetProperty("imageReference").GetProperty("virtualMachineImageId").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("virtualMachineConfiguration").GetProperty("imageReference").GetProperty("exactVersion").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("virtualMachineConfiguration").GetProperty("nodeAgentSKUId").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("virtualMachineConfiguration").GetProperty("windowsConfiguration").GetProperty("enableAutomaticUpdates").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("virtualMachineConfiguration").GetProperty("dataDisks")[0].GetProperty("lun").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("virtualMachineConfiguration").GetProperty("dataDisks")[0].GetProperty("caching").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("virtualMachineConfiguration").GetProperty("dataDisks")[0].GetProperty("diskSizeGB").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("virtualMachineConfiguration").GetProperty("dataDisks")[0].GetProperty("storageAccountType").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("virtualMachineConfiguration").GetProperty("licenseType").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("virtualMachineConfiguration").GetProperty("containerConfiguration").GetProperty("type").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("virtualMachineConfiguration").GetProperty("containerConfiguration").GetProperty("containerImageNames")[0].ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("virtualMachineConfiguration").GetProperty("containerConfiguration").GetProperty("containerRegistries")[0].GetProperty("username").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("virtualMachineConfiguration").GetProperty("containerConfiguration").GetProperty("containerRegistries")[0].GetProperty("password").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("virtualMachineConfiguration").GetProperty("containerConfiguration").GetProperty("containerRegistries")[0].GetProperty("registryServer").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("virtualMachineConfiguration").GetProperty("containerConfiguration").GetProperty("containerRegistries")[0].GetProperty("identityReference").GetProperty("resourceId").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("virtualMachineConfiguration").GetProperty("diskEncryptionConfiguration").GetProperty("targets")[0].ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("virtualMachineConfiguration").GetProperty("nodePlacementConfiguration").GetProperty("policy").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("virtualMachineConfiguration").GetProperty("extensions")[0].GetProperty("name").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("virtualMachineConfiguration").GetProperty("extensions")[0].GetProperty("publisher").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("virtualMachineConfiguration").GetProperty("extensions")[0].GetProperty("type").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("virtualMachineConfiguration").GetProperty("extensions")[0].GetProperty("typeHandlerVersion").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("virtualMachineConfiguration").GetProperty("extensions")[0].GetProperty("autoUpgradeMinorVersion").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("virtualMachineConfiguration").GetProperty("extensions")[0].GetProperty("provisionAfterExtensions")[0].ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("virtualMachineConfiguration").GetProperty("osDisk").GetProperty("ephemeralOSDiskSettings").GetProperty("placement").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("resizeTimeout").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("resizeErrors")[0].GetProperty("code").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("resizeErrors")[0].GetProperty("message").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("resizeErrors")[0].GetProperty("values")[0].GetProperty("name").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("resizeErrors")[0].GetProperty("values")[0].GetProperty("value").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("currentDedicatedNodes").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("currentLowPriorityNodes").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("targetDedicatedNodes").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("targetLowPriorityNodes").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("enableAutoScale").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("autoScaleFormula").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("autoScaleEvaluationInterval").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("autoScaleRun").GetProperty("timestamp").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("autoScaleRun").GetProperty("results").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("autoScaleRun").GetProperty("error").GetProperty("code").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("autoScaleRun").GetProperty("error").GetProperty("message").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("autoScaleRun").GetProperty("error").GetProperty("values")[0].GetProperty("name").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("autoScaleRun").GetProperty("error").GetProperty("values")[0].GetProperty("value").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("enableInterNodeCommunication").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("networkConfiguration").GetProperty("subnetId").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("networkConfiguration").GetProperty("dynamicVNetAssignmentScope").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("networkConfiguration").GetProperty("endpointConfiguration").GetProperty("inboundNATPools")[0].GetProperty("name").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("networkConfiguration").GetProperty("endpointConfiguration").GetProperty("inboundNATPools")[0].GetProperty("protocol").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("networkConfiguration").GetProperty("endpointConfiguration").GetProperty("inboundNATPools")[0].GetProperty("backendPort").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("networkConfiguration").GetProperty("endpointConfiguration").GetProperty("inboundNATPools")[0].GetProperty("frontendPortRangeStart").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("networkConfiguration").GetProperty("endpointConfiguration").GetProperty("inboundNATPools")[0].GetProperty("frontendPortRangeEnd").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("networkConfiguration").GetProperty("endpointConfiguration").GetProperty("inboundNATPools")[0].GetProperty("networkSecurityGroupRules")[0].GetProperty("priority").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("networkConfiguration").GetProperty("endpointConfiguration").GetProperty("inboundNATPools")[0].GetProperty("networkSecurityGroupRules")[0].GetProperty("access").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("networkConfiguration").GetProperty("endpointConfiguration").GetProperty("inboundNATPools")[0].GetProperty("networkSecurityGroupRules")[0].GetProperty("sourceAddressPrefix").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("networkConfiguration").GetProperty("endpointConfiguration").GetProperty("inboundNATPools")[0].GetProperty("networkSecurityGroupRules")[0].GetProperty("sourcePortRanges")[0].ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("networkConfiguration").GetProperty("publicIPAddressConfiguration").GetProperty("provision").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("networkConfiguration").GetProperty("publicIPAddressConfiguration").GetProperty("ipAddressIds")[0].ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("startTask").GetProperty("commandLine").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("startTask").GetProperty("containerSettings").GetProperty("containerRunOptions").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("startTask").GetProperty("containerSettings").GetProperty("imageName").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("startTask").GetProperty("containerSettings").GetProperty("registry").GetProperty("username").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("startTask").GetProperty("containerSettings").GetProperty("registry").GetProperty("password").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("startTask").GetProperty("containerSettings").GetProperty("registry").GetProperty("registryServer").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("startTask").GetProperty("containerSettings").GetProperty("registry").GetProperty("identityReference").GetProperty("resourceId").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("startTask").GetProperty("containerSettings").GetProperty("workingDirectory").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("startTask").GetProperty("resourceFiles")[0].GetProperty("autoStorageContainerName").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("startTask").GetProperty("resourceFiles")[0].GetProperty("storageContainerUrl").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("startTask").GetProperty("resourceFiles")[0].GetProperty("httpUrl").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("startTask").GetProperty("resourceFiles")[0].GetProperty("blobPrefix").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("startTask").GetProperty("resourceFiles")[0].GetProperty("filePath").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("startTask").GetProperty("resourceFiles")[0].GetProperty("fileMode").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("startTask").GetProperty("resourceFiles")[0].GetProperty("identityReference").GetProperty("resourceId").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("startTask").GetProperty("environmentSettings")[0].GetProperty("name").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("startTask").GetProperty("environmentSettings")[0].GetProperty("value").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("startTask").GetProperty("userIdentity").GetProperty("username").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("startTask").GetProperty("userIdentity").GetProperty("autoUser").GetProperty("scope").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("startTask").GetProperty("userIdentity").GetProperty("autoUser").GetProperty("elevationLevel").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("startTask").GetProperty("maxTaskRetryCount").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("startTask").GetProperty("waitForSuccess").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("certificateReferences")[0].GetProperty("thumbprint").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("certificateReferences")[0].GetProperty("thumbprintAlgorithm").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("certificateReferences")[0].GetProperty("storeLocation").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("certificateReferences")[0].GetProperty("storeName").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("certificateReferences")[0].GetProperty("visibility")[0].ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("applicationPackageReferences")[0].GetProperty("applicationId").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("applicationPackageReferences")[0].GetProperty("version").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("applicationLicenses")[0].ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("taskSlotsPerNode").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("taskSchedulingPolicy").GetProperty("nodeFillType").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("userAccounts")[0].GetProperty("name").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("userAccounts")[0].GetProperty("password").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("userAccounts")[0].GetProperty("elevationLevel").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("userAccounts")[0].GetProperty("linuxUserConfiguration").GetProperty("uid").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("userAccounts")[0].GetProperty("linuxUserConfiguration").GetProperty("gid").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("userAccounts")[0].GetProperty("linuxUserConfiguration").GetProperty("sshPrivateKey").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("userAccounts")[0].GetProperty("windowsUserConfiguration").GetProperty("loginMode").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("metadata")[0].GetProperty("name").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("metadata")[0].GetProperty("value").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("stats").GetProperty("url").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("stats").GetProperty("startTime").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("stats").GetProperty("lastUpdateTime").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("stats").GetProperty("usageStats").GetProperty("startTime").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("stats").GetProperty("usageStats").GetProperty("lastUpdateTime").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("stats").GetProperty("usageStats").GetProperty("dedicatedCoreTime").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("stats").GetProperty("resourceStats").GetProperty("startTime").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("stats").GetProperty("resourceStats").GetProperty("lastUpdateTime").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("stats").GetProperty("resourceStats").GetProperty("avgCPUPercentage").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("stats").GetProperty("resourceStats").GetProperty("avgMemoryGiB").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("stats").GetProperty("resourceStats").GetProperty("peakMemoryGiB").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("stats").GetProperty("resourceStats").GetProperty("avgDiskGiB").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("stats").GetProperty("resourceStats").GetProperty("peakDiskGiB").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("stats").GetProperty("resourceStats").GetProperty("diskReadIOps").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("stats").GetProperty("resourceStats").GetProperty("diskWriteIOps").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("stats").GetProperty("resourceStats").GetProperty("diskReadGiB").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("stats").GetProperty("resourceStats").GetProperty("diskWriteGiB").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("stats").GetProperty("resourceStats").GetProperty("networkReadGiB").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("stats").GetProperty("resourceStats").GetProperty("networkWriteGiB").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("mountConfiguration")[0].GetProperty("azureBlobFileSystemConfiguration").GetProperty("accountName").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("mountConfiguration")[0].GetProperty("azureBlobFileSystemConfiguration").GetProperty("containerName").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("mountConfiguration")[0].GetProperty("azureBlobFileSystemConfiguration").GetProperty("accountKey").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("mountConfiguration")[0].GetProperty("azureBlobFileSystemConfiguration").GetProperty("sasKey").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("mountConfiguration")[0].GetProperty("azureBlobFileSystemConfiguration").GetProperty("blobfuseOptions").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("mountConfiguration")[0].GetProperty("azureBlobFileSystemConfiguration").GetProperty("relativeMountPath").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("mountConfiguration")[0].GetProperty("azureBlobFileSystemConfiguration").GetProperty("identityReference").GetProperty("resourceId").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("mountConfiguration")[0].GetProperty("nfsMountConfiguration").GetProperty("source").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("mountConfiguration")[0].GetProperty("nfsMountConfiguration").GetProperty("relativeMountPath").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("mountConfiguration")[0].GetProperty("nfsMountConfiguration").GetProperty("mountOptions").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("mountConfiguration")[0].GetProperty("cifsMountConfiguration").GetProperty("username").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("mountConfiguration")[0].GetProperty("cifsMountConfiguration").GetProperty("source").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("mountConfiguration")[0].GetProperty("cifsMountConfiguration").GetProperty("relativeMountPath").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("mountConfiguration")[0].GetProperty("cifsMountConfiguration").GetProperty("mountOptions").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("mountConfiguration")[0].GetProperty("cifsMountConfiguration").GetProperty("password").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("mountConfiguration")[0].GetProperty("azureFileShareConfiguration").GetProperty("accountName").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("mountConfiguration")[0].GetProperty("azureFileShareConfiguration").GetProperty("azureFileUrl").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("mountConfiguration")[0].GetProperty("azureFileShareConfiguration").GetProperty("accountKey").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("mountConfiguration")[0].GetProperty("azureFileShareConfiguration").GetProperty("relativeMountPath").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("mountConfiguration")[0].GetProperty("azureFileShareConfiguration").GetProperty("mountOptions").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("identity").GetProperty("type").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("identity").GetProperty("userAssignedIdentities")[0].GetProperty("resourceId").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("identity").GetProperty("userAssignedIdentities")[0].GetProperty("clientId").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("identity").GetProperty("userAssignedIdentities")[0].GetProperty("principalId").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("targetNodeCommunicationMode").ToString());
Console.WriteLine(result.GetProperty("value")[0].GetProperty("currentNodeCommunicationMode").ToString());
Console.WriteLine(result.GetProperty("odata.nextLink").ToString());
]]></code>
</example>
<remarks>
Below is the JSON schema for the response payload.

Response Body:

Schema for <c>BatchPoolListResult</c>:
<code>{
  value: [
    {
      id: string, # Optional. The ID can contain any combination of alphanumeric characters including hyphens
and underscores, and cannot contain more than 64 characters. The ID is
case-preserving and case-insensitive (that is, you may not have two IDs within
an Account that differ only by case).
      displayName: string, # Optional. The display name need not be unique and can contain any Unicode characters up
to a maximum length of 1024.
      url: string, # Optional. The URL of the Pool.
      eTag: string, # Optional. This is an opaque string. You can use it to detect whether the Pool has changed
between requests. In particular, you can be pass the ETag when updating a Pool
to specify that your changes should take effect only if nobody else has
modified the Pool in the meantime.
      lastModified: string (date &amp; time), # Optional. This is the last time at which the Pool level data, such as the
targetDedicatedNodes or enableAutoscale settings, changed. It does not factor
in node-level changes such as a Compute Node changing state.
      creationTime: string (date &amp; time), # Optional. The creation time of the Pool.
      state: &quot;active&quot; | &quot;deleting&quot;, # Optional. The current state of the Pool.
      stateTransitionTime: string (date &amp; time), # Optional. The time at which the Pool entered its current state.
      allocationState: &quot;steady&quot; | &quot;resizing&quot; | &quot;stopping&quot;, # Optional. Whether the Pool is resizing.
      allocationStateTransitionTime: string (date &amp; time), # Optional. The time at which the Pool entered its current allocation state.
      vmSize: string, # Optional. For information about available sizes of virtual machines in Pools, see Choose
a VM size for Compute Nodes in an Azure Batch Pool
(https://docs.microsoft.com/azure/batch/batch-pool-vm-sizes).
      cloudServiceConfiguration: {
        osFamily: string, # Required. Possible values are:
2 - OS Family 2, equivalent to Windows Server 2008 R2
SP1.
3 - OS Family 3, equivalent to Windows Server 2012.
4 - OS Family 4,
equivalent to Windows Server 2012 R2.
5 - OS Family 5, equivalent to Windows
Server 2016.
6 - OS Family 6, equivalent to Windows Server 2019. For more
information, see Azure Guest OS Releases
(https://azure.microsoft.com/documentation/articles/cloud-services-guestos-update-matrix/#releases).
        osVersion: string, # Optional. The default value is * which specifies the latest operating system version for
the specified OS family.
      }, # Optional. This property and virtualMachineConfiguration are mutually exclusive and one of
the properties must be specified. This property cannot be specified if the
Batch Account was created with its poolAllocationMode property set to
&apos;UserSubscription&apos;.
      virtualMachineConfiguration: {
        imageReference: {
          publisher: string, # Optional. For example, Canonical or MicrosoftWindowsServer.
          offer: string, # Optional. For example, UbuntuServer or WindowsServer.
          sku: string, # Optional. For example, 18.04-LTS or 2019-Datacenter.
          version: string, # Optional. A value of &apos;latest&apos; can be specified to select the latest version of an Image.
If omitted, the default is &apos;latest&apos;.
          virtualMachineImageId: string, # Optional. This property is mutually exclusive with other ImageReference properties. The
Shared Image Gallery Image must have replicas in the same region and must be in
the same subscription as the Azure Batch account. If the image version is not
specified in the imageId, the latest version will be used. For information
about the firewall settings for the Batch Compute Node agent to communicate
with the Batch service see
https://docs.microsoft.com/en-us/azure/batch/batch-api-basics#virtual-network-vnet-and-firewall-configuration.
          exactVersion: string, # Optional. The specific version of the platform image or marketplace image used to create
the node. This read-only field differs from &apos;version&apos; only if the value
specified for &apos;version&apos; when the pool was created was &apos;latest&apos;.
        }, # Required. A reference to an Azure Virtual Machines Marketplace Image or a Shared Image
Gallery Image. To get the list of all Azure Marketplace Image references
verified by Azure Batch, see the &apos;List Supported Images&apos; operation.
        nodeAgentSKUId: string, # Required. The Batch Compute Node agent is a program that runs on each Compute Node in the
Pool, and provides the command-and-control interface between the Compute Node
and the Batch service. There are different implementations of the Compute Node
agent, known as SKUs, for different operating systems. You must specify a
Compute Node agent SKU which matches the selected Image reference. To get the
list of supported Compute Node agent SKUs along with their list of verified
Image references, see the &apos;List supported Compute Node agent SKUs&apos; operation.
        windowsConfiguration: {
          enableAutomaticUpdates: boolean, # Optional. If omitted, the default value is true.
        }, # Optional. This property must not be specified if the imageReference property specifies a
Linux OS Image.
        dataDisks: [DataDisk], # Optional. This property must be specified if the Compute Nodes in the Pool need to have
empty data disks attached to them. This cannot be updated. Each Compute Node
gets its own disk (the disk is not a file share). Existing disks cannot be
attached, each attached disk is empty. When the Compute Node is removed from
the Pool, the disk and all data associated with it is also deleted. The disk is
not formatted after being attached, it must be formatted before use - for more
information see
https://docs.microsoft.com/en-us/azure/virtual-machines/linux/classic/attach-disk#initialize-a-new-data-disk-in-linux
and
https://docs.microsoft.com/en-us/azure/virtual-machines/windows/attach-disk-ps#add-an-empty-data-disk-to-a-virtual-machine.
        licenseType: string, # Optional. This only applies to Images that contain the Windows operating system, and
should only be used when you hold valid on-premises licenses for the Compute
Nodes which will be deployed. If omitted, no on-premises licensing discount is
applied. Values are:

 Windows_Server - The on-premises license is for Windows
Server.
 Windows_Client - The on-premises license is for Windows Client.

        containerConfiguration: {
          type: &quot;dockerCompatible&quot;, # Required. The container technology to be used.
          containerImageNames: [string], # Optional. This is the full Image reference, as would be specified to &quot;docker pull&quot;. An
Image will be sourced from the default Docker registry unless the Image is
fully qualified with an alternative registry.
          containerRegistries: [
            {
              username: string, # Optional. The user name to log into the registry server.
              password: string, # Optional. The password to log into the registry server.
              registryServer: string, # Optional. If omitted, the default is &quot;docker.io&quot;.
              identityReference: {
                resourceId: string, # Optional. The ARM resource id of the user assigned identity.
              }, # Optional. The reference to a user assigned identity associated with the Batch pool which
a compute node will use.
            }
          ], # Optional. If any Images must be downloaded from a private registry which requires
credentials, then those credentials must be provided here.
        }, # Optional. If specified, setup is performed on each Compute Node in the Pool to allow
Tasks to run in containers. All regular Tasks and Job manager Tasks run on this
Pool must specify the containerSettings property, and all other Tasks may
specify it.
        diskEncryptionConfiguration: {
          targets: [&quot;osdisk&quot; | &quot;temporarydisk&quot;], # Optional. If omitted, no disks on the compute nodes in the pool will be encrypted. On
Linux pool, only &quot;TemporaryDisk&quot; is supported; on Windows pool, &quot;OsDisk&quot;
and &quot;TemporaryDisk&quot; must be specified.
        }, # Optional. If specified, encryption is performed on each node in the pool during node
provisioning.
        nodePlacementConfiguration: {
          policy: &quot;regional&quot; | &quot;zonal&quot;, # Optional. Allocation policy used by Batch Service to provision the nodes. If not
specified, Batch will use the regional policy.
        }, # Optional. This configuration will specify rules on how nodes in the pool will be
physically allocated.
        extensions: [VMExtension], # Optional. If specified, the extensions mentioned in this configuration will be installed
on each node.
        osDisk: {
          ephemeralOSDiskSettings: {
            placement: &quot;cachedisk&quot;, # Optional. This property can be used by user in the request to choose the location e.g.,
cache disk space for Ephemeral OS disk provisioning. For more information on
Ephemeral OS disk size requirements, please refer to Ephemeral OS disk size
requirements for Windows VMs at
https://docs.microsoft.com/en-us/azure/virtual-machines/windows/ephemeral-os-disks#size-requirements
and Linux VMs at
https://docs.microsoft.com/en-us/azure/virtual-machines/linux/ephemeral-os-disks#size-requirements.
          }, # Optional. Specifies the ephemeral Disk Settings for the operating system disk used by the
compute node (VM).
        }, # Optional. Settings for the operating system disk of the compute node (VM).
      }, # Optional. This property and cloudServiceConfiguration are mutually exclusive and one of
the properties must be specified.
      resizeTimeout: string (duration ISO 8601 Format), # Optional. This is the timeout for the most recent resize operation. (The initial sizing
when the Pool is created counts as a resize.) The default value is 15 minutes.
      resizeErrors: [ResizeError], # Optional. This property is set only if one or more errors occurred during the last Pool
resize, and only when the Pool allocationState is Steady.
      currentDedicatedNodes: number, # Optional. The number of dedicated Compute Nodes currently in the Pool.
      currentLowPriorityNodes: number, # Optional. Spot/Low-priority Compute Nodes which have been preempted are included in this
count.
      targetDedicatedNodes: number, # Optional. The desired number of dedicated Compute Nodes in the Pool.
      targetLowPriorityNodes: number, # Optional. The desired number of Spot/Low-priority Compute Nodes in the Pool.
      enableAutoScale: boolean, # Optional. If false, at least one of targetDedicatedNodes and targetLowPriorityNodes must
be specified. If true, the autoScaleFormula property is required and the Pool
automatically resizes according to the formula. The default value is false.
      autoScaleFormula: string, # Optional. This property is set only if the Pool automatically scales, i.e.
enableAutoScale is true.
      autoScaleEvaluationInterval: string (duration ISO 8601 Format), # Optional. This property is set only if the Pool automatically scales, i.e.
enableAutoScale is true.
      autoScaleRun: {
        timestamp: string (date &amp; time), # Required. The time at which the autoscale formula was last evaluated.
        results: string, # Optional. Each variable value is returned in the form $variable=value, and variables are
separated by semicolons.
        error: {
          code: string, # Optional. An identifier for the autoscale error. Codes are invariant and are intended to
be consumed programmatically.
          message: string, # Optional. A message describing the autoscale error, intended to be suitable for display
in a user interface.
          values: [NameValuePair], # Optional. A list of additional error details related to the autoscale error.
        }, # Optional. An error that occurred when executing or evaluating a Pool autoscale formula.
      }, # Optional. This property is set only if the Pool automatically scales, i.e.
enableAutoScale is true.
      enableInterNodeCommunication: boolean, # Optional. This imposes restrictions on which Compute Nodes can be assigned to the Pool.
Specifying this value can reduce the chance of the requested number of Compute
Nodes to be allocated in the Pool.
      networkConfiguration: {
        subnetId: string, # Optional. The virtual network must be in the same region and subscription as the Azure
Batch Account. The specified subnet should have enough free IP addresses to
accommodate the number of Compute Nodes in the Pool. If the subnet doesn&apos;t have
enough free IP addresses, the Pool will partially allocate Nodes and a resize
error will occur. The &apos;MicrosoftAzureBatch&apos; service principal must have the
&apos;Classic Virtual Machine Contributor&apos; Role-Based Access Control (RBAC) role for
the specified VNet. The specified subnet must allow communication from the
Azure Batch service to be able to schedule Tasks on the Nodes. This can be
verified by checking if the specified VNet has any associated Network Security
Groups (NSG). If communication to the Nodes in the specified subnet is denied
by an NSG, then the Batch service will set the state of the Compute Nodes to
unusable. For Pools created with virtualMachineConfiguration only ARM virtual
networks (&apos;Microsoft.Network/virtualNetworks&apos;) are supported, but for Pools
created with cloudServiceConfiguration both ARM and classic virtual networks
are supported. If the specified VNet has any associated Network Security Groups
(NSG), then a few reserved system ports must be enabled for inbound
communication. For Pools created with a virtual machine configuration, enable
ports 29876 and 29877, as well as port 22 for Linux and port 3389 for Windows.
For Pools created with a cloud service configuration, enable ports 10100,
20100, and 30100. Also enable outbound connections to Azure Storage on port
443. For more details see:
https://docs.microsoft.com/en-us/azure/batch/batch-api-basics#virtual-network-vnet-and-firewall-configuration
        dynamicVNetAssignmentScope: &quot;none&quot; | &quot;job&quot;, # Optional. The scope of dynamic vnet assignment.
        endpointConfiguration: {
          inboundNATPools: [InboundNATPool], # Required. The maximum number of inbound NAT Pools per Batch Pool is 5. If the maximum
number of inbound NAT Pools is exceeded the request fails with HTTP status code
400. This cannot be specified if the IPAddressProvisioningType is
NoPublicIPAddresses.
        }, # Optional. Pool endpoint configuration is only supported on Pools with the
virtualMachineConfiguration property.
        publicIPAddressConfiguration: {
          provision: &quot;batchmanaged&quot; | &quot;usermanaged&quot; | &quot;nopublicipaddresses&quot;, # Optional. The default value is BatchManaged.
          ipAddressIds: [string], # Optional. The number of IPs specified here limits the maximum size of the Pool - 100
dedicated nodes or 100 Spot/Low-priority nodes can be allocated for each public
IP. For example, a pool needing 250 dedicated VMs would need at least 3 public
IPs specified. Each element of this collection is of the form:
/subscriptions/{subscription}/resourceGroups/{group}/providers/Microsoft.Network/publicIPAddresses/{ip}.
        }, # Optional. Public IP configuration property is only supported on Pools with the
virtualMachineConfiguration property.
      }, # Optional. The network configuration for a Pool.
      startTask: {
        commandLine: string, # Required. The command line does not run under a shell, and therefore cannot take
advantage of shell features such as environment variable expansion. If you want
to take advantage of such features, you should invoke the shell in the command
line, for example using &quot;cmd /c MyCommand&quot; in Windows or &quot;/bin/sh -c
MyCommand&quot; in Linux. If the command line refers to file paths, it should use a
relative path (relative to the Task working directory), or use the Batch
provided environment variable
(https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).
        containerSettings: {
          containerRunOptions: string, # Optional. These additional options are supplied as arguments to the &quot;docker create&quot;
command, in addition to those controlled by the Batch Service.
          imageName: string, # Required. This is the full Image reference, as would be specified to &quot;docker pull&quot;. If
no tag is provided as part of the Image name, the tag &quot;:latest&quot; is used as a
default.
          registry: ContainerRegistry, # Optional. This setting can be omitted if was already provided at Pool creation.
          workingDirectory: &quot;taskWorkingDirectory&quot; | &quot;containerImageDefault&quot;, # Optional. The default is &apos;taskWorkingDirectory&apos;.
        }, # Optional. When this is specified, all directories recursively below the
AZ_BATCH_NODE_ROOT_DIR (the root of Azure Batch directories on the node) are
mapped into the container, all Task environment variables are mapped into the
container, and the Task command line is executed in the container. Files
produced in the container outside of AZ_BATCH_NODE_ROOT_DIR might not be
reflected to the host disk, meaning that Batch file APIs will not be able to
access those files.
        resourceFiles: [ResourceFile], # Optional. Files listed under this element are located in the Task&apos;s working directory.
        environmentSettings: [EnvironmentSetting], # Optional. A list of environment variable settings for the StartTask.
        userIdentity: {
          username: string, # Optional. The userName and autoUser properties are mutually exclusive; you must specify
one but not both.
          autoUser: {
            scope: &quot;task&quot; | &quot;pool&quot;, # Optional. The default value is pool. If the pool is running Windows a value of Task
should be specified if stricter isolation between tasks is required. For
example, if the task mutates the registry in a way which could impact other
tasks, or if certificates have been specified on the pool which should not be
accessible by normal tasks but should be accessible by StartTasks.
            elevationLevel: &quot;nonadmin&quot; | &quot;admin&quot;, # Optional. The default value is nonAdmin.
          }, # Optional. The userName and autoUser properties are mutually exclusive; you must specify
one but not both.
        }, # Optional. If omitted, the Task runs as a non-administrative user unique to the Task.
        maxTaskRetryCount: number, # Optional. The Batch service retries a Task if its exit code is nonzero. Note that this
value specifically controls the number of retries. The Batch service will try
the Task once, and may then retry up to this limit. For example, if the maximum
retry count is 3, Batch tries the Task up to 4 times (one initial try and 3
retries). If the maximum retry count is 0, the Batch service does not retry the
Task. If the maximum retry count is -1, the Batch service retries the Task
without limit, however this is not recommended for a start task or any task.
The default value is 0 (no retries)
        waitForSuccess: boolean, # Optional. If true and the StartTask fails on a Node, the Batch service retries the
StartTask up to its maximum retry count (maxTaskRetryCount). If the Task has
still not completed successfully after all retries, then the Batch service
marks the Node unusable, and will not schedule Tasks to it. This condition can
be detected via the Compute Node state and failure info details. If false, the
Batch service will not wait for the StartTask to complete. In this case, other
Tasks can start executing on the Compute Node while the StartTask is still
running; and even if the StartTask fails, new Tasks will continue to be
scheduled on the Compute Node. The default is true.
      }, # Optional. Batch will retry Tasks when a recovery operation is triggered on a Node.
Examples of recovery operations include (but are not limited to) when an
unhealthy Node is rebooted or a Compute Node disappeared due to host failure.
Retries due to recovery operations are independent of and are not counted
against the maxTaskRetryCount. Even if the maxTaskRetryCount is 0, an internal
retry due to a recovery operation may occur. Because of this, all Tasks should
be idempotent. This means Tasks need to tolerate being interrupted and
restarted without causing any corruption or duplicate data. The best practice
for long running Tasks is to use some form of checkpointing. In some cases the
StartTask may be re-run even though the Compute Node was not rebooted. Special
care should be taken to avoid StartTasks which create breakaway process or
install/launch services from the StartTask working directory, as this will
block Batch from being able to re-run the StartTask.
      certificateReferences: [CertificateReference], # Optional. For Windows Nodes, the Batch service installs the Certificates to the specified
Certificate store and location. For Linux Compute Nodes, the Certificates are
stored in a directory inside the Task working directory and an environment
variable AZ_BATCH_CERTIFICATES_DIR is supplied to the Task to query for this
location. For Certificates with visibility of &apos;remoteUser&apos;, a &apos;certs&apos; directory
is created in the user&apos;s home directory (e.g., /home/{user-name}/certs) and
Certificates are placed in that directory.
      applicationPackageReferences: [ApplicationPackageReference], # Optional. Changes to Package references affect all new Nodes joining the Pool, but do not
affect Compute Nodes that are already in the Pool until they are rebooted or
reimaged. There is a maximum of 10 Package references on any given Pool.
      applicationLicenses: [string], # Optional. The list of application licenses must be a subset of available Batch service
application licenses. If a license is requested which is not supported, Pool
creation will fail.
      taskSlotsPerNode: number, # Optional. The default value is 1. The maximum value is the smaller of 4 times the number
of cores of the vmSize of the pool or 256.
      taskSchedulingPolicy: {
        nodeFillType: &quot;spread&quot; | &quot;pack&quot;, # Required. If not specified, the default is spread.
      }, # Optional. If not specified, the default is spread.
      userAccounts: [UserAccount], # Optional. The list of user Accounts to be created on each Compute Node in the Pool.
      metadata: [MetadataItem], # Optional. A list of name-value pairs associated with the Pool as metadata.
      stats: {
        url: string, # Required. The URL for the statistics.
        startTime: string (date &amp; time), # Required. The start time of the time range covered by the statistics.
        lastUpdateTime: string (date &amp; time), # Required. The time at which the statistics were last updated. All statistics are limited
to the range between startTime and lastUpdateTime.
        usageStats: {
          startTime: string (date &amp; time), # Required. The start time of the time range covered by the statistics.
          lastUpdateTime: string (date &amp; time), # Required. The time at which the statistics were last updated. All statistics are limited
to the range between startTime and lastUpdateTime.
          dedicatedCoreTime: string (duration ISO 8601 Format), # Required. The aggregated wall-clock time of the dedicated Compute Node cores being part
of the Pool.
        }, # Optional. Statistics related to Pool usage information.
        resourceStats: {
          startTime: string (date &amp; time), # Required. The start time of the time range covered by the statistics.
          lastUpdateTime: string (date &amp; time), # Required. The time at which the statistics were last updated. All statistics are limited
to the range between startTime and lastUpdateTime.
          avgCPUPercentage: number, # Required. The average CPU usage across all Compute Nodes in the Pool (percentage per
node).
          avgMemoryGiB: number, # Required. The average memory usage in GiB across all Compute Nodes in the Pool.
          peakMemoryGiB: number, # Required. The peak memory usage in GiB across all Compute Nodes in the Pool.
          avgDiskGiB: number, # Required. The average used disk space in GiB across all Compute Nodes in the Pool.
          peakDiskGiB: number, # Required. The peak used disk space in GiB across all Compute Nodes in the Pool.
          diskReadIOps: number, # Required. The total number of disk read operations across all Compute Nodes in the Pool.
          diskWriteIOps: number, # Required. The total number of disk write operations across all Compute Nodes in the Pool.
          diskReadGiB: number, # Required. The total amount of data in GiB of disk reads across all Compute Nodes in the
Pool.
          diskWriteGiB: number, # Required. The total amount of data in GiB of disk writes across all Compute Nodes in the
Pool.
          networkReadGiB: number, # Required. The total amount of data in GiB of network reads across all Compute Nodes in
the Pool.
          networkWriteGiB: number, # Required. The total amount of data in GiB of network writes across all Compute Nodes in
the Pool.
        }, # Optional. Statistics related to resource consumption by Compute Nodes in a Pool.
      }, # Optional. This property is populated only if the CloudPool was retrieved with an expand
clause including the &apos;stats&apos; attribute; otherwise it is null. The statistics
may not be immediately available. The Batch service performs periodic roll-up
of statistics. The typical delay is about 30 minutes.
      mountConfiguration: [MountConfiguration], # Optional. This supports Azure Files, NFS, CIFS/SMB, and Blobfuse.
      identity: {
        type: &quot;UserAssigned&quot; | &quot;None&quot;, # Required. The list of user identities associated with the Batch pool. The user identity
dictionary key references will be ARM resource ids in the form:
&apos;/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.ManagedIdentity/userAssignedIdentities/{identityName}&apos;.
        userAssignedIdentities: [UserAssignedIdentity], # Optional. The user identity dictionary key references will be ARM resource ids in the
form:
&apos;/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.ManagedIdentity/userAssignedIdentities/{identityName}&apos;.
      }, # Optional. The list of user identities associated with the Batch pool. The user identity
dictionary key references will be ARM resource ids in the form:
&apos;/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.ManagedIdentity/userAssignedIdentities/{identityName}&apos;.
      targetNodeCommunicationMode: &quot;default&quot; | &quot;classic&quot; | &quot;simplified&quot;, # Optional. If omitted, the default value is Default.
      currentNodeCommunicationMode: &quot;default&quot; | &quot;classic&quot; | &quot;simplified&quot;, # Optional. Determines how a pool communicates with the Batch service.
    }
  ], # Optional. The list of Pools.
  odata.nextLink: string, # Optional. The URL to get the next set of results.
}
</code>

</remarks>
    </member>
    <member name="DeleteAsync(String,Int32,String,Boolean,String,RequestConditions,RequestContext)">
<example>
This sample shows how to call DeleteAsync with required parameters.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetPoolClient(<2022-10-01.16.0>);

Response response = await client.DeleteAsync("<poolId>");
Console.WriteLine(response.Status);
]]></code>
This sample shows how to call DeleteAsync with all parameters.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetPoolClient(<2022-10-01.16.0>);

Response response = await client.DeleteAsync("<poolId>", 1234, "<clientRequestId>", true, "<ocpDate>", null);
Console.WriteLine(response.Status);
]]></code>
</example>
<remarks>
When you request that a Pool be deleted, the following actions occur: the Pool
state is set to deleting; any ongoing resize operation on the Pool are stopped;
the Batch service starts resizing the Pool to zero Compute Nodes; any Tasks
running on existing Compute Nodes are terminated and requeued (as if a resize
Pool operation had been requested with the default requeue option); finally,
the Pool is removed from the system. Because running Tasks are requeued, the
user can rerun these Tasks by updating their Job to target a different Pool.
The Tasks can then run on the new Pool. If you want to override the requeue
behavior, then you should call resize Pool explicitly to shrink the Pool to
zero size before deleting the Pool. If you call an Update, Patch or Delete API
on a Pool in the deleting state, it will fail with HTTP status code 409 with
error code PoolBeingDeleted.
</remarks>
    </member>
    <member name="Delete(String,Int32,String,Boolean,String,RequestConditions,RequestContext)">
<example>
This sample shows how to call Delete with required parameters.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetPoolClient(<2022-10-01.16.0>);

Response response = client.Delete("<poolId>");
Console.WriteLine(response.Status);
]]></code>
This sample shows how to call Delete with all parameters.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetPoolClient(<2022-10-01.16.0>);

Response response = client.Delete("<poolId>", 1234, "<clientRequestId>", true, "<ocpDate>", null);
Console.WriteLine(response.Status);
]]></code>
</example>
<remarks>
When you request that a Pool be deleted, the following actions occur: the Pool
state is set to deleting; any ongoing resize operation on the Pool are stopped;
the Batch service starts resizing the Pool to zero Compute Nodes; any Tasks
running on existing Compute Nodes are terminated and requeued (as if a resize
Pool operation had been requested with the default requeue option); finally,
the Pool is removed from the system. Because running Tasks are requeued, the
user can rerun these Tasks by updating their Job to target a different Pool.
The Tasks can then run on the new Pool. If you want to override the requeue
behavior, then you should call resize Pool explicitly to shrink the Pool to
zero size before deleting the Pool. If you call an Update, Patch or Delete API
on a Pool in the deleting state, it will fail with HTTP status code 409 with
error code PoolBeingDeleted.
</remarks>
    </member>
    <member name="ExistsAsync(String,Int32,String,Boolean,String,RequestConditions,RequestContext)">
<example>
This sample shows how to call ExistsAsync with required parameters.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetPoolClient(<2022-10-01.16.0>);

Response response = await client.ExistsAsync("<poolId>");
Console.WriteLine(response.Status);
]]></code>
This sample shows how to call ExistsAsync with all parameters.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetPoolClient(<2022-10-01.16.0>);

Response response = await client.ExistsAsync("<poolId>", 1234, "<clientRequestId>", true, "<ocpDate>", null);
Console.WriteLine(response.Status);
]]></code>
</example>
    </member>
    <member name="Exists(String,Int32,String,Boolean,String,RequestConditions,RequestContext)">
<example>
This sample shows how to call Exists with required parameters.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetPoolClient(<2022-10-01.16.0>);

Response response = client.Exists("<poolId>");
Console.WriteLine(response.Status);
]]></code>
This sample shows how to call Exists with all parameters.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetPoolClient(<2022-10-01.16.0>);

Response response = client.Exists("<poolId>", 1234, "<clientRequestId>", true, "<ocpDate>", null);
Console.WriteLine(response.Status);
]]></code>
</example>
    </member>
    <member name="GetPoolAsync(String,Int32,String,Boolean,String,String,String,RequestConditions,RequestContext)">
<example>
This sample shows how to call GetPoolAsync with required parameters and parse the result.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetPoolClient(<2022-10-01.16.0>);

Response response = await client.GetPoolAsync("<poolId>");

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.ToString());
]]></code>
This sample shows how to call GetPoolAsync with all parameters, and how to parse the result.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetPoolClient(<2022-10-01.16.0>);

Response response = await client.GetPoolAsync("<poolId>", 1234, "<clientRequestId>", true, "<ocpDate>", "<select>", "<expand>", null);

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.GetProperty("id").ToString());
Console.WriteLine(result.GetProperty("displayName").ToString());
Console.WriteLine(result.GetProperty("url").ToString());
Console.WriteLine(result.GetProperty("eTag").ToString());
Console.WriteLine(result.GetProperty("lastModified").ToString());
Console.WriteLine(result.GetProperty("creationTime").ToString());
Console.WriteLine(result.GetProperty("state").ToString());
Console.WriteLine(result.GetProperty("stateTransitionTime").ToString());
Console.WriteLine(result.GetProperty("allocationState").ToString());
Console.WriteLine(result.GetProperty("allocationStateTransitionTime").ToString());
Console.WriteLine(result.GetProperty("vmSize").ToString());
Console.WriteLine(result.GetProperty("cloudServiceConfiguration").GetProperty("osFamily").ToString());
Console.WriteLine(result.GetProperty("cloudServiceConfiguration").GetProperty("osVersion").ToString());
Console.WriteLine(result.GetProperty("virtualMachineConfiguration").GetProperty("imageReference").GetProperty("publisher").ToString());
Console.WriteLine(result.GetProperty("virtualMachineConfiguration").GetProperty("imageReference").GetProperty("offer").ToString());
Console.WriteLine(result.GetProperty("virtualMachineConfiguration").GetProperty("imageReference").GetProperty("sku").ToString());
Console.WriteLine(result.GetProperty("virtualMachineConfiguration").GetProperty("imageReference").GetProperty("version").ToString());
Console.WriteLine(result.GetProperty("virtualMachineConfiguration").GetProperty("imageReference").GetProperty("virtualMachineImageId").ToString());
Console.WriteLine(result.GetProperty("virtualMachineConfiguration").GetProperty("imageReference").GetProperty("exactVersion").ToString());
Console.WriteLine(result.GetProperty("virtualMachineConfiguration").GetProperty("nodeAgentSKUId").ToString());
Console.WriteLine(result.GetProperty("virtualMachineConfiguration").GetProperty("windowsConfiguration").GetProperty("enableAutomaticUpdates").ToString());
Console.WriteLine(result.GetProperty("virtualMachineConfiguration").GetProperty("dataDisks")[0].GetProperty("lun").ToString());
Console.WriteLine(result.GetProperty("virtualMachineConfiguration").GetProperty("dataDisks")[0].GetProperty("caching").ToString());
Console.WriteLine(result.GetProperty("virtualMachineConfiguration").GetProperty("dataDisks")[0].GetProperty("diskSizeGB").ToString());
Console.WriteLine(result.GetProperty("virtualMachineConfiguration").GetProperty("dataDisks")[0].GetProperty("storageAccountType").ToString());
Console.WriteLine(result.GetProperty("virtualMachineConfiguration").GetProperty("licenseType").ToString());
Console.WriteLine(result.GetProperty("virtualMachineConfiguration").GetProperty("containerConfiguration").GetProperty("type").ToString());
Console.WriteLine(result.GetProperty("virtualMachineConfiguration").GetProperty("containerConfiguration").GetProperty("containerImageNames")[0].ToString());
Console.WriteLine(result.GetProperty("virtualMachineConfiguration").GetProperty("containerConfiguration").GetProperty("containerRegistries")[0].GetProperty("username").ToString());
Console.WriteLine(result.GetProperty("virtualMachineConfiguration").GetProperty("containerConfiguration").GetProperty("containerRegistries")[0].GetProperty("password").ToString());
Console.WriteLine(result.GetProperty("virtualMachineConfiguration").GetProperty("containerConfiguration").GetProperty("containerRegistries")[0].GetProperty("registryServer").ToString());
Console.WriteLine(result.GetProperty("virtualMachineConfiguration").GetProperty("containerConfiguration").GetProperty("containerRegistries")[0].GetProperty("identityReference").GetProperty("resourceId").ToString());
Console.WriteLine(result.GetProperty("virtualMachineConfiguration").GetProperty("diskEncryptionConfiguration").GetProperty("targets")[0].ToString());
Console.WriteLine(result.GetProperty("virtualMachineConfiguration").GetProperty("nodePlacementConfiguration").GetProperty("policy").ToString());
Console.WriteLine(result.GetProperty("virtualMachineConfiguration").GetProperty("extensions")[0].GetProperty("name").ToString());
Console.WriteLine(result.GetProperty("virtualMachineConfiguration").GetProperty("extensions")[0].GetProperty("publisher").ToString());
Console.WriteLine(result.GetProperty("virtualMachineConfiguration").GetProperty("extensions")[0].GetProperty("type").ToString());
Console.WriteLine(result.GetProperty("virtualMachineConfiguration").GetProperty("extensions")[0].GetProperty("typeHandlerVersion").ToString());
Console.WriteLine(result.GetProperty("virtualMachineConfiguration").GetProperty("extensions")[0].GetProperty("autoUpgradeMinorVersion").ToString());
Console.WriteLine(result.GetProperty("virtualMachineConfiguration").GetProperty("extensions")[0].GetProperty("provisionAfterExtensions")[0].ToString());
Console.WriteLine(result.GetProperty("virtualMachineConfiguration").GetProperty("osDisk").GetProperty("ephemeralOSDiskSettings").GetProperty("placement").ToString());
Console.WriteLine(result.GetProperty("resizeTimeout").ToString());
Console.WriteLine(result.GetProperty("resizeErrors")[0].GetProperty("code").ToString());
Console.WriteLine(result.GetProperty("resizeErrors")[0].GetProperty("message").ToString());
Console.WriteLine(result.GetProperty("resizeErrors")[0].GetProperty("values")[0].GetProperty("name").ToString());
Console.WriteLine(result.GetProperty("resizeErrors")[0].GetProperty("values")[0].GetProperty("value").ToString());
Console.WriteLine(result.GetProperty("currentDedicatedNodes").ToString());
Console.WriteLine(result.GetProperty("currentLowPriorityNodes").ToString());
Console.WriteLine(result.GetProperty("targetDedicatedNodes").ToString());
Console.WriteLine(result.GetProperty("targetLowPriorityNodes").ToString());
Console.WriteLine(result.GetProperty("enableAutoScale").ToString());
Console.WriteLine(result.GetProperty("autoScaleFormula").ToString());
Console.WriteLine(result.GetProperty("autoScaleEvaluationInterval").ToString());
Console.WriteLine(result.GetProperty("autoScaleRun").GetProperty("timestamp").ToString());
Console.WriteLine(result.GetProperty("autoScaleRun").GetProperty("results").ToString());
Console.WriteLine(result.GetProperty("autoScaleRun").GetProperty("error").GetProperty("code").ToString());
Console.WriteLine(result.GetProperty("autoScaleRun").GetProperty("error").GetProperty("message").ToString());
Console.WriteLine(result.GetProperty("autoScaleRun").GetProperty("error").GetProperty("values")[0].GetProperty("name").ToString());
Console.WriteLine(result.GetProperty("autoScaleRun").GetProperty("error").GetProperty("values")[0].GetProperty("value").ToString());
Console.WriteLine(result.GetProperty("enableInterNodeCommunication").ToString());
Console.WriteLine(result.GetProperty("networkConfiguration").GetProperty("subnetId").ToString());
Console.WriteLine(result.GetProperty("networkConfiguration").GetProperty("dynamicVNetAssignmentScope").ToString());
Console.WriteLine(result.GetProperty("networkConfiguration").GetProperty("endpointConfiguration").GetProperty("inboundNATPools")[0].GetProperty("name").ToString());
Console.WriteLine(result.GetProperty("networkConfiguration").GetProperty("endpointConfiguration").GetProperty("inboundNATPools")[0].GetProperty("protocol").ToString());
Console.WriteLine(result.GetProperty("networkConfiguration").GetProperty("endpointConfiguration").GetProperty("inboundNATPools")[0].GetProperty("backendPort").ToString());
Console.WriteLine(result.GetProperty("networkConfiguration").GetProperty("endpointConfiguration").GetProperty("inboundNATPools")[0].GetProperty("frontendPortRangeStart").ToString());
Console.WriteLine(result.GetProperty("networkConfiguration").GetProperty("endpointConfiguration").GetProperty("inboundNATPools")[0].GetProperty("frontendPortRangeEnd").ToString());
Console.WriteLine(result.GetProperty("networkConfiguration").GetProperty("endpointConfiguration").GetProperty("inboundNATPools")[0].GetProperty("networkSecurityGroupRules")[0].GetProperty("priority").ToString());
Console.WriteLine(result.GetProperty("networkConfiguration").GetProperty("endpointConfiguration").GetProperty("inboundNATPools")[0].GetProperty("networkSecurityGroupRules")[0].GetProperty("access").ToString());
Console.WriteLine(result.GetProperty("networkConfiguration").GetProperty("endpointConfiguration").GetProperty("inboundNATPools")[0].GetProperty("networkSecurityGroupRules")[0].GetProperty("sourceAddressPrefix").ToString());
Console.WriteLine(result.GetProperty("networkConfiguration").GetProperty("endpointConfiguration").GetProperty("inboundNATPools")[0].GetProperty("networkSecurityGroupRules")[0].GetProperty("sourcePortRanges")[0].ToString());
Console.WriteLine(result.GetProperty("networkConfiguration").GetProperty("publicIPAddressConfiguration").GetProperty("provision").ToString());
Console.WriteLine(result.GetProperty("networkConfiguration").GetProperty("publicIPAddressConfiguration").GetProperty("ipAddressIds")[0].ToString());
Console.WriteLine(result.GetProperty("startTask").GetProperty("commandLine").ToString());
Console.WriteLine(result.GetProperty("startTask").GetProperty("containerSettings").GetProperty("containerRunOptions").ToString());
Console.WriteLine(result.GetProperty("startTask").GetProperty("containerSettings").GetProperty("imageName").ToString());
Console.WriteLine(result.GetProperty("startTask").GetProperty("containerSettings").GetProperty("registry").GetProperty("username").ToString());
Console.WriteLine(result.GetProperty("startTask").GetProperty("containerSettings").GetProperty("registry").GetProperty("password").ToString());
Console.WriteLine(result.GetProperty("startTask").GetProperty("containerSettings").GetProperty("registry").GetProperty("registryServer").ToString());
Console.WriteLine(result.GetProperty("startTask").GetProperty("containerSettings").GetProperty("registry").GetProperty("identityReference").GetProperty("resourceId").ToString());
Console.WriteLine(result.GetProperty("startTask").GetProperty("containerSettings").GetProperty("workingDirectory").ToString());
Console.WriteLine(result.GetProperty("startTask").GetProperty("resourceFiles")[0].GetProperty("autoStorageContainerName").ToString());
Console.WriteLine(result.GetProperty("startTask").GetProperty("resourceFiles")[0].GetProperty("storageContainerUrl").ToString());
Console.WriteLine(result.GetProperty("startTask").GetProperty("resourceFiles")[0].GetProperty("httpUrl").ToString());
Console.WriteLine(result.GetProperty("startTask").GetProperty("resourceFiles")[0].GetProperty("blobPrefix").ToString());
Console.WriteLine(result.GetProperty("startTask").GetProperty("resourceFiles")[0].GetProperty("filePath").ToString());
Console.WriteLine(result.GetProperty("startTask").GetProperty("resourceFiles")[0].GetProperty("fileMode").ToString());
Console.WriteLine(result.GetProperty("startTask").GetProperty("resourceFiles")[0].GetProperty("identityReference").GetProperty("resourceId").ToString());
Console.WriteLine(result.GetProperty("startTask").GetProperty("environmentSettings")[0].GetProperty("name").ToString());
Console.WriteLine(result.GetProperty("startTask").GetProperty("environmentSettings")[0].GetProperty("value").ToString());
Console.WriteLine(result.GetProperty("startTask").GetProperty("userIdentity").GetProperty("username").ToString());
Console.WriteLine(result.GetProperty("startTask").GetProperty("userIdentity").GetProperty("autoUser").GetProperty("scope").ToString());
Console.WriteLine(result.GetProperty("startTask").GetProperty("userIdentity").GetProperty("autoUser").GetProperty("elevationLevel").ToString());
Console.WriteLine(result.GetProperty("startTask").GetProperty("maxTaskRetryCount").ToString());
Console.WriteLine(result.GetProperty("startTask").GetProperty("waitForSuccess").ToString());
Console.WriteLine(result.GetProperty("certificateReferences")[0].GetProperty("thumbprint").ToString());
Console.WriteLine(result.GetProperty("certificateReferences")[0].GetProperty("thumbprintAlgorithm").ToString());
Console.WriteLine(result.GetProperty("certificateReferences")[0].GetProperty("storeLocation").ToString());
Console.WriteLine(result.GetProperty("certificateReferences")[0].GetProperty("storeName").ToString());
Console.WriteLine(result.GetProperty("certificateReferences")[0].GetProperty("visibility")[0].ToString());
Console.WriteLine(result.GetProperty("applicationPackageReferences")[0].GetProperty("applicationId").ToString());
Console.WriteLine(result.GetProperty("applicationPackageReferences")[0].GetProperty("version").ToString());
Console.WriteLine(result.GetProperty("applicationLicenses")[0].ToString());
Console.WriteLine(result.GetProperty("taskSlotsPerNode").ToString());
Console.WriteLine(result.GetProperty("taskSchedulingPolicy").GetProperty("nodeFillType").ToString());
Console.WriteLine(result.GetProperty("userAccounts")[0].GetProperty("name").ToString());
Console.WriteLine(result.GetProperty("userAccounts")[0].GetProperty("password").ToString());
Console.WriteLine(result.GetProperty("userAccounts")[0].GetProperty("elevationLevel").ToString());
Console.WriteLine(result.GetProperty("userAccounts")[0].GetProperty("linuxUserConfiguration").GetProperty("uid").ToString());
Console.WriteLine(result.GetProperty("userAccounts")[0].GetProperty("linuxUserConfiguration").GetProperty("gid").ToString());
Console.WriteLine(result.GetProperty("userAccounts")[0].GetProperty("linuxUserConfiguration").GetProperty("sshPrivateKey").ToString());
Console.WriteLine(result.GetProperty("userAccounts")[0].GetProperty("windowsUserConfiguration").GetProperty("loginMode").ToString());
Console.WriteLine(result.GetProperty("metadata")[0].GetProperty("name").ToString());
Console.WriteLine(result.GetProperty("metadata")[0].GetProperty("value").ToString());
Console.WriteLine(result.GetProperty("stats").GetProperty("url").ToString());
Console.WriteLine(result.GetProperty("stats").GetProperty("startTime").ToString());
Console.WriteLine(result.GetProperty("stats").GetProperty("lastUpdateTime").ToString());
Console.WriteLine(result.GetProperty("stats").GetProperty("usageStats").GetProperty("startTime").ToString());
Console.WriteLine(result.GetProperty("stats").GetProperty("usageStats").GetProperty("lastUpdateTime").ToString());
Console.WriteLine(result.GetProperty("stats").GetProperty("usageStats").GetProperty("dedicatedCoreTime").ToString());
Console.WriteLine(result.GetProperty("stats").GetProperty("resourceStats").GetProperty("startTime").ToString());
Console.WriteLine(result.GetProperty("stats").GetProperty("resourceStats").GetProperty("lastUpdateTime").ToString());
Console.WriteLine(result.GetProperty("stats").GetProperty("resourceStats").GetProperty("avgCPUPercentage").ToString());
Console.WriteLine(result.GetProperty("stats").GetProperty("resourceStats").GetProperty("avgMemoryGiB").ToString());
Console.WriteLine(result.GetProperty("stats").GetProperty("resourceStats").GetProperty("peakMemoryGiB").ToString());
Console.WriteLine(result.GetProperty("stats").GetProperty("resourceStats").GetProperty("avgDiskGiB").ToString());
Console.WriteLine(result.GetProperty("stats").GetProperty("resourceStats").GetProperty("peakDiskGiB").ToString());
Console.WriteLine(result.GetProperty("stats").GetProperty("resourceStats").GetProperty("diskReadIOps").ToString());
Console.WriteLine(result.GetProperty("stats").GetProperty("resourceStats").GetProperty("diskWriteIOps").ToString());
Console.WriteLine(result.GetProperty("stats").GetProperty("resourceStats").GetProperty("diskReadGiB").ToString());
Console.WriteLine(result.GetProperty("stats").GetProperty("resourceStats").GetProperty("diskWriteGiB").ToString());
Console.WriteLine(result.GetProperty("stats").GetProperty("resourceStats").GetProperty("networkReadGiB").ToString());
Console.WriteLine(result.GetProperty("stats").GetProperty("resourceStats").GetProperty("networkWriteGiB").ToString());
Console.WriteLine(result.GetProperty("mountConfiguration")[0].GetProperty("azureBlobFileSystemConfiguration").GetProperty("accountName").ToString());
Console.WriteLine(result.GetProperty("mountConfiguration")[0].GetProperty("azureBlobFileSystemConfiguration").GetProperty("containerName").ToString());
Console.WriteLine(result.GetProperty("mountConfiguration")[0].GetProperty("azureBlobFileSystemConfiguration").GetProperty("accountKey").ToString());
Console.WriteLine(result.GetProperty("mountConfiguration")[0].GetProperty("azureBlobFileSystemConfiguration").GetProperty("sasKey").ToString());
Console.WriteLine(result.GetProperty("mountConfiguration")[0].GetProperty("azureBlobFileSystemConfiguration").GetProperty("blobfuseOptions").ToString());
Console.WriteLine(result.GetProperty("mountConfiguration")[0].GetProperty("azureBlobFileSystemConfiguration").GetProperty("relativeMountPath").ToString());
Console.WriteLine(result.GetProperty("mountConfiguration")[0].GetProperty("azureBlobFileSystemConfiguration").GetProperty("identityReference").GetProperty("resourceId").ToString());
Console.WriteLine(result.GetProperty("mountConfiguration")[0].GetProperty("nfsMountConfiguration").GetProperty("source").ToString());
Console.WriteLine(result.GetProperty("mountConfiguration")[0].GetProperty("nfsMountConfiguration").GetProperty("relativeMountPath").ToString());
Console.WriteLine(result.GetProperty("mountConfiguration")[0].GetProperty("nfsMountConfiguration").GetProperty("mountOptions").ToString());
Console.WriteLine(result.GetProperty("mountConfiguration")[0].GetProperty("cifsMountConfiguration").GetProperty("username").ToString());
Console.WriteLine(result.GetProperty("mountConfiguration")[0].GetProperty("cifsMountConfiguration").GetProperty("source").ToString());
Console.WriteLine(result.GetProperty("mountConfiguration")[0].GetProperty("cifsMountConfiguration").GetProperty("relativeMountPath").ToString());
Console.WriteLine(result.GetProperty("mountConfiguration")[0].GetProperty("cifsMountConfiguration").GetProperty("mountOptions").ToString());
Console.WriteLine(result.GetProperty("mountConfiguration")[0].GetProperty("cifsMountConfiguration").GetProperty("password").ToString());
Console.WriteLine(result.GetProperty("mountConfiguration")[0].GetProperty("azureFileShareConfiguration").GetProperty("accountName").ToString());
Console.WriteLine(result.GetProperty("mountConfiguration")[0].GetProperty("azureFileShareConfiguration").GetProperty("azureFileUrl").ToString());
Console.WriteLine(result.GetProperty("mountConfiguration")[0].GetProperty("azureFileShareConfiguration").GetProperty("accountKey").ToString());
Console.WriteLine(result.GetProperty("mountConfiguration")[0].GetProperty("azureFileShareConfiguration").GetProperty("relativeMountPath").ToString());
Console.WriteLine(result.GetProperty("mountConfiguration")[0].GetProperty("azureFileShareConfiguration").GetProperty("mountOptions").ToString());
Console.WriteLine(result.GetProperty("identity").GetProperty("type").ToString());
Console.WriteLine(result.GetProperty("identity").GetProperty("userAssignedIdentities")[0].GetProperty("resourceId").ToString());
Console.WriteLine(result.GetProperty("identity").GetProperty("userAssignedIdentities")[0].GetProperty("clientId").ToString());
Console.WriteLine(result.GetProperty("identity").GetProperty("userAssignedIdentities")[0].GetProperty("principalId").ToString());
Console.WriteLine(result.GetProperty("targetNodeCommunicationMode").ToString());
Console.WriteLine(result.GetProperty("currentNodeCommunicationMode").ToString());
]]></code>
</example>
<remarks>
Below is the JSON schema for the response payload.

Response Body:

Schema for <c>BatchPool</c>:
<code>{
  id: string, # Optional. The ID can contain any combination of alphanumeric characters including hyphens
and underscores, and cannot contain more than 64 characters. The ID is
case-preserving and case-insensitive (that is, you may not have two IDs within
an Account that differ only by case).
  displayName: string, # Optional. The display name need not be unique and can contain any Unicode characters up
to a maximum length of 1024.
  url: string, # Optional. The URL of the Pool.
  eTag: string, # Optional. This is an opaque string. You can use it to detect whether the Pool has changed
between requests. In particular, you can be pass the ETag when updating a Pool
to specify that your changes should take effect only if nobody else has
modified the Pool in the meantime.
  lastModified: string (date &amp; time), # Optional. This is the last time at which the Pool level data, such as the
targetDedicatedNodes or enableAutoscale settings, changed. It does not factor
in node-level changes such as a Compute Node changing state.
  creationTime: string (date &amp; time), # Optional. The creation time of the Pool.
  state: &quot;active&quot; | &quot;deleting&quot;, # Optional. The current state of the Pool.
  stateTransitionTime: string (date &amp; time), # Optional. The time at which the Pool entered its current state.
  allocationState: &quot;steady&quot; | &quot;resizing&quot; | &quot;stopping&quot;, # Optional. Whether the Pool is resizing.
  allocationStateTransitionTime: string (date &amp; time), # Optional. The time at which the Pool entered its current allocation state.
  vmSize: string, # Optional. For information about available sizes of virtual machines in Pools, see Choose
a VM size for Compute Nodes in an Azure Batch Pool
(https://docs.microsoft.com/azure/batch/batch-pool-vm-sizes).
  cloudServiceConfiguration: {
    osFamily: string, # Required. Possible values are:
2 - OS Family 2, equivalent to Windows Server 2008 R2
SP1.
3 - OS Family 3, equivalent to Windows Server 2012.
4 - OS Family 4,
equivalent to Windows Server 2012 R2.
5 - OS Family 5, equivalent to Windows
Server 2016.
6 - OS Family 6, equivalent to Windows Server 2019. For more
information, see Azure Guest OS Releases
(https://azure.microsoft.com/documentation/articles/cloud-services-guestos-update-matrix/#releases).
    osVersion: string, # Optional. The default value is * which specifies the latest operating system version for
the specified OS family.
  }, # Optional. This property and virtualMachineConfiguration are mutually exclusive and one of
the properties must be specified. This property cannot be specified if the
Batch Account was created with its poolAllocationMode property set to
&apos;UserSubscription&apos;.
  virtualMachineConfiguration: {
    imageReference: {
      publisher: string, # Optional. For example, Canonical or MicrosoftWindowsServer.
      offer: string, # Optional. For example, UbuntuServer or WindowsServer.
      sku: string, # Optional. For example, 18.04-LTS or 2019-Datacenter.
      version: string, # Optional. A value of &apos;latest&apos; can be specified to select the latest version of an Image.
If omitted, the default is &apos;latest&apos;.
      virtualMachineImageId: string, # Optional. This property is mutually exclusive with other ImageReference properties. The
Shared Image Gallery Image must have replicas in the same region and must be in
the same subscription as the Azure Batch account. If the image version is not
specified in the imageId, the latest version will be used. For information
about the firewall settings for the Batch Compute Node agent to communicate
with the Batch service see
https://docs.microsoft.com/en-us/azure/batch/batch-api-basics#virtual-network-vnet-and-firewall-configuration.
      exactVersion: string, # Optional. The specific version of the platform image or marketplace image used to create
the node. This read-only field differs from &apos;version&apos; only if the value
specified for &apos;version&apos; when the pool was created was &apos;latest&apos;.
    }, # Required. A reference to an Azure Virtual Machines Marketplace Image or a Shared Image
Gallery Image. To get the list of all Azure Marketplace Image references
verified by Azure Batch, see the &apos;List Supported Images&apos; operation.
    nodeAgentSKUId: string, # Required. The Batch Compute Node agent is a program that runs on each Compute Node in the
Pool, and provides the command-and-control interface between the Compute Node
and the Batch service. There are different implementations of the Compute Node
agent, known as SKUs, for different operating systems. You must specify a
Compute Node agent SKU which matches the selected Image reference. To get the
list of supported Compute Node agent SKUs along with their list of verified
Image references, see the &apos;List supported Compute Node agent SKUs&apos; operation.
    windowsConfiguration: {
      enableAutomaticUpdates: boolean, # Optional. If omitted, the default value is true.
    }, # Optional. This property must not be specified if the imageReference property specifies a
Linux OS Image.
    dataDisks: [DataDisk], # Optional. This property must be specified if the Compute Nodes in the Pool need to have
empty data disks attached to them. This cannot be updated. Each Compute Node
gets its own disk (the disk is not a file share). Existing disks cannot be
attached, each attached disk is empty. When the Compute Node is removed from
the Pool, the disk and all data associated with it is also deleted. The disk is
not formatted after being attached, it must be formatted before use - for more
information see
https://docs.microsoft.com/en-us/azure/virtual-machines/linux/classic/attach-disk#initialize-a-new-data-disk-in-linux
and
https://docs.microsoft.com/en-us/azure/virtual-machines/windows/attach-disk-ps#add-an-empty-data-disk-to-a-virtual-machine.
    licenseType: string, # Optional. This only applies to Images that contain the Windows operating system, and
should only be used when you hold valid on-premises licenses for the Compute
Nodes which will be deployed. If omitted, no on-premises licensing discount is
applied. Values are:

 Windows_Server - The on-premises license is for Windows
Server.
 Windows_Client - The on-premises license is for Windows Client.

    containerConfiguration: {
      type: &quot;dockerCompatible&quot;, # Required. The container technology to be used.
      containerImageNames: [string], # Optional. This is the full Image reference, as would be specified to &quot;docker pull&quot;. An
Image will be sourced from the default Docker registry unless the Image is
fully qualified with an alternative registry.
      containerRegistries: [
        {
          username: string, # Optional. The user name to log into the registry server.
          password: string, # Optional. The password to log into the registry server.
          registryServer: string, # Optional. If omitted, the default is &quot;docker.io&quot;.
          identityReference: {
            resourceId: string, # Optional. The ARM resource id of the user assigned identity.
          }, # Optional. The reference to a user assigned identity associated with the Batch pool which
a compute node will use.
        }
      ], # Optional. If any Images must be downloaded from a private registry which requires
credentials, then those credentials must be provided here.
    }, # Optional. If specified, setup is performed on each Compute Node in the Pool to allow
Tasks to run in containers. All regular Tasks and Job manager Tasks run on this
Pool must specify the containerSettings property, and all other Tasks may
specify it.
    diskEncryptionConfiguration: {
      targets: [&quot;osdisk&quot; | &quot;temporarydisk&quot;], # Optional. If omitted, no disks on the compute nodes in the pool will be encrypted. On
Linux pool, only &quot;TemporaryDisk&quot; is supported; on Windows pool, &quot;OsDisk&quot;
and &quot;TemporaryDisk&quot; must be specified.
    }, # Optional. If specified, encryption is performed on each node in the pool during node
provisioning.
    nodePlacementConfiguration: {
      policy: &quot;regional&quot; | &quot;zonal&quot;, # Optional. Allocation policy used by Batch Service to provision the nodes. If not
specified, Batch will use the regional policy.
    }, # Optional. This configuration will specify rules on how nodes in the pool will be
physically allocated.
    extensions: [VMExtension], # Optional. If specified, the extensions mentioned in this configuration will be installed
on each node.
    osDisk: {
      ephemeralOSDiskSettings: {
        placement: &quot;cachedisk&quot;, # Optional. This property can be used by user in the request to choose the location e.g.,
cache disk space for Ephemeral OS disk provisioning. For more information on
Ephemeral OS disk size requirements, please refer to Ephemeral OS disk size
requirements for Windows VMs at
https://docs.microsoft.com/en-us/azure/virtual-machines/windows/ephemeral-os-disks#size-requirements
and Linux VMs at
https://docs.microsoft.com/en-us/azure/virtual-machines/linux/ephemeral-os-disks#size-requirements.
      }, # Optional. Specifies the ephemeral Disk Settings for the operating system disk used by the
compute node (VM).
    }, # Optional. Settings for the operating system disk of the compute node (VM).
  }, # Optional. This property and cloudServiceConfiguration are mutually exclusive and one of
the properties must be specified.
  resizeTimeout: string (duration ISO 8601 Format), # Optional. This is the timeout for the most recent resize operation. (The initial sizing
when the Pool is created counts as a resize.) The default value is 15 minutes.
  resizeErrors: [
    {
      code: string, # Optional. An identifier for the Pool resize error. Codes are invariant and are intended
to be consumed programmatically.
      message: string, # Optional. A message describing the Pool resize error, intended to be suitable for display
in a user interface.
      values: [NameValuePair], # Optional. A list of additional error details related to the Pool resize error.
    }
  ], # Optional. This property is set only if one or more errors occurred during the last Pool
resize, and only when the Pool allocationState is Steady.
  currentDedicatedNodes: number, # Optional. The number of dedicated Compute Nodes currently in the Pool.
  currentLowPriorityNodes: number, # Optional. Spot/Low-priority Compute Nodes which have been preempted are included in this
count.
  targetDedicatedNodes: number, # Optional. The desired number of dedicated Compute Nodes in the Pool.
  targetLowPriorityNodes: number, # Optional. The desired number of Spot/Low-priority Compute Nodes in the Pool.
  enableAutoScale: boolean, # Optional. If false, at least one of targetDedicatedNodes and targetLowPriorityNodes must
be specified. If true, the autoScaleFormula property is required and the Pool
automatically resizes according to the formula. The default value is false.
  autoScaleFormula: string, # Optional. This property is set only if the Pool automatically scales, i.e.
enableAutoScale is true.
  autoScaleEvaluationInterval: string (duration ISO 8601 Format), # Optional. This property is set only if the Pool automatically scales, i.e.
enableAutoScale is true.
  autoScaleRun: {
    timestamp: string (date &amp; time), # Required. The time at which the autoscale formula was last evaluated.
    results: string, # Optional. Each variable value is returned in the form $variable=value, and variables are
separated by semicolons.
    error: {
      code: string, # Optional. An identifier for the autoscale error. Codes are invariant and are intended to
be consumed programmatically.
      message: string, # Optional. A message describing the autoscale error, intended to be suitable for display
in a user interface.
      values: [NameValuePair], # Optional. A list of additional error details related to the autoscale error.
    }, # Optional. An error that occurred when executing or evaluating a Pool autoscale formula.
  }, # Optional. This property is set only if the Pool automatically scales, i.e.
enableAutoScale is true.
  enableInterNodeCommunication: boolean, # Optional. This imposes restrictions on which Compute Nodes can be assigned to the Pool.
Specifying this value can reduce the chance of the requested number of Compute
Nodes to be allocated in the Pool.
  networkConfiguration: {
    subnetId: string, # Optional. The virtual network must be in the same region and subscription as the Azure
Batch Account. The specified subnet should have enough free IP addresses to
accommodate the number of Compute Nodes in the Pool. If the subnet doesn&apos;t have
enough free IP addresses, the Pool will partially allocate Nodes and a resize
error will occur. The &apos;MicrosoftAzureBatch&apos; service principal must have the
&apos;Classic Virtual Machine Contributor&apos; Role-Based Access Control (RBAC) role for
the specified VNet. The specified subnet must allow communication from the
Azure Batch service to be able to schedule Tasks on the Nodes. This can be
verified by checking if the specified VNet has any associated Network Security
Groups (NSG). If communication to the Nodes in the specified subnet is denied
by an NSG, then the Batch service will set the state of the Compute Nodes to
unusable. For Pools created with virtualMachineConfiguration only ARM virtual
networks (&apos;Microsoft.Network/virtualNetworks&apos;) are supported, but for Pools
created with cloudServiceConfiguration both ARM and classic virtual networks
are supported. If the specified VNet has any associated Network Security Groups
(NSG), then a few reserved system ports must be enabled for inbound
communication. For Pools created with a virtual machine configuration, enable
ports 29876 and 29877, as well as port 22 for Linux and port 3389 for Windows.
For Pools created with a cloud service configuration, enable ports 10100,
20100, and 30100. Also enable outbound connections to Azure Storage on port
443. For more details see:
https://docs.microsoft.com/en-us/azure/batch/batch-api-basics#virtual-network-vnet-and-firewall-configuration
    dynamicVNetAssignmentScope: &quot;none&quot; | &quot;job&quot;, # Optional. The scope of dynamic vnet assignment.
    endpointConfiguration: {
      inboundNATPools: [InboundNATPool], # Required. The maximum number of inbound NAT Pools per Batch Pool is 5. If the maximum
number of inbound NAT Pools is exceeded the request fails with HTTP status code
400. This cannot be specified if the IPAddressProvisioningType is
NoPublicIPAddresses.
    }, # Optional. Pool endpoint configuration is only supported on Pools with the
virtualMachineConfiguration property.
    publicIPAddressConfiguration: {
      provision: &quot;batchmanaged&quot; | &quot;usermanaged&quot; | &quot;nopublicipaddresses&quot;, # Optional. The default value is BatchManaged.
      ipAddressIds: [string], # Optional. The number of IPs specified here limits the maximum size of the Pool - 100
dedicated nodes or 100 Spot/Low-priority nodes can be allocated for each public
IP. For example, a pool needing 250 dedicated VMs would need at least 3 public
IPs specified. Each element of this collection is of the form:
/subscriptions/{subscription}/resourceGroups/{group}/providers/Microsoft.Network/publicIPAddresses/{ip}.
    }, # Optional. Public IP configuration property is only supported on Pools with the
virtualMachineConfiguration property.
  }, # Optional. The network configuration for a Pool.
  startTask: {
    commandLine: string, # Required. The command line does not run under a shell, and therefore cannot take
advantage of shell features such as environment variable expansion. If you want
to take advantage of such features, you should invoke the shell in the command
line, for example using &quot;cmd /c MyCommand&quot; in Windows or &quot;/bin/sh -c
MyCommand&quot; in Linux. If the command line refers to file paths, it should use a
relative path (relative to the Task working directory), or use the Batch
provided environment variable
(https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).
    containerSettings: {
      containerRunOptions: string, # Optional. These additional options are supplied as arguments to the &quot;docker create&quot;
command, in addition to those controlled by the Batch Service.
      imageName: string, # Required. This is the full Image reference, as would be specified to &quot;docker pull&quot;. If
no tag is provided as part of the Image name, the tag &quot;:latest&quot; is used as a
default.
      registry: ContainerRegistry, # Optional. This setting can be omitted if was already provided at Pool creation.
      workingDirectory: &quot;taskWorkingDirectory&quot; | &quot;containerImageDefault&quot;, # Optional. The default is &apos;taskWorkingDirectory&apos;.
    }, # Optional. When this is specified, all directories recursively below the
AZ_BATCH_NODE_ROOT_DIR (the root of Azure Batch directories on the node) are
mapped into the container, all Task environment variables are mapped into the
container, and the Task command line is executed in the container. Files
produced in the container outside of AZ_BATCH_NODE_ROOT_DIR might not be
reflected to the host disk, meaning that Batch file APIs will not be able to
access those files.
    resourceFiles: [ResourceFile], # Optional. Files listed under this element are located in the Task&apos;s working directory.
    environmentSettings: [EnvironmentSetting], # Optional. A list of environment variable settings for the StartTask.
    userIdentity: {
      username: string, # Optional. The userName and autoUser properties are mutually exclusive; you must specify
one but not both.
      autoUser: {
        scope: &quot;task&quot; | &quot;pool&quot;, # Optional. The default value is pool. If the pool is running Windows a value of Task
should be specified if stricter isolation between tasks is required. For
example, if the task mutates the registry in a way which could impact other
tasks, or if certificates have been specified on the pool which should not be
accessible by normal tasks but should be accessible by StartTasks.
        elevationLevel: &quot;nonadmin&quot; | &quot;admin&quot;, # Optional. The default value is nonAdmin.
      }, # Optional. The userName and autoUser properties are mutually exclusive; you must specify
one but not both.
    }, # Optional. If omitted, the Task runs as a non-administrative user unique to the Task.
    maxTaskRetryCount: number, # Optional. The Batch service retries a Task if its exit code is nonzero. Note that this
value specifically controls the number of retries. The Batch service will try
the Task once, and may then retry up to this limit. For example, if the maximum
retry count is 3, Batch tries the Task up to 4 times (one initial try and 3
retries). If the maximum retry count is 0, the Batch service does not retry the
Task. If the maximum retry count is -1, the Batch service retries the Task
without limit, however this is not recommended for a start task or any task.
The default value is 0 (no retries)
    waitForSuccess: boolean, # Optional. If true and the StartTask fails on a Node, the Batch service retries the
StartTask up to its maximum retry count (maxTaskRetryCount). If the Task has
still not completed successfully after all retries, then the Batch service
marks the Node unusable, and will not schedule Tasks to it. This condition can
be detected via the Compute Node state and failure info details. If false, the
Batch service will not wait for the StartTask to complete. In this case, other
Tasks can start executing on the Compute Node while the StartTask is still
running; and even if the StartTask fails, new Tasks will continue to be
scheduled on the Compute Node. The default is true.
  }, # Optional. Batch will retry Tasks when a recovery operation is triggered on a Node.
Examples of recovery operations include (but are not limited to) when an
unhealthy Node is rebooted or a Compute Node disappeared due to host failure.
Retries due to recovery operations are independent of and are not counted
against the maxTaskRetryCount. Even if the maxTaskRetryCount is 0, an internal
retry due to a recovery operation may occur. Because of this, all Tasks should
be idempotent. This means Tasks need to tolerate being interrupted and
restarted without causing any corruption or duplicate data. The best practice
for long running Tasks is to use some form of checkpointing. In some cases the
StartTask may be re-run even though the Compute Node was not rebooted. Special
care should be taken to avoid StartTasks which create breakaway process or
install/launch services from the StartTask working directory, as this will
block Batch from being able to re-run the StartTask.
  certificateReferences: [CertificateReference], # Optional. For Windows Nodes, the Batch service installs the Certificates to the specified
Certificate store and location. For Linux Compute Nodes, the Certificates are
stored in a directory inside the Task working directory and an environment
variable AZ_BATCH_CERTIFICATES_DIR is supplied to the Task to query for this
location. For Certificates with visibility of &apos;remoteUser&apos;, a &apos;certs&apos; directory
is created in the user&apos;s home directory (e.g., /home/{user-name}/certs) and
Certificates are placed in that directory.
  applicationPackageReferences: [ApplicationPackageReference], # Optional. Changes to Package references affect all new Nodes joining the Pool, but do not
affect Compute Nodes that are already in the Pool until they are rebooted or
reimaged. There is a maximum of 10 Package references on any given Pool.
  applicationLicenses: [string], # Optional. The list of application licenses must be a subset of available Batch service
application licenses. If a license is requested which is not supported, Pool
creation will fail.
  taskSlotsPerNode: number, # Optional. The default value is 1. The maximum value is the smaller of 4 times the number
of cores of the vmSize of the pool or 256.
  taskSchedulingPolicy: {
    nodeFillType: &quot;spread&quot; | &quot;pack&quot;, # Required. If not specified, the default is spread.
  }, # Optional. If not specified, the default is spread.
  userAccounts: [UserAccount], # Optional. The list of user Accounts to be created on each Compute Node in the Pool.
  metadata: [MetadataItem], # Optional. A list of name-value pairs associated with the Pool as metadata.
  stats: {
    url: string, # Required. The URL for the statistics.
    startTime: string (date &amp; time), # Required. The start time of the time range covered by the statistics.
    lastUpdateTime: string (date &amp; time), # Required. The time at which the statistics were last updated. All statistics are limited
to the range between startTime and lastUpdateTime.
    usageStats: {
      startTime: string (date &amp; time), # Required. The start time of the time range covered by the statistics.
      lastUpdateTime: string (date &amp; time), # Required. The time at which the statistics were last updated. All statistics are limited
to the range between startTime and lastUpdateTime.
      dedicatedCoreTime: string (duration ISO 8601 Format), # Required. The aggregated wall-clock time of the dedicated Compute Node cores being part
of the Pool.
    }, # Optional. Statistics related to Pool usage information.
    resourceStats: {
      startTime: string (date &amp; time), # Required. The start time of the time range covered by the statistics.
      lastUpdateTime: string (date &amp; time), # Required. The time at which the statistics were last updated. All statistics are limited
to the range between startTime and lastUpdateTime.
      avgCPUPercentage: number, # Required. The average CPU usage across all Compute Nodes in the Pool (percentage per
node).
      avgMemoryGiB: number, # Required. The average memory usage in GiB across all Compute Nodes in the Pool.
      peakMemoryGiB: number, # Required. The peak memory usage in GiB across all Compute Nodes in the Pool.
      avgDiskGiB: number, # Required. The average used disk space in GiB across all Compute Nodes in the Pool.
      peakDiskGiB: number, # Required. The peak used disk space in GiB across all Compute Nodes in the Pool.
      diskReadIOps: number, # Required. The total number of disk read operations across all Compute Nodes in the Pool.
      diskWriteIOps: number, # Required. The total number of disk write operations across all Compute Nodes in the Pool.
      diskReadGiB: number, # Required. The total amount of data in GiB of disk reads across all Compute Nodes in the
Pool.
      diskWriteGiB: number, # Required. The total amount of data in GiB of disk writes across all Compute Nodes in the
Pool.
      networkReadGiB: number, # Required. The total amount of data in GiB of network reads across all Compute Nodes in
the Pool.
      networkWriteGiB: number, # Required. The total amount of data in GiB of network writes across all Compute Nodes in
the Pool.
    }, # Optional. Statistics related to resource consumption by Compute Nodes in a Pool.
  }, # Optional. This property is populated only if the CloudPool was retrieved with an expand
clause including the &apos;stats&apos; attribute; otherwise it is null. The statistics
may not be immediately available. The Batch service performs periodic roll-up
of statistics. The typical delay is about 30 minutes.
  mountConfiguration: [MountConfiguration], # Optional. This supports Azure Files, NFS, CIFS/SMB, and Blobfuse.
  identity: {
    type: &quot;UserAssigned&quot; | &quot;None&quot;, # Required. The list of user identities associated with the Batch pool. The user identity
dictionary key references will be ARM resource ids in the form:
&apos;/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.ManagedIdentity/userAssignedIdentities/{identityName}&apos;.
    userAssignedIdentities: [UserAssignedIdentity], # Optional. The user identity dictionary key references will be ARM resource ids in the
form:
&apos;/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.ManagedIdentity/userAssignedIdentities/{identityName}&apos;.
  }, # Optional. The list of user identities associated with the Batch pool. The user identity
dictionary key references will be ARM resource ids in the form:
&apos;/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.ManagedIdentity/userAssignedIdentities/{identityName}&apos;.
  targetNodeCommunicationMode: &quot;default&quot; | &quot;classic&quot; | &quot;simplified&quot;, # Optional. If omitted, the default value is Default.
  currentNodeCommunicationMode: &quot;default&quot; | &quot;classic&quot; | &quot;simplified&quot;, # Optional. Determines how a pool communicates with the Batch service.
}
</code>

</remarks>
    </member>
    <member name="GetPool(String,Int32,String,Boolean,String,String,String,RequestConditions,RequestContext)">
<example>
This sample shows how to call GetPool with required parameters and parse the result.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetPoolClient(<2022-10-01.16.0>);

Response response = client.GetPool("<poolId>");

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.ToString());
]]></code>
This sample shows how to call GetPool with all parameters, and how to parse the result.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetPoolClient(<2022-10-01.16.0>);

Response response = client.GetPool("<poolId>", 1234, "<clientRequestId>", true, "<ocpDate>", "<select>", "<expand>", null);

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.GetProperty("id").ToString());
Console.WriteLine(result.GetProperty("displayName").ToString());
Console.WriteLine(result.GetProperty("url").ToString());
Console.WriteLine(result.GetProperty("eTag").ToString());
Console.WriteLine(result.GetProperty("lastModified").ToString());
Console.WriteLine(result.GetProperty("creationTime").ToString());
Console.WriteLine(result.GetProperty("state").ToString());
Console.WriteLine(result.GetProperty("stateTransitionTime").ToString());
Console.WriteLine(result.GetProperty("allocationState").ToString());
Console.WriteLine(result.GetProperty("allocationStateTransitionTime").ToString());
Console.WriteLine(result.GetProperty("vmSize").ToString());
Console.WriteLine(result.GetProperty("cloudServiceConfiguration").GetProperty("osFamily").ToString());
Console.WriteLine(result.GetProperty("cloudServiceConfiguration").GetProperty("osVersion").ToString());
Console.WriteLine(result.GetProperty("virtualMachineConfiguration").GetProperty("imageReference").GetProperty("publisher").ToString());
Console.WriteLine(result.GetProperty("virtualMachineConfiguration").GetProperty("imageReference").GetProperty("offer").ToString());
Console.WriteLine(result.GetProperty("virtualMachineConfiguration").GetProperty("imageReference").GetProperty("sku").ToString());
Console.WriteLine(result.GetProperty("virtualMachineConfiguration").GetProperty("imageReference").GetProperty("version").ToString());
Console.WriteLine(result.GetProperty("virtualMachineConfiguration").GetProperty("imageReference").GetProperty("virtualMachineImageId").ToString());
Console.WriteLine(result.GetProperty("virtualMachineConfiguration").GetProperty("imageReference").GetProperty("exactVersion").ToString());
Console.WriteLine(result.GetProperty("virtualMachineConfiguration").GetProperty("nodeAgentSKUId").ToString());
Console.WriteLine(result.GetProperty("virtualMachineConfiguration").GetProperty("windowsConfiguration").GetProperty("enableAutomaticUpdates").ToString());
Console.WriteLine(result.GetProperty("virtualMachineConfiguration").GetProperty("dataDisks")[0].GetProperty("lun").ToString());
Console.WriteLine(result.GetProperty("virtualMachineConfiguration").GetProperty("dataDisks")[0].GetProperty("caching").ToString());
Console.WriteLine(result.GetProperty("virtualMachineConfiguration").GetProperty("dataDisks")[0].GetProperty("diskSizeGB").ToString());
Console.WriteLine(result.GetProperty("virtualMachineConfiguration").GetProperty("dataDisks")[0].GetProperty("storageAccountType").ToString());
Console.WriteLine(result.GetProperty("virtualMachineConfiguration").GetProperty("licenseType").ToString());
Console.WriteLine(result.GetProperty("virtualMachineConfiguration").GetProperty("containerConfiguration").GetProperty("type").ToString());
Console.WriteLine(result.GetProperty("virtualMachineConfiguration").GetProperty("containerConfiguration").GetProperty("containerImageNames")[0].ToString());
Console.WriteLine(result.GetProperty("virtualMachineConfiguration").GetProperty("containerConfiguration").GetProperty("containerRegistries")[0].GetProperty("username").ToString());
Console.WriteLine(result.GetProperty("virtualMachineConfiguration").GetProperty("containerConfiguration").GetProperty("containerRegistries")[0].GetProperty("password").ToString());
Console.WriteLine(result.GetProperty("virtualMachineConfiguration").GetProperty("containerConfiguration").GetProperty("containerRegistries")[0].GetProperty("registryServer").ToString());
Console.WriteLine(result.GetProperty("virtualMachineConfiguration").GetProperty("containerConfiguration").GetProperty("containerRegistries")[0].GetProperty("identityReference").GetProperty("resourceId").ToString());
Console.WriteLine(result.GetProperty("virtualMachineConfiguration").GetProperty("diskEncryptionConfiguration").GetProperty("targets")[0].ToString());
Console.WriteLine(result.GetProperty("virtualMachineConfiguration").GetProperty("nodePlacementConfiguration").GetProperty("policy").ToString());
Console.WriteLine(result.GetProperty("virtualMachineConfiguration").GetProperty("extensions")[0].GetProperty("name").ToString());
Console.WriteLine(result.GetProperty("virtualMachineConfiguration").GetProperty("extensions")[0].GetProperty("publisher").ToString());
Console.WriteLine(result.GetProperty("virtualMachineConfiguration").GetProperty("extensions")[0].GetProperty("type").ToString());
Console.WriteLine(result.GetProperty("virtualMachineConfiguration").GetProperty("extensions")[0].GetProperty("typeHandlerVersion").ToString());
Console.WriteLine(result.GetProperty("virtualMachineConfiguration").GetProperty("extensions")[0].GetProperty("autoUpgradeMinorVersion").ToString());
Console.WriteLine(result.GetProperty("virtualMachineConfiguration").GetProperty("extensions")[0].GetProperty("provisionAfterExtensions")[0].ToString());
Console.WriteLine(result.GetProperty("virtualMachineConfiguration").GetProperty("osDisk").GetProperty("ephemeralOSDiskSettings").GetProperty("placement").ToString());
Console.WriteLine(result.GetProperty("resizeTimeout").ToString());
Console.WriteLine(result.GetProperty("resizeErrors")[0].GetProperty("code").ToString());
Console.WriteLine(result.GetProperty("resizeErrors")[0].GetProperty("message").ToString());
Console.WriteLine(result.GetProperty("resizeErrors")[0].GetProperty("values")[0].GetProperty("name").ToString());
Console.WriteLine(result.GetProperty("resizeErrors")[0].GetProperty("values")[0].GetProperty("value").ToString());
Console.WriteLine(result.GetProperty("currentDedicatedNodes").ToString());
Console.WriteLine(result.GetProperty("currentLowPriorityNodes").ToString());
Console.WriteLine(result.GetProperty("targetDedicatedNodes").ToString());
Console.WriteLine(result.GetProperty("targetLowPriorityNodes").ToString());
Console.WriteLine(result.GetProperty("enableAutoScale").ToString());
Console.WriteLine(result.GetProperty("autoScaleFormula").ToString());
Console.WriteLine(result.GetProperty("autoScaleEvaluationInterval").ToString());
Console.WriteLine(result.GetProperty("autoScaleRun").GetProperty("timestamp").ToString());
Console.WriteLine(result.GetProperty("autoScaleRun").GetProperty("results").ToString());
Console.WriteLine(result.GetProperty("autoScaleRun").GetProperty("error").GetProperty("code").ToString());
Console.WriteLine(result.GetProperty("autoScaleRun").GetProperty("error").GetProperty("message").ToString());
Console.WriteLine(result.GetProperty("autoScaleRun").GetProperty("error").GetProperty("values")[0].GetProperty("name").ToString());
Console.WriteLine(result.GetProperty("autoScaleRun").GetProperty("error").GetProperty("values")[0].GetProperty("value").ToString());
Console.WriteLine(result.GetProperty("enableInterNodeCommunication").ToString());
Console.WriteLine(result.GetProperty("networkConfiguration").GetProperty("subnetId").ToString());
Console.WriteLine(result.GetProperty("networkConfiguration").GetProperty("dynamicVNetAssignmentScope").ToString());
Console.WriteLine(result.GetProperty("networkConfiguration").GetProperty("endpointConfiguration").GetProperty("inboundNATPools")[0].GetProperty("name").ToString());
Console.WriteLine(result.GetProperty("networkConfiguration").GetProperty("endpointConfiguration").GetProperty("inboundNATPools")[0].GetProperty("protocol").ToString());
Console.WriteLine(result.GetProperty("networkConfiguration").GetProperty("endpointConfiguration").GetProperty("inboundNATPools")[0].GetProperty("backendPort").ToString());
Console.WriteLine(result.GetProperty("networkConfiguration").GetProperty("endpointConfiguration").GetProperty("inboundNATPools")[0].GetProperty("frontendPortRangeStart").ToString());
Console.WriteLine(result.GetProperty("networkConfiguration").GetProperty("endpointConfiguration").GetProperty("inboundNATPools")[0].GetProperty("frontendPortRangeEnd").ToString());
Console.WriteLine(result.GetProperty("networkConfiguration").GetProperty("endpointConfiguration").GetProperty("inboundNATPools")[0].GetProperty("networkSecurityGroupRules")[0].GetProperty("priority").ToString());
Console.WriteLine(result.GetProperty("networkConfiguration").GetProperty("endpointConfiguration").GetProperty("inboundNATPools")[0].GetProperty("networkSecurityGroupRules")[0].GetProperty("access").ToString());
Console.WriteLine(result.GetProperty("networkConfiguration").GetProperty("endpointConfiguration").GetProperty("inboundNATPools")[0].GetProperty("networkSecurityGroupRules")[0].GetProperty("sourceAddressPrefix").ToString());
Console.WriteLine(result.GetProperty("networkConfiguration").GetProperty("endpointConfiguration").GetProperty("inboundNATPools")[0].GetProperty("networkSecurityGroupRules")[0].GetProperty("sourcePortRanges")[0].ToString());
Console.WriteLine(result.GetProperty("networkConfiguration").GetProperty("publicIPAddressConfiguration").GetProperty("provision").ToString());
Console.WriteLine(result.GetProperty("networkConfiguration").GetProperty("publicIPAddressConfiguration").GetProperty("ipAddressIds")[0].ToString());
Console.WriteLine(result.GetProperty("startTask").GetProperty("commandLine").ToString());
Console.WriteLine(result.GetProperty("startTask").GetProperty("containerSettings").GetProperty("containerRunOptions").ToString());
Console.WriteLine(result.GetProperty("startTask").GetProperty("containerSettings").GetProperty("imageName").ToString());
Console.WriteLine(result.GetProperty("startTask").GetProperty("containerSettings").GetProperty("registry").GetProperty("username").ToString());
Console.WriteLine(result.GetProperty("startTask").GetProperty("containerSettings").GetProperty("registry").GetProperty("password").ToString());
Console.WriteLine(result.GetProperty("startTask").GetProperty("containerSettings").GetProperty("registry").GetProperty("registryServer").ToString());
Console.WriteLine(result.GetProperty("startTask").GetProperty("containerSettings").GetProperty("registry").GetProperty("identityReference").GetProperty("resourceId").ToString());
Console.WriteLine(result.GetProperty("startTask").GetProperty("containerSettings").GetProperty("workingDirectory").ToString());
Console.WriteLine(result.GetProperty("startTask").GetProperty("resourceFiles")[0].GetProperty("autoStorageContainerName").ToString());
Console.WriteLine(result.GetProperty("startTask").GetProperty("resourceFiles")[0].GetProperty("storageContainerUrl").ToString());
Console.WriteLine(result.GetProperty("startTask").GetProperty("resourceFiles")[0].GetProperty("httpUrl").ToString());
Console.WriteLine(result.GetProperty("startTask").GetProperty("resourceFiles")[0].GetProperty("blobPrefix").ToString());
Console.WriteLine(result.GetProperty("startTask").GetProperty("resourceFiles")[0].GetProperty("filePath").ToString());
Console.WriteLine(result.GetProperty("startTask").GetProperty("resourceFiles")[0].GetProperty("fileMode").ToString());
Console.WriteLine(result.GetProperty("startTask").GetProperty("resourceFiles")[0].GetProperty("identityReference").GetProperty("resourceId").ToString());
Console.WriteLine(result.GetProperty("startTask").GetProperty("environmentSettings")[0].GetProperty("name").ToString());
Console.WriteLine(result.GetProperty("startTask").GetProperty("environmentSettings")[0].GetProperty("value").ToString());
Console.WriteLine(result.GetProperty("startTask").GetProperty("userIdentity").GetProperty("username").ToString());
Console.WriteLine(result.GetProperty("startTask").GetProperty("userIdentity").GetProperty("autoUser").GetProperty("scope").ToString());
Console.WriteLine(result.GetProperty("startTask").GetProperty("userIdentity").GetProperty("autoUser").GetProperty("elevationLevel").ToString());
Console.WriteLine(result.GetProperty("startTask").GetProperty("maxTaskRetryCount").ToString());
Console.WriteLine(result.GetProperty("startTask").GetProperty("waitForSuccess").ToString());
Console.WriteLine(result.GetProperty("certificateReferences")[0].GetProperty("thumbprint").ToString());
Console.WriteLine(result.GetProperty("certificateReferences")[0].GetProperty("thumbprintAlgorithm").ToString());
Console.WriteLine(result.GetProperty("certificateReferences")[0].GetProperty("storeLocation").ToString());
Console.WriteLine(result.GetProperty("certificateReferences")[0].GetProperty("storeName").ToString());
Console.WriteLine(result.GetProperty("certificateReferences")[0].GetProperty("visibility")[0].ToString());
Console.WriteLine(result.GetProperty("applicationPackageReferences")[0].GetProperty("applicationId").ToString());
Console.WriteLine(result.GetProperty("applicationPackageReferences")[0].GetProperty("version").ToString());
Console.WriteLine(result.GetProperty("applicationLicenses")[0].ToString());
Console.WriteLine(result.GetProperty("taskSlotsPerNode").ToString());
Console.WriteLine(result.GetProperty("taskSchedulingPolicy").GetProperty("nodeFillType").ToString());
Console.WriteLine(result.GetProperty("userAccounts")[0].GetProperty("name").ToString());
Console.WriteLine(result.GetProperty("userAccounts")[0].GetProperty("password").ToString());
Console.WriteLine(result.GetProperty("userAccounts")[0].GetProperty("elevationLevel").ToString());
Console.WriteLine(result.GetProperty("userAccounts")[0].GetProperty("linuxUserConfiguration").GetProperty("uid").ToString());
Console.WriteLine(result.GetProperty("userAccounts")[0].GetProperty("linuxUserConfiguration").GetProperty("gid").ToString());
Console.WriteLine(result.GetProperty("userAccounts")[0].GetProperty("linuxUserConfiguration").GetProperty("sshPrivateKey").ToString());
Console.WriteLine(result.GetProperty("userAccounts")[0].GetProperty("windowsUserConfiguration").GetProperty("loginMode").ToString());
Console.WriteLine(result.GetProperty("metadata")[0].GetProperty("name").ToString());
Console.WriteLine(result.GetProperty("metadata")[0].GetProperty("value").ToString());
Console.WriteLine(result.GetProperty("stats").GetProperty("url").ToString());
Console.WriteLine(result.GetProperty("stats").GetProperty("startTime").ToString());
Console.WriteLine(result.GetProperty("stats").GetProperty("lastUpdateTime").ToString());
Console.WriteLine(result.GetProperty("stats").GetProperty("usageStats").GetProperty("startTime").ToString());
Console.WriteLine(result.GetProperty("stats").GetProperty("usageStats").GetProperty("lastUpdateTime").ToString());
Console.WriteLine(result.GetProperty("stats").GetProperty("usageStats").GetProperty("dedicatedCoreTime").ToString());
Console.WriteLine(result.GetProperty("stats").GetProperty("resourceStats").GetProperty("startTime").ToString());
Console.WriteLine(result.GetProperty("stats").GetProperty("resourceStats").GetProperty("lastUpdateTime").ToString());
Console.WriteLine(result.GetProperty("stats").GetProperty("resourceStats").GetProperty("avgCPUPercentage").ToString());
Console.WriteLine(result.GetProperty("stats").GetProperty("resourceStats").GetProperty("avgMemoryGiB").ToString());
Console.WriteLine(result.GetProperty("stats").GetProperty("resourceStats").GetProperty("peakMemoryGiB").ToString());
Console.WriteLine(result.GetProperty("stats").GetProperty("resourceStats").GetProperty("avgDiskGiB").ToString());
Console.WriteLine(result.GetProperty("stats").GetProperty("resourceStats").GetProperty("peakDiskGiB").ToString());
Console.WriteLine(result.GetProperty("stats").GetProperty("resourceStats").GetProperty("diskReadIOps").ToString());
Console.WriteLine(result.GetProperty("stats").GetProperty("resourceStats").GetProperty("diskWriteIOps").ToString());
Console.WriteLine(result.GetProperty("stats").GetProperty("resourceStats").GetProperty("diskReadGiB").ToString());
Console.WriteLine(result.GetProperty("stats").GetProperty("resourceStats").GetProperty("diskWriteGiB").ToString());
Console.WriteLine(result.GetProperty("stats").GetProperty("resourceStats").GetProperty("networkReadGiB").ToString());
Console.WriteLine(result.GetProperty("stats").GetProperty("resourceStats").GetProperty("networkWriteGiB").ToString());
Console.WriteLine(result.GetProperty("mountConfiguration")[0].GetProperty("azureBlobFileSystemConfiguration").GetProperty("accountName").ToString());
Console.WriteLine(result.GetProperty("mountConfiguration")[0].GetProperty("azureBlobFileSystemConfiguration").GetProperty("containerName").ToString());
Console.WriteLine(result.GetProperty("mountConfiguration")[0].GetProperty("azureBlobFileSystemConfiguration").GetProperty("accountKey").ToString());
Console.WriteLine(result.GetProperty("mountConfiguration")[0].GetProperty("azureBlobFileSystemConfiguration").GetProperty("sasKey").ToString());
Console.WriteLine(result.GetProperty("mountConfiguration")[0].GetProperty("azureBlobFileSystemConfiguration").GetProperty("blobfuseOptions").ToString());
Console.WriteLine(result.GetProperty("mountConfiguration")[0].GetProperty("azureBlobFileSystemConfiguration").GetProperty("relativeMountPath").ToString());
Console.WriteLine(result.GetProperty("mountConfiguration")[0].GetProperty("azureBlobFileSystemConfiguration").GetProperty("identityReference").GetProperty("resourceId").ToString());
Console.WriteLine(result.GetProperty("mountConfiguration")[0].GetProperty("nfsMountConfiguration").GetProperty("source").ToString());
Console.WriteLine(result.GetProperty("mountConfiguration")[0].GetProperty("nfsMountConfiguration").GetProperty("relativeMountPath").ToString());
Console.WriteLine(result.GetProperty("mountConfiguration")[0].GetProperty("nfsMountConfiguration").GetProperty("mountOptions").ToString());
Console.WriteLine(result.GetProperty("mountConfiguration")[0].GetProperty("cifsMountConfiguration").GetProperty("username").ToString());
Console.WriteLine(result.GetProperty("mountConfiguration")[0].GetProperty("cifsMountConfiguration").GetProperty("source").ToString());
Console.WriteLine(result.GetProperty("mountConfiguration")[0].GetProperty("cifsMountConfiguration").GetProperty("relativeMountPath").ToString());
Console.WriteLine(result.GetProperty("mountConfiguration")[0].GetProperty("cifsMountConfiguration").GetProperty("mountOptions").ToString());
Console.WriteLine(result.GetProperty("mountConfiguration")[0].GetProperty("cifsMountConfiguration").GetProperty("password").ToString());
Console.WriteLine(result.GetProperty("mountConfiguration")[0].GetProperty("azureFileShareConfiguration").GetProperty("accountName").ToString());
Console.WriteLine(result.GetProperty("mountConfiguration")[0].GetProperty("azureFileShareConfiguration").GetProperty("azureFileUrl").ToString());
Console.WriteLine(result.GetProperty("mountConfiguration")[0].GetProperty("azureFileShareConfiguration").GetProperty("accountKey").ToString());
Console.WriteLine(result.GetProperty("mountConfiguration")[0].GetProperty("azureFileShareConfiguration").GetProperty("relativeMountPath").ToString());
Console.WriteLine(result.GetProperty("mountConfiguration")[0].GetProperty("azureFileShareConfiguration").GetProperty("mountOptions").ToString());
Console.WriteLine(result.GetProperty("identity").GetProperty("type").ToString());
Console.WriteLine(result.GetProperty("identity").GetProperty("userAssignedIdentities")[0].GetProperty("resourceId").ToString());
Console.WriteLine(result.GetProperty("identity").GetProperty("userAssignedIdentities")[0].GetProperty("clientId").ToString());
Console.WriteLine(result.GetProperty("identity").GetProperty("userAssignedIdentities")[0].GetProperty("principalId").ToString());
Console.WriteLine(result.GetProperty("targetNodeCommunicationMode").ToString());
Console.WriteLine(result.GetProperty("currentNodeCommunicationMode").ToString());
]]></code>
</example>
<remarks>
Below is the JSON schema for the response payload.

Response Body:

Schema for <c>BatchPool</c>:
<code>{
  id: string, # Optional. The ID can contain any combination of alphanumeric characters including hyphens
and underscores, and cannot contain more than 64 characters. The ID is
case-preserving and case-insensitive (that is, you may not have two IDs within
an Account that differ only by case).
  displayName: string, # Optional. The display name need not be unique and can contain any Unicode characters up
to a maximum length of 1024.
  url: string, # Optional. The URL of the Pool.
  eTag: string, # Optional. This is an opaque string. You can use it to detect whether the Pool has changed
between requests. In particular, you can be pass the ETag when updating a Pool
to specify that your changes should take effect only if nobody else has
modified the Pool in the meantime.
  lastModified: string (date &amp; time), # Optional. This is the last time at which the Pool level data, such as the
targetDedicatedNodes or enableAutoscale settings, changed. It does not factor
in node-level changes such as a Compute Node changing state.
  creationTime: string (date &amp; time), # Optional. The creation time of the Pool.
  state: &quot;active&quot; | &quot;deleting&quot;, # Optional. The current state of the Pool.
  stateTransitionTime: string (date &amp; time), # Optional. The time at which the Pool entered its current state.
  allocationState: &quot;steady&quot; | &quot;resizing&quot; | &quot;stopping&quot;, # Optional. Whether the Pool is resizing.
  allocationStateTransitionTime: string (date &amp; time), # Optional. The time at which the Pool entered its current allocation state.
  vmSize: string, # Optional. For information about available sizes of virtual machines in Pools, see Choose
a VM size for Compute Nodes in an Azure Batch Pool
(https://docs.microsoft.com/azure/batch/batch-pool-vm-sizes).
  cloudServiceConfiguration: {
    osFamily: string, # Required. Possible values are:
2 - OS Family 2, equivalent to Windows Server 2008 R2
SP1.
3 - OS Family 3, equivalent to Windows Server 2012.
4 - OS Family 4,
equivalent to Windows Server 2012 R2.
5 - OS Family 5, equivalent to Windows
Server 2016.
6 - OS Family 6, equivalent to Windows Server 2019. For more
information, see Azure Guest OS Releases
(https://azure.microsoft.com/documentation/articles/cloud-services-guestos-update-matrix/#releases).
    osVersion: string, # Optional. The default value is * which specifies the latest operating system version for
the specified OS family.
  }, # Optional. This property and virtualMachineConfiguration are mutually exclusive and one of
the properties must be specified. This property cannot be specified if the
Batch Account was created with its poolAllocationMode property set to
&apos;UserSubscription&apos;.
  virtualMachineConfiguration: {
    imageReference: {
      publisher: string, # Optional. For example, Canonical or MicrosoftWindowsServer.
      offer: string, # Optional. For example, UbuntuServer or WindowsServer.
      sku: string, # Optional. For example, 18.04-LTS or 2019-Datacenter.
      version: string, # Optional. A value of &apos;latest&apos; can be specified to select the latest version of an Image.
If omitted, the default is &apos;latest&apos;.
      virtualMachineImageId: string, # Optional. This property is mutually exclusive with other ImageReference properties. The
Shared Image Gallery Image must have replicas in the same region and must be in
the same subscription as the Azure Batch account. If the image version is not
specified in the imageId, the latest version will be used. For information
about the firewall settings for the Batch Compute Node agent to communicate
with the Batch service see
https://docs.microsoft.com/en-us/azure/batch/batch-api-basics#virtual-network-vnet-and-firewall-configuration.
      exactVersion: string, # Optional. The specific version of the platform image or marketplace image used to create
the node. This read-only field differs from &apos;version&apos; only if the value
specified for &apos;version&apos; when the pool was created was &apos;latest&apos;.
    }, # Required. A reference to an Azure Virtual Machines Marketplace Image or a Shared Image
Gallery Image. To get the list of all Azure Marketplace Image references
verified by Azure Batch, see the &apos;List Supported Images&apos; operation.
    nodeAgentSKUId: string, # Required. The Batch Compute Node agent is a program that runs on each Compute Node in the
Pool, and provides the command-and-control interface between the Compute Node
and the Batch service. There are different implementations of the Compute Node
agent, known as SKUs, for different operating systems. You must specify a
Compute Node agent SKU which matches the selected Image reference. To get the
list of supported Compute Node agent SKUs along with their list of verified
Image references, see the &apos;List supported Compute Node agent SKUs&apos; operation.
    windowsConfiguration: {
      enableAutomaticUpdates: boolean, # Optional. If omitted, the default value is true.
    }, # Optional. This property must not be specified if the imageReference property specifies a
Linux OS Image.
    dataDisks: [DataDisk], # Optional. This property must be specified if the Compute Nodes in the Pool need to have
empty data disks attached to them. This cannot be updated. Each Compute Node
gets its own disk (the disk is not a file share). Existing disks cannot be
attached, each attached disk is empty. When the Compute Node is removed from
the Pool, the disk and all data associated with it is also deleted. The disk is
not formatted after being attached, it must be formatted before use - for more
information see
https://docs.microsoft.com/en-us/azure/virtual-machines/linux/classic/attach-disk#initialize-a-new-data-disk-in-linux
and
https://docs.microsoft.com/en-us/azure/virtual-machines/windows/attach-disk-ps#add-an-empty-data-disk-to-a-virtual-machine.
    licenseType: string, # Optional. This only applies to Images that contain the Windows operating system, and
should only be used when you hold valid on-premises licenses for the Compute
Nodes which will be deployed. If omitted, no on-premises licensing discount is
applied. Values are:

 Windows_Server - The on-premises license is for Windows
Server.
 Windows_Client - The on-premises license is for Windows Client.

    containerConfiguration: {
      type: &quot;dockerCompatible&quot;, # Required. The container technology to be used.
      containerImageNames: [string], # Optional. This is the full Image reference, as would be specified to &quot;docker pull&quot;. An
Image will be sourced from the default Docker registry unless the Image is
fully qualified with an alternative registry.
      containerRegistries: [
        {
          username: string, # Optional. The user name to log into the registry server.
          password: string, # Optional. The password to log into the registry server.
          registryServer: string, # Optional. If omitted, the default is &quot;docker.io&quot;.
          identityReference: {
            resourceId: string, # Optional. The ARM resource id of the user assigned identity.
          }, # Optional. The reference to a user assigned identity associated with the Batch pool which
a compute node will use.
        }
      ], # Optional. If any Images must be downloaded from a private registry which requires
credentials, then those credentials must be provided here.
    }, # Optional. If specified, setup is performed on each Compute Node in the Pool to allow
Tasks to run in containers. All regular Tasks and Job manager Tasks run on this
Pool must specify the containerSettings property, and all other Tasks may
specify it.
    diskEncryptionConfiguration: {
      targets: [&quot;osdisk&quot; | &quot;temporarydisk&quot;], # Optional. If omitted, no disks on the compute nodes in the pool will be encrypted. On
Linux pool, only &quot;TemporaryDisk&quot; is supported; on Windows pool, &quot;OsDisk&quot;
and &quot;TemporaryDisk&quot; must be specified.
    }, # Optional. If specified, encryption is performed on each node in the pool during node
provisioning.
    nodePlacementConfiguration: {
      policy: &quot;regional&quot; | &quot;zonal&quot;, # Optional. Allocation policy used by Batch Service to provision the nodes. If not
specified, Batch will use the regional policy.
    }, # Optional. This configuration will specify rules on how nodes in the pool will be
physically allocated.
    extensions: [VMExtension], # Optional. If specified, the extensions mentioned in this configuration will be installed
on each node.
    osDisk: {
      ephemeralOSDiskSettings: {
        placement: &quot;cachedisk&quot;, # Optional. This property can be used by user in the request to choose the location e.g.,
cache disk space for Ephemeral OS disk provisioning. For more information on
Ephemeral OS disk size requirements, please refer to Ephemeral OS disk size
requirements for Windows VMs at
https://docs.microsoft.com/en-us/azure/virtual-machines/windows/ephemeral-os-disks#size-requirements
and Linux VMs at
https://docs.microsoft.com/en-us/azure/virtual-machines/linux/ephemeral-os-disks#size-requirements.
      }, # Optional. Specifies the ephemeral Disk Settings for the operating system disk used by the
compute node (VM).
    }, # Optional. Settings for the operating system disk of the compute node (VM).
  }, # Optional. This property and cloudServiceConfiguration are mutually exclusive and one of
the properties must be specified.
  resizeTimeout: string (duration ISO 8601 Format), # Optional. This is the timeout for the most recent resize operation. (The initial sizing
when the Pool is created counts as a resize.) The default value is 15 minutes.
  resizeErrors: [
    {
      code: string, # Optional. An identifier for the Pool resize error. Codes are invariant and are intended
to be consumed programmatically.
      message: string, # Optional. A message describing the Pool resize error, intended to be suitable for display
in a user interface.
      values: [NameValuePair], # Optional. A list of additional error details related to the Pool resize error.
    }
  ], # Optional. This property is set only if one or more errors occurred during the last Pool
resize, and only when the Pool allocationState is Steady.
  currentDedicatedNodes: number, # Optional. The number of dedicated Compute Nodes currently in the Pool.
  currentLowPriorityNodes: number, # Optional. Spot/Low-priority Compute Nodes which have been preempted are included in this
count.
  targetDedicatedNodes: number, # Optional. The desired number of dedicated Compute Nodes in the Pool.
  targetLowPriorityNodes: number, # Optional. The desired number of Spot/Low-priority Compute Nodes in the Pool.
  enableAutoScale: boolean, # Optional. If false, at least one of targetDedicatedNodes and targetLowPriorityNodes must
be specified. If true, the autoScaleFormula property is required and the Pool
automatically resizes according to the formula. The default value is false.
  autoScaleFormula: string, # Optional. This property is set only if the Pool automatically scales, i.e.
enableAutoScale is true.
  autoScaleEvaluationInterval: string (duration ISO 8601 Format), # Optional. This property is set only if the Pool automatically scales, i.e.
enableAutoScale is true.
  autoScaleRun: {
    timestamp: string (date &amp; time), # Required. The time at which the autoscale formula was last evaluated.
    results: string, # Optional. Each variable value is returned in the form $variable=value, and variables are
separated by semicolons.
    error: {
      code: string, # Optional. An identifier for the autoscale error. Codes are invariant and are intended to
be consumed programmatically.
      message: string, # Optional. A message describing the autoscale error, intended to be suitable for display
in a user interface.
      values: [NameValuePair], # Optional. A list of additional error details related to the autoscale error.
    }, # Optional. An error that occurred when executing or evaluating a Pool autoscale formula.
  }, # Optional. This property is set only if the Pool automatically scales, i.e.
enableAutoScale is true.
  enableInterNodeCommunication: boolean, # Optional. This imposes restrictions on which Compute Nodes can be assigned to the Pool.
Specifying this value can reduce the chance of the requested number of Compute
Nodes to be allocated in the Pool.
  networkConfiguration: {
    subnetId: string, # Optional. The virtual network must be in the same region and subscription as the Azure
Batch Account. The specified subnet should have enough free IP addresses to
accommodate the number of Compute Nodes in the Pool. If the subnet doesn&apos;t have
enough free IP addresses, the Pool will partially allocate Nodes and a resize
error will occur. The &apos;MicrosoftAzureBatch&apos; service principal must have the
&apos;Classic Virtual Machine Contributor&apos; Role-Based Access Control (RBAC) role for
the specified VNet. The specified subnet must allow communication from the
Azure Batch service to be able to schedule Tasks on the Nodes. This can be
verified by checking if the specified VNet has any associated Network Security
Groups (NSG). If communication to the Nodes in the specified subnet is denied
by an NSG, then the Batch service will set the state of the Compute Nodes to
unusable. For Pools created with virtualMachineConfiguration only ARM virtual
networks (&apos;Microsoft.Network/virtualNetworks&apos;) are supported, but for Pools
created with cloudServiceConfiguration both ARM and classic virtual networks
are supported. If the specified VNet has any associated Network Security Groups
(NSG), then a few reserved system ports must be enabled for inbound
communication. For Pools created with a virtual machine configuration, enable
ports 29876 and 29877, as well as port 22 for Linux and port 3389 for Windows.
For Pools created with a cloud service configuration, enable ports 10100,
20100, and 30100. Also enable outbound connections to Azure Storage on port
443. For more details see:
https://docs.microsoft.com/en-us/azure/batch/batch-api-basics#virtual-network-vnet-and-firewall-configuration
    dynamicVNetAssignmentScope: &quot;none&quot; | &quot;job&quot;, # Optional. The scope of dynamic vnet assignment.
    endpointConfiguration: {
      inboundNATPools: [InboundNATPool], # Required. The maximum number of inbound NAT Pools per Batch Pool is 5. If the maximum
number of inbound NAT Pools is exceeded the request fails with HTTP status code
400. This cannot be specified if the IPAddressProvisioningType is
NoPublicIPAddresses.
    }, # Optional. Pool endpoint configuration is only supported on Pools with the
virtualMachineConfiguration property.
    publicIPAddressConfiguration: {
      provision: &quot;batchmanaged&quot; | &quot;usermanaged&quot; | &quot;nopublicipaddresses&quot;, # Optional. The default value is BatchManaged.
      ipAddressIds: [string], # Optional. The number of IPs specified here limits the maximum size of the Pool - 100
dedicated nodes or 100 Spot/Low-priority nodes can be allocated for each public
IP. For example, a pool needing 250 dedicated VMs would need at least 3 public
IPs specified. Each element of this collection is of the form:
/subscriptions/{subscription}/resourceGroups/{group}/providers/Microsoft.Network/publicIPAddresses/{ip}.
    }, # Optional. Public IP configuration property is only supported on Pools with the
virtualMachineConfiguration property.
  }, # Optional. The network configuration for a Pool.
  startTask: {
    commandLine: string, # Required. The command line does not run under a shell, and therefore cannot take
advantage of shell features such as environment variable expansion. If you want
to take advantage of such features, you should invoke the shell in the command
line, for example using &quot;cmd /c MyCommand&quot; in Windows or &quot;/bin/sh -c
MyCommand&quot; in Linux. If the command line refers to file paths, it should use a
relative path (relative to the Task working directory), or use the Batch
provided environment variable
(https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).
    containerSettings: {
      containerRunOptions: string, # Optional. These additional options are supplied as arguments to the &quot;docker create&quot;
command, in addition to those controlled by the Batch Service.
      imageName: string, # Required. This is the full Image reference, as would be specified to &quot;docker pull&quot;. If
no tag is provided as part of the Image name, the tag &quot;:latest&quot; is used as a
default.
      registry: ContainerRegistry, # Optional. This setting can be omitted if was already provided at Pool creation.
      workingDirectory: &quot;taskWorkingDirectory&quot; | &quot;containerImageDefault&quot;, # Optional. The default is &apos;taskWorkingDirectory&apos;.
    }, # Optional. When this is specified, all directories recursively below the
AZ_BATCH_NODE_ROOT_DIR (the root of Azure Batch directories on the node) are
mapped into the container, all Task environment variables are mapped into the
container, and the Task command line is executed in the container. Files
produced in the container outside of AZ_BATCH_NODE_ROOT_DIR might not be
reflected to the host disk, meaning that Batch file APIs will not be able to
access those files.
    resourceFiles: [ResourceFile], # Optional. Files listed under this element are located in the Task&apos;s working directory.
    environmentSettings: [EnvironmentSetting], # Optional. A list of environment variable settings for the StartTask.
    userIdentity: {
      username: string, # Optional. The userName and autoUser properties are mutually exclusive; you must specify
one but not both.
      autoUser: {
        scope: &quot;task&quot; | &quot;pool&quot;, # Optional. The default value is pool. If the pool is running Windows a value of Task
should be specified if stricter isolation between tasks is required. For
example, if the task mutates the registry in a way which could impact other
tasks, or if certificates have been specified on the pool which should not be
accessible by normal tasks but should be accessible by StartTasks.
        elevationLevel: &quot;nonadmin&quot; | &quot;admin&quot;, # Optional. The default value is nonAdmin.
      }, # Optional. The userName and autoUser properties are mutually exclusive; you must specify
one but not both.
    }, # Optional. If omitted, the Task runs as a non-administrative user unique to the Task.
    maxTaskRetryCount: number, # Optional. The Batch service retries a Task if its exit code is nonzero. Note that this
value specifically controls the number of retries. The Batch service will try
the Task once, and may then retry up to this limit. For example, if the maximum
retry count is 3, Batch tries the Task up to 4 times (one initial try and 3
retries). If the maximum retry count is 0, the Batch service does not retry the
Task. If the maximum retry count is -1, the Batch service retries the Task
without limit, however this is not recommended for a start task or any task.
The default value is 0 (no retries)
    waitForSuccess: boolean, # Optional. If true and the StartTask fails on a Node, the Batch service retries the
StartTask up to its maximum retry count (maxTaskRetryCount). If the Task has
still not completed successfully after all retries, then the Batch service
marks the Node unusable, and will not schedule Tasks to it. This condition can
be detected via the Compute Node state and failure info details. If false, the
Batch service will not wait for the StartTask to complete. In this case, other
Tasks can start executing on the Compute Node while the StartTask is still
running; and even if the StartTask fails, new Tasks will continue to be
scheduled on the Compute Node. The default is true.
  }, # Optional. Batch will retry Tasks when a recovery operation is triggered on a Node.
Examples of recovery operations include (but are not limited to) when an
unhealthy Node is rebooted or a Compute Node disappeared due to host failure.
Retries due to recovery operations are independent of and are not counted
against the maxTaskRetryCount. Even if the maxTaskRetryCount is 0, an internal
retry due to a recovery operation may occur. Because of this, all Tasks should
be idempotent. This means Tasks need to tolerate being interrupted and
restarted without causing any corruption or duplicate data. The best practice
for long running Tasks is to use some form of checkpointing. In some cases the
StartTask may be re-run even though the Compute Node was not rebooted. Special
care should be taken to avoid StartTasks which create breakaway process or
install/launch services from the StartTask working directory, as this will
block Batch from being able to re-run the StartTask.
  certificateReferences: [CertificateReference], # Optional. For Windows Nodes, the Batch service installs the Certificates to the specified
Certificate store and location. For Linux Compute Nodes, the Certificates are
stored in a directory inside the Task working directory and an environment
variable AZ_BATCH_CERTIFICATES_DIR is supplied to the Task to query for this
location. For Certificates with visibility of &apos;remoteUser&apos;, a &apos;certs&apos; directory
is created in the user&apos;s home directory (e.g., /home/{user-name}/certs) and
Certificates are placed in that directory.
  applicationPackageReferences: [ApplicationPackageReference], # Optional. Changes to Package references affect all new Nodes joining the Pool, but do not
affect Compute Nodes that are already in the Pool until they are rebooted or
reimaged. There is a maximum of 10 Package references on any given Pool.
  applicationLicenses: [string], # Optional. The list of application licenses must be a subset of available Batch service
application licenses. If a license is requested which is not supported, Pool
creation will fail.
  taskSlotsPerNode: number, # Optional. The default value is 1. The maximum value is the smaller of 4 times the number
of cores of the vmSize of the pool or 256.
  taskSchedulingPolicy: {
    nodeFillType: &quot;spread&quot; | &quot;pack&quot;, # Required. If not specified, the default is spread.
  }, # Optional. If not specified, the default is spread.
  userAccounts: [UserAccount], # Optional. The list of user Accounts to be created on each Compute Node in the Pool.
  metadata: [MetadataItem], # Optional. A list of name-value pairs associated with the Pool as metadata.
  stats: {
    url: string, # Required. The URL for the statistics.
    startTime: string (date &amp; time), # Required. The start time of the time range covered by the statistics.
    lastUpdateTime: string (date &amp; time), # Required. The time at which the statistics were last updated. All statistics are limited
to the range between startTime and lastUpdateTime.
    usageStats: {
      startTime: string (date &amp; time), # Required. The start time of the time range covered by the statistics.
      lastUpdateTime: string (date &amp; time), # Required. The time at which the statistics were last updated. All statistics are limited
to the range between startTime and lastUpdateTime.
      dedicatedCoreTime: string (duration ISO 8601 Format), # Required. The aggregated wall-clock time of the dedicated Compute Node cores being part
of the Pool.
    }, # Optional. Statistics related to Pool usage information.
    resourceStats: {
      startTime: string (date &amp; time), # Required. The start time of the time range covered by the statistics.
      lastUpdateTime: string (date &amp; time), # Required. The time at which the statistics were last updated. All statistics are limited
to the range between startTime and lastUpdateTime.
      avgCPUPercentage: number, # Required. The average CPU usage across all Compute Nodes in the Pool (percentage per
node).
      avgMemoryGiB: number, # Required. The average memory usage in GiB across all Compute Nodes in the Pool.
      peakMemoryGiB: number, # Required. The peak memory usage in GiB across all Compute Nodes in the Pool.
      avgDiskGiB: number, # Required. The average used disk space in GiB across all Compute Nodes in the Pool.
      peakDiskGiB: number, # Required. The peak used disk space in GiB across all Compute Nodes in the Pool.
      diskReadIOps: number, # Required. The total number of disk read operations across all Compute Nodes in the Pool.
      diskWriteIOps: number, # Required. The total number of disk write operations across all Compute Nodes in the Pool.
      diskReadGiB: number, # Required. The total amount of data in GiB of disk reads across all Compute Nodes in the
Pool.
      diskWriteGiB: number, # Required. The total amount of data in GiB of disk writes across all Compute Nodes in the
Pool.
      networkReadGiB: number, # Required. The total amount of data in GiB of network reads across all Compute Nodes in
the Pool.
      networkWriteGiB: number, # Required. The total amount of data in GiB of network writes across all Compute Nodes in
the Pool.
    }, # Optional. Statistics related to resource consumption by Compute Nodes in a Pool.
  }, # Optional. This property is populated only if the CloudPool was retrieved with an expand
clause including the &apos;stats&apos; attribute; otherwise it is null. The statistics
may not be immediately available. The Batch service performs periodic roll-up
of statistics. The typical delay is about 30 minutes.
  mountConfiguration: [MountConfiguration], # Optional. This supports Azure Files, NFS, CIFS/SMB, and Blobfuse.
  identity: {
    type: &quot;UserAssigned&quot; | &quot;None&quot;, # Required. The list of user identities associated with the Batch pool. The user identity
dictionary key references will be ARM resource ids in the form:
&apos;/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.ManagedIdentity/userAssignedIdentities/{identityName}&apos;.
    userAssignedIdentities: [UserAssignedIdentity], # Optional. The user identity dictionary key references will be ARM resource ids in the
form:
&apos;/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.ManagedIdentity/userAssignedIdentities/{identityName}&apos;.
  }, # Optional. The list of user identities associated with the Batch pool. The user identity
dictionary key references will be ARM resource ids in the form:
&apos;/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.ManagedIdentity/userAssignedIdentities/{identityName}&apos;.
  targetNodeCommunicationMode: &quot;default&quot; | &quot;classic&quot; | &quot;simplified&quot;, # Optional. If omitted, the default value is Default.
  currentNodeCommunicationMode: &quot;default&quot; | &quot;classic&quot; | &quot;simplified&quot;, # Optional. Determines how a pool communicates with the Batch service.
}
</code>

</remarks>
    </member>
    <member name="PatchAsync(String,RequestContent,Int32,String,Boolean,String,RequestConditions,RequestContext)">
<example>
This sample shows how to call PatchAsync with required parameters.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetPoolClient(<2022-10-01.16.0>);

var data = new {};

Response response = await client.PatchAsync("<poolId>", RequestContent.Create(data));
Console.WriteLine(response.Status);
]]></code>
This sample shows how to call PatchAsync with all parameters and request content.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetPoolClient(<2022-10-01.16.0>);

var data = new {
    id = "<id>",
    displayName = "<displayName>",
    vmSize = "<vmSize>",
    cloudServiceConfiguration = new {
        osFamily = "<osFamily>",
        osVersion = "<osVersion>",
    },
    virtualMachineConfiguration = new {
        imageReference = new {
            publisher = "<publisher>",
            offer = "<offer>",
            sku = "<sku>",
            version = "<version>",
            virtualMachineImageId = "<virtualMachineImageId>",
        },
        nodeAgentSKUId = "<nodeAgentSKUId>",
        windowsConfiguration = new {
            enableAutomaticUpdates = true,
        },
        dataDisks = new[] {
            new {
                lun = 1234,
                caching = "none",
                diskSizeGB = 1234,
                storageAccountType = "standard_lrs",
            }
        },
        licenseType = "<licenseType>",
        containerConfiguration = new {
            type = "dockerCompatible",
            containerImageNames = new[] {
                "<String>"
            },
            containerRegistries = new[] {
                new {
                    username = "<username>",
                    password = "<password>",
                    registryServer = "<registryServer>",
                    identityReference = new {
                        resourceId = "<resourceId>",
                    },
                }
            },
        },
        diskEncryptionConfiguration = new {
            targets = new[] {
                "osdisk"
            },
        },
        nodePlacementConfiguration = new {
            policy = "regional",
        },
        extensions = new[] {
            new {
                name = "<name>",
                publisher = "<publisher>",
                type = "<type>",
                typeHandlerVersion = "<typeHandlerVersion>",
                autoUpgradeMinorVersion = true,
                settings = new {},
                protectedSettings = new {},
                provisionAfterExtensions = new[] {
                    "<String>"
                },
            }
        },
        osDisk = new {
            ephemeralOSDiskSettings = new {
                placement = "cachedisk",
            },
        },
    },
    resizeTimeout = PT1H23M45S,
    targetDedicatedNodes = 1234,
    targetLowPriorityNodes = 1234,
    enableAutoScale = true,
    autoScaleFormula = "<autoScaleFormula>",
    autoScaleEvaluationInterval = PT1H23M45S,
    enableInterNodeCommunication = true,
    networkConfiguration = new {
        subnetId = "<subnetId>",
        dynamicVNetAssignmentScope = "none",
        endpointConfiguration = new {
            inboundNATPools = new[] {
                new {
                    name = "<name>",
                    protocol = "tcp",
                    backendPort = 1234,
                    frontendPortRangeStart = 1234,
                    frontendPortRangeEnd = 1234,
                    networkSecurityGroupRules = new[] {
                        new {
                            priority = 1234,
                            access = "allow",
                            sourceAddressPrefix = "<sourceAddressPrefix>",
                            sourcePortRanges = new[] {
                                "<String>"
                            },
                        }
                    },
                }
            },
        },
        publicIPAddressConfiguration = new {
            provision = "batchmanaged",
            ipAddressIds = new[] {
                "<String>"
            },
        },
    },
    startTask = new {
        commandLine = "<commandLine>",
        containerSettings = new {
            containerRunOptions = "<containerRunOptions>",
            imageName = "<imageName>",
            registry = new {
                username = "<username>",
                password = "<password>",
                registryServer = "<registryServer>",
                identityReference = new {
                    resourceId = "<resourceId>",
                },
            },
            workingDirectory = "taskWorkingDirectory",
        },
        resourceFiles = new[] {
            new {
                autoStorageContainerName = "<autoStorageContainerName>",
                storageContainerUrl = "<storageContainerUrl>",
                httpUrl = "<httpUrl>",
                blobPrefix = "<blobPrefix>",
                filePath = "<filePath>",
                fileMode = "<fileMode>",
                identityReference = new {
                    resourceId = "<resourceId>",
                },
            }
        },
        environmentSettings = new[] {
            new {
                name = "<name>",
                value = "<value>",
            }
        },
        userIdentity = new {
            username = "<username>",
            autoUser = new {
                scope = "task",
                elevationLevel = "nonadmin",
            },
        },
        maxTaskRetryCount = 1234,
        waitForSuccess = true,
    },
    certificateReferences = new[] {
        new {
            thumbprint = "<thumbprint>",
            thumbprintAlgorithm = "<thumbprintAlgorithm>",
            storeLocation = "currentuser",
            storeName = "<storeName>",
            visibility = new[] {
                "starttask"
            },
        }
    },
    applicationPackageReferences = new[] {
        new {
            applicationId = "<applicationId>",
            version = "<version>",
        }
    },
    applicationLicenses = new[] {
        "<String>"
    },
    taskSlotsPerNode = 1234,
    taskSchedulingPolicy = new {
        nodeFillType = "spread",
    },
    userAccounts = new[] {
        new {
            name = "<name>",
            password = "<password>",
            elevationLevel = "nonadmin",
            linuxUserConfiguration = new {
                uid = 1234,
                gid = 1234,
                sshPrivateKey = "<sshPrivateKey>",
            },
            windowsUserConfiguration = new {
                loginMode = "batch",
            },
        }
    },
    metadata = new[] {
        new {
            name = "<name>",
            value = "<value>",
        }
    },
    mountConfiguration = new[] {
        new {
            azureBlobFileSystemConfiguration = new {
                accountName = "<accountName>",
                containerName = "<containerName>",
                accountKey = "<accountKey>",
                sasKey = "<sasKey>",
                blobfuseOptions = "<blobfuseOptions>",
                relativeMountPath = "<relativeMountPath>",
                identityReference = new {
                    resourceId = "<resourceId>",
                },
            },
            nfsMountConfiguration = new {
                source = "<source>",
                relativeMountPath = "<relativeMountPath>",
                mountOptions = "<mountOptions>",
            },
            cifsMountConfiguration = new {
                username = "<username>",
                source = "<source>",
                relativeMountPath = "<relativeMountPath>",
                mountOptions = "<mountOptions>",
                password = "<password>",
            },
            azureFileShareConfiguration = new {
                accountName = "<accountName>",
                azureFileUrl = "<azureFileUrl>",
                accountKey = "<accountKey>",
                relativeMountPath = "<relativeMountPath>",
                mountOptions = "<mountOptions>",
            },
        }
    },
    targetNodeCommunicationMode = "default",
};

Response response = await client.PatchAsync("<poolId>", RequestContent.Create(data), 1234, "<clientRequestId>", true, "<ocpDate>", null);
Console.WriteLine(response.Status);
]]></code>
</example>
<remarks>
This only replaces the Pool properties specified in the request. For example,
if the Pool has a StartTask associated with it, and a request does not specify
a StartTask element, then the Pool keeps the existing StartTask.

Below is the JSON schema for the request payload.

Request Body:

Schema for <c>BatchPool</c>:
<code>{
  id: string, # Optional. The ID can contain any combination of alphanumeric characters including hyphens
and underscores, and cannot contain more than 64 characters. The ID is
case-preserving and case-insensitive (that is, you may not have two IDs within
an Account that differ only by case).
  displayName: string, # Optional. The display name need not be unique and can contain any Unicode characters up
to a maximum length of 1024.
  url: string, # Optional. The URL of the Pool.
  eTag: string, # Optional. This is an opaque string. You can use it to detect whether the Pool has changed
between requests. In particular, you can be pass the ETag when updating a Pool
to specify that your changes should take effect only if nobody else has
modified the Pool in the meantime.
  lastModified: string (date &amp; time), # Optional. This is the last time at which the Pool level data, such as the
targetDedicatedNodes or enableAutoscale settings, changed. It does not factor
in node-level changes such as a Compute Node changing state.
  creationTime: string (date &amp; time), # Optional. The creation time of the Pool.
  state: &quot;active&quot; | &quot;deleting&quot;, # Optional. The current state of the Pool.
  stateTransitionTime: string (date &amp; time), # Optional. The time at which the Pool entered its current state.
  allocationState: &quot;steady&quot; | &quot;resizing&quot; | &quot;stopping&quot;, # Optional. Whether the Pool is resizing.
  allocationStateTransitionTime: string (date &amp; time), # Optional. The time at which the Pool entered its current allocation state.
  vmSize: string, # Optional. For information about available sizes of virtual machines in Pools, see Choose
a VM size for Compute Nodes in an Azure Batch Pool
(https://docs.microsoft.com/azure/batch/batch-pool-vm-sizes).
  cloudServiceConfiguration: {
    osFamily: string, # Required. Possible values are:
2 - OS Family 2, equivalent to Windows Server 2008 R2
SP1.
3 - OS Family 3, equivalent to Windows Server 2012.
4 - OS Family 4,
equivalent to Windows Server 2012 R2.
5 - OS Family 5, equivalent to Windows
Server 2016.
6 - OS Family 6, equivalent to Windows Server 2019. For more
information, see Azure Guest OS Releases
(https://azure.microsoft.com/documentation/articles/cloud-services-guestos-update-matrix/#releases).
    osVersion: string, # Optional. The default value is * which specifies the latest operating system version for
the specified OS family.
  }, # Optional. This property and virtualMachineConfiguration are mutually exclusive and one of
the properties must be specified. This property cannot be specified if the
Batch Account was created with its poolAllocationMode property set to
&apos;UserSubscription&apos;.
  virtualMachineConfiguration: {
    imageReference: {
      publisher: string, # Optional. For example, Canonical or MicrosoftWindowsServer.
      offer: string, # Optional. For example, UbuntuServer or WindowsServer.
      sku: string, # Optional. For example, 18.04-LTS or 2019-Datacenter.
      version: string, # Optional. A value of &apos;latest&apos; can be specified to select the latest version of an Image.
If omitted, the default is &apos;latest&apos;.
      virtualMachineImageId: string, # Optional. This property is mutually exclusive with other ImageReference properties. The
Shared Image Gallery Image must have replicas in the same region and must be in
the same subscription as the Azure Batch account. If the image version is not
specified in the imageId, the latest version will be used. For information
about the firewall settings for the Batch Compute Node agent to communicate
with the Batch service see
https://docs.microsoft.com/en-us/azure/batch/batch-api-basics#virtual-network-vnet-and-firewall-configuration.
      exactVersion: string, # Optional. The specific version of the platform image or marketplace image used to create
the node. This read-only field differs from &apos;version&apos; only if the value
specified for &apos;version&apos; when the pool was created was &apos;latest&apos;.
    }, # Required. A reference to an Azure Virtual Machines Marketplace Image or a Shared Image
Gallery Image. To get the list of all Azure Marketplace Image references
verified by Azure Batch, see the &apos;List Supported Images&apos; operation.
    nodeAgentSKUId: string, # Required. The Batch Compute Node agent is a program that runs on each Compute Node in the
Pool, and provides the command-and-control interface between the Compute Node
and the Batch service. There are different implementations of the Compute Node
agent, known as SKUs, for different operating systems. You must specify a
Compute Node agent SKU which matches the selected Image reference. To get the
list of supported Compute Node agent SKUs along with their list of verified
Image references, see the &apos;List supported Compute Node agent SKUs&apos; operation.
    windowsConfiguration: {
      enableAutomaticUpdates: boolean, # Optional. If omitted, the default value is true.
    }, # Optional. This property must not be specified if the imageReference property specifies a
Linux OS Image.
    dataDisks: [DataDisk], # Optional. This property must be specified if the Compute Nodes in the Pool need to have
empty data disks attached to them. This cannot be updated. Each Compute Node
gets its own disk (the disk is not a file share). Existing disks cannot be
attached, each attached disk is empty. When the Compute Node is removed from
the Pool, the disk and all data associated with it is also deleted. The disk is
not formatted after being attached, it must be formatted before use - for more
information see
https://docs.microsoft.com/en-us/azure/virtual-machines/linux/classic/attach-disk#initialize-a-new-data-disk-in-linux
and
https://docs.microsoft.com/en-us/azure/virtual-machines/windows/attach-disk-ps#add-an-empty-data-disk-to-a-virtual-machine.
    licenseType: string, # Optional. This only applies to Images that contain the Windows operating system, and
should only be used when you hold valid on-premises licenses for the Compute
Nodes which will be deployed. If omitted, no on-premises licensing discount is
applied. Values are:

 Windows_Server - The on-premises license is for Windows
Server.
 Windows_Client - The on-premises license is for Windows Client.

    containerConfiguration: {
      type: &quot;dockerCompatible&quot;, # Required. The container technology to be used.
      containerImageNames: [string], # Optional. This is the full Image reference, as would be specified to &quot;docker pull&quot;. An
Image will be sourced from the default Docker registry unless the Image is
fully qualified with an alternative registry.
      containerRegistries: [
        {
          username: string, # Optional. The user name to log into the registry server.
          password: string, # Optional. The password to log into the registry server.
          registryServer: string, # Optional. If omitted, the default is &quot;docker.io&quot;.
          identityReference: {
            resourceId: string, # Optional. The ARM resource id of the user assigned identity.
          }, # Optional. The reference to a user assigned identity associated with the Batch pool which
a compute node will use.
        }
      ], # Optional. If any Images must be downloaded from a private registry which requires
credentials, then those credentials must be provided here.
    }, # Optional. If specified, setup is performed on each Compute Node in the Pool to allow
Tasks to run in containers. All regular Tasks and Job manager Tasks run on this
Pool must specify the containerSettings property, and all other Tasks may
specify it.
    diskEncryptionConfiguration: {
      targets: [&quot;osdisk&quot; | &quot;temporarydisk&quot;], # Optional. If omitted, no disks on the compute nodes in the pool will be encrypted. On
Linux pool, only &quot;TemporaryDisk&quot; is supported; on Windows pool, &quot;OsDisk&quot;
and &quot;TemporaryDisk&quot; must be specified.
    }, # Optional. If specified, encryption is performed on each node in the pool during node
provisioning.
    nodePlacementConfiguration: {
      policy: &quot;regional&quot; | &quot;zonal&quot;, # Optional. Allocation policy used by Batch Service to provision the nodes. If not
specified, Batch will use the regional policy.
    }, # Optional. This configuration will specify rules on how nodes in the pool will be
physically allocated.
    extensions: [VMExtension], # Optional. If specified, the extensions mentioned in this configuration will be installed
on each node.
    osDisk: {
      ephemeralOSDiskSettings: {
        placement: &quot;cachedisk&quot;, # Optional. This property can be used by user in the request to choose the location e.g.,
cache disk space for Ephemeral OS disk provisioning. For more information on
Ephemeral OS disk size requirements, please refer to Ephemeral OS disk size
requirements for Windows VMs at
https://docs.microsoft.com/en-us/azure/virtual-machines/windows/ephemeral-os-disks#size-requirements
and Linux VMs at
https://docs.microsoft.com/en-us/azure/virtual-machines/linux/ephemeral-os-disks#size-requirements.
      }, # Optional. Specifies the ephemeral Disk Settings for the operating system disk used by the
compute node (VM).
    }, # Optional. Settings for the operating system disk of the compute node (VM).
  }, # Optional. This property and cloudServiceConfiguration are mutually exclusive and one of
the properties must be specified.
  resizeTimeout: string (duration ISO 8601 Format), # Optional. This is the timeout for the most recent resize operation. (The initial sizing
when the Pool is created counts as a resize.) The default value is 15 minutes.
  resizeErrors: [
    {
      code: string, # Optional. An identifier for the Pool resize error. Codes are invariant and are intended
to be consumed programmatically.
      message: string, # Optional. A message describing the Pool resize error, intended to be suitable for display
in a user interface.
      values: [NameValuePair], # Optional. A list of additional error details related to the Pool resize error.
    }
  ], # Optional. This property is set only if one or more errors occurred during the last Pool
resize, and only when the Pool allocationState is Steady.
  currentDedicatedNodes: number, # Optional. The number of dedicated Compute Nodes currently in the Pool.
  currentLowPriorityNodes: number, # Optional. Spot/Low-priority Compute Nodes which have been preempted are included in this
count.
  targetDedicatedNodes: number, # Optional. The desired number of dedicated Compute Nodes in the Pool.
  targetLowPriorityNodes: number, # Optional. The desired number of Spot/Low-priority Compute Nodes in the Pool.
  enableAutoScale: boolean, # Optional. If false, at least one of targetDedicatedNodes and targetLowPriorityNodes must
be specified. If true, the autoScaleFormula property is required and the Pool
automatically resizes according to the formula. The default value is false.
  autoScaleFormula: string, # Optional. This property is set only if the Pool automatically scales, i.e.
enableAutoScale is true.
  autoScaleEvaluationInterval: string (duration ISO 8601 Format), # Optional. This property is set only if the Pool automatically scales, i.e.
enableAutoScale is true.
  autoScaleRun: {
    timestamp: string (date &amp; time), # Required. The time at which the autoscale formula was last evaluated.
    results: string, # Optional. Each variable value is returned in the form $variable=value, and variables are
separated by semicolons.
    error: {
      code: string, # Optional. An identifier for the autoscale error. Codes are invariant and are intended to
be consumed programmatically.
      message: string, # Optional. A message describing the autoscale error, intended to be suitable for display
in a user interface.
      values: [NameValuePair], # Optional. A list of additional error details related to the autoscale error.
    }, # Optional. An error that occurred when executing or evaluating a Pool autoscale formula.
  }, # Optional. This property is set only if the Pool automatically scales, i.e.
enableAutoScale is true.
  enableInterNodeCommunication: boolean, # Optional. This imposes restrictions on which Compute Nodes can be assigned to the Pool.
Specifying this value can reduce the chance of the requested number of Compute
Nodes to be allocated in the Pool.
  networkConfiguration: {
    subnetId: string, # Optional. The virtual network must be in the same region and subscription as the Azure
Batch Account. The specified subnet should have enough free IP addresses to
accommodate the number of Compute Nodes in the Pool. If the subnet doesn&apos;t have
enough free IP addresses, the Pool will partially allocate Nodes and a resize
error will occur. The &apos;MicrosoftAzureBatch&apos; service principal must have the
&apos;Classic Virtual Machine Contributor&apos; Role-Based Access Control (RBAC) role for
the specified VNet. The specified subnet must allow communication from the
Azure Batch service to be able to schedule Tasks on the Nodes. This can be
verified by checking if the specified VNet has any associated Network Security
Groups (NSG). If communication to the Nodes in the specified subnet is denied
by an NSG, then the Batch service will set the state of the Compute Nodes to
unusable. For Pools created with virtualMachineConfiguration only ARM virtual
networks (&apos;Microsoft.Network/virtualNetworks&apos;) are supported, but for Pools
created with cloudServiceConfiguration both ARM and classic virtual networks
are supported. If the specified VNet has any associated Network Security Groups
(NSG), then a few reserved system ports must be enabled for inbound
communication. For Pools created with a virtual machine configuration, enable
ports 29876 and 29877, as well as port 22 for Linux and port 3389 for Windows.
For Pools created with a cloud service configuration, enable ports 10100,
20100, and 30100. Also enable outbound connections to Azure Storage on port
443. For more details see:
https://docs.microsoft.com/en-us/azure/batch/batch-api-basics#virtual-network-vnet-and-firewall-configuration
    dynamicVNetAssignmentScope: &quot;none&quot; | &quot;job&quot;, # Optional. The scope of dynamic vnet assignment.
    endpointConfiguration: {
      inboundNATPools: [InboundNATPool], # Required. The maximum number of inbound NAT Pools per Batch Pool is 5. If the maximum
number of inbound NAT Pools is exceeded the request fails with HTTP status code
400. This cannot be specified if the IPAddressProvisioningType is
NoPublicIPAddresses.
    }, # Optional. Pool endpoint configuration is only supported on Pools with the
virtualMachineConfiguration property.
    publicIPAddressConfiguration: {
      provision: &quot;batchmanaged&quot; | &quot;usermanaged&quot; | &quot;nopublicipaddresses&quot;, # Optional. The default value is BatchManaged.
      ipAddressIds: [string], # Optional. The number of IPs specified here limits the maximum size of the Pool - 100
dedicated nodes or 100 Spot/Low-priority nodes can be allocated for each public
IP. For example, a pool needing 250 dedicated VMs would need at least 3 public
IPs specified. Each element of this collection is of the form:
/subscriptions/{subscription}/resourceGroups/{group}/providers/Microsoft.Network/publicIPAddresses/{ip}.
    }, # Optional. Public IP configuration property is only supported on Pools with the
virtualMachineConfiguration property.
  }, # Optional. The network configuration for a Pool.
  startTask: {
    commandLine: string, # Required. The command line does not run under a shell, and therefore cannot take
advantage of shell features such as environment variable expansion. If you want
to take advantage of such features, you should invoke the shell in the command
line, for example using &quot;cmd /c MyCommand&quot; in Windows or &quot;/bin/sh -c
MyCommand&quot; in Linux. If the command line refers to file paths, it should use a
relative path (relative to the Task working directory), or use the Batch
provided environment variable
(https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).
    containerSettings: {
      containerRunOptions: string, # Optional. These additional options are supplied as arguments to the &quot;docker create&quot;
command, in addition to those controlled by the Batch Service.
      imageName: string, # Required. This is the full Image reference, as would be specified to &quot;docker pull&quot;. If
no tag is provided as part of the Image name, the tag &quot;:latest&quot; is used as a
default.
      registry: ContainerRegistry, # Optional. This setting can be omitted if was already provided at Pool creation.
      workingDirectory: &quot;taskWorkingDirectory&quot; | &quot;containerImageDefault&quot;, # Optional. The default is &apos;taskWorkingDirectory&apos;.
    }, # Optional. When this is specified, all directories recursively below the
AZ_BATCH_NODE_ROOT_DIR (the root of Azure Batch directories on the node) are
mapped into the container, all Task environment variables are mapped into the
container, and the Task command line is executed in the container. Files
produced in the container outside of AZ_BATCH_NODE_ROOT_DIR might not be
reflected to the host disk, meaning that Batch file APIs will not be able to
access those files.
    resourceFiles: [ResourceFile], # Optional. Files listed under this element are located in the Task&apos;s working directory.
    environmentSettings: [EnvironmentSetting], # Optional. A list of environment variable settings for the StartTask.
    userIdentity: {
      username: string, # Optional. The userName and autoUser properties are mutually exclusive; you must specify
one but not both.
      autoUser: {
        scope: &quot;task&quot; | &quot;pool&quot;, # Optional. The default value is pool. If the pool is running Windows a value of Task
should be specified if stricter isolation between tasks is required. For
example, if the task mutates the registry in a way which could impact other
tasks, or if certificates have been specified on the pool which should not be
accessible by normal tasks but should be accessible by StartTasks.
        elevationLevel: &quot;nonadmin&quot; | &quot;admin&quot;, # Optional. The default value is nonAdmin.
      }, # Optional. The userName and autoUser properties are mutually exclusive; you must specify
one but not both.
    }, # Optional. If omitted, the Task runs as a non-administrative user unique to the Task.
    maxTaskRetryCount: number, # Optional. The Batch service retries a Task if its exit code is nonzero. Note that this
value specifically controls the number of retries. The Batch service will try
the Task once, and may then retry up to this limit. For example, if the maximum
retry count is 3, Batch tries the Task up to 4 times (one initial try and 3
retries). If the maximum retry count is 0, the Batch service does not retry the
Task. If the maximum retry count is -1, the Batch service retries the Task
without limit, however this is not recommended for a start task or any task.
The default value is 0 (no retries)
    waitForSuccess: boolean, # Optional. If true and the StartTask fails on a Node, the Batch service retries the
StartTask up to its maximum retry count (maxTaskRetryCount). If the Task has
still not completed successfully after all retries, then the Batch service
marks the Node unusable, and will not schedule Tasks to it. This condition can
be detected via the Compute Node state and failure info details. If false, the
Batch service will not wait for the StartTask to complete. In this case, other
Tasks can start executing on the Compute Node while the StartTask is still
running; and even if the StartTask fails, new Tasks will continue to be
scheduled on the Compute Node. The default is true.
  }, # Optional. Batch will retry Tasks when a recovery operation is triggered on a Node.
Examples of recovery operations include (but are not limited to) when an
unhealthy Node is rebooted or a Compute Node disappeared due to host failure.
Retries due to recovery operations are independent of and are not counted
against the maxTaskRetryCount. Even if the maxTaskRetryCount is 0, an internal
retry due to a recovery operation may occur. Because of this, all Tasks should
be idempotent. This means Tasks need to tolerate being interrupted and
restarted without causing any corruption or duplicate data. The best practice
for long running Tasks is to use some form of checkpointing. In some cases the
StartTask may be re-run even though the Compute Node was not rebooted. Special
care should be taken to avoid StartTasks which create breakaway process or
install/launch services from the StartTask working directory, as this will
block Batch from being able to re-run the StartTask.
  certificateReferences: [CertificateReference], # Optional. For Windows Nodes, the Batch service installs the Certificates to the specified
Certificate store and location. For Linux Compute Nodes, the Certificates are
stored in a directory inside the Task working directory and an environment
variable AZ_BATCH_CERTIFICATES_DIR is supplied to the Task to query for this
location. For Certificates with visibility of &apos;remoteUser&apos;, a &apos;certs&apos; directory
is created in the user&apos;s home directory (e.g., /home/{user-name}/certs) and
Certificates are placed in that directory.
  applicationPackageReferences: [ApplicationPackageReference], # Optional. Changes to Package references affect all new Nodes joining the Pool, but do not
affect Compute Nodes that are already in the Pool until they are rebooted or
reimaged. There is a maximum of 10 Package references on any given Pool.
  applicationLicenses: [string], # Optional. The list of application licenses must be a subset of available Batch service
application licenses. If a license is requested which is not supported, Pool
creation will fail.
  taskSlotsPerNode: number, # Optional. The default value is 1. The maximum value is the smaller of 4 times the number
of cores of the vmSize of the pool or 256.
  taskSchedulingPolicy: {
    nodeFillType: &quot;spread&quot; | &quot;pack&quot;, # Required. If not specified, the default is spread.
  }, # Optional. If not specified, the default is spread.
  userAccounts: [UserAccount], # Optional. The list of user Accounts to be created on each Compute Node in the Pool.
  metadata: [MetadataItem], # Optional. A list of name-value pairs associated with the Pool as metadata.
  stats: {
    url: string, # Required. The URL for the statistics.
    startTime: string (date &amp; time), # Required. The start time of the time range covered by the statistics.
    lastUpdateTime: string (date &amp; time), # Required. The time at which the statistics were last updated. All statistics are limited
to the range between startTime and lastUpdateTime.
    usageStats: {
      startTime: string (date &amp; time), # Required. The start time of the time range covered by the statistics.
      lastUpdateTime: string (date &amp; time), # Required. The time at which the statistics were last updated. All statistics are limited
to the range between startTime and lastUpdateTime.
      dedicatedCoreTime: string (duration ISO 8601 Format), # Required. The aggregated wall-clock time of the dedicated Compute Node cores being part
of the Pool.
    }, # Optional. Statistics related to Pool usage information.
    resourceStats: {
      startTime: string (date &amp; time), # Required. The start time of the time range covered by the statistics.
      lastUpdateTime: string (date &amp; time), # Required. The time at which the statistics were last updated. All statistics are limited
to the range between startTime and lastUpdateTime.
      avgCPUPercentage: number, # Required. The average CPU usage across all Compute Nodes in the Pool (percentage per
node).
      avgMemoryGiB: number, # Required. The average memory usage in GiB across all Compute Nodes in the Pool.
      peakMemoryGiB: number, # Required. The peak memory usage in GiB across all Compute Nodes in the Pool.
      avgDiskGiB: number, # Required. The average used disk space in GiB across all Compute Nodes in the Pool.
      peakDiskGiB: number, # Required. The peak used disk space in GiB across all Compute Nodes in the Pool.
      diskReadIOps: number, # Required. The total number of disk read operations across all Compute Nodes in the Pool.
      diskWriteIOps: number, # Required. The total number of disk write operations across all Compute Nodes in the Pool.
      diskReadGiB: number, # Required. The total amount of data in GiB of disk reads across all Compute Nodes in the
Pool.
      diskWriteGiB: number, # Required. The total amount of data in GiB of disk writes across all Compute Nodes in the
Pool.
      networkReadGiB: number, # Required. The total amount of data in GiB of network reads across all Compute Nodes in
the Pool.
      networkWriteGiB: number, # Required. The total amount of data in GiB of network writes across all Compute Nodes in
the Pool.
    }, # Optional. Statistics related to resource consumption by Compute Nodes in a Pool.
  }, # Optional. This property is populated only if the CloudPool was retrieved with an expand
clause including the &apos;stats&apos; attribute; otherwise it is null. The statistics
may not be immediately available. The Batch service performs periodic roll-up
of statistics. The typical delay is about 30 minutes.
  mountConfiguration: [MountConfiguration], # Optional. This supports Azure Files, NFS, CIFS/SMB, and Blobfuse.
  identity: {
    type: &quot;UserAssigned&quot; | &quot;None&quot;, # Required. The list of user identities associated with the Batch pool. The user identity
dictionary key references will be ARM resource ids in the form:
&apos;/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.ManagedIdentity/userAssignedIdentities/{identityName}&apos;.
    userAssignedIdentities: [UserAssignedIdentity], # Optional. The user identity dictionary key references will be ARM resource ids in the
form:
&apos;/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.ManagedIdentity/userAssignedIdentities/{identityName}&apos;.
  }, # Optional. The list of user identities associated with the Batch pool. The user identity
dictionary key references will be ARM resource ids in the form:
&apos;/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.ManagedIdentity/userAssignedIdentities/{identityName}&apos;.
  targetNodeCommunicationMode: &quot;default&quot; | &quot;classic&quot; | &quot;simplified&quot;, # Optional. If omitted, the default value is Default.
  currentNodeCommunicationMode: &quot;default&quot; | &quot;classic&quot; | &quot;simplified&quot;, # Optional. Determines how a pool communicates with the Batch service.
}
</code>

</remarks>
    </member>
    <member name="Patch(String,RequestContent,Int32,String,Boolean,String,RequestConditions,RequestContext)">
<example>
This sample shows how to call Patch with required parameters.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetPoolClient(<2022-10-01.16.0>);

var data = new {};

Response response = client.Patch("<poolId>", RequestContent.Create(data));
Console.WriteLine(response.Status);
]]></code>
This sample shows how to call Patch with all parameters and request content.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetPoolClient(<2022-10-01.16.0>);

var data = new {
    id = "<id>",
    displayName = "<displayName>",
    vmSize = "<vmSize>",
    cloudServiceConfiguration = new {
        osFamily = "<osFamily>",
        osVersion = "<osVersion>",
    },
    virtualMachineConfiguration = new {
        imageReference = new {
            publisher = "<publisher>",
            offer = "<offer>",
            sku = "<sku>",
            version = "<version>",
            virtualMachineImageId = "<virtualMachineImageId>",
        },
        nodeAgentSKUId = "<nodeAgentSKUId>",
        windowsConfiguration = new {
            enableAutomaticUpdates = true,
        },
        dataDisks = new[] {
            new {
                lun = 1234,
                caching = "none",
                diskSizeGB = 1234,
                storageAccountType = "standard_lrs",
            }
        },
        licenseType = "<licenseType>",
        containerConfiguration = new {
            type = "dockerCompatible",
            containerImageNames = new[] {
                "<String>"
            },
            containerRegistries = new[] {
                new {
                    username = "<username>",
                    password = "<password>",
                    registryServer = "<registryServer>",
                    identityReference = new {
                        resourceId = "<resourceId>",
                    },
                }
            },
        },
        diskEncryptionConfiguration = new {
            targets = new[] {
                "osdisk"
            },
        },
        nodePlacementConfiguration = new {
            policy = "regional",
        },
        extensions = new[] {
            new {
                name = "<name>",
                publisher = "<publisher>",
                type = "<type>",
                typeHandlerVersion = "<typeHandlerVersion>",
                autoUpgradeMinorVersion = true,
                settings = new {},
                protectedSettings = new {},
                provisionAfterExtensions = new[] {
                    "<String>"
                },
            }
        },
        osDisk = new {
            ephemeralOSDiskSettings = new {
                placement = "cachedisk",
            },
        },
    },
    resizeTimeout = PT1H23M45S,
    targetDedicatedNodes = 1234,
    targetLowPriorityNodes = 1234,
    enableAutoScale = true,
    autoScaleFormula = "<autoScaleFormula>",
    autoScaleEvaluationInterval = PT1H23M45S,
    enableInterNodeCommunication = true,
    networkConfiguration = new {
        subnetId = "<subnetId>",
        dynamicVNetAssignmentScope = "none",
        endpointConfiguration = new {
            inboundNATPools = new[] {
                new {
                    name = "<name>",
                    protocol = "tcp",
                    backendPort = 1234,
                    frontendPortRangeStart = 1234,
                    frontendPortRangeEnd = 1234,
                    networkSecurityGroupRules = new[] {
                        new {
                            priority = 1234,
                            access = "allow",
                            sourceAddressPrefix = "<sourceAddressPrefix>",
                            sourcePortRanges = new[] {
                                "<String>"
                            },
                        }
                    },
                }
            },
        },
        publicIPAddressConfiguration = new {
            provision = "batchmanaged",
            ipAddressIds = new[] {
                "<String>"
            },
        },
    },
    startTask = new {
        commandLine = "<commandLine>",
        containerSettings = new {
            containerRunOptions = "<containerRunOptions>",
            imageName = "<imageName>",
            registry = new {
                username = "<username>",
                password = "<password>",
                registryServer = "<registryServer>",
                identityReference = new {
                    resourceId = "<resourceId>",
                },
            },
            workingDirectory = "taskWorkingDirectory",
        },
        resourceFiles = new[] {
            new {
                autoStorageContainerName = "<autoStorageContainerName>",
                storageContainerUrl = "<storageContainerUrl>",
                httpUrl = "<httpUrl>",
                blobPrefix = "<blobPrefix>",
                filePath = "<filePath>",
                fileMode = "<fileMode>",
                identityReference = new {
                    resourceId = "<resourceId>",
                },
            }
        },
        environmentSettings = new[] {
            new {
                name = "<name>",
                value = "<value>",
            }
        },
        userIdentity = new {
            username = "<username>",
            autoUser = new {
                scope = "task",
                elevationLevel = "nonadmin",
            },
        },
        maxTaskRetryCount = 1234,
        waitForSuccess = true,
    },
    certificateReferences = new[] {
        new {
            thumbprint = "<thumbprint>",
            thumbprintAlgorithm = "<thumbprintAlgorithm>",
            storeLocation = "currentuser",
            storeName = "<storeName>",
            visibility = new[] {
                "starttask"
            },
        }
    },
    applicationPackageReferences = new[] {
        new {
            applicationId = "<applicationId>",
            version = "<version>",
        }
    },
    applicationLicenses = new[] {
        "<String>"
    },
    taskSlotsPerNode = 1234,
    taskSchedulingPolicy = new {
        nodeFillType = "spread",
    },
    userAccounts = new[] {
        new {
            name = "<name>",
            password = "<password>",
            elevationLevel = "nonadmin",
            linuxUserConfiguration = new {
                uid = 1234,
                gid = 1234,
                sshPrivateKey = "<sshPrivateKey>",
            },
            windowsUserConfiguration = new {
                loginMode = "batch",
            },
        }
    },
    metadata = new[] {
        new {
            name = "<name>",
            value = "<value>",
        }
    },
    mountConfiguration = new[] {
        new {
            azureBlobFileSystemConfiguration = new {
                accountName = "<accountName>",
                containerName = "<containerName>",
                accountKey = "<accountKey>",
                sasKey = "<sasKey>",
                blobfuseOptions = "<blobfuseOptions>",
                relativeMountPath = "<relativeMountPath>",
                identityReference = new {
                    resourceId = "<resourceId>",
                },
            },
            nfsMountConfiguration = new {
                source = "<source>",
                relativeMountPath = "<relativeMountPath>",
                mountOptions = "<mountOptions>",
            },
            cifsMountConfiguration = new {
                username = "<username>",
                source = "<source>",
                relativeMountPath = "<relativeMountPath>",
                mountOptions = "<mountOptions>",
                password = "<password>",
            },
            azureFileShareConfiguration = new {
                accountName = "<accountName>",
                azureFileUrl = "<azureFileUrl>",
                accountKey = "<accountKey>",
                relativeMountPath = "<relativeMountPath>",
                mountOptions = "<mountOptions>",
            },
        }
    },
    targetNodeCommunicationMode = "default",
};

Response response = client.Patch("<poolId>", RequestContent.Create(data), 1234, "<clientRequestId>", true, "<ocpDate>", null);
Console.WriteLine(response.Status);
]]></code>
</example>
<remarks>
This only replaces the Pool properties specified in the request. For example,
if the Pool has a StartTask associated with it, and a request does not specify
a StartTask element, then the Pool keeps the existing StartTask.

Below is the JSON schema for the request payload.

Request Body:

Schema for <c>BatchPool</c>:
<code>{
  id: string, # Optional. The ID can contain any combination of alphanumeric characters including hyphens
and underscores, and cannot contain more than 64 characters. The ID is
case-preserving and case-insensitive (that is, you may not have two IDs within
an Account that differ only by case).
  displayName: string, # Optional. The display name need not be unique and can contain any Unicode characters up
to a maximum length of 1024.
  url: string, # Optional. The URL of the Pool.
  eTag: string, # Optional. This is an opaque string. You can use it to detect whether the Pool has changed
between requests. In particular, you can be pass the ETag when updating a Pool
to specify that your changes should take effect only if nobody else has
modified the Pool in the meantime.
  lastModified: string (date &amp; time), # Optional. This is the last time at which the Pool level data, such as the
targetDedicatedNodes or enableAutoscale settings, changed. It does not factor
in node-level changes such as a Compute Node changing state.
  creationTime: string (date &amp; time), # Optional. The creation time of the Pool.
  state: &quot;active&quot; | &quot;deleting&quot;, # Optional. The current state of the Pool.
  stateTransitionTime: string (date &amp; time), # Optional. The time at which the Pool entered its current state.
  allocationState: &quot;steady&quot; | &quot;resizing&quot; | &quot;stopping&quot;, # Optional. Whether the Pool is resizing.
  allocationStateTransitionTime: string (date &amp; time), # Optional. The time at which the Pool entered its current allocation state.
  vmSize: string, # Optional. For information about available sizes of virtual machines in Pools, see Choose
a VM size for Compute Nodes in an Azure Batch Pool
(https://docs.microsoft.com/azure/batch/batch-pool-vm-sizes).
  cloudServiceConfiguration: {
    osFamily: string, # Required. Possible values are:
2 - OS Family 2, equivalent to Windows Server 2008 R2
SP1.
3 - OS Family 3, equivalent to Windows Server 2012.
4 - OS Family 4,
equivalent to Windows Server 2012 R2.
5 - OS Family 5, equivalent to Windows
Server 2016.
6 - OS Family 6, equivalent to Windows Server 2019. For more
information, see Azure Guest OS Releases
(https://azure.microsoft.com/documentation/articles/cloud-services-guestos-update-matrix/#releases).
    osVersion: string, # Optional. The default value is * which specifies the latest operating system version for
the specified OS family.
  }, # Optional. This property and virtualMachineConfiguration are mutually exclusive and one of
the properties must be specified. This property cannot be specified if the
Batch Account was created with its poolAllocationMode property set to
&apos;UserSubscription&apos;.
  virtualMachineConfiguration: {
    imageReference: {
      publisher: string, # Optional. For example, Canonical or MicrosoftWindowsServer.
      offer: string, # Optional. For example, UbuntuServer or WindowsServer.
      sku: string, # Optional. For example, 18.04-LTS or 2019-Datacenter.
      version: string, # Optional. A value of &apos;latest&apos; can be specified to select the latest version of an Image.
If omitted, the default is &apos;latest&apos;.
      virtualMachineImageId: string, # Optional. This property is mutually exclusive with other ImageReference properties. The
Shared Image Gallery Image must have replicas in the same region and must be in
the same subscription as the Azure Batch account. If the image version is not
specified in the imageId, the latest version will be used. For information
about the firewall settings for the Batch Compute Node agent to communicate
with the Batch service see
https://docs.microsoft.com/en-us/azure/batch/batch-api-basics#virtual-network-vnet-and-firewall-configuration.
      exactVersion: string, # Optional. The specific version of the platform image or marketplace image used to create
the node. This read-only field differs from &apos;version&apos; only if the value
specified for &apos;version&apos; when the pool was created was &apos;latest&apos;.
    }, # Required. A reference to an Azure Virtual Machines Marketplace Image or a Shared Image
Gallery Image. To get the list of all Azure Marketplace Image references
verified by Azure Batch, see the &apos;List Supported Images&apos; operation.
    nodeAgentSKUId: string, # Required. The Batch Compute Node agent is a program that runs on each Compute Node in the
Pool, and provides the command-and-control interface between the Compute Node
and the Batch service. There are different implementations of the Compute Node
agent, known as SKUs, for different operating systems. You must specify a
Compute Node agent SKU which matches the selected Image reference. To get the
list of supported Compute Node agent SKUs along with their list of verified
Image references, see the &apos;List supported Compute Node agent SKUs&apos; operation.
    windowsConfiguration: {
      enableAutomaticUpdates: boolean, # Optional. If omitted, the default value is true.
    }, # Optional. This property must not be specified if the imageReference property specifies a
Linux OS Image.
    dataDisks: [DataDisk], # Optional. This property must be specified if the Compute Nodes in the Pool need to have
empty data disks attached to them. This cannot be updated. Each Compute Node
gets its own disk (the disk is not a file share). Existing disks cannot be
attached, each attached disk is empty. When the Compute Node is removed from
the Pool, the disk and all data associated with it is also deleted. The disk is
not formatted after being attached, it must be formatted before use - for more
information see
https://docs.microsoft.com/en-us/azure/virtual-machines/linux/classic/attach-disk#initialize-a-new-data-disk-in-linux
and
https://docs.microsoft.com/en-us/azure/virtual-machines/windows/attach-disk-ps#add-an-empty-data-disk-to-a-virtual-machine.
    licenseType: string, # Optional. This only applies to Images that contain the Windows operating system, and
should only be used when you hold valid on-premises licenses for the Compute
Nodes which will be deployed. If omitted, no on-premises licensing discount is
applied. Values are:

 Windows_Server - The on-premises license is for Windows
Server.
 Windows_Client - The on-premises license is for Windows Client.

    containerConfiguration: {
      type: &quot;dockerCompatible&quot;, # Required. The container technology to be used.
      containerImageNames: [string], # Optional. This is the full Image reference, as would be specified to &quot;docker pull&quot;. An
Image will be sourced from the default Docker registry unless the Image is
fully qualified with an alternative registry.
      containerRegistries: [
        {
          username: string, # Optional. The user name to log into the registry server.
          password: string, # Optional. The password to log into the registry server.
          registryServer: string, # Optional. If omitted, the default is &quot;docker.io&quot;.
          identityReference: {
            resourceId: string, # Optional. The ARM resource id of the user assigned identity.
          }, # Optional. The reference to a user assigned identity associated with the Batch pool which
a compute node will use.
        }
      ], # Optional. If any Images must be downloaded from a private registry which requires
credentials, then those credentials must be provided here.
    }, # Optional. If specified, setup is performed on each Compute Node in the Pool to allow
Tasks to run in containers. All regular Tasks and Job manager Tasks run on this
Pool must specify the containerSettings property, and all other Tasks may
specify it.
    diskEncryptionConfiguration: {
      targets: [&quot;osdisk&quot; | &quot;temporarydisk&quot;], # Optional. If omitted, no disks on the compute nodes in the pool will be encrypted. On
Linux pool, only &quot;TemporaryDisk&quot; is supported; on Windows pool, &quot;OsDisk&quot;
and &quot;TemporaryDisk&quot; must be specified.
    }, # Optional. If specified, encryption is performed on each node in the pool during node
provisioning.
    nodePlacementConfiguration: {
      policy: &quot;regional&quot; | &quot;zonal&quot;, # Optional. Allocation policy used by Batch Service to provision the nodes. If not
specified, Batch will use the regional policy.
    }, # Optional. This configuration will specify rules on how nodes in the pool will be
physically allocated.
    extensions: [VMExtension], # Optional. If specified, the extensions mentioned in this configuration will be installed
on each node.
    osDisk: {
      ephemeralOSDiskSettings: {
        placement: &quot;cachedisk&quot;, # Optional. This property can be used by user in the request to choose the location e.g.,
cache disk space for Ephemeral OS disk provisioning. For more information on
Ephemeral OS disk size requirements, please refer to Ephemeral OS disk size
requirements for Windows VMs at
https://docs.microsoft.com/en-us/azure/virtual-machines/windows/ephemeral-os-disks#size-requirements
and Linux VMs at
https://docs.microsoft.com/en-us/azure/virtual-machines/linux/ephemeral-os-disks#size-requirements.
      }, # Optional. Specifies the ephemeral Disk Settings for the operating system disk used by the
compute node (VM).
    }, # Optional. Settings for the operating system disk of the compute node (VM).
  }, # Optional. This property and cloudServiceConfiguration are mutually exclusive and one of
the properties must be specified.
  resizeTimeout: string (duration ISO 8601 Format), # Optional. This is the timeout for the most recent resize operation. (The initial sizing
when the Pool is created counts as a resize.) The default value is 15 minutes.
  resizeErrors: [
    {
      code: string, # Optional. An identifier for the Pool resize error. Codes are invariant and are intended
to be consumed programmatically.
      message: string, # Optional. A message describing the Pool resize error, intended to be suitable for display
in a user interface.
      values: [NameValuePair], # Optional. A list of additional error details related to the Pool resize error.
    }
  ], # Optional. This property is set only if one or more errors occurred during the last Pool
resize, and only when the Pool allocationState is Steady.
  currentDedicatedNodes: number, # Optional. The number of dedicated Compute Nodes currently in the Pool.
  currentLowPriorityNodes: number, # Optional. Spot/Low-priority Compute Nodes which have been preempted are included in this
count.
  targetDedicatedNodes: number, # Optional. The desired number of dedicated Compute Nodes in the Pool.
  targetLowPriorityNodes: number, # Optional. The desired number of Spot/Low-priority Compute Nodes in the Pool.
  enableAutoScale: boolean, # Optional. If false, at least one of targetDedicatedNodes and targetLowPriorityNodes must
be specified. If true, the autoScaleFormula property is required and the Pool
automatically resizes according to the formula. The default value is false.
  autoScaleFormula: string, # Optional. This property is set only if the Pool automatically scales, i.e.
enableAutoScale is true.
  autoScaleEvaluationInterval: string (duration ISO 8601 Format), # Optional. This property is set only if the Pool automatically scales, i.e.
enableAutoScale is true.
  autoScaleRun: {
    timestamp: string (date &amp; time), # Required. The time at which the autoscale formula was last evaluated.
    results: string, # Optional. Each variable value is returned in the form $variable=value, and variables are
separated by semicolons.
    error: {
      code: string, # Optional. An identifier for the autoscale error. Codes are invariant and are intended to
be consumed programmatically.
      message: string, # Optional. A message describing the autoscale error, intended to be suitable for display
in a user interface.
      values: [NameValuePair], # Optional. A list of additional error details related to the autoscale error.
    }, # Optional. An error that occurred when executing or evaluating a Pool autoscale formula.
  }, # Optional. This property is set only if the Pool automatically scales, i.e.
enableAutoScale is true.
  enableInterNodeCommunication: boolean, # Optional. This imposes restrictions on which Compute Nodes can be assigned to the Pool.
Specifying this value can reduce the chance of the requested number of Compute
Nodes to be allocated in the Pool.
  networkConfiguration: {
    subnetId: string, # Optional. The virtual network must be in the same region and subscription as the Azure
Batch Account. The specified subnet should have enough free IP addresses to
accommodate the number of Compute Nodes in the Pool. If the subnet doesn&apos;t have
enough free IP addresses, the Pool will partially allocate Nodes and a resize
error will occur. The &apos;MicrosoftAzureBatch&apos; service principal must have the
&apos;Classic Virtual Machine Contributor&apos; Role-Based Access Control (RBAC) role for
the specified VNet. The specified subnet must allow communication from the
Azure Batch service to be able to schedule Tasks on the Nodes. This can be
verified by checking if the specified VNet has any associated Network Security
Groups (NSG). If communication to the Nodes in the specified subnet is denied
by an NSG, then the Batch service will set the state of the Compute Nodes to
unusable. For Pools created with virtualMachineConfiguration only ARM virtual
networks (&apos;Microsoft.Network/virtualNetworks&apos;) are supported, but for Pools
created with cloudServiceConfiguration both ARM and classic virtual networks
are supported. If the specified VNet has any associated Network Security Groups
(NSG), then a few reserved system ports must be enabled for inbound
communication. For Pools created with a virtual machine configuration, enable
ports 29876 and 29877, as well as port 22 for Linux and port 3389 for Windows.
For Pools created with a cloud service configuration, enable ports 10100,
20100, and 30100. Also enable outbound connections to Azure Storage on port
443. For more details see:
https://docs.microsoft.com/en-us/azure/batch/batch-api-basics#virtual-network-vnet-and-firewall-configuration
    dynamicVNetAssignmentScope: &quot;none&quot; | &quot;job&quot;, # Optional. The scope of dynamic vnet assignment.
    endpointConfiguration: {
      inboundNATPools: [InboundNATPool], # Required. The maximum number of inbound NAT Pools per Batch Pool is 5. If the maximum
number of inbound NAT Pools is exceeded the request fails with HTTP status code
400. This cannot be specified if the IPAddressProvisioningType is
NoPublicIPAddresses.
    }, # Optional. Pool endpoint configuration is only supported on Pools with the
virtualMachineConfiguration property.
    publicIPAddressConfiguration: {
      provision: &quot;batchmanaged&quot; | &quot;usermanaged&quot; | &quot;nopublicipaddresses&quot;, # Optional. The default value is BatchManaged.
      ipAddressIds: [string], # Optional. The number of IPs specified here limits the maximum size of the Pool - 100
dedicated nodes or 100 Spot/Low-priority nodes can be allocated for each public
IP. For example, a pool needing 250 dedicated VMs would need at least 3 public
IPs specified. Each element of this collection is of the form:
/subscriptions/{subscription}/resourceGroups/{group}/providers/Microsoft.Network/publicIPAddresses/{ip}.
    }, # Optional. Public IP configuration property is only supported on Pools with the
virtualMachineConfiguration property.
  }, # Optional. The network configuration for a Pool.
  startTask: {
    commandLine: string, # Required. The command line does not run under a shell, and therefore cannot take
advantage of shell features such as environment variable expansion. If you want
to take advantage of such features, you should invoke the shell in the command
line, for example using &quot;cmd /c MyCommand&quot; in Windows or &quot;/bin/sh -c
MyCommand&quot; in Linux. If the command line refers to file paths, it should use a
relative path (relative to the Task working directory), or use the Batch
provided environment variable
(https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).
    containerSettings: {
      containerRunOptions: string, # Optional. These additional options are supplied as arguments to the &quot;docker create&quot;
command, in addition to those controlled by the Batch Service.
      imageName: string, # Required. This is the full Image reference, as would be specified to &quot;docker pull&quot;. If
no tag is provided as part of the Image name, the tag &quot;:latest&quot; is used as a
default.
      registry: ContainerRegistry, # Optional. This setting can be omitted if was already provided at Pool creation.
      workingDirectory: &quot;taskWorkingDirectory&quot; | &quot;containerImageDefault&quot;, # Optional. The default is &apos;taskWorkingDirectory&apos;.
    }, # Optional. When this is specified, all directories recursively below the
AZ_BATCH_NODE_ROOT_DIR (the root of Azure Batch directories on the node) are
mapped into the container, all Task environment variables are mapped into the
container, and the Task command line is executed in the container. Files
produced in the container outside of AZ_BATCH_NODE_ROOT_DIR might not be
reflected to the host disk, meaning that Batch file APIs will not be able to
access those files.
    resourceFiles: [ResourceFile], # Optional. Files listed under this element are located in the Task&apos;s working directory.
    environmentSettings: [EnvironmentSetting], # Optional. A list of environment variable settings for the StartTask.
    userIdentity: {
      username: string, # Optional. The userName and autoUser properties are mutually exclusive; you must specify
one but not both.
      autoUser: {
        scope: &quot;task&quot; | &quot;pool&quot;, # Optional. The default value is pool. If the pool is running Windows a value of Task
should be specified if stricter isolation between tasks is required. For
example, if the task mutates the registry in a way which could impact other
tasks, or if certificates have been specified on the pool which should not be
accessible by normal tasks but should be accessible by StartTasks.
        elevationLevel: &quot;nonadmin&quot; | &quot;admin&quot;, # Optional. The default value is nonAdmin.
      }, # Optional. The userName and autoUser properties are mutually exclusive; you must specify
one but not both.
    }, # Optional. If omitted, the Task runs as a non-administrative user unique to the Task.
    maxTaskRetryCount: number, # Optional. The Batch service retries a Task if its exit code is nonzero. Note that this
value specifically controls the number of retries. The Batch service will try
the Task once, and may then retry up to this limit. For example, if the maximum
retry count is 3, Batch tries the Task up to 4 times (one initial try and 3
retries). If the maximum retry count is 0, the Batch service does not retry the
Task. If the maximum retry count is -1, the Batch service retries the Task
without limit, however this is not recommended for a start task or any task.
The default value is 0 (no retries)
    waitForSuccess: boolean, # Optional. If true and the StartTask fails on a Node, the Batch service retries the
StartTask up to its maximum retry count (maxTaskRetryCount). If the Task has
still not completed successfully after all retries, then the Batch service
marks the Node unusable, and will not schedule Tasks to it. This condition can
be detected via the Compute Node state and failure info details. If false, the
Batch service will not wait for the StartTask to complete. In this case, other
Tasks can start executing on the Compute Node while the StartTask is still
running; and even if the StartTask fails, new Tasks will continue to be
scheduled on the Compute Node. The default is true.
  }, # Optional. Batch will retry Tasks when a recovery operation is triggered on a Node.
Examples of recovery operations include (but are not limited to) when an
unhealthy Node is rebooted or a Compute Node disappeared due to host failure.
Retries due to recovery operations are independent of and are not counted
against the maxTaskRetryCount. Even if the maxTaskRetryCount is 0, an internal
retry due to a recovery operation may occur. Because of this, all Tasks should
be idempotent. This means Tasks need to tolerate being interrupted and
restarted without causing any corruption or duplicate data. The best practice
for long running Tasks is to use some form of checkpointing. In some cases the
StartTask may be re-run even though the Compute Node was not rebooted. Special
care should be taken to avoid StartTasks which create breakaway process or
install/launch services from the StartTask working directory, as this will
block Batch from being able to re-run the StartTask.
  certificateReferences: [CertificateReference], # Optional. For Windows Nodes, the Batch service installs the Certificates to the specified
Certificate store and location. For Linux Compute Nodes, the Certificates are
stored in a directory inside the Task working directory and an environment
variable AZ_BATCH_CERTIFICATES_DIR is supplied to the Task to query for this
location. For Certificates with visibility of &apos;remoteUser&apos;, a &apos;certs&apos; directory
is created in the user&apos;s home directory (e.g., /home/{user-name}/certs) and
Certificates are placed in that directory.
  applicationPackageReferences: [ApplicationPackageReference], # Optional. Changes to Package references affect all new Nodes joining the Pool, but do not
affect Compute Nodes that are already in the Pool until they are rebooted or
reimaged. There is a maximum of 10 Package references on any given Pool.
  applicationLicenses: [string], # Optional. The list of application licenses must be a subset of available Batch service
application licenses. If a license is requested which is not supported, Pool
creation will fail.
  taskSlotsPerNode: number, # Optional. The default value is 1. The maximum value is the smaller of 4 times the number
of cores of the vmSize of the pool or 256.
  taskSchedulingPolicy: {
    nodeFillType: &quot;spread&quot; | &quot;pack&quot;, # Required. If not specified, the default is spread.
  }, # Optional. If not specified, the default is spread.
  userAccounts: [UserAccount], # Optional. The list of user Accounts to be created on each Compute Node in the Pool.
  metadata: [MetadataItem], # Optional. A list of name-value pairs associated with the Pool as metadata.
  stats: {
    url: string, # Required. The URL for the statistics.
    startTime: string (date &amp; time), # Required. The start time of the time range covered by the statistics.
    lastUpdateTime: string (date &amp; time), # Required. The time at which the statistics were last updated. All statistics are limited
to the range between startTime and lastUpdateTime.
    usageStats: {
      startTime: string (date &amp; time), # Required. The start time of the time range covered by the statistics.
      lastUpdateTime: string (date &amp; time), # Required. The time at which the statistics were last updated. All statistics are limited
to the range between startTime and lastUpdateTime.
      dedicatedCoreTime: string (duration ISO 8601 Format), # Required. The aggregated wall-clock time of the dedicated Compute Node cores being part
of the Pool.
    }, # Optional. Statistics related to Pool usage information.
    resourceStats: {
      startTime: string (date &amp; time), # Required. The start time of the time range covered by the statistics.
      lastUpdateTime: string (date &amp; time), # Required. The time at which the statistics were last updated. All statistics are limited
to the range between startTime and lastUpdateTime.
      avgCPUPercentage: number, # Required. The average CPU usage across all Compute Nodes in the Pool (percentage per
node).
      avgMemoryGiB: number, # Required. The average memory usage in GiB across all Compute Nodes in the Pool.
      peakMemoryGiB: number, # Required. The peak memory usage in GiB across all Compute Nodes in the Pool.
      avgDiskGiB: number, # Required. The average used disk space in GiB across all Compute Nodes in the Pool.
      peakDiskGiB: number, # Required. The peak used disk space in GiB across all Compute Nodes in the Pool.
      diskReadIOps: number, # Required. The total number of disk read operations across all Compute Nodes in the Pool.
      diskWriteIOps: number, # Required. The total number of disk write operations across all Compute Nodes in the Pool.
      diskReadGiB: number, # Required. The total amount of data in GiB of disk reads across all Compute Nodes in the
Pool.
      diskWriteGiB: number, # Required. The total amount of data in GiB of disk writes across all Compute Nodes in the
Pool.
      networkReadGiB: number, # Required. The total amount of data in GiB of network reads across all Compute Nodes in
the Pool.
      networkWriteGiB: number, # Required. The total amount of data in GiB of network writes across all Compute Nodes in
the Pool.
    }, # Optional. Statistics related to resource consumption by Compute Nodes in a Pool.
  }, # Optional. This property is populated only if the CloudPool was retrieved with an expand
clause including the &apos;stats&apos; attribute; otherwise it is null. The statistics
may not be immediately available. The Batch service performs periodic roll-up
of statistics. The typical delay is about 30 minutes.
  mountConfiguration: [MountConfiguration], # Optional. This supports Azure Files, NFS, CIFS/SMB, and Blobfuse.
  identity: {
    type: &quot;UserAssigned&quot; | &quot;None&quot;, # Required. The list of user identities associated with the Batch pool. The user identity
dictionary key references will be ARM resource ids in the form:
&apos;/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.ManagedIdentity/userAssignedIdentities/{identityName}&apos;.
    userAssignedIdentities: [UserAssignedIdentity], # Optional. The user identity dictionary key references will be ARM resource ids in the
form:
&apos;/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.ManagedIdentity/userAssignedIdentities/{identityName}&apos;.
  }, # Optional. The list of user identities associated with the Batch pool. The user identity
dictionary key references will be ARM resource ids in the form:
&apos;/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.ManagedIdentity/userAssignedIdentities/{identityName}&apos;.
  targetNodeCommunicationMode: &quot;default&quot; | &quot;classic&quot; | &quot;simplified&quot;, # Optional. If omitted, the default value is Default.
  currentNodeCommunicationMode: &quot;default&quot; | &quot;classic&quot; | &quot;simplified&quot;, # Optional. Determines how a pool communicates with the Batch service.
}
</code>

</remarks>
    </member>
    <member name="DisableAutoScaleAsync(String,Int32,String,Boolean,String,RequestContext)">
<example>
This sample shows how to call DisableAutoScaleAsync with required parameters.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetPoolClient(<2022-10-01.16.0>);

Response response = await client.DisableAutoScaleAsync("<poolId>");
Console.WriteLine(response.Status);
]]></code>
This sample shows how to call DisableAutoScaleAsync with all parameters.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetPoolClient(<2022-10-01.16.0>);

Response response = await client.DisableAutoScaleAsync("<poolId>", 1234, "<clientRequestId>", true, "<ocpDate>");
Console.WriteLine(response.Status);
]]></code>
</example>
    </member>
    <member name="DisableAutoScale(String,Int32,String,Boolean,String,RequestContext)">
<example>
This sample shows how to call DisableAutoScale with required parameters.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetPoolClient(<2022-10-01.16.0>);

Response response = client.DisableAutoScale("<poolId>");
Console.WriteLine(response.Status);
]]></code>
This sample shows how to call DisableAutoScale with all parameters.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetPoolClient(<2022-10-01.16.0>);

Response response = client.DisableAutoScale("<poolId>", 1234, "<clientRequestId>", true, "<ocpDate>");
Console.WriteLine(response.Status);
]]></code>
</example>
    </member>
    <member name="EnableAutoScaleAsync(String,RequestContent,Int32,String,Boolean,String,RequestConditions,RequestContext)">
<example>
This sample shows how to call EnableAutoScaleAsync with required parameters.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetPoolClient(<2022-10-01.16.0>);

var data = new {};

Response response = await client.EnableAutoScaleAsync("<poolId>", RequestContent.Create(data));
Console.WriteLine(response.Status);
]]></code>
This sample shows how to call EnableAutoScaleAsync with all parameters and request content.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetPoolClient(<2022-10-01.16.0>);

var data = new {
    autoScaleFormula = "<autoScaleFormula>",
    autoScaleEvaluationInterval = PT1H23M45S,
};

Response response = await client.EnableAutoScaleAsync("<poolId>", RequestContent.Create(data), 1234, "<clientRequestId>", true, "<ocpDate>", null);
Console.WriteLine(response.Status);
]]></code>
</example>
<remarks>
You cannot enable automatic scaling on a Pool if a resize operation is in
progress on the Pool. If automatic scaling of the Pool is currently disabled,
you must specify a valid autoscale formula as part of the request. If automatic
scaling of the Pool is already enabled, you may specify a new autoscale formula
and/or a new evaluation interval. You cannot call this API for the same Pool
more than once every 30 seconds.

Below is the JSON schema for the request payload.

Request Body:

Schema for <c>BatchPoolEnableAutoScaleParameters</c>:
<code>{
  autoScaleFormula: string, # Optional. The formula is checked for validity before it is applied to the Pool. If the
formula is not valid, the Batch service rejects the request with detailed error
information. For more information about specifying this formula, see
Automatically scale Compute Nodes in an Azure Batch Pool
(https://azure.microsoft.com/en-us/documentation/articles/batch-automatic-scaling).
  autoScaleEvaluationInterval: string (duration ISO 8601 Format), # Optional. The default value is 15 minutes. The minimum and maximum value are 5 minutes
and 168 hours respectively. If you specify a value less than 5 minutes or
greater than 168 hours, the Batch service rejects the request with an invalid
property value error; if you are calling the REST API directly, the HTTP status
code is 400 (Bad Request). If you specify a new interval, then the existing
autoscale evaluation schedule will be stopped and a new autoscale evaluation
schedule will be started, with its starting time being the time when this
request was issued.
}
</code>

</remarks>
    </member>
    <member name="EnableAutoScale(String,RequestContent,Int32,String,Boolean,String,RequestConditions,RequestContext)">
<example>
This sample shows how to call EnableAutoScale with required parameters.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetPoolClient(<2022-10-01.16.0>);

var data = new {};

Response response = client.EnableAutoScale("<poolId>", RequestContent.Create(data));
Console.WriteLine(response.Status);
]]></code>
This sample shows how to call EnableAutoScale with all parameters and request content.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetPoolClient(<2022-10-01.16.0>);

var data = new {
    autoScaleFormula = "<autoScaleFormula>",
    autoScaleEvaluationInterval = PT1H23M45S,
};

Response response = client.EnableAutoScale("<poolId>", RequestContent.Create(data), 1234, "<clientRequestId>", true, "<ocpDate>", null);
Console.WriteLine(response.Status);
]]></code>
</example>
<remarks>
You cannot enable automatic scaling on a Pool if a resize operation is in
progress on the Pool. If automatic scaling of the Pool is currently disabled,
you must specify a valid autoscale formula as part of the request. If automatic
scaling of the Pool is already enabled, you may specify a new autoscale formula
and/or a new evaluation interval. You cannot call this API for the same Pool
more than once every 30 seconds.

Below is the JSON schema for the request payload.

Request Body:

Schema for <c>BatchPoolEnableAutoScaleParameters</c>:
<code>{
  autoScaleFormula: string, # Optional. The formula is checked for validity before it is applied to the Pool. If the
formula is not valid, the Batch service rejects the request with detailed error
information. For more information about specifying this formula, see
Automatically scale Compute Nodes in an Azure Batch Pool
(https://azure.microsoft.com/en-us/documentation/articles/batch-automatic-scaling).
  autoScaleEvaluationInterval: string (duration ISO 8601 Format), # Optional. The default value is 15 minutes. The minimum and maximum value are 5 minutes
and 168 hours respectively. If you specify a value less than 5 minutes or
greater than 168 hours, the Batch service rejects the request with an invalid
property value error; if you are calling the REST API directly, the HTTP status
code is 400 (Bad Request). If you specify a new interval, then the existing
autoscale evaluation schedule will be stopped and a new autoscale evaluation
schedule will be started, with its starting time being the time when this
request was issued.
}
</code>

</remarks>
    </member>
    <member name="EvaluateAutoScaleAsync(String,RequestContent,Int32,String,Boolean,String,RequestContext)">
<example>
This sample shows how to call EvaluateAutoScaleAsync with required parameters and request content, and how to parse the result.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetPoolClient(<2022-10-01.16.0>);

var data = new {
    autoScaleFormula = "<autoScaleFormula>",
};

Response response = await client.EvaluateAutoScaleAsync("<poolId>", RequestContent.Create(data));

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.GetProperty("timestamp").ToString());
]]></code>
This sample shows how to call EvaluateAutoScaleAsync with all parameters and request content, and how to parse the result.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetPoolClient(<2022-10-01.16.0>);

var data = new {
    autoScaleFormula = "<autoScaleFormula>",
};

Response response = await client.EvaluateAutoScaleAsync("<poolId>", RequestContent.Create(data), 1234, "<clientRequestId>", true, "<ocpDate>");

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.GetProperty("timestamp").ToString());
Console.WriteLine(result.GetProperty("results").ToString());
Console.WriteLine(result.GetProperty("error").GetProperty("code").ToString());
Console.WriteLine(result.GetProperty("error").GetProperty("message").ToString());
Console.WriteLine(result.GetProperty("error").GetProperty("values")[0].GetProperty("name").ToString());
Console.WriteLine(result.GetProperty("error").GetProperty("values")[0].GetProperty("value").ToString());
]]></code>
</example>
<remarks>
This API is primarily for validating an autoscale formula, as it simply returns
the result without applying the formula to the Pool. The Pool must have auto
scaling enabled in order to evaluate a formula.

Below is the JSON schema for the request and response payloads.

Request Body:

Schema for <c>BatchPoolEvaluateAutoScaleParameters</c>:
<code>{
  autoScaleFormula: string, # Required. The formula is validated and its results calculated, but it is not applied to
the Pool. To apply the formula to the Pool, &apos;Enable automatic scaling on a
Pool&apos;. For more information about specifying this formula, see Automatically
scale Compute Nodes in an Azure Batch Pool
(https://azure.microsoft.com/en-us/documentation/articles/batch-automatic-scaling).
}
</code>

Response Body:

Schema for <c>AutoScaleRun</c>:
<code>{
  timestamp: string (date &amp; time), # Required. The time at which the autoscale formula was last evaluated.
  results: string, # Optional. Each variable value is returned in the form $variable=value, and variables are
separated by semicolons.
  error: {
    code: string, # Optional. An identifier for the autoscale error. Codes are invariant and are intended to
be consumed programmatically.
    message: string, # Optional. A message describing the autoscale error, intended to be suitable for display
in a user interface.
    values: [
      {
        name: string, # Optional. The name in the name-value pair.
        value: string, # Optional. The value in the name-value pair.
      }
    ], # Optional. A list of additional error details related to the autoscale error.
  }, # Optional. An error that occurred when executing or evaluating a Pool autoscale formula.
}
</code>

</remarks>
    </member>
    <member name="EvaluateAutoScale(String,RequestContent,Int32,String,Boolean,String,RequestContext)">
<example>
This sample shows how to call EvaluateAutoScale with required parameters and request content, and how to parse the result.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetPoolClient(<2022-10-01.16.0>);

var data = new {
    autoScaleFormula = "<autoScaleFormula>",
};

Response response = client.EvaluateAutoScale("<poolId>", RequestContent.Create(data));

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.GetProperty("timestamp").ToString());
]]></code>
This sample shows how to call EvaluateAutoScale with all parameters and request content, and how to parse the result.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetPoolClient(<2022-10-01.16.0>);

var data = new {
    autoScaleFormula = "<autoScaleFormula>",
};

Response response = client.EvaluateAutoScale("<poolId>", RequestContent.Create(data), 1234, "<clientRequestId>", true, "<ocpDate>");

JsonElement result = JsonDocument.Parse(response.ContentStream).RootElement;
Console.WriteLine(result.GetProperty("timestamp").ToString());
Console.WriteLine(result.GetProperty("results").ToString());
Console.WriteLine(result.GetProperty("error").GetProperty("code").ToString());
Console.WriteLine(result.GetProperty("error").GetProperty("message").ToString());
Console.WriteLine(result.GetProperty("error").GetProperty("values")[0].GetProperty("name").ToString());
Console.WriteLine(result.GetProperty("error").GetProperty("values")[0].GetProperty("value").ToString());
]]></code>
</example>
<remarks>
This API is primarily for validating an autoscale formula, as it simply returns
the result without applying the formula to the Pool. The Pool must have auto
scaling enabled in order to evaluate a formula.

Below is the JSON schema for the request and response payloads.

Request Body:

Schema for <c>BatchPoolEvaluateAutoScaleParameters</c>:
<code>{
  autoScaleFormula: string, # Required. The formula is validated and its results calculated, but it is not applied to
the Pool. To apply the formula to the Pool, &apos;Enable automatic scaling on a
Pool&apos;. For more information about specifying this formula, see Automatically
scale Compute Nodes in an Azure Batch Pool
(https://azure.microsoft.com/en-us/documentation/articles/batch-automatic-scaling).
}
</code>

Response Body:

Schema for <c>AutoScaleRun</c>:
<code>{
  timestamp: string (date &amp; time), # Required. The time at which the autoscale formula was last evaluated.
  results: string, # Optional. Each variable value is returned in the form $variable=value, and variables are
separated by semicolons.
  error: {
    code: string, # Optional. An identifier for the autoscale error. Codes are invariant and are intended to
be consumed programmatically.
    message: string, # Optional. A message describing the autoscale error, intended to be suitable for display
in a user interface.
    values: [
      {
        name: string, # Optional. The name in the name-value pair.
        value: string, # Optional. The value in the name-value pair.
      }
    ], # Optional. A list of additional error details related to the autoscale error.
  }, # Optional. An error that occurred when executing or evaluating a Pool autoscale formula.
}
</code>

</remarks>
    </member>
    <member name="ResizeAsync(String,RequestContent,Int32,String,Boolean,String,RequestConditions,RequestContext)">
<example>
This sample shows how to call ResizeAsync with required parameters.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetPoolClient(<2022-10-01.16.0>);

var data = new {};

Response response = await client.ResizeAsync("<poolId>", RequestContent.Create(data));
Console.WriteLine(response.Status);
]]></code>
This sample shows how to call ResizeAsync with all parameters and request content.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetPoolClient(<2022-10-01.16.0>);

var data = new {
    targetDedicatedNodes = 1234,
    targetLowPriorityNodes = 1234,
    resizeTimeout = PT1H23M45S,
    nodeDeallocationOption = "requeue",
};

Response response = await client.ResizeAsync("<poolId>", RequestContent.Create(data), 1234, "<clientRequestId>", true, "<ocpDate>", null);
Console.WriteLine(response.Status);
]]></code>
</example>
<remarks>
You can only resize a Pool when its allocation state is steady. If the Pool is
already resizing, the request fails with status code 409. When you resize a
Pool, the Pool&apos;s allocation state changes from steady to resizing. You cannot
resize Pools which are configured for automatic scaling. If you try to do this,
the Batch service returns an error 409. If you resize a Pool downwards, the
Batch service chooses which Compute Nodes to remove. To remove specific Compute
Nodes, use the Pool remove Compute Nodes API instead.

Below is the JSON schema for the request payload.

Request Body:

Schema for <c>BatchPoolResizeParameters</c>:
<code>{
  targetDedicatedNodes: number, # Optional. The desired number of dedicated Compute Nodes in the Pool.
  targetLowPriorityNodes: number, # Optional. The desired number of Spot/Low-priority Compute Nodes in the Pool.
  resizeTimeout: string (duration ISO 8601 Format), # Optional. The default value is 15 minutes. The minimum value is 5 minutes. If you specify
a value less than 5 minutes, the Batch service returns an error; if you are
calling the REST API directly, the HTTP status code is 400 (Bad Request).
  nodeDeallocationOption: &quot;requeue&quot; | &quot;terminate&quot; | &quot;taskcompletion&quot; | &quot;retaineddata&quot;, # Optional. The default value is requeue.
}
</code>

</remarks>
    </member>
    <member name="Resize(String,RequestContent,Int32,String,Boolean,String,RequestConditions,RequestContext)">
<example>
This sample shows how to call Resize with required parameters.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetPoolClient(<2022-10-01.16.0>);

var data = new {};

Response response = client.Resize("<poolId>", RequestContent.Create(data));
Console.WriteLine(response.Status);
]]></code>
This sample shows how to call Resize with all parameters and request content.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetPoolClient(<2022-10-01.16.0>);

var data = new {
    targetDedicatedNodes = 1234,
    targetLowPriorityNodes = 1234,
    resizeTimeout = PT1H23M45S,
    nodeDeallocationOption = "requeue",
};

Response response = client.Resize("<poolId>", RequestContent.Create(data), 1234, "<clientRequestId>", true, "<ocpDate>", null);
Console.WriteLine(response.Status);
]]></code>
</example>
<remarks>
You can only resize a Pool when its allocation state is steady. If the Pool is
already resizing, the request fails with status code 409. When you resize a
Pool, the Pool&apos;s allocation state changes from steady to resizing. You cannot
resize Pools which are configured for automatic scaling. If you try to do this,
the Batch service returns an error 409. If you resize a Pool downwards, the
Batch service chooses which Compute Nodes to remove. To remove specific Compute
Nodes, use the Pool remove Compute Nodes API instead.

Below is the JSON schema for the request payload.

Request Body:

Schema for <c>BatchPoolResizeParameters</c>:
<code>{
  targetDedicatedNodes: number, # Optional. The desired number of dedicated Compute Nodes in the Pool.
  targetLowPriorityNodes: number, # Optional. The desired number of Spot/Low-priority Compute Nodes in the Pool.
  resizeTimeout: string (duration ISO 8601 Format), # Optional. The default value is 15 minutes. The minimum value is 5 minutes. If you specify
a value less than 5 minutes, the Batch service returns an error; if you are
calling the REST API directly, the HTTP status code is 400 (Bad Request).
  nodeDeallocationOption: &quot;requeue&quot; | &quot;terminate&quot; | &quot;taskcompletion&quot; | &quot;retaineddata&quot;, # Optional. The default value is requeue.
}
</code>

</remarks>
    </member>
    <member name="StopResizeAsync(String,Int32,String,Boolean,String,RequestConditions,RequestContext)">
<example>
This sample shows how to call StopResizeAsync with required parameters.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetPoolClient(<2022-10-01.16.0>);

Response response = await client.StopResizeAsync("<poolId>");
Console.WriteLine(response.Status);
]]></code>
This sample shows how to call StopResizeAsync with all parameters.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetPoolClient(<2022-10-01.16.0>);

Response response = await client.StopResizeAsync("<poolId>", 1234, "<clientRequestId>", true, "<ocpDate>", null);
Console.WriteLine(response.Status);
]]></code>
</example>
<remarks>
This does not restore the Pool to its previous state before the resize
operation: it only stops any further changes being made, and the Pool maintains
its current state. After stopping, the Pool stabilizes at the number of Compute
Nodes it was at when the stop operation was done. During the stop operation,
the Pool allocation state changes first to stopping and then to steady. A
resize operation need not be an explicit resize Pool request; this API can also
be used to halt the initial sizing of the Pool when it is created.
</remarks>
    </member>
    <member name="StopResize(String,Int32,String,Boolean,String,RequestConditions,RequestContext)">
<example>
This sample shows how to call StopResize with required parameters.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetPoolClient(<2022-10-01.16.0>);

Response response = client.StopResize("<poolId>");
Console.WriteLine(response.Status);
]]></code>
This sample shows how to call StopResize with all parameters.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetPoolClient(<2022-10-01.16.0>);

Response response = client.StopResize("<poolId>", 1234, "<clientRequestId>", true, "<ocpDate>", null);
Console.WriteLine(response.Status);
]]></code>
</example>
<remarks>
This does not restore the Pool to its previous state before the resize
operation: it only stops any further changes being made, and the Pool maintains
its current state. After stopping, the Pool stabilizes at the number of Compute
Nodes it was at when the stop operation was done. During the stop operation,
the Pool allocation state changes first to stopping and then to steady. A
resize operation need not be an explicit resize Pool request; this API can also
be used to halt the initial sizing of the Pool when it is created.
</remarks>
    </member>
    <member name="UpdatePropertiesAsync(String,RequestContent,Int32,String,Boolean,String,RequestContext)">
<example>
This sample shows how to call UpdatePropertiesAsync with required parameters.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetPoolClient(<2022-10-01.16.0>);

var data = new {};

Response response = await client.UpdatePropertiesAsync("<poolId>", RequestContent.Create(data));
Console.WriteLine(response.Status);
]]></code>
This sample shows how to call UpdatePropertiesAsync with all parameters and request content.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetPoolClient(<2022-10-01.16.0>);

var data = new {
    id = "<id>",
    displayName = "<displayName>",
    vmSize = "<vmSize>",
    cloudServiceConfiguration = new {
        osFamily = "<osFamily>",
        osVersion = "<osVersion>",
    },
    virtualMachineConfiguration = new {
        imageReference = new {
            publisher = "<publisher>",
            offer = "<offer>",
            sku = "<sku>",
            version = "<version>",
            virtualMachineImageId = "<virtualMachineImageId>",
        },
        nodeAgentSKUId = "<nodeAgentSKUId>",
        windowsConfiguration = new {
            enableAutomaticUpdates = true,
        },
        dataDisks = new[] {
            new {
                lun = 1234,
                caching = "none",
                diskSizeGB = 1234,
                storageAccountType = "standard_lrs",
            }
        },
        licenseType = "<licenseType>",
        containerConfiguration = new {
            type = "dockerCompatible",
            containerImageNames = new[] {
                "<String>"
            },
            containerRegistries = new[] {
                new {
                    username = "<username>",
                    password = "<password>",
                    registryServer = "<registryServer>",
                    identityReference = new {
                        resourceId = "<resourceId>",
                    },
                }
            },
        },
        diskEncryptionConfiguration = new {
            targets = new[] {
                "osdisk"
            },
        },
        nodePlacementConfiguration = new {
            policy = "regional",
        },
        extensions = new[] {
            new {
                name = "<name>",
                publisher = "<publisher>",
                type = "<type>",
                typeHandlerVersion = "<typeHandlerVersion>",
                autoUpgradeMinorVersion = true,
                settings = new {},
                protectedSettings = new {},
                provisionAfterExtensions = new[] {
                    "<String>"
                },
            }
        },
        osDisk = new {
            ephemeralOSDiskSettings = new {
                placement = "cachedisk",
            },
        },
    },
    resizeTimeout = PT1H23M45S,
    targetDedicatedNodes = 1234,
    targetLowPriorityNodes = 1234,
    enableAutoScale = true,
    autoScaleFormula = "<autoScaleFormula>",
    autoScaleEvaluationInterval = PT1H23M45S,
    enableInterNodeCommunication = true,
    networkConfiguration = new {
        subnetId = "<subnetId>",
        dynamicVNetAssignmentScope = "none",
        endpointConfiguration = new {
            inboundNATPools = new[] {
                new {
                    name = "<name>",
                    protocol = "tcp",
                    backendPort = 1234,
                    frontendPortRangeStart = 1234,
                    frontendPortRangeEnd = 1234,
                    networkSecurityGroupRules = new[] {
                        new {
                            priority = 1234,
                            access = "allow",
                            sourceAddressPrefix = "<sourceAddressPrefix>",
                            sourcePortRanges = new[] {
                                "<String>"
                            },
                        }
                    },
                }
            },
        },
        publicIPAddressConfiguration = new {
            provision = "batchmanaged",
            ipAddressIds = new[] {
                "<String>"
            },
        },
    },
    startTask = new {
        commandLine = "<commandLine>",
        containerSettings = new {
            containerRunOptions = "<containerRunOptions>",
            imageName = "<imageName>",
            registry = new {
                username = "<username>",
                password = "<password>",
                registryServer = "<registryServer>",
                identityReference = new {
                    resourceId = "<resourceId>",
                },
            },
            workingDirectory = "taskWorkingDirectory",
        },
        resourceFiles = new[] {
            new {
                autoStorageContainerName = "<autoStorageContainerName>",
                storageContainerUrl = "<storageContainerUrl>",
                httpUrl = "<httpUrl>",
                blobPrefix = "<blobPrefix>",
                filePath = "<filePath>",
                fileMode = "<fileMode>",
                identityReference = new {
                    resourceId = "<resourceId>",
                },
            }
        },
        environmentSettings = new[] {
            new {
                name = "<name>",
                value = "<value>",
            }
        },
        userIdentity = new {
            username = "<username>",
            autoUser = new {
                scope = "task",
                elevationLevel = "nonadmin",
            },
        },
        maxTaskRetryCount = 1234,
        waitForSuccess = true,
    },
    certificateReferences = new[] {
        new {
            thumbprint = "<thumbprint>",
            thumbprintAlgorithm = "<thumbprintAlgorithm>",
            storeLocation = "currentuser",
            storeName = "<storeName>",
            visibility = new[] {
                "starttask"
            },
        }
    },
    applicationPackageReferences = new[] {
        new {
            applicationId = "<applicationId>",
            version = "<version>",
        }
    },
    applicationLicenses = new[] {
        "<String>"
    },
    taskSlotsPerNode = 1234,
    taskSchedulingPolicy = new {
        nodeFillType = "spread",
    },
    userAccounts = new[] {
        new {
            name = "<name>",
            password = "<password>",
            elevationLevel = "nonadmin",
            linuxUserConfiguration = new {
                uid = 1234,
                gid = 1234,
                sshPrivateKey = "<sshPrivateKey>",
            },
            windowsUserConfiguration = new {
                loginMode = "batch",
            },
        }
    },
    metadata = new[] {
        new {
            name = "<name>",
            value = "<value>",
        }
    },
    mountConfiguration = new[] {
        new {
            azureBlobFileSystemConfiguration = new {
                accountName = "<accountName>",
                containerName = "<containerName>",
                accountKey = "<accountKey>",
                sasKey = "<sasKey>",
                blobfuseOptions = "<blobfuseOptions>",
                relativeMountPath = "<relativeMountPath>",
                identityReference = new {
                    resourceId = "<resourceId>",
                },
            },
            nfsMountConfiguration = new {
                source = "<source>",
                relativeMountPath = "<relativeMountPath>",
                mountOptions = "<mountOptions>",
            },
            cifsMountConfiguration = new {
                username = "<username>",
                source = "<source>",
                relativeMountPath = "<relativeMountPath>",
                mountOptions = "<mountOptions>",
                password = "<password>",
            },
            azureFileShareConfiguration = new {
                accountName = "<accountName>",
                azureFileUrl = "<azureFileUrl>",
                accountKey = "<accountKey>",
                relativeMountPath = "<relativeMountPath>",
                mountOptions = "<mountOptions>",
            },
        }
    },
    targetNodeCommunicationMode = "default",
};

Response response = await client.UpdatePropertiesAsync("<poolId>", RequestContent.Create(data), 1234, "<clientRequestId>", true, "<ocpDate>");
Console.WriteLine(response.Status);
]]></code>
</example>
<remarks>
This fully replaces all the updatable properties of the Pool. For example, if
the Pool has a StartTask associated with it and if StartTask is not specified
with this request, then the Batch service will remove the existing StartTask.

Below is the JSON schema for the request payload.

Request Body:

Schema for <c>BatchPool</c>:
<code>{
  id: string, # Optional. The ID can contain any combination of alphanumeric characters including hyphens
and underscores, and cannot contain more than 64 characters. The ID is
case-preserving and case-insensitive (that is, you may not have two IDs within
an Account that differ only by case).
  displayName: string, # Optional. The display name need not be unique and can contain any Unicode characters up
to a maximum length of 1024.
  url: string, # Optional. The URL of the Pool.
  eTag: string, # Optional. This is an opaque string. You can use it to detect whether the Pool has changed
between requests. In particular, you can be pass the ETag when updating a Pool
to specify that your changes should take effect only if nobody else has
modified the Pool in the meantime.
  lastModified: string (date &amp; time), # Optional. This is the last time at which the Pool level data, such as the
targetDedicatedNodes or enableAutoscale settings, changed. It does not factor
in node-level changes such as a Compute Node changing state.
  creationTime: string (date &amp; time), # Optional. The creation time of the Pool.
  state: &quot;active&quot; | &quot;deleting&quot;, # Optional. The current state of the Pool.
  stateTransitionTime: string (date &amp; time), # Optional. The time at which the Pool entered its current state.
  allocationState: &quot;steady&quot; | &quot;resizing&quot; | &quot;stopping&quot;, # Optional. Whether the Pool is resizing.
  allocationStateTransitionTime: string (date &amp; time), # Optional. The time at which the Pool entered its current allocation state.
  vmSize: string, # Optional. For information about available sizes of virtual machines in Pools, see Choose
a VM size for Compute Nodes in an Azure Batch Pool
(https://docs.microsoft.com/azure/batch/batch-pool-vm-sizes).
  cloudServiceConfiguration: {
    osFamily: string, # Required. Possible values are:
2 - OS Family 2, equivalent to Windows Server 2008 R2
SP1.
3 - OS Family 3, equivalent to Windows Server 2012.
4 - OS Family 4,
equivalent to Windows Server 2012 R2.
5 - OS Family 5, equivalent to Windows
Server 2016.
6 - OS Family 6, equivalent to Windows Server 2019. For more
information, see Azure Guest OS Releases
(https://azure.microsoft.com/documentation/articles/cloud-services-guestos-update-matrix/#releases).
    osVersion: string, # Optional. The default value is * which specifies the latest operating system version for
the specified OS family.
  }, # Optional. This property and virtualMachineConfiguration are mutually exclusive and one of
the properties must be specified. This property cannot be specified if the
Batch Account was created with its poolAllocationMode property set to
&apos;UserSubscription&apos;.
  virtualMachineConfiguration: {
    imageReference: {
      publisher: string, # Optional. For example, Canonical or MicrosoftWindowsServer.
      offer: string, # Optional. For example, UbuntuServer or WindowsServer.
      sku: string, # Optional. For example, 18.04-LTS or 2019-Datacenter.
      version: string, # Optional. A value of &apos;latest&apos; can be specified to select the latest version of an Image.
If omitted, the default is &apos;latest&apos;.
      virtualMachineImageId: string, # Optional. This property is mutually exclusive with other ImageReference properties. The
Shared Image Gallery Image must have replicas in the same region and must be in
the same subscription as the Azure Batch account. If the image version is not
specified in the imageId, the latest version will be used. For information
about the firewall settings for the Batch Compute Node agent to communicate
with the Batch service see
https://docs.microsoft.com/en-us/azure/batch/batch-api-basics#virtual-network-vnet-and-firewall-configuration.
      exactVersion: string, # Optional. The specific version of the platform image or marketplace image used to create
the node. This read-only field differs from &apos;version&apos; only if the value
specified for &apos;version&apos; when the pool was created was &apos;latest&apos;.
    }, # Required. A reference to an Azure Virtual Machines Marketplace Image or a Shared Image
Gallery Image. To get the list of all Azure Marketplace Image references
verified by Azure Batch, see the &apos;List Supported Images&apos; operation.
    nodeAgentSKUId: string, # Required. The Batch Compute Node agent is a program that runs on each Compute Node in the
Pool, and provides the command-and-control interface between the Compute Node
and the Batch service. There are different implementations of the Compute Node
agent, known as SKUs, for different operating systems. You must specify a
Compute Node agent SKU which matches the selected Image reference. To get the
list of supported Compute Node agent SKUs along with their list of verified
Image references, see the &apos;List supported Compute Node agent SKUs&apos; operation.
    windowsConfiguration: {
      enableAutomaticUpdates: boolean, # Optional. If omitted, the default value is true.
    }, # Optional. This property must not be specified if the imageReference property specifies a
Linux OS Image.
    dataDisks: [DataDisk], # Optional. This property must be specified if the Compute Nodes in the Pool need to have
empty data disks attached to them. This cannot be updated. Each Compute Node
gets its own disk (the disk is not a file share). Existing disks cannot be
attached, each attached disk is empty. When the Compute Node is removed from
the Pool, the disk and all data associated with it is also deleted. The disk is
not formatted after being attached, it must be formatted before use - for more
information see
https://docs.microsoft.com/en-us/azure/virtual-machines/linux/classic/attach-disk#initialize-a-new-data-disk-in-linux
and
https://docs.microsoft.com/en-us/azure/virtual-machines/windows/attach-disk-ps#add-an-empty-data-disk-to-a-virtual-machine.
    licenseType: string, # Optional. This only applies to Images that contain the Windows operating system, and
should only be used when you hold valid on-premises licenses for the Compute
Nodes which will be deployed. If omitted, no on-premises licensing discount is
applied. Values are:

 Windows_Server - The on-premises license is for Windows
Server.
 Windows_Client - The on-premises license is for Windows Client.

    containerConfiguration: {
      type: &quot;dockerCompatible&quot;, # Required. The container technology to be used.
      containerImageNames: [string], # Optional. This is the full Image reference, as would be specified to &quot;docker pull&quot;. An
Image will be sourced from the default Docker registry unless the Image is
fully qualified with an alternative registry.
      containerRegistries: [
        {
          username: string, # Optional. The user name to log into the registry server.
          password: string, # Optional. The password to log into the registry server.
          registryServer: string, # Optional. If omitted, the default is &quot;docker.io&quot;.
          identityReference: {
            resourceId: string, # Optional. The ARM resource id of the user assigned identity.
          }, # Optional. The reference to a user assigned identity associated with the Batch pool which
a compute node will use.
        }
      ], # Optional. If any Images must be downloaded from a private registry which requires
credentials, then those credentials must be provided here.
    }, # Optional. If specified, setup is performed on each Compute Node in the Pool to allow
Tasks to run in containers. All regular Tasks and Job manager Tasks run on this
Pool must specify the containerSettings property, and all other Tasks may
specify it.
    diskEncryptionConfiguration: {
      targets: [&quot;osdisk&quot; | &quot;temporarydisk&quot;], # Optional. If omitted, no disks on the compute nodes in the pool will be encrypted. On
Linux pool, only &quot;TemporaryDisk&quot; is supported; on Windows pool, &quot;OsDisk&quot;
and &quot;TemporaryDisk&quot; must be specified.
    }, # Optional. If specified, encryption is performed on each node in the pool during node
provisioning.
    nodePlacementConfiguration: {
      policy: &quot;regional&quot; | &quot;zonal&quot;, # Optional. Allocation policy used by Batch Service to provision the nodes. If not
specified, Batch will use the regional policy.
    }, # Optional. This configuration will specify rules on how nodes in the pool will be
physically allocated.
    extensions: [VMExtension], # Optional. If specified, the extensions mentioned in this configuration will be installed
on each node.
    osDisk: {
      ephemeralOSDiskSettings: {
        placement: &quot;cachedisk&quot;, # Optional. This property can be used by user in the request to choose the location e.g.,
cache disk space for Ephemeral OS disk provisioning. For more information on
Ephemeral OS disk size requirements, please refer to Ephemeral OS disk size
requirements for Windows VMs at
https://docs.microsoft.com/en-us/azure/virtual-machines/windows/ephemeral-os-disks#size-requirements
and Linux VMs at
https://docs.microsoft.com/en-us/azure/virtual-machines/linux/ephemeral-os-disks#size-requirements.
      }, # Optional. Specifies the ephemeral Disk Settings for the operating system disk used by the
compute node (VM).
    }, # Optional. Settings for the operating system disk of the compute node (VM).
  }, # Optional. This property and cloudServiceConfiguration are mutually exclusive and one of
the properties must be specified.
  resizeTimeout: string (duration ISO 8601 Format), # Optional. This is the timeout for the most recent resize operation. (The initial sizing
when the Pool is created counts as a resize.) The default value is 15 minutes.
  resizeErrors: [
    {
      code: string, # Optional. An identifier for the Pool resize error. Codes are invariant and are intended
to be consumed programmatically.
      message: string, # Optional. A message describing the Pool resize error, intended to be suitable for display
in a user interface.
      values: [NameValuePair], # Optional. A list of additional error details related to the Pool resize error.
    }
  ], # Optional. This property is set only if one or more errors occurred during the last Pool
resize, and only when the Pool allocationState is Steady.
  currentDedicatedNodes: number, # Optional. The number of dedicated Compute Nodes currently in the Pool.
  currentLowPriorityNodes: number, # Optional. Spot/Low-priority Compute Nodes which have been preempted are included in this
count.
  targetDedicatedNodes: number, # Optional. The desired number of dedicated Compute Nodes in the Pool.
  targetLowPriorityNodes: number, # Optional. The desired number of Spot/Low-priority Compute Nodes in the Pool.
  enableAutoScale: boolean, # Optional. If false, at least one of targetDedicatedNodes and targetLowPriorityNodes must
be specified. If true, the autoScaleFormula property is required and the Pool
automatically resizes according to the formula. The default value is false.
  autoScaleFormula: string, # Optional. This property is set only if the Pool automatically scales, i.e.
enableAutoScale is true.
  autoScaleEvaluationInterval: string (duration ISO 8601 Format), # Optional. This property is set only if the Pool automatically scales, i.e.
enableAutoScale is true.
  autoScaleRun: {
    timestamp: string (date &amp; time), # Required. The time at which the autoscale formula was last evaluated.
    results: string, # Optional. Each variable value is returned in the form $variable=value, and variables are
separated by semicolons.
    error: {
      code: string, # Optional. An identifier for the autoscale error. Codes are invariant and are intended to
be consumed programmatically.
      message: string, # Optional. A message describing the autoscale error, intended to be suitable for display
in a user interface.
      values: [NameValuePair], # Optional. A list of additional error details related to the autoscale error.
    }, # Optional. An error that occurred when executing or evaluating a Pool autoscale formula.
  }, # Optional. This property is set only if the Pool automatically scales, i.e.
enableAutoScale is true.
  enableInterNodeCommunication: boolean, # Optional. This imposes restrictions on which Compute Nodes can be assigned to the Pool.
Specifying this value can reduce the chance of the requested number of Compute
Nodes to be allocated in the Pool.
  networkConfiguration: {
    subnetId: string, # Optional. The virtual network must be in the same region and subscription as the Azure
Batch Account. The specified subnet should have enough free IP addresses to
accommodate the number of Compute Nodes in the Pool. If the subnet doesn&apos;t have
enough free IP addresses, the Pool will partially allocate Nodes and a resize
error will occur. The &apos;MicrosoftAzureBatch&apos; service principal must have the
&apos;Classic Virtual Machine Contributor&apos; Role-Based Access Control (RBAC) role for
the specified VNet. The specified subnet must allow communication from the
Azure Batch service to be able to schedule Tasks on the Nodes. This can be
verified by checking if the specified VNet has any associated Network Security
Groups (NSG). If communication to the Nodes in the specified subnet is denied
by an NSG, then the Batch service will set the state of the Compute Nodes to
unusable. For Pools created with virtualMachineConfiguration only ARM virtual
networks (&apos;Microsoft.Network/virtualNetworks&apos;) are supported, but for Pools
created with cloudServiceConfiguration both ARM and classic virtual networks
are supported. If the specified VNet has any associated Network Security Groups
(NSG), then a few reserved system ports must be enabled for inbound
communication. For Pools created with a virtual machine configuration, enable
ports 29876 and 29877, as well as port 22 for Linux and port 3389 for Windows.
For Pools created with a cloud service configuration, enable ports 10100,
20100, and 30100. Also enable outbound connections to Azure Storage on port
443. For more details see:
https://docs.microsoft.com/en-us/azure/batch/batch-api-basics#virtual-network-vnet-and-firewall-configuration
    dynamicVNetAssignmentScope: &quot;none&quot; | &quot;job&quot;, # Optional. The scope of dynamic vnet assignment.
    endpointConfiguration: {
      inboundNATPools: [InboundNATPool], # Required. The maximum number of inbound NAT Pools per Batch Pool is 5. If the maximum
number of inbound NAT Pools is exceeded the request fails with HTTP status code
400. This cannot be specified if the IPAddressProvisioningType is
NoPublicIPAddresses.
    }, # Optional. Pool endpoint configuration is only supported on Pools with the
virtualMachineConfiguration property.
    publicIPAddressConfiguration: {
      provision: &quot;batchmanaged&quot; | &quot;usermanaged&quot; | &quot;nopublicipaddresses&quot;, # Optional. The default value is BatchManaged.
      ipAddressIds: [string], # Optional. The number of IPs specified here limits the maximum size of the Pool - 100
dedicated nodes or 100 Spot/Low-priority nodes can be allocated for each public
IP. For example, a pool needing 250 dedicated VMs would need at least 3 public
IPs specified. Each element of this collection is of the form:
/subscriptions/{subscription}/resourceGroups/{group}/providers/Microsoft.Network/publicIPAddresses/{ip}.
    }, # Optional. Public IP configuration property is only supported on Pools with the
virtualMachineConfiguration property.
  }, # Optional. The network configuration for a Pool.
  startTask: {
    commandLine: string, # Required. The command line does not run under a shell, and therefore cannot take
advantage of shell features such as environment variable expansion. If you want
to take advantage of such features, you should invoke the shell in the command
line, for example using &quot;cmd /c MyCommand&quot; in Windows or &quot;/bin/sh -c
MyCommand&quot; in Linux. If the command line refers to file paths, it should use a
relative path (relative to the Task working directory), or use the Batch
provided environment variable
(https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).
    containerSettings: {
      containerRunOptions: string, # Optional. These additional options are supplied as arguments to the &quot;docker create&quot;
command, in addition to those controlled by the Batch Service.
      imageName: string, # Required. This is the full Image reference, as would be specified to &quot;docker pull&quot;. If
no tag is provided as part of the Image name, the tag &quot;:latest&quot; is used as a
default.
      registry: ContainerRegistry, # Optional. This setting can be omitted if was already provided at Pool creation.
      workingDirectory: &quot;taskWorkingDirectory&quot; | &quot;containerImageDefault&quot;, # Optional. The default is &apos;taskWorkingDirectory&apos;.
    }, # Optional. When this is specified, all directories recursively below the
AZ_BATCH_NODE_ROOT_DIR (the root of Azure Batch directories on the node) are
mapped into the container, all Task environment variables are mapped into the
container, and the Task command line is executed in the container. Files
produced in the container outside of AZ_BATCH_NODE_ROOT_DIR might not be
reflected to the host disk, meaning that Batch file APIs will not be able to
access those files.
    resourceFiles: [ResourceFile], # Optional. Files listed under this element are located in the Task&apos;s working directory.
    environmentSettings: [EnvironmentSetting], # Optional. A list of environment variable settings for the StartTask.
    userIdentity: {
      username: string, # Optional. The userName and autoUser properties are mutually exclusive; you must specify
one but not both.
      autoUser: {
        scope: &quot;task&quot; | &quot;pool&quot;, # Optional. The default value is pool. If the pool is running Windows a value of Task
should be specified if stricter isolation between tasks is required. For
example, if the task mutates the registry in a way which could impact other
tasks, or if certificates have been specified on the pool which should not be
accessible by normal tasks but should be accessible by StartTasks.
        elevationLevel: &quot;nonadmin&quot; | &quot;admin&quot;, # Optional. The default value is nonAdmin.
      }, # Optional. The userName and autoUser properties are mutually exclusive; you must specify
one but not both.
    }, # Optional. If omitted, the Task runs as a non-administrative user unique to the Task.
    maxTaskRetryCount: number, # Optional. The Batch service retries a Task if its exit code is nonzero. Note that this
value specifically controls the number of retries. The Batch service will try
the Task once, and may then retry up to this limit. For example, if the maximum
retry count is 3, Batch tries the Task up to 4 times (one initial try and 3
retries). If the maximum retry count is 0, the Batch service does not retry the
Task. If the maximum retry count is -1, the Batch service retries the Task
without limit, however this is not recommended for a start task or any task.
The default value is 0 (no retries)
    waitForSuccess: boolean, # Optional. If true and the StartTask fails on a Node, the Batch service retries the
StartTask up to its maximum retry count (maxTaskRetryCount). If the Task has
still not completed successfully after all retries, then the Batch service
marks the Node unusable, and will not schedule Tasks to it. This condition can
be detected via the Compute Node state and failure info details. If false, the
Batch service will not wait for the StartTask to complete. In this case, other
Tasks can start executing on the Compute Node while the StartTask is still
running; and even if the StartTask fails, new Tasks will continue to be
scheduled on the Compute Node. The default is true.
  }, # Optional. Batch will retry Tasks when a recovery operation is triggered on a Node.
Examples of recovery operations include (but are not limited to) when an
unhealthy Node is rebooted or a Compute Node disappeared due to host failure.
Retries due to recovery operations are independent of and are not counted
against the maxTaskRetryCount. Even if the maxTaskRetryCount is 0, an internal
retry due to a recovery operation may occur. Because of this, all Tasks should
be idempotent. This means Tasks need to tolerate being interrupted and
restarted without causing any corruption or duplicate data. The best practice
for long running Tasks is to use some form of checkpointing. In some cases the
StartTask may be re-run even though the Compute Node was not rebooted. Special
care should be taken to avoid StartTasks which create breakaway process or
install/launch services from the StartTask working directory, as this will
block Batch from being able to re-run the StartTask.
  certificateReferences: [CertificateReference], # Optional. For Windows Nodes, the Batch service installs the Certificates to the specified
Certificate store and location. For Linux Compute Nodes, the Certificates are
stored in a directory inside the Task working directory and an environment
variable AZ_BATCH_CERTIFICATES_DIR is supplied to the Task to query for this
location. For Certificates with visibility of &apos;remoteUser&apos;, a &apos;certs&apos; directory
is created in the user&apos;s home directory (e.g., /home/{user-name}/certs) and
Certificates are placed in that directory.
  applicationPackageReferences: [ApplicationPackageReference], # Optional. Changes to Package references affect all new Nodes joining the Pool, but do not
affect Compute Nodes that are already in the Pool until they are rebooted or
reimaged. There is a maximum of 10 Package references on any given Pool.
  applicationLicenses: [string], # Optional. The list of application licenses must be a subset of available Batch service
application licenses. If a license is requested which is not supported, Pool
creation will fail.
  taskSlotsPerNode: number, # Optional. The default value is 1. The maximum value is the smaller of 4 times the number
of cores of the vmSize of the pool or 256.
  taskSchedulingPolicy: {
    nodeFillType: &quot;spread&quot; | &quot;pack&quot;, # Required. If not specified, the default is spread.
  }, # Optional. If not specified, the default is spread.
  userAccounts: [UserAccount], # Optional. The list of user Accounts to be created on each Compute Node in the Pool.
  metadata: [MetadataItem], # Optional. A list of name-value pairs associated with the Pool as metadata.
  stats: {
    url: string, # Required. The URL for the statistics.
    startTime: string (date &amp; time), # Required. The start time of the time range covered by the statistics.
    lastUpdateTime: string (date &amp; time), # Required. The time at which the statistics were last updated. All statistics are limited
to the range between startTime and lastUpdateTime.
    usageStats: {
      startTime: string (date &amp; time), # Required. The start time of the time range covered by the statistics.
      lastUpdateTime: string (date &amp; time), # Required. The time at which the statistics were last updated. All statistics are limited
to the range between startTime and lastUpdateTime.
      dedicatedCoreTime: string (duration ISO 8601 Format), # Required. The aggregated wall-clock time of the dedicated Compute Node cores being part
of the Pool.
    }, # Optional. Statistics related to Pool usage information.
    resourceStats: {
      startTime: string (date &amp; time), # Required. The start time of the time range covered by the statistics.
      lastUpdateTime: string (date &amp; time), # Required. The time at which the statistics were last updated. All statistics are limited
to the range between startTime and lastUpdateTime.
      avgCPUPercentage: number, # Required. The average CPU usage across all Compute Nodes in the Pool (percentage per
node).
      avgMemoryGiB: number, # Required. The average memory usage in GiB across all Compute Nodes in the Pool.
      peakMemoryGiB: number, # Required. The peak memory usage in GiB across all Compute Nodes in the Pool.
      avgDiskGiB: number, # Required. The average used disk space in GiB across all Compute Nodes in the Pool.
      peakDiskGiB: number, # Required. The peak used disk space in GiB across all Compute Nodes in the Pool.
      diskReadIOps: number, # Required. The total number of disk read operations across all Compute Nodes in the Pool.
      diskWriteIOps: number, # Required. The total number of disk write operations across all Compute Nodes in the Pool.
      diskReadGiB: number, # Required. The total amount of data in GiB of disk reads across all Compute Nodes in the
Pool.
      diskWriteGiB: number, # Required. The total amount of data in GiB of disk writes across all Compute Nodes in the
Pool.
      networkReadGiB: number, # Required. The total amount of data in GiB of network reads across all Compute Nodes in
the Pool.
      networkWriteGiB: number, # Required. The total amount of data in GiB of network writes across all Compute Nodes in
the Pool.
    }, # Optional. Statistics related to resource consumption by Compute Nodes in a Pool.
  }, # Optional. This property is populated only if the CloudPool was retrieved with an expand
clause including the &apos;stats&apos; attribute; otherwise it is null. The statistics
may not be immediately available. The Batch service performs periodic roll-up
of statistics. The typical delay is about 30 minutes.
  mountConfiguration: [MountConfiguration], # Optional. This supports Azure Files, NFS, CIFS/SMB, and Blobfuse.
  identity: {
    type: &quot;UserAssigned&quot; | &quot;None&quot;, # Required. The list of user identities associated with the Batch pool. The user identity
dictionary key references will be ARM resource ids in the form:
&apos;/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.ManagedIdentity/userAssignedIdentities/{identityName}&apos;.
    userAssignedIdentities: [UserAssignedIdentity], # Optional. The user identity dictionary key references will be ARM resource ids in the
form:
&apos;/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.ManagedIdentity/userAssignedIdentities/{identityName}&apos;.
  }, # Optional. The list of user identities associated with the Batch pool. The user identity
dictionary key references will be ARM resource ids in the form:
&apos;/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.ManagedIdentity/userAssignedIdentities/{identityName}&apos;.
  targetNodeCommunicationMode: &quot;default&quot; | &quot;classic&quot; | &quot;simplified&quot;, # Optional. If omitted, the default value is Default.
  currentNodeCommunicationMode: &quot;default&quot; | &quot;classic&quot; | &quot;simplified&quot;, # Optional. Determines how a pool communicates with the Batch service.
}
</code>

</remarks>
    </member>
    <member name="UpdateProperties(String,RequestContent,Int32,String,Boolean,String,RequestContext)">
<example>
This sample shows how to call UpdateProperties with required parameters.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetPoolClient(<2022-10-01.16.0>);

var data = new {};

Response response = client.UpdateProperties("<poolId>", RequestContent.Create(data));
Console.WriteLine(response.Status);
]]></code>
This sample shows how to call UpdateProperties with all parameters and request content.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetPoolClient(<2022-10-01.16.0>);

var data = new {
    id = "<id>",
    displayName = "<displayName>",
    vmSize = "<vmSize>",
    cloudServiceConfiguration = new {
        osFamily = "<osFamily>",
        osVersion = "<osVersion>",
    },
    virtualMachineConfiguration = new {
        imageReference = new {
            publisher = "<publisher>",
            offer = "<offer>",
            sku = "<sku>",
            version = "<version>",
            virtualMachineImageId = "<virtualMachineImageId>",
        },
        nodeAgentSKUId = "<nodeAgentSKUId>",
        windowsConfiguration = new {
            enableAutomaticUpdates = true,
        },
        dataDisks = new[] {
            new {
                lun = 1234,
                caching = "none",
                diskSizeGB = 1234,
                storageAccountType = "standard_lrs",
            }
        },
        licenseType = "<licenseType>",
        containerConfiguration = new {
            type = "dockerCompatible",
            containerImageNames = new[] {
                "<String>"
            },
            containerRegistries = new[] {
                new {
                    username = "<username>",
                    password = "<password>",
                    registryServer = "<registryServer>",
                    identityReference = new {
                        resourceId = "<resourceId>",
                    },
                }
            },
        },
        diskEncryptionConfiguration = new {
            targets = new[] {
                "osdisk"
            },
        },
        nodePlacementConfiguration = new {
            policy = "regional",
        },
        extensions = new[] {
            new {
                name = "<name>",
                publisher = "<publisher>",
                type = "<type>",
                typeHandlerVersion = "<typeHandlerVersion>",
                autoUpgradeMinorVersion = true,
                settings = new {},
                protectedSettings = new {},
                provisionAfterExtensions = new[] {
                    "<String>"
                },
            }
        },
        osDisk = new {
            ephemeralOSDiskSettings = new {
                placement = "cachedisk",
            },
        },
    },
    resizeTimeout = PT1H23M45S,
    targetDedicatedNodes = 1234,
    targetLowPriorityNodes = 1234,
    enableAutoScale = true,
    autoScaleFormula = "<autoScaleFormula>",
    autoScaleEvaluationInterval = PT1H23M45S,
    enableInterNodeCommunication = true,
    networkConfiguration = new {
        subnetId = "<subnetId>",
        dynamicVNetAssignmentScope = "none",
        endpointConfiguration = new {
            inboundNATPools = new[] {
                new {
                    name = "<name>",
                    protocol = "tcp",
                    backendPort = 1234,
                    frontendPortRangeStart = 1234,
                    frontendPortRangeEnd = 1234,
                    networkSecurityGroupRules = new[] {
                        new {
                            priority = 1234,
                            access = "allow",
                            sourceAddressPrefix = "<sourceAddressPrefix>",
                            sourcePortRanges = new[] {
                                "<String>"
                            },
                        }
                    },
                }
            },
        },
        publicIPAddressConfiguration = new {
            provision = "batchmanaged",
            ipAddressIds = new[] {
                "<String>"
            },
        },
    },
    startTask = new {
        commandLine = "<commandLine>",
        containerSettings = new {
            containerRunOptions = "<containerRunOptions>",
            imageName = "<imageName>",
            registry = new {
                username = "<username>",
                password = "<password>",
                registryServer = "<registryServer>",
                identityReference = new {
                    resourceId = "<resourceId>",
                },
            },
            workingDirectory = "taskWorkingDirectory",
        },
        resourceFiles = new[] {
            new {
                autoStorageContainerName = "<autoStorageContainerName>",
                storageContainerUrl = "<storageContainerUrl>",
                httpUrl = "<httpUrl>",
                blobPrefix = "<blobPrefix>",
                filePath = "<filePath>",
                fileMode = "<fileMode>",
                identityReference = new {
                    resourceId = "<resourceId>",
                },
            }
        },
        environmentSettings = new[] {
            new {
                name = "<name>",
                value = "<value>",
            }
        },
        userIdentity = new {
            username = "<username>",
            autoUser = new {
                scope = "task",
                elevationLevel = "nonadmin",
            },
        },
        maxTaskRetryCount = 1234,
        waitForSuccess = true,
    },
    certificateReferences = new[] {
        new {
            thumbprint = "<thumbprint>",
            thumbprintAlgorithm = "<thumbprintAlgorithm>",
            storeLocation = "currentuser",
            storeName = "<storeName>",
            visibility = new[] {
                "starttask"
            },
        }
    },
    applicationPackageReferences = new[] {
        new {
            applicationId = "<applicationId>",
            version = "<version>",
        }
    },
    applicationLicenses = new[] {
        "<String>"
    },
    taskSlotsPerNode = 1234,
    taskSchedulingPolicy = new {
        nodeFillType = "spread",
    },
    userAccounts = new[] {
        new {
            name = "<name>",
            password = "<password>",
            elevationLevel = "nonadmin",
            linuxUserConfiguration = new {
                uid = 1234,
                gid = 1234,
                sshPrivateKey = "<sshPrivateKey>",
            },
            windowsUserConfiguration = new {
                loginMode = "batch",
            },
        }
    },
    metadata = new[] {
        new {
            name = "<name>",
            value = "<value>",
        }
    },
    mountConfiguration = new[] {
        new {
            azureBlobFileSystemConfiguration = new {
                accountName = "<accountName>",
                containerName = "<containerName>",
                accountKey = "<accountKey>",
                sasKey = "<sasKey>",
                blobfuseOptions = "<blobfuseOptions>",
                relativeMountPath = "<relativeMountPath>",
                identityReference = new {
                    resourceId = "<resourceId>",
                },
            },
            nfsMountConfiguration = new {
                source = "<source>",
                relativeMountPath = "<relativeMountPath>",
                mountOptions = "<mountOptions>",
            },
            cifsMountConfiguration = new {
                username = "<username>",
                source = "<source>",
                relativeMountPath = "<relativeMountPath>",
                mountOptions = "<mountOptions>",
                password = "<password>",
            },
            azureFileShareConfiguration = new {
                accountName = "<accountName>",
                azureFileUrl = "<azureFileUrl>",
                accountKey = "<accountKey>",
                relativeMountPath = "<relativeMountPath>",
                mountOptions = "<mountOptions>",
            },
        }
    },
    targetNodeCommunicationMode = "default",
};

Response response = client.UpdateProperties("<poolId>", RequestContent.Create(data), 1234, "<clientRequestId>", true, "<ocpDate>");
Console.WriteLine(response.Status);
]]></code>
</example>
<remarks>
This fully replaces all the updatable properties of the Pool. For example, if
the Pool has a StartTask associated with it and if StartTask is not specified
with this request, then the Batch service will remove the existing StartTask.

Below is the JSON schema for the request payload.

Request Body:

Schema for <c>BatchPool</c>:
<code>{
  id: string, # Optional. The ID can contain any combination of alphanumeric characters including hyphens
and underscores, and cannot contain more than 64 characters. The ID is
case-preserving and case-insensitive (that is, you may not have two IDs within
an Account that differ only by case).
  displayName: string, # Optional. The display name need not be unique and can contain any Unicode characters up
to a maximum length of 1024.
  url: string, # Optional. The URL of the Pool.
  eTag: string, # Optional. This is an opaque string. You can use it to detect whether the Pool has changed
between requests. In particular, you can be pass the ETag when updating a Pool
to specify that your changes should take effect only if nobody else has
modified the Pool in the meantime.
  lastModified: string (date &amp; time), # Optional. This is the last time at which the Pool level data, such as the
targetDedicatedNodes or enableAutoscale settings, changed. It does not factor
in node-level changes such as a Compute Node changing state.
  creationTime: string (date &amp; time), # Optional. The creation time of the Pool.
  state: &quot;active&quot; | &quot;deleting&quot;, # Optional. The current state of the Pool.
  stateTransitionTime: string (date &amp; time), # Optional. The time at which the Pool entered its current state.
  allocationState: &quot;steady&quot; | &quot;resizing&quot; | &quot;stopping&quot;, # Optional. Whether the Pool is resizing.
  allocationStateTransitionTime: string (date &amp; time), # Optional. The time at which the Pool entered its current allocation state.
  vmSize: string, # Optional. For information about available sizes of virtual machines in Pools, see Choose
a VM size for Compute Nodes in an Azure Batch Pool
(https://docs.microsoft.com/azure/batch/batch-pool-vm-sizes).
  cloudServiceConfiguration: {
    osFamily: string, # Required. Possible values are:
2 - OS Family 2, equivalent to Windows Server 2008 R2
SP1.
3 - OS Family 3, equivalent to Windows Server 2012.
4 - OS Family 4,
equivalent to Windows Server 2012 R2.
5 - OS Family 5, equivalent to Windows
Server 2016.
6 - OS Family 6, equivalent to Windows Server 2019. For more
information, see Azure Guest OS Releases
(https://azure.microsoft.com/documentation/articles/cloud-services-guestos-update-matrix/#releases).
    osVersion: string, # Optional. The default value is * which specifies the latest operating system version for
the specified OS family.
  }, # Optional. This property and virtualMachineConfiguration are mutually exclusive and one of
the properties must be specified. This property cannot be specified if the
Batch Account was created with its poolAllocationMode property set to
&apos;UserSubscription&apos;.
  virtualMachineConfiguration: {
    imageReference: {
      publisher: string, # Optional. For example, Canonical or MicrosoftWindowsServer.
      offer: string, # Optional. For example, UbuntuServer or WindowsServer.
      sku: string, # Optional. For example, 18.04-LTS or 2019-Datacenter.
      version: string, # Optional. A value of &apos;latest&apos; can be specified to select the latest version of an Image.
If omitted, the default is &apos;latest&apos;.
      virtualMachineImageId: string, # Optional. This property is mutually exclusive with other ImageReference properties. The
Shared Image Gallery Image must have replicas in the same region and must be in
the same subscription as the Azure Batch account. If the image version is not
specified in the imageId, the latest version will be used. For information
about the firewall settings for the Batch Compute Node agent to communicate
with the Batch service see
https://docs.microsoft.com/en-us/azure/batch/batch-api-basics#virtual-network-vnet-and-firewall-configuration.
      exactVersion: string, # Optional. The specific version of the platform image or marketplace image used to create
the node. This read-only field differs from &apos;version&apos; only if the value
specified for &apos;version&apos; when the pool was created was &apos;latest&apos;.
    }, # Required. A reference to an Azure Virtual Machines Marketplace Image or a Shared Image
Gallery Image. To get the list of all Azure Marketplace Image references
verified by Azure Batch, see the &apos;List Supported Images&apos; operation.
    nodeAgentSKUId: string, # Required. The Batch Compute Node agent is a program that runs on each Compute Node in the
Pool, and provides the command-and-control interface between the Compute Node
and the Batch service. There are different implementations of the Compute Node
agent, known as SKUs, for different operating systems. You must specify a
Compute Node agent SKU which matches the selected Image reference. To get the
list of supported Compute Node agent SKUs along with their list of verified
Image references, see the &apos;List supported Compute Node agent SKUs&apos; operation.
    windowsConfiguration: {
      enableAutomaticUpdates: boolean, # Optional. If omitted, the default value is true.
    }, # Optional. This property must not be specified if the imageReference property specifies a
Linux OS Image.
    dataDisks: [DataDisk], # Optional. This property must be specified if the Compute Nodes in the Pool need to have
empty data disks attached to them. This cannot be updated. Each Compute Node
gets its own disk (the disk is not a file share). Existing disks cannot be
attached, each attached disk is empty. When the Compute Node is removed from
the Pool, the disk and all data associated with it is also deleted. The disk is
not formatted after being attached, it must be formatted before use - for more
information see
https://docs.microsoft.com/en-us/azure/virtual-machines/linux/classic/attach-disk#initialize-a-new-data-disk-in-linux
and
https://docs.microsoft.com/en-us/azure/virtual-machines/windows/attach-disk-ps#add-an-empty-data-disk-to-a-virtual-machine.
    licenseType: string, # Optional. This only applies to Images that contain the Windows operating system, and
should only be used when you hold valid on-premises licenses for the Compute
Nodes which will be deployed. If omitted, no on-premises licensing discount is
applied. Values are:

 Windows_Server - The on-premises license is for Windows
Server.
 Windows_Client - The on-premises license is for Windows Client.

    containerConfiguration: {
      type: &quot;dockerCompatible&quot;, # Required. The container technology to be used.
      containerImageNames: [string], # Optional. This is the full Image reference, as would be specified to &quot;docker pull&quot;. An
Image will be sourced from the default Docker registry unless the Image is
fully qualified with an alternative registry.
      containerRegistries: [
        {
          username: string, # Optional. The user name to log into the registry server.
          password: string, # Optional. The password to log into the registry server.
          registryServer: string, # Optional. If omitted, the default is &quot;docker.io&quot;.
          identityReference: {
            resourceId: string, # Optional. The ARM resource id of the user assigned identity.
          }, # Optional. The reference to a user assigned identity associated with the Batch pool which
a compute node will use.
        }
      ], # Optional. If any Images must be downloaded from a private registry which requires
credentials, then those credentials must be provided here.
    }, # Optional. If specified, setup is performed on each Compute Node in the Pool to allow
Tasks to run in containers. All regular Tasks and Job manager Tasks run on this
Pool must specify the containerSettings property, and all other Tasks may
specify it.
    diskEncryptionConfiguration: {
      targets: [&quot;osdisk&quot; | &quot;temporarydisk&quot;], # Optional. If omitted, no disks on the compute nodes in the pool will be encrypted. On
Linux pool, only &quot;TemporaryDisk&quot; is supported; on Windows pool, &quot;OsDisk&quot;
and &quot;TemporaryDisk&quot; must be specified.
    }, # Optional. If specified, encryption is performed on each node in the pool during node
provisioning.
    nodePlacementConfiguration: {
      policy: &quot;regional&quot; | &quot;zonal&quot;, # Optional. Allocation policy used by Batch Service to provision the nodes. If not
specified, Batch will use the regional policy.
    }, # Optional. This configuration will specify rules on how nodes in the pool will be
physically allocated.
    extensions: [VMExtension], # Optional. If specified, the extensions mentioned in this configuration will be installed
on each node.
    osDisk: {
      ephemeralOSDiskSettings: {
        placement: &quot;cachedisk&quot;, # Optional. This property can be used by user in the request to choose the location e.g.,
cache disk space for Ephemeral OS disk provisioning. For more information on
Ephemeral OS disk size requirements, please refer to Ephemeral OS disk size
requirements for Windows VMs at
https://docs.microsoft.com/en-us/azure/virtual-machines/windows/ephemeral-os-disks#size-requirements
and Linux VMs at
https://docs.microsoft.com/en-us/azure/virtual-machines/linux/ephemeral-os-disks#size-requirements.
      }, # Optional. Specifies the ephemeral Disk Settings for the operating system disk used by the
compute node (VM).
    }, # Optional. Settings for the operating system disk of the compute node (VM).
  }, # Optional. This property and cloudServiceConfiguration are mutually exclusive and one of
the properties must be specified.
  resizeTimeout: string (duration ISO 8601 Format), # Optional. This is the timeout for the most recent resize operation. (The initial sizing
when the Pool is created counts as a resize.) The default value is 15 minutes.
  resizeErrors: [
    {
      code: string, # Optional. An identifier for the Pool resize error. Codes are invariant and are intended
to be consumed programmatically.
      message: string, # Optional. A message describing the Pool resize error, intended to be suitable for display
in a user interface.
      values: [NameValuePair], # Optional. A list of additional error details related to the Pool resize error.
    }
  ], # Optional. This property is set only if one or more errors occurred during the last Pool
resize, and only when the Pool allocationState is Steady.
  currentDedicatedNodes: number, # Optional. The number of dedicated Compute Nodes currently in the Pool.
  currentLowPriorityNodes: number, # Optional. Spot/Low-priority Compute Nodes which have been preempted are included in this
count.
  targetDedicatedNodes: number, # Optional. The desired number of dedicated Compute Nodes in the Pool.
  targetLowPriorityNodes: number, # Optional. The desired number of Spot/Low-priority Compute Nodes in the Pool.
  enableAutoScale: boolean, # Optional. If false, at least one of targetDedicatedNodes and targetLowPriorityNodes must
be specified. If true, the autoScaleFormula property is required and the Pool
automatically resizes according to the formula. The default value is false.
  autoScaleFormula: string, # Optional. This property is set only if the Pool automatically scales, i.e.
enableAutoScale is true.
  autoScaleEvaluationInterval: string (duration ISO 8601 Format), # Optional. This property is set only if the Pool automatically scales, i.e.
enableAutoScale is true.
  autoScaleRun: {
    timestamp: string (date &amp; time), # Required. The time at which the autoscale formula was last evaluated.
    results: string, # Optional. Each variable value is returned in the form $variable=value, and variables are
separated by semicolons.
    error: {
      code: string, # Optional. An identifier for the autoscale error. Codes are invariant and are intended to
be consumed programmatically.
      message: string, # Optional. A message describing the autoscale error, intended to be suitable for display
in a user interface.
      values: [NameValuePair], # Optional. A list of additional error details related to the autoscale error.
    }, # Optional. An error that occurred when executing or evaluating a Pool autoscale formula.
  }, # Optional. This property is set only if the Pool automatically scales, i.e.
enableAutoScale is true.
  enableInterNodeCommunication: boolean, # Optional. This imposes restrictions on which Compute Nodes can be assigned to the Pool.
Specifying this value can reduce the chance of the requested number of Compute
Nodes to be allocated in the Pool.
  networkConfiguration: {
    subnetId: string, # Optional. The virtual network must be in the same region and subscription as the Azure
Batch Account. The specified subnet should have enough free IP addresses to
accommodate the number of Compute Nodes in the Pool. If the subnet doesn&apos;t have
enough free IP addresses, the Pool will partially allocate Nodes and a resize
error will occur. The &apos;MicrosoftAzureBatch&apos; service principal must have the
&apos;Classic Virtual Machine Contributor&apos; Role-Based Access Control (RBAC) role for
the specified VNet. The specified subnet must allow communication from the
Azure Batch service to be able to schedule Tasks on the Nodes. This can be
verified by checking if the specified VNet has any associated Network Security
Groups (NSG). If communication to the Nodes in the specified subnet is denied
by an NSG, then the Batch service will set the state of the Compute Nodes to
unusable. For Pools created with virtualMachineConfiguration only ARM virtual
networks (&apos;Microsoft.Network/virtualNetworks&apos;) are supported, but for Pools
created with cloudServiceConfiguration both ARM and classic virtual networks
are supported. If the specified VNet has any associated Network Security Groups
(NSG), then a few reserved system ports must be enabled for inbound
communication. For Pools created with a virtual machine configuration, enable
ports 29876 and 29877, as well as port 22 for Linux and port 3389 for Windows.
For Pools created with a cloud service configuration, enable ports 10100,
20100, and 30100. Also enable outbound connections to Azure Storage on port
443. For more details see:
https://docs.microsoft.com/en-us/azure/batch/batch-api-basics#virtual-network-vnet-and-firewall-configuration
    dynamicVNetAssignmentScope: &quot;none&quot; | &quot;job&quot;, # Optional. The scope of dynamic vnet assignment.
    endpointConfiguration: {
      inboundNATPools: [InboundNATPool], # Required. The maximum number of inbound NAT Pools per Batch Pool is 5. If the maximum
number of inbound NAT Pools is exceeded the request fails with HTTP status code
400. This cannot be specified if the IPAddressProvisioningType is
NoPublicIPAddresses.
    }, # Optional. Pool endpoint configuration is only supported on Pools with the
virtualMachineConfiguration property.
    publicIPAddressConfiguration: {
      provision: &quot;batchmanaged&quot; | &quot;usermanaged&quot; | &quot;nopublicipaddresses&quot;, # Optional. The default value is BatchManaged.
      ipAddressIds: [string], # Optional. The number of IPs specified here limits the maximum size of the Pool - 100
dedicated nodes or 100 Spot/Low-priority nodes can be allocated for each public
IP. For example, a pool needing 250 dedicated VMs would need at least 3 public
IPs specified. Each element of this collection is of the form:
/subscriptions/{subscription}/resourceGroups/{group}/providers/Microsoft.Network/publicIPAddresses/{ip}.
    }, # Optional. Public IP configuration property is only supported on Pools with the
virtualMachineConfiguration property.
  }, # Optional. The network configuration for a Pool.
  startTask: {
    commandLine: string, # Required. The command line does not run under a shell, and therefore cannot take
advantage of shell features such as environment variable expansion. If you want
to take advantage of such features, you should invoke the shell in the command
line, for example using &quot;cmd /c MyCommand&quot; in Windows or &quot;/bin/sh -c
MyCommand&quot; in Linux. If the command line refers to file paths, it should use a
relative path (relative to the Task working directory), or use the Batch
provided environment variable
(https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).
    containerSettings: {
      containerRunOptions: string, # Optional. These additional options are supplied as arguments to the &quot;docker create&quot;
command, in addition to those controlled by the Batch Service.
      imageName: string, # Required. This is the full Image reference, as would be specified to &quot;docker pull&quot;. If
no tag is provided as part of the Image name, the tag &quot;:latest&quot; is used as a
default.
      registry: ContainerRegistry, # Optional. This setting can be omitted if was already provided at Pool creation.
      workingDirectory: &quot;taskWorkingDirectory&quot; | &quot;containerImageDefault&quot;, # Optional. The default is &apos;taskWorkingDirectory&apos;.
    }, # Optional. When this is specified, all directories recursively below the
AZ_BATCH_NODE_ROOT_DIR (the root of Azure Batch directories on the node) are
mapped into the container, all Task environment variables are mapped into the
container, and the Task command line is executed in the container. Files
produced in the container outside of AZ_BATCH_NODE_ROOT_DIR might not be
reflected to the host disk, meaning that Batch file APIs will not be able to
access those files.
    resourceFiles: [ResourceFile], # Optional. Files listed under this element are located in the Task&apos;s working directory.
    environmentSettings: [EnvironmentSetting], # Optional. A list of environment variable settings for the StartTask.
    userIdentity: {
      username: string, # Optional. The userName and autoUser properties are mutually exclusive; you must specify
one but not both.
      autoUser: {
        scope: &quot;task&quot; | &quot;pool&quot;, # Optional. The default value is pool. If the pool is running Windows a value of Task
should be specified if stricter isolation between tasks is required. For
example, if the task mutates the registry in a way which could impact other
tasks, or if certificates have been specified on the pool which should not be
accessible by normal tasks but should be accessible by StartTasks.
        elevationLevel: &quot;nonadmin&quot; | &quot;admin&quot;, # Optional. The default value is nonAdmin.
      }, # Optional. The userName and autoUser properties are mutually exclusive; you must specify
one but not both.
    }, # Optional. If omitted, the Task runs as a non-administrative user unique to the Task.
    maxTaskRetryCount: number, # Optional. The Batch service retries a Task if its exit code is nonzero. Note that this
value specifically controls the number of retries. The Batch service will try
the Task once, and may then retry up to this limit. For example, if the maximum
retry count is 3, Batch tries the Task up to 4 times (one initial try and 3
retries). If the maximum retry count is 0, the Batch service does not retry the
Task. If the maximum retry count is -1, the Batch service retries the Task
without limit, however this is not recommended for a start task or any task.
The default value is 0 (no retries)
    waitForSuccess: boolean, # Optional. If true and the StartTask fails on a Node, the Batch service retries the
StartTask up to its maximum retry count (maxTaskRetryCount). If the Task has
still not completed successfully after all retries, then the Batch service
marks the Node unusable, and will not schedule Tasks to it. This condition can
be detected via the Compute Node state and failure info details. If false, the
Batch service will not wait for the StartTask to complete. In this case, other
Tasks can start executing on the Compute Node while the StartTask is still
running; and even if the StartTask fails, new Tasks will continue to be
scheduled on the Compute Node. The default is true.
  }, # Optional. Batch will retry Tasks when a recovery operation is triggered on a Node.
Examples of recovery operations include (but are not limited to) when an
unhealthy Node is rebooted or a Compute Node disappeared due to host failure.
Retries due to recovery operations are independent of and are not counted
against the maxTaskRetryCount. Even if the maxTaskRetryCount is 0, an internal
retry due to a recovery operation may occur. Because of this, all Tasks should
be idempotent. This means Tasks need to tolerate being interrupted and
restarted without causing any corruption or duplicate data. The best practice
for long running Tasks is to use some form of checkpointing. In some cases the
StartTask may be re-run even though the Compute Node was not rebooted. Special
care should be taken to avoid StartTasks which create breakaway process or
install/launch services from the StartTask working directory, as this will
block Batch from being able to re-run the StartTask.
  certificateReferences: [CertificateReference], # Optional. For Windows Nodes, the Batch service installs the Certificates to the specified
Certificate store and location. For Linux Compute Nodes, the Certificates are
stored in a directory inside the Task working directory and an environment
variable AZ_BATCH_CERTIFICATES_DIR is supplied to the Task to query for this
location. For Certificates with visibility of &apos;remoteUser&apos;, a &apos;certs&apos; directory
is created in the user&apos;s home directory (e.g., /home/{user-name}/certs) and
Certificates are placed in that directory.
  applicationPackageReferences: [ApplicationPackageReference], # Optional. Changes to Package references affect all new Nodes joining the Pool, but do not
affect Compute Nodes that are already in the Pool until they are rebooted or
reimaged. There is a maximum of 10 Package references on any given Pool.
  applicationLicenses: [string], # Optional. The list of application licenses must be a subset of available Batch service
application licenses. If a license is requested which is not supported, Pool
creation will fail.
  taskSlotsPerNode: number, # Optional. The default value is 1. The maximum value is the smaller of 4 times the number
of cores of the vmSize of the pool or 256.
  taskSchedulingPolicy: {
    nodeFillType: &quot;spread&quot; | &quot;pack&quot;, # Required. If not specified, the default is spread.
  }, # Optional. If not specified, the default is spread.
  userAccounts: [UserAccount], # Optional. The list of user Accounts to be created on each Compute Node in the Pool.
  metadata: [MetadataItem], # Optional. A list of name-value pairs associated with the Pool as metadata.
  stats: {
    url: string, # Required. The URL for the statistics.
    startTime: string (date &amp; time), # Required. The start time of the time range covered by the statistics.
    lastUpdateTime: string (date &amp; time), # Required. The time at which the statistics were last updated. All statistics are limited
to the range between startTime and lastUpdateTime.
    usageStats: {
      startTime: string (date &amp; time), # Required. The start time of the time range covered by the statistics.
      lastUpdateTime: string (date &amp; time), # Required. The time at which the statistics were last updated. All statistics are limited
to the range between startTime and lastUpdateTime.
      dedicatedCoreTime: string (duration ISO 8601 Format), # Required. The aggregated wall-clock time of the dedicated Compute Node cores being part
of the Pool.
    }, # Optional. Statistics related to Pool usage information.
    resourceStats: {
      startTime: string (date &amp; time), # Required. The start time of the time range covered by the statistics.
      lastUpdateTime: string (date &amp; time), # Required. The time at which the statistics were last updated. All statistics are limited
to the range between startTime and lastUpdateTime.
      avgCPUPercentage: number, # Required. The average CPU usage across all Compute Nodes in the Pool (percentage per
node).
      avgMemoryGiB: number, # Required. The average memory usage in GiB across all Compute Nodes in the Pool.
      peakMemoryGiB: number, # Required. The peak memory usage in GiB across all Compute Nodes in the Pool.
      avgDiskGiB: number, # Required. The average used disk space in GiB across all Compute Nodes in the Pool.
      peakDiskGiB: number, # Required. The peak used disk space in GiB across all Compute Nodes in the Pool.
      diskReadIOps: number, # Required. The total number of disk read operations across all Compute Nodes in the Pool.
      diskWriteIOps: number, # Required. The total number of disk write operations across all Compute Nodes in the Pool.
      diskReadGiB: number, # Required. The total amount of data in GiB of disk reads across all Compute Nodes in the
Pool.
      diskWriteGiB: number, # Required. The total amount of data in GiB of disk writes across all Compute Nodes in the
Pool.
      networkReadGiB: number, # Required. The total amount of data in GiB of network reads across all Compute Nodes in
the Pool.
      networkWriteGiB: number, # Required. The total amount of data in GiB of network writes across all Compute Nodes in
the Pool.
    }, # Optional. Statistics related to resource consumption by Compute Nodes in a Pool.
  }, # Optional. This property is populated only if the CloudPool was retrieved with an expand
clause including the &apos;stats&apos; attribute; otherwise it is null. The statistics
may not be immediately available. The Batch service performs periodic roll-up
of statistics. The typical delay is about 30 minutes.
  mountConfiguration: [MountConfiguration], # Optional. This supports Azure Files, NFS, CIFS/SMB, and Blobfuse.
  identity: {
    type: &quot;UserAssigned&quot; | &quot;None&quot;, # Required. The list of user identities associated with the Batch pool. The user identity
dictionary key references will be ARM resource ids in the form:
&apos;/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.ManagedIdentity/userAssignedIdentities/{identityName}&apos;.
    userAssignedIdentities: [UserAssignedIdentity], # Optional. The user identity dictionary key references will be ARM resource ids in the
form:
&apos;/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.ManagedIdentity/userAssignedIdentities/{identityName}&apos;.
  }, # Optional. The list of user identities associated with the Batch pool. The user identity
dictionary key references will be ARM resource ids in the form:
&apos;/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.ManagedIdentity/userAssignedIdentities/{identityName}&apos;.
  targetNodeCommunicationMode: &quot;default&quot; | &quot;classic&quot; | &quot;simplified&quot;, # Optional. If omitted, the default value is Default.
  currentNodeCommunicationMode: &quot;default&quot; | &quot;classic&quot; | &quot;simplified&quot;, # Optional. Determines how a pool communicates with the Batch service.
}
</code>

</remarks>
    </member>
    <member name="RemoveNodesAsync(String,RequestContent,Int32,String,Boolean,String,RequestConditions,RequestContext)">
<example>
This sample shows how to call RemoveNodesAsync with required parameters and request content.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetPoolClient(<2022-10-01.16.0>);

var data = new {
    nodeList = new[] {
        "<String>"
    },
};

Response response = await client.RemoveNodesAsync("<poolId>", RequestContent.Create(data));
Console.WriteLine(response.Status);
]]></code>
This sample shows how to call RemoveNodesAsync with all parameters and request content.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetPoolClient(<2022-10-01.16.0>);

var data = new {
    nodeList = new[] {
        "<String>"
    },
    resizeTimeout = PT1H23M45S,
    nodeDeallocationOption = "requeue",
};

Response response = await client.RemoveNodesAsync("<poolId>", RequestContent.Create(data), 1234, "<clientRequestId>", true, "<ocpDate>", null);
Console.WriteLine(response.Status);
]]></code>
</example>
<remarks>
This operation can only run when the allocation state of the Pool is steady.
When this operation runs, the allocation state changes from steady to resizing.
Each request may remove up to 100 nodes.

Below is the JSON schema for the request payload.

Request Body:

Schema for <c>NodeRemoveParameters</c>:
<code>{
  nodeList: [string], # Required. A maximum of 100 nodes may be removed per request.
  resizeTimeout: string (duration ISO 8601 Format), # Optional. The default value is 15 minutes. The minimum value is 5 minutes. If you specify
a value less than 5 minutes, the Batch service returns an error; if you are
calling the REST API directly, the HTTP status code is 400 (Bad Request).
  nodeDeallocationOption: &quot;requeue&quot; | &quot;terminate&quot; | &quot;taskcompletion&quot; | &quot;retaineddata&quot;, # Optional. The default value is requeue.
}
</code>

</remarks>
    </member>
    <member name="RemoveNodes(String,RequestContent,Int32,String,Boolean,String,RequestConditions,RequestContext)">
<example>
This sample shows how to call RemoveNodes with required parameters and request content.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetPoolClient(<2022-10-01.16.0>);

var data = new {
    nodeList = new[] {
        "<String>"
    },
};

Response response = client.RemoveNodes("<poolId>", RequestContent.Create(data));
Console.WriteLine(response.Status);
]]></code>
This sample shows how to call RemoveNodes with all parameters and request content.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetPoolClient(<2022-10-01.16.0>);

var data = new {
    nodeList = new[] {
        "<String>"
    },
    resizeTimeout = PT1H23M45S,
    nodeDeallocationOption = "requeue",
};

Response response = client.RemoveNodes("<poolId>", RequestContent.Create(data), 1234, "<clientRequestId>", true, "<ocpDate>", null);
Console.WriteLine(response.Status);
]]></code>
</example>
<remarks>
This operation can only run when the allocation state of the Pool is steady.
When this operation runs, the allocation state changes from steady to resizing.
Each request may remove up to 100 nodes.

Below is the JSON schema for the request payload.

Request Body:

Schema for <c>NodeRemoveParameters</c>:
<code>{
  nodeList: [string], # Required. A maximum of 100 nodes may be removed per request.
  resizeTimeout: string (duration ISO 8601 Format), # Optional. The default value is 15 minutes. The minimum value is 5 minutes. If you specify
a value less than 5 minutes, the Batch service returns an error; if you are
calling the REST API directly, the HTTP status code is 400 (Bad Request).
  nodeDeallocationOption: &quot;requeue&quot; | &quot;terminate&quot; | &quot;taskcompletion&quot; | &quot;retaineddata&quot;, # Optional. The default value is requeue.
}
</code>

</remarks>
    </member>
    <member name="GetUsageMetricsAsync(RequestContext)">
<example>
This sample shows how to call GetUsageMetricsAsync and parse the result.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetPoolClient(<2022-10-01.16.0>);

await foreach (var data in client.GetUsageMetricsAsync())
{
    JsonElement result = JsonDocument.Parse(data.ToStream()).RootElement;
    Console.WriteLine(result.GetProperty("poolId").ToString());
    Console.WriteLine(result.GetProperty("startTime").ToString());
    Console.WriteLine(result.GetProperty("endTime").ToString());
    Console.WriteLine(result.GetProperty("vmSize").ToString());
    Console.WriteLine(result.GetProperty("totalCoreHours").ToString());
}
]]></code>
</example>
<remarks>
If you do not specify a $filter clause including a poolId, the response
includes all Pools that existed in the Account in the time range of the
returned aggregation intervals. If you do not specify a $filter clause
including a startTime or endTime these filters default to the start and end
times of the last aggregation interval currently available; that is, only the
last aggregation interval is returned.

Below is the JSON schema for one item in the pageable response.

Response Body:

Schema for <c>Array</c>:
<code>{
  poolId: string, # Required. The ID of the Pool whose metrics are aggregated in this entry.
  startTime: string (date &amp; time), # Required. The start time of the aggregation interval covered by this entry.
  endTime: string (date &amp; time), # Required. The end time of the aggregation interval covered by this entry.
  vmSize: string, # Required. For information about available sizes of virtual machines in Pools, see Choose
a VM size for Compute Nodes in an Azure Batch Pool
(https://docs.microsoft.com/azure/batch/batch-pool-vm-sizes).
  totalCoreHours: number, # Required. The total core hours used in the Pool during this aggregation interval.
}
</code>

</remarks>
    </member>
    <member name="GetUsageMetrics(RequestContext)">
<example>
This sample shows how to call GetUsageMetrics and parse the result.
<code><![CDATA[
var credential = new DefaultAzureCredential();
var client = new BatchServiceClient(credential).GetPoolClient(<2022-10-01.16.0>);

foreach (var data in client.GetUsageMetrics())
{
    JsonElement result = JsonDocument.Parse(data.ToStream()).RootElement;
    Console.WriteLine(result.GetProperty("poolId").ToString());
    Console.WriteLine(result.GetProperty("startTime").ToString());
    Console.WriteLine(result.GetProperty("endTime").ToString());
    Console.WriteLine(result.GetProperty("vmSize").ToString());
    Console.WriteLine(result.GetProperty("totalCoreHours").ToString());
}
]]></code>
</example>
<remarks>
If you do not specify a $filter clause including a poolId, the response
includes all Pools that existed in the Account in the time range of the
returned aggregation intervals. If you do not specify a $filter clause
including a startTime or endTime these filters default to the start and end
times of the last aggregation interval currently available; that is, only the
last aggregation interval is returned.

Below is the JSON schema for one item in the pageable response.

Response Body:

Schema for <c>Array</c>:
<code>{
  poolId: string, # Required. The ID of the Pool whose metrics are aggregated in this entry.
  startTime: string (date &amp; time), # Required. The start time of the aggregation interval covered by this entry.
  endTime: string (date &amp; time), # Required. The end time of the aggregation interval covered by this entry.
  vmSize: string, # Required. For information about available sizes of virtual machines in Pools, see Choose
a VM size for Compute Nodes in an Azure Batch Pool
(https://docs.microsoft.com/azure/batch/batch-pool-vm-sizes).
  totalCoreHours: number, # Required. The total core hours used in the Pool during this aggregation interval.
}
</code>

</remarks>
    </member>
  </members>
</doc>
// <auto-generated>
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License. See License.txt in the project root for
// license information.
//
// Code generated by Microsoft (R) AutoRest Code Generator.
// Changes may cause incorrect behavior and will be lost if the code is
// regenerated.
// </auto-generated>

namespace Microsoft.Azure.CognitiveServices.Vision.ComputerVision
{
    using Microsoft.Rest;
    using Models;
    using Newtonsoft.Json;
    using System.Collections;
    using System.Collections.Generic;
    using System.IO;
    using System.Threading;
    using System.Threading.Tasks;

    /// <summary>
    /// The Computer Vision API provides state-of-the-art algorithms to process
    /// images and return information. For example, it can be used to determine
    /// if an image contains mature content, or it can be used to find all the
    /// faces in an image.  It also has other features like estimating dominant
    /// and accent colors, categorizing the content of images, and describing
    /// an image with complete English sentences.  Additionally, it can also
    /// intelligently generate images thumbnails for displaying large images
    /// effectively.
    /// </summary>
    public partial interface IComputerVisionAPI : System.IDisposable
    {
        /// <summary>
        /// The base URI of the service.
        /// </summary>

        /// <summary>
        /// Gets or sets json serialization settings.
        /// </summary>
        JsonSerializerSettings SerializationSettings { get; }

        /// <summary>
        /// Gets or sets json deserialization settings.
        /// </summary>
        JsonSerializerSettings DeserializationSettings { get; }

        /// <summary>
        /// Supported Azure regions for Cognitive Services endpoints. Possible
        /// values include: 'westus', 'westeurope', 'southeastasia', 'eastus2',
        /// 'westcentralus', 'westus2', 'eastus', 'southcentralus',
        /// 'northeurope', 'eastasia', 'australiaeast', 'brazilsouth'
        /// </summary>
        AzureRegions AzureRegion { get; set; }

        /// <summary>
        /// Subscription credentials which uniquely identify client
        /// subscription.
        /// </summary>
        ServiceClientCredentials Credentials { get; }


        /// <summary>
        /// This operation returns the list of domain-specific models that are
        /// supported by the Computer Vision API.  Currently, the API only
        /// supports one domain-specific model: a celebrity recognizer. A
        /// successful response will be returned in JSON.  If the request
        /// failed, the response will contain an error code and a message to
        /// help understand what went wrong.
        /// </summary>
        /// <param name='customHeaders'>
        /// The headers that will be added to request.
        /// </param>
        /// <param name='cancellationToken'>
        /// The cancellation token.
        /// </param>
        Task<HttpOperationResponse<ListModelsResult>> ListModelsWithHttpMessagesAsync(Dictionary<string, List<string>> customHeaders = null, CancellationToken cancellationToken = default(CancellationToken));

        /// <summary>
        /// This operation extracts a rich set of visual features based on the
        /// image content. Two input methods are supported -- (1) Uploading an
        /// image or (2) specifying an image URL.  Within your request, there
        /// is an optional parameter to allow you to choose which features to
        /// return.  By default, image categories are returned in the response.
        /// </summary>
        /// <param name='url'>
        /// </param>
        /// <param name='visualFeatures'>
        /// A string indicating what visual feature types to return. Multiple
        /// values should be comma-separated. Valid visual feature types
        /// include:Categories - categorizes image content according to a
        /// taxonomy defined in documentation. Tags - tags the image with a
        /// detailed list of words related to the image content. Description -
        /// describes the image content with a complete English sentence. Faces
        /// - detects if faces are present. If present, generate coordinates,
        /// gender and age. ImageType - detects if image is clipart or a line
        /// drawing. Color - determines the accent color, dominant color, and
        /// whether an image is black&amp;white.Adult - detects if the image is
        /// pornographic in nature (depicts nudity or a sex act).  Sexually
        /// suggestive content is also detected.
        /// </param>
        /// <param name='details'>
        /// A string indicating which domain-specific details to return.
        /// Multiple values should be comma-separated. Valid visual feature
        /// types include:Celebrities - identifies celebrities if detected in
        /// the image.
        /// </param>
        /// <param name='language'>
        /// A string indicating which language to return. The service will
        /// return recognition results in specified language. If this parameter
        /// is not specified, the default value is
        /// &amp;quot;en&amp;quot;.Supported languages:en - English, Default.zh
        /// - Simplified Chinese. Possible values include: 'en', 'zh'
        /// </param>
        /// <param name='customHeaders'>
        /// The headers that will be added to request.
        /// </param>
        /// <param name='cancellationToken'>
        /// The cancellation token.
        /// </param>
        Task<HttpOperationResponse<ImageAnalysis>> AnalyzeImageWithHttpMessagesAsync(string url, IList<VisualFeatureTypes> visualFeatures = default(IList<VisualFeatureTypes>), IList<Details> details = default(IList<Details>), Language1 language = default(Language1), Dictionary<string, List<string>> customHeaders = null, CancellationToken cancellationToken = default(CancellationToken));

        /// <summary>
        /// This operation generates a thumbnail image with the user-specified
        /// width and height. By default, the service analyzes the image,
        /// identifies the region of interest (ROI), and generates smart
        /// cropping coordinates based on the ROI. Smart cropping helps when
        /// you specify an aspect ratio that differs from that of the input
        /// image. A successful response contains the thumbnail image binary.
        /// If the request failed, the response contains an error code and a
        /// message to help determine what went wrong.
        /// </summary>
        /// <param name='width'>
        /// Width of the thumbnail. It must be between 1 and 1024. Recommended
        /// minimum of 50.
        /// </param>
        /// <param name='height'>
        /// Height of the thumbnail. It must be between 1 and 1024. Recommended
        /// minimum of 50.
        /// </param>
        /// <param name='url'>
        /// </param>
        /// <param name='smartCropping'>
        /// Boolean flag for enabling smart cropping.
        /// </param>
        /// <param name='customHeaders'>
        /// The headers that will be added to request.
        /// </param>
        /// <param name='cancellationToken'>
        /// The cancellation token.
        /// </param>
        Task<HttpOperationResponse<Stream>> GenerateThumbnailWithHttpMessagesAsync(int width, int height, string url, bool? smartCropping = false, Dictionary<string, List<string>> customHeaders = null, CancellationToken cancellationToken = default(CancellationToken));

        /// <summary>
        /// Optical Character Recognition (OCR) detects printed text in an
        /// image and extracts the recognized characters into a machine-usable
        /// character stream.   Upon success, the OCR results will be returned.
        /// Upon failure, the error code together with an error message will be
        /// returned. The error code can be one of InvalidImageUrl,
        /// InvalidImageFormat, InvalidImageSize, NotSupportedImage,
        /// NotSupportedLanguage, or InternalServerError.
        /// </summary>
        /// <param name='detectOrientation'>
        /// Whether detect the text orientation in the image. With
        /// detectOrientation=true the OCR service tries to detect the image
        /// orientation and correct it before further processing (e.g. if it's
        /// upside-down).
        /// </param>
        /// <param name='url'>
        /// </param>
        /// <param name='language'>
        /// The BCP-47 language code of the text to be detected in the image.
        /// The default value is 'unk'. Possible values include: 'unk',
        /// 'zh-Hans', 'zh-Hant', 'cs', 'da', 'nl', 'en', 'fi', 'fr', 'de',
        /// 'el', 'hu', 'it', 'ja', 'ko', 'nb', 'pl', 'pt', 'ru', 'es', 'sv',
        /// 'tr', 'ar', 'ro', 'sr-Cyrl', 'sr-Latn', 'sk'
        /// </param>
        /// <param name='customHeaders'>
        /// The headers that will be added to request.
        /// </param>
        /// <param name='cancellationToken'>
        /// The cancellation token.
        /// </param>
        Task<HttpOperationResponse<OcrResult>> RecognizePrintedTextWithHttpMessagesAsync(bool detectOrientation, string url, OcrLanguages language = default(OcrLanguages), Dictionary<string, List<string>> customHeaders = null, CancellationToken cancellationToken = default(CancellationToken));

        /// <summary>
        /// This operation generates a description of an image in human
        /// readable language with complete sentences.  The description is
        /// based on a collection of content tags, which are also returned by
        /// the operation. More than one description can be generated for each
        /// image.  Descriptions are ordered by their confidence score. All
        /// descriptions are in English. Two input methods are supported -- (1)
        /// Uploading an image or (2) specifying an image URL.A successful
        /// response will be returned in JSON.  If the request failed, the
        /// response will contain an error code and a message to help
        /// understand what went wrong.
        /// </summary>
        /// <param name='url'>
        /// </param>
        /// <param name='maxCandidates'>
        /// Maximum number of candidate descriptions to be returned.  The
        /// default is 1.
        /// </param>
        /// <param name='customHeaders'>
        /// The headers that will be added to request.
        /// </param>
        /// <param name='cancellationToken'>
        /// The cancellation token.
        /// </param>
        Task<HttpOperationResponse<ImageDescription>> DescribeImageWithHttpMessagesAsync(string url, string maxCandidates = "1", Dictionary<string, List<string>> customHeaders = null, CancellationToken cancellationToken = default(CancellationToken));

        /// <summary>
        /// This operation generates a list of words, or tags, that are
        /// relevant to the content of the supplied image. The Computer Vision
        /// API can return tags based on objects, living beings, scenery or
        /// actions found in images. Unlike categories, tags are not organized
        /// according to a hierarchical classification system, but correspond
        /// to image content. Tags may contain hints to avoid ambiguity or
        /// provide context, for example the tag “cello” may be accompanied by
        /// the hint “musical instrument”. All tags are in English.
        /// </summary>
        /// <param name='url'>
        /// </param>
        /// <param name='customHeaders'>
        /// The headers that will be added to request.
        /// </param>
        /// <param name='cancellationToken'>
        /// The cancellation token.
        /// </param>
        Task<HttpOperationResponse<TagResult>> TagImageWithHttpMessagesAsync(string url, Dictionary<string, List<string>> customHeaders = null, CancellationToken cancellationToken = default(CancellationToken));

        /// <summary>
        /// This operation recognizes content within an image by applying a
        /// domain-specific model.  The list of domain-specific models that are
        /// supported by the Computer Vision API can be retrieved using the
        /// /models GET request.  Currently, the API only provides a single
        /// domain-specific model: celebrities. Two input methods are supported
        /// -- (1) Uploading an image or (2) specifying an image URL. A
        /// successful response will be returned in JSON.  If the request
        /// failed, the response will contain an error code and a message to
        /// help understand what went wrong.
        /// </summary>
        /// <param name='model'>
        /// The domain-specific content to recognize. Possible values include:
        /// 'Celebrities', 'Landmarks'
        /// </param>
        /// <param name='url'>
        /// </param>
        /// <param name='customHeaders'>
        /// The headers that will be added to request.
        /// </param>
        /// <param name='cancellationToken'>
        /// The cancellation token.
        /// </param>
        Task<HttpOperationResponse<DomainModelResults>> AnalyzeImageByDomainWithHttpMessagesAsync(DomainModels model, string url, Dictionary<string, List<string>> customHeaders = null, CancellationToken cancellationToken = default(CancellationToken));

        /// <summary>
        /// Recognize Text operation. When you use the Recognize Text
        /// interface, the response contains a field called
        /// “Operation-Location”. The “Operation-Location” field contains the
        /// URL that you must use for your Get Handwritten Text Operation
        /// Result operation.
        /// </summary>
        /// <param name='url'>
        /// </param>
        /// <param name='detectHandwriting'>
        /// If “true” is specified, handwriting recognition is performed. If
        /// this parameter is set to “false” or is not specified, printed text
        /// recognition is performed.
        /// </param>
        /// <param name='customHeaders'>
        /// The headers that will be added to request.
        /// </param>
        /// <param name='cancellationToken'>
        /// The cancellation token.
        /// </param>
        Task<HttpOperationHeaderResponse<RecognizeTextHeaders>> RecognizeTextWithHttpMessagesAsync(string url, bool? detectHandwriting = false, Dictionary<string, List<string>> customHeaders = null, CancellationToken cancellationToken = default(CancellationToken));

        /// <summary>
        /// This interface is used for getting text operation result. The URL
        /// to this interface should be retrieved from 'Operation-Location'
        /// field returned from Recognize Text interface.
        /// </summary>
        /// <param name='operationId'>
        /// Id of the text operation returned in the response of the 'Recognize
        /// Handwritten Text'
        /// </param>
        /// <param name='customHeaders'>
        /// The headers that will be added to request.
        /// </param>
        /// <param name='cancellationToken'>
        /// The cancellation token.
        /// </param>
        Task<HttpOperationResponse<TextOperationResult>> GetTextOperationResultWithHttpMessagesAsync(string operationId, Dictionary<string, List<string>> customHeaders = null, CancellationToken cancellationToken = default(CancellationToken));

        /// <summary>
        /// This operation extracts a rich set of visual features based on the
        /// image content.
        /// </summary>
        /// <param name='image'>
        /// An image stream.
        /// </param>
        /// <param name='visualFeatures'>
        /// A string indicating what visual feature types to return. Multiple
        /// values should be comma-separated. Valid visual feature types
        /// include:Categories - categorizes image content according to a
        /// taxonomy defined in documentation. Tags - tags the image with a
        /// detailed list of words related to the image content. Description -
        /// describes the image content with a complete English sentence. Faces
        /// - detects if faces are present. If present, generate coordinates,
        /// gender and age. ImageType - detects if image is clipart or a line
        /// drawing. Color - determines the accent color, dominant color, and
        /// whether an image is black&amp;white.Adult - detects if the image is
        /// pornographic in nature (depicts nudity or a sex act).  Sexually
        /// suggestive content is also detected.
        /// </param>
        /// <param name='details'>
        /// A string indicating which domain-specific details to return.
        /// Multiple values should be comma-separated. Valid visual feature
        /// types include:Celebrities - identifies celebrities if detected in
        /// the image. Possible values include: 'Celebrities', 'Landmarks'
        /// </param>
        /// <param name='language'>
        /// A string indicating which language to return. The service will
        /// return recognition results in specified language. If this parameter
        /// is not specified, the default value is
        /// &amp;quot;en&amp;quot;.Supported languages:en - English, Default.zh
        /// - Simplified Chinese. Possible values include: 'en', 'zh'
        /// </param>
        /// <param name='customHeaders'>
        /// The headers that will be added to request.
        /// </param>
        /// <param name='cancellationToken'>
        /// The cancellation token.
        /// </param>
        Task<HttpOperationResponse<ImageAnalysis>> AnalyzeImageInStreamWithHttpMessagesAsync(Stream image, IList<VisualFeatureTypes> visualFeatures = default(IList<VisualFeatureTypes>), string details = default(string), string language = default(string), Dictionary<string, List<string>> customHeaders = null, CancellationToken cancellationToken = default(CancellationToken));

        /// <summary>
        /// This operation generates a thumbnail image with the user-specified
        /// width and height. By default, the service analyzes the image,
        /// identifies the region of interest (ROI), and generates smart
        /// cropping coordinates based on the ROI. Smart cropping helps when
        /// you specify an aspect ratio that differs from that of the input
        /// image. A successful response contains the thumbnail image binary.
        /// If the request failed, the response contains an error code and a
        /// message to help determine what went wrong.
        /// </summary>
        /// <param name='width'>
        /// Width of the thumbnail. It must be between 1 and 1024. Recommended
        /// minimum of 50.
        /// </param>
        /// <param name='height'>
        /// Height of the thumbnail. It must be between 1 and 1024. Recommended
        /// minimum of 50.
        /// </param>
        /// <param name='image'>
        /// An image stream.
        /// </param>
        /// <param name='smartCropping'>
        /// Boolean flag for enabling smart cropping.
        /// </param>
        /// <param name='customHeaders'>
        /// The headers that will be added to request.
        /// </param>
        /// <param name='cancellationToken'>
        /// The cancellation token.
        /// </param>
        Task<HttpOperationResponse<Stream>> GenerateThumbnailInStreamWithHttpMessagesAsync(int width, int height, Stream image, bool? smartCropping = false, Dictionary<string, List<string>> customHeaders = null, CancellationToken cancellationToken = default(CancellationToken));

        /// <summary>
        /// Optical Character Recognition (OCR) detects printed text in an
        /// image and extracts the recognized characters into a machine-usable
        /// character stream.   Upon success, the OCR results will be returned.
        /// Upon failure, the error code together with an error message will be
        /// returned. The error code can be one of InvalidImageUrl,
        /// InvalidImageFormat, InvalidImageSize, NotSupportedImage,
        /// NotSupportedLanguage, or InternalServerError.
        /// </summary>
        /// <param name='detectOrientation'>
        /// Whether detect the text orientation in the image. With
        /// detectOrientation=true the OCR service tries to detect the image
        /// orientation and correct it before further processing (e.g. if it's
        /// upside-down).
        /// </param>
        /// <param name='image'>
        /// An image stream.
        /// </param>
        /// <param name='language'>
        /// The BCP-47 language code of the text to be detected in the image.
        /// The default value is 'unk'. Possible values include: 'unk',
        /// 'zh-Hans', 'zh-Hant', 'cs', 'da', 'nl', 'en', 'fi', 'fr', 'de',
        /// 'el', 'hu', 'it', 'ja', 'ko', 'nb', 'pl', 'pt', 'ru', 'es', 'sv',
        /// 'tr', 'ar', 'ro', 'sr-Cyrl', 'sr-Latn', 'sk'
        /// </param>
        /// <param name='customHeaders'>
        /// The headers that will be added to request.
        /// </param>
        /// <param name='cancellationToken'>
        /// The cancellation token.
        /// </param>
        Task<HttpOperationResponse<OcrResult>> RecognizePrintedTextInStreamWithHttpMessagesAsync(bool detectOrientation, Stream image, OcrLanguages language = default(OcrLanguages), Dictionary<string, List<string>> customHeaders = null, CancellationToken cancellationToken = default(CancellationToken));

        /// <summary>
        /// This operation generates a description of an image in human
        /// readable language with complete sentences.  The description is
        /// based on a collection of content tags, which are also returned by
        /// the operation. More than one description can be generated for each
        /// image.  Descriptions are ordered by their confidence score. All
        /// descriptions are in English. Two input methods are supported -- (1)
        /// Uploading an image or (2) specifying an image URL.A successful
        /// response will be returned in JSON.  If the request failed, the
        /// response will contain an error code and a message to help
        /// understand what went wrong.
        /// </summary>
        /// <param name='image'>
        /// An image stream.
        /// </param>
        /// <param name='maxCandidates'>
        /// Maximum number of candidate descriptions to be returned.  The
        /// default is 1.
        /// </param>
        /// <param name='customHeaders'>
        /// The headers that will be added to request.
        /// </param>
        /// <param name='cancellationToken'>
        /// The cancellation token.
        /// </param>
        Task<HttpOperationResponse<ImageDescription>> DescribeImageInStreamWithHttpMessagesAsync(Stream image, string maxCandidates = "1", Dictionary<string, List<string>> customHeaders = null, CancellationToken cancellationToken = default(CancellationToken));

        /// <summary>
        /// This operation generates a list of words, or tags, that are
        /// relevant to the content of the supplied image. The Computer Vision
        /// API can return tags based on objects, living beings, scenery or
        /// actions found in images. Unlike categories, tags are not organized
        /// according to a hierarchical classification system, but correspond
        /// to image content. Tags may contain hints to avoid ambiguity or
        /// provide context, for example the tag “cello” may be accompanied by
        /// the hint “musical instrument”. All tags are in English.
        /// </summary>
        /// <param name='image'>
        /// An image stream.
        /// </param>
        /// <param name='customHeaders'>
        /// The headers that will be added to request.
        /// </param>
        /// <param name='cancellationToken'>
        /// The cancellation token.
        /// </param>
        Task<HttpOperationResponse<TagResult>> TagImageInStreamWithHttpMessagesAsync(Stream image, Dictionary<string, List<string>> customHeaders = null, CancellationToken cancellationToken = default(CancellationToken));

        /// <summary>
        /// This operation recognizes content within an image by applying a
        /// domain-specific model.  The list of domain-specific models that are
        /// supported by the Computer Vision API can be retrieved using the
        /// /models GET request.  Currently, the API only provides a single
        /// domain-specific model: celebrities. Two input methods are supported
        /// -- (1) Uploading an image or (2) specifying an image URL. A
        /// successful response will be returned in JSON.  If the request
        /// failed, the response will contain an error code and a message to
        /// help understand what went wrong.
        /// </summary>
        /// <param name='model'>
        /// The domain-specific content to recognize.
        /// </param>
        /// <param name='image'>
        /// An image stream.
        /// </param>
        /// <param name='customHeaders'>
        /// The headers that will be added to request.
        /// </param>
        /// <param name='cancellationToken'>
        /// The cancellation token.
        /// </param>
        Task<HttpOperationResponse<DomainModelResults>> AnalyzeImageByDomainInStreamWithHttpMessagesAsync(string model, Stream image, Dictionary<string, List<string>> customHeaders = null, CancellationToken cancellationToken = default(CancellationToken));

        /// <summary>
        /// Recognize Text operation. When you use the Recognize Text
        /// interface, the response contains a field called
        /// “Operation-Location”. The “Operation-Location” field contains the
        /// URL that you must use for your Get Handwritten Text Operation
        /// Result operation.
        /// </summary>
        /// <param name='image'>
        /// An image stream.
        /// </param>
        /// <param name='detectHandwriting'>
        /// If “true” is specified, handwriting recognition is performed. If
        /// this parameter is set to “false” or is not specified, printed text
        /// recognition is performed.
        /// </param>
        /// <param name='customHeaders'>
        /// The headers that will be added to request.
        /// </param>
        /// <param name='cancellationToken'>
        /// The cancellation token.
        /// </param>
        Task<HttpOperationHeaderResponse<RecognizeTextInStreamHeaders>> RecognizeTextInStreamWithHttpMessagesAsync(Stream image, bool? detectHandwriting = false, Dictionary<string, List<string>> customHeaders = null, CancellationToken cancellationToken = default(CancellationToken));

    }
}

// <auto-generated>
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License. See License.txt in the project root for
// license information.
//
// Code generated by Microsoft (R) AutoRest Code Generator.
// Changes may cause incorrect behavior and will be lost if the code is
// regenerated.
// </auto-generated>

namespace Microsoft.Azure.Search.Models
{
    using Microsoft.Rest;
    using Newtonsoft.Json;
    using System.Collections;
    using System.Collections.Generic;
    using System.Linq;

    /// <summary>
    /// Tokenizes the input into n-grams of the given size(s). This tokenizer
    /// is implemented using Apache Lucene.
    /// <see
    /// href="http://lucene.apache.org/core/4_10_3/analyzers-common/org/apache/lucene/analysis/ngram/NGramTokenizer.html"
    /// />
    /// </summary>
    [Newtonsoft.Json.JsonObject("#Microsoft.Azure.Search.NGramTokenizer")]
    public partial class NGramTokenizer : Tokenizer
    {
        /// <summary>
        /// Initializes a new instance of the NGramTokenizer class.
        /// </summary>
        public NGramTokenizer()
        {
            CustomInit();
        }

        /// <summary>
        /// Initializes a new instance of the NGramTokenizer class.
        /// </summary>
        /// <param name="name">The name of the tokenizer. It must only contain
        /// letters, digits, spaces, dashes or underscores, can only start and
        /// end with alphanumeric characters, and is limited to 128
        /// characters.</param>
        /// <param name="minGram">The minimum n-gram length. Default is 1.
        /// Maximum is 300. Must be less than the value of maxGram.</param>
        /// <param name="maxGram">The maximum n-gram length. Default is 2.
        /// Maximum is 300.</param>
        /// <param name="tokenChars">Character classes to keep in the
        /// tokens.</param>
        public NGramTokenizer(string name, int? minGram = default(int?), int? maxGram = default(int?), IList<TokenCharacterKind> tokenChars = default(IList<TokenCharacterKind>))
            : base(name)
        {
            MinGram = minGram;
            MaxGram = maxGram;
            TokenChars = tokenChars;
            CustomInit();
        }

        /// <summary>
        /// An initialization method that performs custom operations like setting defaults
        /// </summary>
        partial void CustomInit();

        /// <summary>
        /// Gets or sets the minimum n-gram length. Default is 1. Maximum is
        /// 300. Must be less than the value of maxGram.
        /// </summary>
        [JsonProperty(PropertyName = "minGram")]
        public int? MinGram { get; set; }

        /// <summary>
        /// Gets or sets the maximum n-gram length. Default is 2. Maximum is
        /// 300.
        /// </summary>
        [JsonProperty(PropertyName = "maxGram")]
        public int? MaxGram { get; set; }

        /// <summary>
        /// Gets or sets character classes to keep in the tokens.
        /// </summary>
        [JsonProperty(PropertyName = "tokenChars")]
        public IList<TokenCharacterKind> TokenChars { get; set; }

        /// <summary>
        /// Validate the object.
        /// </summary>
        /// <exception cref="ValidationException">
        /// Thrown if validation fails
        /// </exception>
        public override void Validate()
        {
            base.Validate();
            if (MinGram > 300)
            {
                throw new ValidationException(ValidationRules.InclusiveMaximum, "MinGram", 300);
            }
            if (MaxGram > 300)
            {
                throw new ValidationException(ValidationRules.InclusiveMaximum, "MaxGram", 300);
            }
        }
    }
}
